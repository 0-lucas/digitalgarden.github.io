# What is it?
*Statistical modelling* is the use of [[Mathematics|mathematical]] models and [[Statistics|statistical]] concepts to **analyze and understand complex data sets**, making informed decisions and predictions.
___
# Statistical models

A *statistical model* is a set of [[Statistics|statistical]] assumptions concerning the generation of the data. The *statistical model* represents the **data-generating process in itself**, with **added intrinsic random errors** that could not be predicted.

For example, if a *statistical model* tries to predict the generation of data using a function, it needs to assume that there **may be some variables** that cannot be **controlled or let alone be observed**. This generate random errors, represented by the letter $\epsilon$.

Because of this effect, every **model should account for errors**. For example, given a function $y = f(x_1...x_n)$ one could express it accounting for errors just by **adding the errors as part of the function**, $y = f(x_1...x_n) \pm \epsilon$.

>[!tip] Models vs Randomness
>In most cases, the errors of a *statistical model* could be simplified to the **randomness of the problem**, which in itself, it's **impossible to model**. One might be able to model **how random the problem is**, but **not the randomness itself**.

