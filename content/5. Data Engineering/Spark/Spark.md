# What is it?

*Apache Spark* is a *cluster computing platform* widely used in [[Data Engineering]], designed to be **fast** and **general-purpose**. It extends other [[Distributed Computing]] frameworks like [[Hadoop]], and the [[MapReduce]] model to **efficiently handle** all needed workload.

![[spar.png]]

The *Spark* engine is **designed to be flexible enough** to cover wide ranges of workloads, including *batch processing*, *iterative [[Algorithms|algorithms]]*, *queries* and *stream processing*. *Spark* also offers [[API|APIs]] in [[Python]], [[Java]], [[Scala]], and *SQL*.
___
# Spark components