# What is it?

*Apache Hadoop* is a open-source software for reliable, [[Scaling|scalable]], [[Distributed Computing]], written in [[Java]]. It's mainly used in [[Data Engineering]] to **process large datasets** across **clusters of computers** using **simple programming models**, while [[Scaling|scaling]] from a single node to thousand of machines. After its development in 2006, by *Doug Cutting* and *Mike Cafarella*, it became a **standard** for [[Big Data]] analytics.
___
# The Hadoop ecosystem

*Hadoop* only really needs three components: 
- ##### [[MapReduce]]
- [[Hadoop Distributed File System|HDFS]]
- [[YARN]]


![[Pasted image 20241110105533.png]]