{"path":"Data Engineering/My Books/Linear Algebra Done Right.pdf","text":"Undergraduate Texts in Mathematics Linear Algebra Done Right Sheldon Axler Fourth Edition Undergraduate Texts in Mathematics Undergraduate Texts in Mathematics Series Editors Pamela Gorkin, Mathematics Department, Bucknell University, Lewisburg, PA, USA Jessica Sidman, Mathematics and Statistics, Amherst College, Amherst, MA, USA Colin Adams, Williams College, Williamstown, MA, USA Jayadev S. Athreya, University of Washington, Seattle, WA, USA Nathan Kaplan, University of California, Irvine, CA, USA Jill Pipher, Brown University, Providence, RI, USA Jeremy Tyson, University of Illinois at Urbana-Champaign, Urbana, IL, USA Undergraduate Texts in Mathematics are generally aimed at third- and fourth- year undergraduate mathematics students at North American universities. These texts strive to provide students and teachers with new perspectives and novel approaches. The books include motivation that guides the reader to an appreciation of interrelations among different aspects of the subject. They feature examples that illustrate key concepts as well as exercises that strengthen understanding. Advisory Board Sheldon Axler Linear Algebra Done Right Fourth Edition Sheldon Axler San Francisco, CA, USA ISSN 0172-6056 ISSN 2197-5604 (electronic) ISBN 978-3-031-41025-3 ISBN 978-3-031-41026-0 (eBook) https://doi.org/10.1007/978-3-031-41026-0 Mathematics Subject Classification (2020): 15-01, 15A03, 15A04, 15A15, 15A18, 15A21 Undergraduate Texts in Mathematics ¬© Sheldon Axler 1996, 1997, 2015, 2024. This book is an open access publication. Open Access This book is licensed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (http://creativecommons.org/licenses/by-nc/4.0/), which permits any noncom- mercial use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this book are included in the book‚Äôs Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the book‚Äôs Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. This work is subject to copyright. All commercial rights are reserved by the author(s), whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed. Regarding these commercial rights a non-exclusive license has been granted to the publisher. The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. The publisher, the authors, and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, expressed or implied, with respect to the material contained herein or for any errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. This Springer imprint is published by the registered company Springer Nature Switzerland AG. The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland. Paper in this product is recyclable. About the Author Sheldon Axler received his undergraduate degree from Princeton University, followed by a PhD in mathematics from the University of California at Berkeley. As a postdoctoral Moore Instructor at MIT, Axler received a university-wide teaching award. He was then an assistant professor, associate professor, and professor at Michigan State University, where he received the first J. Sutherland Frame Teaching Award and the Distinguished Faculty Award. Axler received the Lester R. Ford Award for expository writing from the Math- ematical Association of America in 1996, for a paper that eventually expanded into this book. In addition to publishing numerous research papers, he is the author of six mathematics textbooks, ranging from freshman to graduate level. Previous editions of this book have been adopted as a textbook at over 375 universities and colleges and have been translated into three languages. Axler has served as Editor-in-Chief of the Mathematical Intelligencer and Associate Editor of the American Mathematical Monthly. He has been a member of the Council of the American Mathematical Society and of the Board of Trustees of the Mathematical Sciences Research Institute. He has also served on the editorial board of Springer‚Äôs series Undergraduate Texts in Mathematics, Graduate Texts in Mathematics, Universitext, and Springer Monographs in Mathematics. Axler is a Fellow of the American Mathematical Society and has been a recipient of numerous grants from the National Science Foundation. Axler joined San Francisco State University as chair of the Mathematics Department in 1997. He served as dean of the College of Science & Engineering from 2002 to 2015, when he returned to a regular faculty appointment as a professor in the Mathematics Department.CarrieHeeter,BishnuSarangi The author and his cat Moon. Cover equation: Formula for the ùëõ th Fibonacci number. Exercise 21 in Section 5D uses linear algebra to derive this formula. v Contents About the Author v Preface for Students xii Preface for Instructors xiii Acknowledgments xvii Chapter 1 Vector Spaces 1 1A ùêëùëõ and ùêÇ ùëõ 2 Complex Numbers 2 Lists 5 ùêÖùëõ 6 Digression on Fields 10 Exercises 1A 10 1B Definition of Vector Space 12 Exercises 1B 16 1C Subspaces 18 Sums of Subspaces 19 Direct Sums 21 Exercises 1C 24 Chapter 2 Finite-Dimensional Vector Spaces 27 2A Span and Linear Independence 28 Linear Combinations and Span 28 Linear Independence 31 Exercises 2A 37 vi Contents vii 2B Bases 39 Exercises 2B 42 2C Dimension 44 Exercises 2C 48 Chapter 3 Linear Maps 51 3A Vector Space of Linear Maps 52 Definition and Examples of Linear Maps 52 Algebraic Operations on ‚Ñí(ùëâ, ùëä) 55 Exercises 3A 57 3B Null Spaces and Ranges 59 Null Space and Injectivity 59 Range and Surjectivity 61 Fundamental Theorem of Linear Maps 62 Exercises 3B 66 3C Matrices 69 Representing a Linear Map by a Matrix 69 Addition and Scalar Multiplication of Matrices 71 Matrix Multiplication 72 Column‚ÄìRow Factorization and Rank of a Matrix 77 Exercises 3C 79 3D Invertibility and Isomorphisms 82 Invertible Linear Maps 82 Isomorphic Vector Spaces 86 Linear Maps Thought of as Matrix Multiplication 88 Change of Basis 90 Exercises 3D 93 3E Products and Quotients of Vector Spaces 96 Products of Vector Spaces 96 Quotient Spaces 98 Exercises 3E 103 3F Duality 105 Dual Space and Dual Map 105 Null Space and Range of Dual of Linear Map 109 viii Contents Matrix of Dual of Linear Map 113 Exercises 3F 115 Chapter 4 Polynomials 119 Zeros of Polynomials 122 Division Algorithm for Polynomials 123 Factorization of Polynomials over ùêÇ 124 Factorization of Polynomials over ùêë 127 Exercises 4 129 Chapter 5 Eigenvalues and Eigenvectors 132 5A Invariant Subspaces 133 Eigenvalues 133 Polynomials Applied to Operators 137 Exercises 5A 139 5B The Minimal Polynomial 143 Existence of Eigenvalues on Complex Vector Spaces 143 Eigenvalues and the Minimal Polynomial 144 Eigenvalues on Odd-Dimensional Real Vector Spaces 149 Exercises 5B 150 5C Upper-Triangular Matrices 154 Exercises 5C 160 5D Diagonalizable Operators 163 Diagonal Matrices 163 Conditions for Diagonalizability 165 Gershgorin Disk Theorem 170 Exercises 5D 172 5E Commuting Operators 175 Exercises 5E 179 Chapter 6 Inner Product Spaces 181 6A Inner Products and Norms 182 Inner Products 182 Contents ix Norms 186 Exercises 6A 191 6B Orthonormal Bases 197 Orthonormal Lists and the Gram‚ÄìSchmidt Procedure 197 Linear Functionals on Inner Product Spaces 204 Exercises 6B 207 6C Orthogonal Complements and Minimization Problems 211 Orthogonal Complements 211 Minimization Problems 217 Pseudoinverse 220 Exercises 6C 224 Chapter 7 Operators on Inner Product Spaces 227 7A Self-Adjoint and Normal Operators 228 Adjoints 228 Self-Adjoint Operators 233 Normal Operators 235 Exercises 7A 239 7B Spectral Theorem 243 Real Spectral Theorem 243 Complex Spectral Theorem 246 Exercises 7B 247 7C Positive Operators 251 Exercises 7C 255 7D Isometries, Unitary Operators, and Matrix Factorization 258 Isometries 258 Unitary Operators 260 QR Factorization 263 Cholesky Factorization 266 Exercises 7D 268 7E Singular Value Decomposition 270 Singular Values 270 SVD for Linear Maps and for Matrices 273 Exercises 7E 278 x Contents 7F Consequences of Singular Value Decomposition 280 Norms of Linear Maps 280 Approximation by Linear Maps with Lower-Dimensional Range 283 Polar Decomposition 285 Operators Applied to Ellipsoids and Parallelepipeds 287 Volume via Singular Values 291 Properties of an Operator as Determined by Its Eigenvalues 293 Exercises 7F 294 Chapter 8 Operators on Complex Vector Spaces 297 8A Generalized Eigenvectors and Nilpotent Operators 298 Null Spaces of Powers of an Operator 298 Generalized Eigenvectors 300 Nilpotent Operators 303 Exercises 8A 306 8B Generalized Eigenspace Decomposition 308 Generalized Eigenspaces 308 Multiplicity of an Eigenvalue 310 Block Diagonal Matrices 314 Exercises 8B 316 8C Consequences of Generalized Eigenspace Decomposition 319 Square Roots of Operators 319 Jordan Form 321 Exercises 8C 324 8D Trace: A Connection Between Matrices and Operators 326 Exercises 8D 330 Chapter 9 Multilinear Algebra and Determinants 332 9A Bilinear Forms and Quadratic Forms 333 Bilinear Forms 333 Symmetric Bilinear Forms 337 Quadratic Forms 341 Exercises 9A 344 Contents xi 9B Alternating Multilinear Forms 346 Multilinear Forms 346 Alternating Multilinear Forms and Permutations 348 Exercises 9B 352 9C Determinants 354 Defining the Determinant 354 Properties of Determinants 357 Exercises 9C 367 9D Tensor Products 370 Tensor Product of Two Vector Spaces 370 Tensor Product of Inner Product Spaces 376 Tensor Product of Multiple Vector Spaces 378 Exercises 9D 380 Photo Credits 383 Symbol Index 384 Index 385 Colophon: Notes on Typesetting 390 Preface for Students You are probably about to begin your second exposure to linear algebra. Unlike your first brush with the subject, which probably emphasized Euclidean spaces and matrices, this encounter will focus on abstract vector spaces and linear maps. These terms will be defined later, so don‚Äôt worry if you do not know what they mean. This book starts from the beginning of the subject, assuming no knowledge of linear algebra. The key point is that you are about to immerse yourself in serious mathematics, with an emphasis on attaining a deep understanding of the definitions, theorems, and proofs. You cannot read mathematics the way you read a novel. If you zip through a page in less than an hour, you are probably going too fast. When you encounter the phrase ‚Äúas you should verify‚Äù, you should indeed do the verification, which will usually require some writing on your part. When steps are left out, you need to supply the missing pieces. You should ponder and internalize each definition. For each theorem, you should seek examples to show why each hypothesis is necessary. Discussions with other students should help. As a visual aid, definitions are in yellow boxes and theorems are in blue boxes (in color versions of the book). Each theorem has an infomal descriptive name. Please check the website below for additional information about the book, including a link to videos that are freely available to accompany the book. Your suggestions, comments, and corrections are most welcome. Best wishes for success and enjoyment in learning linear algebra! Sheldon Axler San Francisco State University website: https://linear.axler.net e-mail: linear@axler.net xii Preface for Instructors You are about to teach a course that will probably give students their second exposure to linear algebra. During their first brush with the subject, your students probably worked with Euclidean spaces and matrices. In contrast, this course will emphasize abstract vector spaces and linear maps. The title of this book deserves an explanation. Most linear algebra textbooks use determinants to prove that every linear operator on a finite-dimensional com- plex vector space has an eigenvalue. Determinants are difficult, nonintuitive, and often defined without motivation. To prove the theorem about existence of eigenvalues on complex vector spaces, most books must define determinants, prove that a linear operator is not invertible if and only if its determinant equals 0, and then define the characteristic polynomial. This tortuous (torturous?) path gives students little feeling for why eigenvalues exist. In contrast, the simple determinant-free proofs presented here (for example, see 5.19) offer more insight. Once determinants have been moved to the end of the book, a new route opens to the main goal of linear algebra‚Äîunderstanding the structure of linear operators. This book starts at the beginning of the subject, with no prerequisites other than the usual demand for suitable mathematical maturity. A few examples and exercises involve calculus concepts such as continuity, differentiation, and integration. You can easily skip those examples and exercises if your students have not had calculus. If your students have had calculus, then those examples and exercises can enrich their experience by showing connections between different parts of mathematics. Even if your students have already seen some of the material in the first few chapters, they may be unaccustomed to working exercises of the type presented here, most of which require an understanding of proofs. Here is a chapter-by-chapter summary of the highlights of the book: ‚Ä¢ Chapter 1: Vector spaces are defined in this chapter, and their basic properties are developed. ‚Ä¢ Chapter 2: Linear independence, span, basis, and dimension are defined in this chapter, which presents the basic theory of finite-dimensional vector spaces. ‚Ä¢ Chapter 3: This chapter introduces linear maps. The key result here is the fundamental theorem of linear maps: if ùëá is a linear map on ùëâ, then dim ùëâ = dim null ùëá + dim range ùëá. Quotient spaces and duality are topics in this chapter at a higher level of abstraction than most of the book; these topics can be skipped (except that duality is needed for tensor products in Section 9D). xiii xiv Preface for Instructors ‚Ä¢ Chapter 4: The part of the theory of polynomials that will be needed to un- derstand linear operators is presented in this chapter. This chapter contains no linear algebra. It can be covered quickly, especially if your students are already familiar with these results. ‚Ä¢ Chapter 5: The idea of studying a linear operator by restricting it to small sub- spaces leads to eigenvectors in the early part of this chapter. The highlight of this chapter is a simple proof that on complex vector spaces, eigenvalues always ex- ist. This result is then used to show that each linear operator on a complex vector space has an upper-triangular matrix with respect to some basis. The minimal polynomial plays an important role here and later in the book. For example, this chapter gives a characterization of the diagonalizable operators in terms of the minimal polynomial. Section 5E can be skipped if you want to save some time. ‚Ä¢ Chapter 6: Inner product spaces are defined in this chapter, and their basic properties are developed along with tools such as orthonormal bases and the Gram‚ÄìSchmidt procedure. This chapter also shows how orthogonal projections can be used to solve certain minimization problems. The pseudoinverse is then introduced as a useful tool when the inverse does not exist. The material on the pseudoinverse can be skipped if you want to save some time. ‚Ä¢ Chapter 7: The spectral theorem, which characterizes the linear operators for which there exists an orthonormal basis consisting of eigenvectors, is one of the highlights of this book. The work in earlier chapters pays off here with espe- cially simple proofs. This chapter also deals with positive operators, isometries, unitary operators, matrix factorizations, and especially the singular value de- composition, which leads to the polar decomposition and norms of linear maps. ‚Ä¢ Chapter 8: This chapter shows that for each operator on a complex vector space, there is a basis of the vector space consisting of generalized eigenvectors of the operator. Then the generalized eigenspace decomposition describes a linear operator on a complex vector space. The multiplicity of an eigenvalue is defined as the dimension of the corresponding generalized eigenspace. These tools are used to prove that every invertible linear operator on a complex vector space has a square root. Then the chapter gives a proof that every linear operator on a complex vector space can be put into Jordan form. The chapter concludes with an investigation of the trace of operators. ‚Ä¢ Chapter 9: This chapter begins by looking at bilinear forms and showing that the vector space of bilinear forms is the direct sum of the subspaces of symmetric bilinear forms and alternating bilinear forms. Then quadratic forms are diag- onalized. Moving to multilinear forms, the chapter shows that the subspace of alternating ùëõ-linear forms on an ùëõ-dimensional vector space has dimension one. This result leads to a clean basis-free definition of the determinant of an opera- tor. For complex vector spaces, the determinant turns out to equal the product of the eigenvalues, with each eigenvalue included in the product as many times as its multiplicity. The chapter concludes with an introduction to tensor products. Preface for Instructors xv This book usually develops linear algebra simultaneously for real and complex vector spaces by letting ùêÖ denote either the real or the complex numbers. If you and your students prefer to think of ùêÖ as an arbitrary field, then see the comments at the end of Section 1A. I prefer avoiding arbitrary fields at this level because they intro- duce extra abstraction without leading to any new linear algebra. Also, students are more comfortable thinking of polynomials as functions instead of the more formal objects needed for polynomials with coefficients in finite fields. Finally, even if the beginning part of the theory were developed with arbitrary fields, inner product spaces would push consideration back to just real and complex vector spaces. You probably cannot cover everything in this book in one semester. Going through all the material in the first seven or eight chapters during a one-semester course may require a rapid pace. If you must reach Chapter 9, then consider skipping the material on quotient spaces in Section 3E, skipping Section 3F on duality (unless you intend to cover tensor products in Section 9D), covering Chapter 4 on polynomials in a half hour, skipping Section 5E on commuting operators, and skipping the subsection in Section 6C on the pseudoinverse. A goal more important than teaching any particular theorem is to develop in students the ability to understand and manipulate the objects of linear algebra. Mathematics can be learned only by doing. Fortunately, linear algebra has many good homework exercises. When teaching this course, during each class I usually assign as homework several of the exercises, due the next class. Going over the homework might take up significant time in a typical class. Some of the exercises are intended to lead curious students into important topics beyond what might usually be included in a basic second course in linear algebra. The author‚Äôs top ten Listed below are the author‚Äôs ten favorite results in the book, in order of their appearance in the book. Students who leave your course with a good understanding of these crucial results will have an excellent foundation in linear algebra. ‚Ä¢ any two bases of a vector space have the same length (2.34) ‚Ä¢ fundamental theorem of linear maps (3.21) ‚Ä¢ existence of eigenvalues if ùêÖ = ùêÇ (5.19) ‚Ä¢ upper-triangular form always exists if ùêÖ = ùêÇ (5.47) ‚Ä¢ Cauchy‚ÄìSchwarz inequality (6.14) ‚Ä¢ Gram‚ÄìSchmidt procedure (6.32) ‚Ä¢ spectral theorem (7.29 and 7.31) ‚Ä¢ singular value decomposition (7.70) ‚Ä¢ generalized eigenspace decomposition theorem when ùêÖ = ùêÇ (8.22) ‚Ä¢ dimension of alternating ùëõ-linear forms on ùëâ is 1if dim ùëâ = ùëõ (9.37) xvi Preface for Instructors Major improvements and additions for the fourth edition ‚Ä¢ Over 250 new exercises and over 70 new examples. ‚Ä¢ Increasing use of the minimal polynomial to provide cleaner proofs of multiple results, including necessary and sufficient conditions for an operator to have an upper-triangular matrix with respect to some basis (see Section 5C), necessary and sufficient conditions for diagonalizability (see Section 5D), and the real spectral theorem (see Section 7B). ‚Ä¢ New section on commuting operators (see Section 5E). ‚Ä¢ New subsection on pseudoinverse (see Section 6C). ‚Ä¢ New subsections on QR factorization/Cholesky factorization (see Section 7D). ‚Ä¢ Singular value decomposition now done for linear maps from an inner product space to another (possibly different) inner product space, rather than only deal- ing with linear operators from an inner product space to itself (see Section 7E). ‚Ä¢ Polar decomposition now proved from singular value decomposition, rather than in the opposite order; this has led to cleaner proofs of both the singular value decomposition (see Section 7E) and the polar decomposition (see Section 7F). ‚Ä¢ New subsection on norms of linear maps on finite-dimensional inner prod- uct spaces, using the singular value decomposition to avoid even mentioning supremum in the definition of the norm of a linear map (see Section7F). ‚Ä¢ New subsection on approximation by linear maps with lower-dimensional range (see Section 7F). ‚Ä¢ New elementary proof of the important result that if ùëá is an operator on a finite- dimensional complex vector space ùëâ, then there exists a basis of ùëâ consisting of generalized eigenvectors of ùëá (see 8.9). ‚Ä¢ New Chapter 9 on multilinear algebra, including bilinear forms, quadratic forms, multilinear forms, and tensor products. Determinants now are defined using a basis-free approach via alternating multilinear forms. ‚Ä¢ New formatting to improve the student-friendly appearance of the book. For example, the definition and result boxes now have rounded corners instead of right-angle corners, for a gentler look. The main font size has been reduced from 11 point to 10.5 point. Please check the website below for additional links and information about the book. Your suggestions, comments, and corrections are most welcome. Best wishes for teaching a successful linear algebra class! Contact the author, or Springer if the author is not available, for permission for translations or other commercial reuse of the contents of this book. Sheldon Axler San Francisco State University website: https://linear.axler.net e-mail: linear@axler.net Acknowledgments I owe a huge intellectual debt to all the mathematicians who created linear algebra over the past two centuries. The results in this book belong to the common heritage of mathematics. A special case of a theorem may first have been proved long ago, then sharpened and improved by many mathematicians in different time periods. Bestowing proper credit on all contributors would be a difficult task that I have not undertaken. In no case should the reader assume that any result presented here represents my original contribution. Many people helped make this a better book. The three previous editions of this book were used as a textbook at over 375 universities and colleges around the world. I received thousands of suggestions and comments from faculty and students who used the book. Many of those suggestions led to improvements in this edition. The manuscript for this fourth edition was class tested at 30 universities. I am extremely grateful for the useful feedback that I received from faculty and students during this class testing. The long list of people who should be thanked for their suggestions would fill up many pages. Lists are boring to read. Thus to represent all contributors to this edition, I will mention only Noel Hinton, a graduate student at Australian National University, who sent me more suggestions and corrections for this fourth edition than anyone else. To everyone who contributed suggestions, let me say how truly grateful I am to all of you. Many many thanks! I thank Springer for providing me with help when I needed it and for allowing me the freedom to make the final decisions about the content and appearance of this book. Special thanks to the two terrific mathematics editors at Springer who worked with me on this project‚ÄîLoretta Bartolini during the first half of my work on the fourth edition, and Elizabeth Loew during the second half of my work on the fourth edition. I am deeply indebted to David Kramer, who did a magnificent job of copyediting and prevented me from making many mistakes. Extra special thanks to my fantastic partner Carrie Heeter. Her understanding and encouragement enabled me to work intensely on this new edition. Our won- derful cat Moon, whose picture appears on the About the Author page, provided sweet breaks throughout the writing process. Moon died suddenly due to a blood clot as this book was being finished. We are grateful for five precious years with him. Sheldon Axler xvii Chapter 1 Vector Spaces Linear algebra is the study of linear maps on finite-dimensional vector spaces. Eventually we will learn what all these terms mean. In this chapter we will define vector spaces and discuss their elementary properties. In linear algebra, better theorems and more insight emerge if complex numbers are investigated along with real numbers. Thus we will begin by introducing the complex numbers and their basic properties. We will generalize the examples of a plane and of ordinary space to ùêëùëõ and ùêÇ ùëõ, which we then will generalize to the notion of a vector space. As we will see, a vector space is a set with operations of addition and scalar multiplication that satisfy natural algebraic properties. Then our next topic will be subspaces, which play a role for vector spaces analogous to the role played by subsets for sets. Finally, we will look at sums of subspaces (analogous to unions of subsets) and direct sums of subspaces (analogous to unions of disjoint sets).PierreLouisDumesnil,NilsForsberg Ren√© Descartes explaining his work to Queen Christina of Sweden. Vector spaces are a generalization of the description of a plane using two coordinates, as published by Descartes in 1637. 1 ¬© Sheldon Axler 2024 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0_1 2 Chapter 1 Vector Spaces 1A ùêëùëõ and ùêÇ ùëõ Complex Numbers You should already be familiar with basic properties of the set ùêë of real numbers. Complex numbers were invented so that we can take square roots of negative numbers. The idea is to assume we have a square root of ‚àí1, denoted by ùëñ, that obeys the usual rules of arithmetic. Here are the formal definitions. 1.1 definition: complex numbers, ùêÇ ‚Ä¢ A complex number is an ordered pair (ùëé, ùëè), where ùëé, ùëè ‚àà ùêë, but we will write this as ùëé + ùëèùëñ. ‚Ä¢ The set of all complex numbers is denoted by ùêÇ: ùêÇ = {ùëé + ùëèùëñ ‚à∂ ùëé, ùëè ‚àà ùêë}. ‚Ä¢ Addition and multiplication on ùêÇ are defined by (ùëé + ùëèùëñ) + (ùëê + ùëëùëñ) = (ùëé + ùëê) + (ùëè + ùëë)ùëñ, (ùëé + ùëèùëñ)(ùëê + ùëëùëñ) = (ùëéùëê ‚àí ùëèùëë) + (ùëéùëë + ùëèùëê)ùëñ; here ùëé, ùëè, ùëê, ùëë ‚àà ùêë. If ùëé ‚àà ùêë, we identify ùëé + 0ùëñwith the real number ùëé. Thus we think of ùêë as a subset of ùêÇ. We usually write 0+ ùëèùëñ as just ùëèùëñ, and we usually write 0+ 1ùëñas just ùëñ. The symbol ùëñ was first used to denote ‚àö‚àí1by Leonhard Euler in 1777. To motivate the definition of complex multiplication given above, pretend that we knew that ùëñ2 = ‚àí1and then use the usual rules of arithmetic to derive the formula above for the product of two complex numbers. Then use that formula to verify that we indeed have ùëñ2 = ‚àí1. Do not memorize the formula for the product of two complex numbers‚Äîyou can always rederive it by recalling that ùëñ2 = ‚àí1and then using the usual rules of arithmetic (as given by 1.3). The next example illustrates this procedure. 1.2 example: complex arithmetic The product (2+ 3ùëñ)(4+ 5ùëñ)can be evaluated by applying the distributive and commutative properties from 1.3: (2+ 3ùëñ)(4+ 5ùëñ) = 2 ‚ãÖ (4+ 5ùëñ)+ (3ùëñ)(4+ 5ùëñ) = 2 ‚ãÖ 4+ 2 ‚ãÖ 5ùëñ+ 3ùëñ ‚ãÖ 4+ (3ùëñ)(5ùëñ) = 8+ 10ùëñ+ 12ùëñ ‚àí 15 = ‚àí7+ 22ùëñ. Section 1A ùêëùëõ and ùêÇ ùëõ 3 Our first result states that complex addition and complex multiplication have the familiar properties that we expect. 1.3 properties of complex arithmetic commutativity ùõº + ùõΩ = ùõΩ + ùõº and ùõºùõΩ = ùõΩùõº for all ùõº, ùõΩ ‚àà ùêÇ. associativity (ùõº + ùõΩ) + ùúÜ = ùõº + (ùõΩ + ùúÜ) and (ùõºùõΩ)ùúÜ = ùõº(ùõΩùúÜ) for all ùõº, ùõΩ, ùúÜ ‚àà ùêÇ. identities ùúÜ + 0 = ùúÜand ùúÜ1 = ùúÜfor all ùúÜ ‚àà ùêÇ. additive inverse For every ùõº ‚àà ùêÇ, there exists a unique ùõΩ ‚àà ùêÇ such that ùõº + ùõΩ = 0. multiplicative inverse For every ùõº ‚àà ùêÇ with ùõº ‚â† 0, there exists a unique ùõΩ ‚àà ùêÇ such that ùõºùõΩ = 1. distributive property ùúÜ(ùõº + ùõΩ) = ùúÜùõº + ùúÜùõΩ for all ùúÜ, ùõº, ùõΩ ‚àà ùêÇ. The properties above are proved using the familiar properties of real numbers and the definitions of complex addition and multiplication. The next example shows how commutativity of complex multiplication is proved. Proofs of the other properties above are left as exercises. 1.4 example: commutativity of complex multiplication To show that ùõºùõΩ = ùõΩùõº for all ùõº, ùõΩ ‚àà ùêÇ, suppose ùõº = ùëé + ùëèùëñ and ùõΩ = ùëê + ùëëùëñ, where ùëé, ùëè, ùëê, ùëë ‚àà ùêë. Then the definition of multiplication of complex numbers shows that ùõºùõΩ = (ùëé + ùëèùëñ)(ùëê + ùëëùëñ) = (ùëéùëê ‚àí ùëèùëë) + (ùëéùëë + ùëèùëê)ùëñ and ùõΩùõº = (ùëê + ùëëùëñ)(ùëé + ùëèùëñ) = (ùëêùëé ‚àí ùëëùëè) + (ùëêùëè + ùëëùëé)ùëñ. The equations above and the commutativity of multiplication and addition of real numbers show that ùõºùõΩ = ùõΩùõº. 4 Chapter 1 Vector Spaces Next, we define the additive and multiplicative inverses of complex numbers, and then use those inverses to define subtraction and division operations with complex numbers. 1.5 definition: ‚àíùõº, subtraction, 1/ùõº, division Suppose ùõº, ùõΩ ‚àà ùêÇ. ‚Ä¢ Let ‚àíùõº denote the additive inverse of ùõº. Thus ‚àíùõº is the unique complex number such that ùõº + (‚àíùõº) = 0. ‚Ä¢ Subtraction on ùêÇ is defined by ùõΩ ‚àí ùõº = ùõΩ + (‚àíùõº). ‚Ä¢ For ùõº ‚â† 0, let 1/ùõºand 1 ùõº denote the multiplicative inverse of ùõº. Thus 1/ùõºis the unique complex number such that ùõº(1/ùõº) = 1. ‚Ä¢ For ùõº ‚â† 0, division by ùõº is defined by ùõΩ/ùõº = ùõΩ(1/ùõº). So that we can conveniently make definitions and prove theorems that apply to both real and complex numbers, we adopt the following notation. 1.6 notation:ùêÖ Throughout this book, ùêÖ stands for either ùêë or ùêÇ. The letter ùêÖ is used because ùêë and ùêÇ are examples of what are called fields. Thus if we prove a theorem involving ùêÖ, we will know that it holds when ùêÖ is replaced with ùêë and when ùêÖ is replaced with ùêÇ. Elements of ùêÖ are called scalars. The word ‚Äúscalar‚Äù (which is just a fancy word for ‚Äúnumber‚Äù) is often used when we want to emphasize that an object is a number, as opposed to a vector (vectors will be defined soon). For ùõº ‚àà ùêÖ and ùëö a positive integer, we defineùõºùëö to denote the product of ùõº with itself ùëö times: ùõº ùëö = ùõº‚ãØùõº‚èü ùëö times . This definition implies that (ùõº ùëö) ùëõ = ùõºùëöùëõ and (ùõºùõΩ) ùëö = ùõºùëöùõΩ ùëö for all ùõº, ùõΩ ‚àà ùêÖ and all positive integers ùëö, ùëõ. Section 1A ùêëùëõ and ùêÇ ùëõ 5 Lists Before definingùêëùëõ and ùêÇ ùëõ, we look at two important examples. 1.7 example:ùêë2 and ùêë3 ‚Ä¢ The set ùêë2, which you can think of as a plane, is the set of all ordered pairs of real numbers: ùêë2 = {(ùë•, ùë¶) ‚à∂ ùë•, ùë¶ ‚àà ùêë}. ‚Ä¢ The set ùêë3, which you can think of as ordinary space, is the set of all ordered triples of real numbers: ùêë3 = {(ùë•, ùë¶, ùëß) ‚à∂ ùë•, ùë¶, ùëß ‚àà ùêë}. To generalize ùêë2 and ùêë3 to higher dimensions, we first need to discuss the concept of lists. 1.8 definition: list, length ‚Ä¢ Suppose ùëõ is a nonnegative integer. A list of length ùëõ is an ordered collec- tion of ùëõ elements (which might be numbers, other lists, or more abstract objects). ‚Ä¢ Two lists are equal if and only if they have the same length and the same elements in the same order. Many mathematicians call a list of length ùëõ an ùëõ-tuple. Lists are often written as elements separated by commas and surrounded by parentheses. Thus a list of length two is an ordered pair that might be written as (ùëé, ùëè). A list of length three is an ordered triple that might be written as (ùë•, ùë¶, ùëß). A list of length ùëõ might look like this: (ùëß1, ‚Ä¶, ùëßùëõ). Sometimes we will use the word list without specifying its length. Remember, however, that by definition each list has a finite length that is a nonnegative integer. Thus an object that looks like (ùë•1, ùë•2, ‚Ä¶ ), which might be said to have infinite length, is not a list. A list of length 0looks like this: ( ). We consider such an object to be a list so that some of our theorems will not have trivial exceptions. Lists differ from sets in two ways: in lists, order matters and repetitions have meaning; in sets, order and repetitions are irrelevant. 1.9 example: lists versus sets ‚Ä¢ The lists (3, 5)and (5, 3)are not equal, but the sets {3, 5}and {5, 3}are equal. ‚Ä¢ The lists (4, 4)and (4, 4, 4)are not equal (they do not have the same length), although the sets {4, 4}and {4, 4, 4}both equal the set {4}. 6 Chapter 1 Vector Spaces ùêÖùëõ To define the higher-dimensional analogues ofùêë2 and ùêë3, we will simply replace ùêë with ùêÖ (which equals ùêë or ùêÇ) and replace the 2or 3with an arbitrary positive integer. 1.10 notation: ùëõ Fix a positive integer ùëõ for the rest of this chapter. 1.11 definition: ùêÖùëõ, coordinate ùêÖùëõ is the set of all lists of length ùëõ of elements of ùêÖ: ùêÖùëõ = {(ùë•1, ‚Ä¶, ùë•ùëõ) ‚à∂ ùë•ùëò ‚àà ùêÖ for ùëò = 1, ‚Ä¶, ùëõ}. For (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêÖùëõ and ùëò ‚àà {1, ‚Ä¶, ùëõ}, we say that ùë•ùëò is the ùëòth coordinate of (ùë•1, ‚Ä¶, ùë•ùëõ). If ùêÖ = ùêë and ùëõ equals 2or 3, then the definition above ofùêÖùëõ agrees with our previous notions of ùêë2 and ùêë3. 1.12 example: ùêÇ 4 ùêÇ 4 is the set of all lists of four complex numbers: ùêÇ 4 = {(ùëß1, ùëß2, ùëß3, ùëß4) ‚à∂ ùëß1, ùëß2, ùëß3, ùëß4 ‚àà ùêÇ}. Read Flatland: A Romance of Many Dimensions, by Edwin A. Abbott, for an amusing account of how ùêë3 would be perceived by creatures living in ùêë2. This novel, published in 1884, may help you imagine a physical space of four or more dimensions. If ùëõ ‚â• 4, we cannot visualize ùêëùëõ as a physical object. Similarly, ùêÇ 1 can be thought of as a plane, but for ùëõ ‚â• 2, the human brain cannot provide a full image of ùêÇ ùëõ. However, even if ùëõ is large, we can perform algebraic manipulations in ùêÖùëõ as easily as in ùêë2 or ùêë3. For example, addition in ùêÖùëõ is defined as follows. 1.13 definition: addition in ùêÖùëõ Addition in ùêÖùëõ is defined by adding corresponding coordinates: (ùë•1, ‚Ä¶, ùë•ùëõ) + (ùë¶1, ‚Ä¶, ùë¶ùëõ) = (ùë•1 + ùë¶1, ‚Ä¶, ùë•ùëõ + ùë¶ùëõ). Often the mathematics of ùêÖùëõ becomes cleaner if we use a single letter to denote a list of ùëõ numbers, without explicitly writing the coordinates. For example, the next result is stated with ùë• and ùë¶ in ùêÖùëõ even though the proof requires the more cumbersome notation of (ùë•1, ‚Ä¶, ùë•ùëõ) and (ùë¶1, ‚Ä¶, ùë¶ùëõ). Section 1A ùêëùëõ and ùêÇ ùëõ 7 1.14 commutativity of addition in ùêÖùëõ If ùë•, ùë¶ ‚àà ùêÖùëõ, then ùë• + ùë¶ = ùë¶ + ùë•. Proof Suppose ùë• = (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêÖùëõ and ùë¶ = (ùë¶1, ‚Ä¶, ùë¶ùëõ) ‚àà ùêÖùëõ. Then ùë• + ùë¶ = (ùë•1, ‚Ä¶, ùë•ùëõ) + (ùë¶1, ‚Ä¶, ùë¶ùëõ) = (ùë•1 + ùë¶1, ‚Ä¶, ùë•ùëõ + ùë¶ùëõ) = (ùë¶1 + ùë•1, ‚Ä¶, ùë¶ùëõ + ùë•ùëõ) = (ùë¶1, ‚Ä¶, ùë¶ùëõ) + (ùë•1, ‚Ä¶, ùë•ùëõ) = ùë¶ + ùë•, where the second and fourth equalities above hold because of the definition of addition in ùêÖùëõ and the third equality holds because of the usual commutativity of addition in ùêÖ. The symbol means ‚Äúend of proof ‚Äù.If a single letter is used to denote an element of ùêÖùëõ, then the same letter with appropriate subscripts is often used when coordinates must be displayed. For example, if ùë• ‚àà ùêÖùëõ, then letting ùë• equal (ùë•1, ‚Ä¶, ùë•ùëõ) is good notation, as shown in the proof above. Even better, work with just ùë• and avoid explicit coordinates when possible. 1.15 notation: 0 Let 0denote the list of length ùëõ whose coordinates are all 0: 0 = (0, ‚Ä¶, 0). Here we are using the symbol 0in two different ways‚Äîon the left side of the equation above, the symbol 0denotes a list of length ùëõ, which is an element of ùêÖùëõ, whereas on the right side, each 0denotes a number. This potentially confusing practice actually causes no problems because the context should always make clear which 0is intended. 1.16 example:context determines which 0is intended Consider the statement that 0is an additive identity for ùêÖùëõ: ùë• + 0 = ùë• for all ùë• ‚àà ùêÖùëõ. Here the 0above is the list defined in1.15, not the number 0, because we have not defined the sum of an element ofùêÖùëõ (namely, ùë•) and the number 0. 8 Chapter 1 Vector Spaces Elements of ùêë2 can be thought of as points or as vectors. A picture can aid our intuition. We will draw pictures in ùêë2 because we can sketch this space on two-dimensional surfaces such as paper and computer screens. A typical element of ùêë2 is a point ùë£ = (ùëé, ùëè). Sometimes we think of ùë£ not as a point but as an arrow starting at the origin and ending at (ùëé, ùëè), as shown here. When we think of an element of ùêë2 as an arrow, we refer to it as a vector. A vector. When we think of vectors in ùêë2 as arrows, we can move an arrow parallel to itself (not changing its length or direction) and still think of it as the same vector. With that viewpoint, you will often gain better understanding by dispensing with the coordinate axes and the explicit coordinates and just thinking of the vector, as shown in the figure here. The two arrows shown here have the same length and same direction, so we think of them as the same vector. Mathematical models of the economy can have thousands of variables, say ùë•1, ‚Ä¶, ùë•5000, which means that we must work in ùêë5000. Such a space cannot be dealt with geometrically. However, the algebraic approach works well. Thus our subject is called linear algebra. Whenever we use pictures in ùêë2 or use the somewhat vague language of points and vectors, remember that these are just aids to our understanding, not sub- stitutes for the actual mathematics that we will develop. Although we cannot draw good pictures in high-dimensional spaces, the elements of these spaces are as rigorously defined as elements ofùêë2. For example, (2, ‚àí3, 17, ùúã, ‚àö2)is an element of ùêë5, and we may casually refer to it as a point in ùêë5 or a vector in ùêë5 without worrying about whether the geometry of ùêë5 has any physical meaning. Recall that we defined the sum of two elements ofùêÖùëõ to be the element of ùêÖùëõ obtained by adding corresponding coordinates; see 1.13. As we will now see, addition has a simple geometric interpretation in the special case of ùêë2. The sum of two vectors. Suppose we have two vectors ùë¢ and ùë£ in ùêë2 that we want to add. Move the vector ùë£ parallel to itself so that its initial point coincides with the end point of the vector ùë¢, as shown here. The sum ùë¢ + ùë£ then equals the vector whose initial point equals the initial point of ùë¢ and whose end point equals the end point of the vector ùë£, as shown here. In the next definition, the0on the right side of the displayed equation is the list 0 ‚àà ùêÖ ùëõ. Section 1A ùêëùëõ and ùêÇ ùëõ 9 1.17 definition:additive inverse in ùêÖùëõ, ‚àíùë• For ùë• ‚àà ùêÖùëõ, the additive inverse of ùë•, denoted by ‚àíùë•, is the vector ‚àíùë• ‚àà ùêÖùëõ such that ùë• + (‚àíùë•) = 0. Thus if ùë• = (ùë•1, ‚Ä¶, ùë•ùëõ), then ‚àíùë• = (‚àíùë•1, ‚Ä¶, ‚àíùë•ùëõ). A vector and its additive inverse. The additive inverse of a vector in ùêë2 is the vector with the same length but pointing in the opposite direction. The figure here illustrates this way of thinking about the additive inverse in ùêë2. As you can see, the vector labeled ‚àíùë• has the same length as the vector labeled ùë• but points in the opposite direction. Having dealt with addition in ùêÖùëõ, we now turn to multiplication. We could definea multiplication in ùêÖùëõ in a similar fashion, starting with two elements of ùêÖùëõ and getting another element of ùêÖùëõ by multiplying corresponding coordinates. Experience shows that this definition is not useful for our purposes. Another type of multiplication, called scalar multiplication, will be central to our subject. Specifically, we need to define what it means to multiply an element ofùêÖùëõ by an element of ùêÖ. 1.18 definition: scalar multiplication in ùêÖùëõ The product of a number ùúÜ and a vector in ùêÖùëõ is computed by multiplying each coordinate of the vector by ùúÜ: ùúÜ(ùë•1, ‚Ä¶, ùë•ùëõ) = (ùúÜùë•1, ‚Ä¶, ùúÜùë•ùëõ); here ùúÜ ‚àà ùêÖ and (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêÖùëõ. Scalar multiplication in ùêÖùëõ multiplies together a scalar and a vector, getting a vector. In contrast, the dot product in ùêë2 or ùêë3 multiplies together two vec- tors and gets a scalar. Generalizations of the dot product will become impor- tant in Chapter 6. Scalar multiplication has a nice geo- metric interpretation in ùêë2. If ùúÜ > 0and ùë• ‚àà ùêë2, then ùúÜùë• is the vector that points in the same direction as ùë• and whose length is ùúÜ times the length of ùë•. In other words, to get ùúÜùë•, we shrink or stretch ùë• by a factor of ùúÜ, depending on whether ùúÜ < 1or ùúÜ > 1. Scalar multiplication. If ùúÜ < 0and ùë• ‚àà ùêë2, then ùúÜùë• is the vector that points in the direction opposite to that of ùë• and whose length is |ùúÜ| times the length of ùë•, as shown here. 10 Chapter 1 Vector Spaces Digression on Fields A field is a set containing at least two distinct elements called 0and 1, along with operations of addition and multiplication satisfying all properties listed in 1.3. Thus ùêë and ùêÇ are fields, as is the set of rational numbers along with the usual operations of addition and multiplication. Another example of a field is the set {0, 1}with the usual operations of addition and multiplication except that 1+ 1is defined to equal0. In this book we will not deal with fields other thanùêë and ùêÇ. However, many of the definitions, theorems, and proofs in linear algebra that work for the fields ùêë and ùêÇ also work without change for arbitrary fields. If you prefer to do so, throughout much of this book (except for Chapters 6 and 7, which deal with inner product spaces) you can think of ùêÖ as denoting an arbitrary field instead ofùêë or ùêÇ. For results (except in the inner product chapters) that have as a hypothesis that ùêÖ is ùêÇ, you can probably replace that hypothesis with the hypothesis that ùêÖ is an algebraically closed field, which means that every nonconstant polynomial with coefficients in ùêÖ has a zero. A few results, such as Exercise 13 in Section 1C, require the hypothesis on ùêÖ that 1+ 1 ‚â† 0. Exercises 1A 1 Show that ùõº + ùõΩ = ùõΩ + ùõº for all ùõº, ùõΩ ‚àà ùêÇ. 2 Show that (ùõº + ùõΩ) + ùúÜ = ùõº + (ùõΩ + ùúÜ) for all ùõº, ùõΩ, ùúÜ ‚àà ùêÇ. 3 Show that (ùõºùõΩ)ùúÜ = ùõº(ùõΩùúÜ) for all ùõº, ùõΩ, ùúÜ ‚àà ùêÇ. 4 Show that ùúÜ(ùõº + ùõΩ) = ùúÜùõº + ùúÜùõΩ for all ùúÜ, ùõº, ùõΩ ‚àà ùêÇ. 5 Show that for every ùõº ‚àà ùêÇ, there exists a unique ùõΩ ‚àà ùêÇ such that ùõº + ùõΩ = 0. 6 Show that for every ùõº ‚àà ùêÇ with ùõº ‚â† 0, there exists a unique ùõΩ ‚àà ùêÇ such that ùõºùõΩ = 1. 7 Show that ‚àí1+ ‚àö3ùëñ 2 is a cube root of 1(meaning that its cube equals 1). 8 Find two distinct square roots of ùëñ. 9 Find ùë• ‚àà ùêë4 such that (4, ‚àí3, 1, 7)+ 2ùë• = (5, 9, ‚àí6, 8). 10 Explain why there does not exist ùúÜ ‚àà ùêÇ such that ùúÜ(2 ‚àí 3ùëñ, 5+ 4ùëñ, ‚àí6+ 7ùëñ) = (12 ‚àí 5ùëñ, 7+ 22ùëñ, ‚àí32 ‚àí 9ùëñ). Section 1A ùêëùëõ and ùêÇ ùëõ 11 11 Show that (ùë• + ùë¶) + ùëß = ùë• + (ùë¶ + ùëß) for all ùë•, ùë¶, ùëß ‚àà ùêÖùëõ. 12 Show that (ùëéùëè)ùë• = ùëé(ùëèùë•) for all ùë• ‚àà ùêÖùëõ and all ùëé, ùëè ‚àà ùêÖ. 13 Show that 1ùë• = ùë•for all ùë• ‚àà ùêÖùëõ. 14 Show that ùúÜ(ùë• + ùë¶) = ùúÜùë• + ùúÜùë¶ for all ùúÜ ‚àà ùêÖ and all ùë•, ùë¶ ‚àà ùêÖùëõ. 15 Show that (ùëé + ùëè)ùë• = ùëéùë• + ùëèùë• for all ùëé, ùëè ‚àà ùêÖ and all ùë• ‚àà ùêÖùëõ. ‚ÄúCan you do addition?‚Äù the White Queen asked. ‚ÄúWhat‚Äôs one and one and one and one and one and one and one and one and one and one?‚Äù ‚ÄúI don‚Äôt know,‚Äù said Alice. ‚ÄúI lost count.‚Äù ‚ÄîThrough the Looking Glass, Lewis Carroll 12 Chapter 1 Vector Spaces 1B Definition of Vector Space The motivation for the definition of a vector space comes from properties of addition and scalar multiplication in ùêÖùëõ: Addition is commutative, associative, and has an identity. Every element has an additive inverse. Scalar multiplication is associative. Scalar multiplication by 1acts as expected. Addition and scalar multiplication are connected by distributive properties. We will define a vector space to be a setùëâ with an addition and a scalar multiplication on ùëâ that satisfy the properties in the paragraph above. 1.19 definition: addition, scalar multiplication ‚Ä¢ An addition on a set ùëâ is a function that assigns an element ùë¢ + ùë£ ‚àà ùëâ to each pair of elements ùë¢, ùë£ ‚àà ùëâ. ‚Ä¢ A scalar multiplication on a set ùëâ is a function that assigns an element ùúÜùë£ ‚àà ùëâ to each ùúÜ ‚àà ùêÖ and each ùë£ ‚àà ùëâ. Now we are ready to give the formal definition of a vector space. 1.20 definition: vector space A vector space is a set ùëâ along with an addition on ùëâ and a scalar multiplication on ùëâ such that the following properties hold. commutativity ùë¢ + ùë£ = ùë£ + ùë¢ for all ùë¢, ùë£ ‚àà ùëâ. associativity (ùë¢ + ùë£) + ùë§ = ùë¢ + (ùë£ + ùë§) and (ùëéùëè)ùë£ = ùëé(ùëèùë£) for all ùë¢, ùë£, ùë§ ‚àà ùëâ and for all ùëé, ùëè ‚àà ùêÖ. additive identity There exists an element 0 ‚àà ùëâsuch that ùë£ + 0 = ùë£for all ùë£ ‚àà ùëâ. additive inverse For every ùë£ ‚àà ùëâ, there exists ùë§ ‚àà ùëâ such that ùë£ + ùë§ = 0. multiplicative identity 1ùë£ = ùë£for all ùë£ ‚àà ùëâ. distributive properties ùëé(ùë¢ + ùë£) = ùëéùë¢ + ùëéùë£ and (ùëé + ùëè)ùë£ = ùëéùë£ + ùëèùë£ for all ùëé, ùëè ‚àà ùêÖ and all ùë¢, ùë£ ‚àà ùëâ. The following geometric language sometimes aids our intuition. 1.21 definition: vector, point Elements of a vector space are called vectors or points. Section 1B Definition of Vector Space 13 The scalar multiplication in a vector space depends on ùêÖ. Thus when we need to be precise, we will say that ùëâ is a vector space over ùêÖ instead of saying simply that ùëâ is a vector space. For example, ùêëùëõ is a vector space over ùêë, and ùêÇ ùëõ is a vector space over ùêÇ. 1.22 definition: real vector space, complex vector space ‚Ä¢ A vector space over ùêë is called a real vector space. ‚Ä¢ A vector space over ùêÇ is called a complex vector space. Usually the choice of ùêÖ is either clear from the context or irrelevant. Thus we often assume that ùêÖ is lurking in the background without specifically mentioning it. The simplest vector space is {0}, which contains only one point. With the usual operations of addition and scalar multiplication, ùêÖùëõ is a vector space over ùêÖ, as you should verify. The example of ùêÖùëõ motivated our definition of vector space. 1.23 example: ùêÖ‚àû ùêÖ‚àû is defined to be the set of all sequences of elements ofùêÖ: ùêÖ‚àû = {(ùë•1, ùë•2, ‚Ä¶ ) ‚à∂ ùë•ùëò ‚àà ùêÖ for ùëò = 1, 2, ‚Ä¶}. Addition and scalar multiplication on ùêÖ‚àû are defined as expected: (ùë•1, ùë•2, ‚Ä¶ ) + (ùë¶1, ùë¶2, ‚Ä¶ ) = (ùë•1 + ùë¶1, ùë•2 + ùë¶2, ‚Ä¶ ), ùúÜ(ùë•1, ùë•2, ‚Ä¶ ) = (ùúÜùë•1, ùúÜùë•2, ‚Ä¶ ). With these definitions,ùêÖ‚àû becomes a vector space over ùêÖ, as you should verify. The additive identity in this vector space is the sequence of all 0‚Äôs. Our next example of a vector space involves a set of functions. 1.24 notation: ùêÖùëÜ ‚Ä¢ If ùëÜ is a set, then ùêÖùëÜ denotes the set of functions from ùëÜ to ùêÖ. ‚Ä¢ For ùëì, ùëî ‚àà ùêÖùëÜ, the sum ùëì + ùëî ‚àà ùêÖùëÜ is the function defined by ( ùëì + ùëî)(ùë•) = ùëì (ùë•) + ùëî(ùë•) for all ùë• ‚àà ùëÜ. ‚Ä¢ For ùúÜ ‚àà ùêÖ and ùëì ‚àà ùêÖùëÜ, the product ùúÜ ùëì ‚àà ùêÖùëÜ is the function defined by (ùúÜ ùëì )(ùë•) = ùúÜ ùëì (ùë•) for all ùë• ‚àà ùëÜ. 14 Chapter 1 Vector Spaces As an example of the notation above, if ùëÜ is the interval [0, 1]and ùêÖ = ùêë, then ùêë[0, 1] is the set of real-valued functions on the interval [0, 1]. You should verify all three bullet points in the next example. 1.25 example: ùêÖùëÜ is a vector space ‚Ä¢ If ùëÜ is a nonempty set, then ùêÖùëÜ (with the operations of addition and scalar multiplication as defined above) is a vector space overùêÖ. ‚Ä¢ The additive identity of ùêÖùëÜ is the function 0‚à∂ ùëÜ ‚Üí ùêÖ defined by 0(ùë•) = 0 for all ùë• ‚àà ùëÜ. ‚Ä¢ For ùëì ‚àà ùêÖùëÜ, the additive inverse of ùëì is the function ‚àí ùëì ‚à∂ ùëÜ ‚Üí ùêÖ defined by (‚àí ùëì )(ùë•) = ‚àí ùëì (ùë•) for all ùë• ‚àà ùëÜ. The elements of the vector space ùêë[0, 1] are real-valued functions on [0, 1], not lists. In general, a vector space is an abstract entity whose elements might be lists, functions, or weird objects. The vector space ùêÖùëõ is a special case of the vector space ùêÖùëÜ because each (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêÖùëõ can be thought of as a function ùë• from the set {1, 2, ‚Ä¶, ùëõ} to ùêÖ by writing ùë•(ùëò) instead of ùë•ùëò for the ùëòth coordinate of (ùë•1, ‚Ä¶, ùë•ùëõ). In other words, we can think of ùêÖùëõ as ùêÖ{1, 2, ‚Ä¶, ùëõ}. Similarly, we can think of ùêÖ‚àû as ùêÖ{1, 2, ‚Ä¶ }. Soon we will see further examples of vector spaces, but first we need to develop some of the elementary properties of vector spaces. The definition of a vector space requires it to have an additive identity. The next result states that this identity is unique. 1.26 unique additive identity A vector space has a unique additive identity. Proof Suppose 0and 0 ‚Ä≤ are both additive identities for some vector space ùëâ. Then 0 ‚Ä≤ = 0 ‚Ä≤ + 0 = 0+ 0 ‚Ä≤ = 0, where the first equality holds because0is an additive identity, the second equality comes from commutativity, and the third equality holds because 0 ‚Ä≤ is an additive identity. Thus 0 ‚Ä≤ = 0, proving that ùëâ has only one additive identity. Each element ùë£ in a vector space has an additive inverse, an element ùë§ in the vector space such that ùë£ + ùë§ = 0. The next result shows that each element in a vector space has only one additive inverse. Section 1B Definition of Vector Space 15 1.27 unique additive inverse Every element in a vector space has a unique additive inverse. Proof Suppose ùëâ is a vector space. Let ùë£ ‚àà ùëâ. Suppose ùë§ and ùë§‚Ä≤ are additive inverses of ùë£. Then ùë§ = ùë§ + 0 = ùë§+ (ùë£ + ùë§‚Ä≤) = (ùë§ + ùë£) + ùë§‚Ä≤ = 0+ ùë§‚Ä≤ = ùë§‚Ä≤. Thus ùë§ = ùë§‚Ä≤, as desired. Because additive inverses are unique, the following notation now makes sense. 1.28 notation: ‚àíùë£, ùë§ ‚àí ùë£ Let ùë£, ùë§ ‚àà ùëâ. Then ‚Ä¢ ‚àíùë£ denotes the additive inverse of ùë£; ‚Ä¢ ùë§ ‚àí ùë£ is defined to beùë§ + (‚àíùë£). Almost all results in this book involve some vector space. To avoid having to restate frequently that ùëâ is a vector space, we now make the necessary declaration once and for all. 1.29 notation: ùëâ For the rest of this book, ùëâ denotes a vector space over ùêÖ. In the next result, 0denotes a scalar (the number 0 ‚àà ùêÖ) on the left side of the equation and a vector (the additive identity of ùëâ) on the right side of the equation. 1.30 the number 0times a vector 0ùë£ = 0for every ùë£ ‚àà ùëâ. The result in 1.30 involves the additive identity of ùëâ and scalar multiplication. The only part of the definition of a vec- tor space that connects vector addition and scalar multiplication is the dis- tributive property. Thus the distribu- tive property must be used in the proof of 1.30. Proof For ùë£ ‚àà ùëâ, we have 0ùë£ = (0+ 0)ùë£ = 0ùë£+ 0ùë£. Adding the additive inverse of 0ùë£to both sides of the equation above gives 0 = 0ùë£, as desired. In the next result, 0denotes the addi- tive identity of ùëâ. Although their proofs are similar, 1.30 and 1.31 are not identical. More precisely, 1.30 states that the product of the scalar 0and any vector equals the vector 0, whereas 1.31 states that the product of any scalar and the vector 0equals the vector 0. 16 Chapter 1 Vector Spaces 1.31 a number times the vector 0 ùëé0 = 0for every ùëé ‚àà ùêÖ. Proof For ùëé ‚àà ùêÖ, we have ùëé0 = ùëé(0+ 0) = ùëé0+ ùëé0. Adding the additive inverse of ùëé0to both sides of the equation above gives 0 = ùëé0, as desired. Now we show that if an element of ùëâ is multiplied by the scalar ‚àí1, then the result is the additive inverse of the element of ùëâ. 1.32 the number ‚àí1times a vector (‚àí1)ùë£ = ‚àíùë£for every ùë£ ‚àà ùëâ. Proof For ùë£ ‚àà ùëâ, we have ùë£ + (‚àí1)ùë£ = 1ùë£+ (‚àí1)ùë£ =(1+ (‚àí1))ùë£ = 0ùë£ = 0. This equation says that (‚àí1)ùë£, when added to ùë£, gives 0. Thus (‚àí1)ùë£is the additive inverse of ùë£, as desired. Exercises 1B 1 Prove that ‚àí(‚àíùë£) = ùë£ for every ùë£ ‚àà ùëâ. 2 Suppose ùëé ‚àà ùêÖ, ùë£ ‚àà ùëâ, and ùëéùë£ = 0. Prove that ùëé = 0or ùë£ = 0. 3 Suppose ùë£, ùë§ ‚àà ùëâ. Explain why there exists a unique ùë• ‚àà ùëâ such that ùë£ + 3ùë• = ùë§. 4 The empty set is not a vector space. The empty set fails to satisfy only one of the requirements listed in the definition of a vector space (1.20). Which one? 5 Show that in the definition of a vector space (1.20), the additive inverse condition can be replaced with the condition that 0ùë£ = 0for all ùë£ ‚àà ùëâ. Here the 0on the left side is the number 0, and the 0on the right side is the additive identity of ùëâ. The phrase a ‚Äúcondition can be replaced‚Äù in a definition means that the collection of objects satisfying the definition is unchanged if the original condition is replaced with the new condition. Section 1B Definition of Vector Space 17 6 Let ‚àû and ‚àí‚àû denote two distinct objects, neither of which is in ùêë. Define an addition and scalar multiplication on ùêë ‚à™ {‚àû, ‚àí‚àû} as you could guess from the notation. Specifically, the sum and product of two real numbers is as usual, and for ùë° ‚àà ùêë define ùë°‚àû = ‚éß {{ ‚é® {{ ‚é© ‚àí‚àû if ùë° < 0, 0 if ùë° = 0, ‚àû if ùë° > 0, ùë°(‚àí‚àû) = ‚éß {{ ‚é® {{ ‚é© ‚àû if ùë° < 0, 0 if ùë° = 0, ‚àí‚àû if ùë° > 0, and ùë° + ‚àû = ‚àû + ùë° = ‚àû + ‚àû = ‚àû, ùë° + (‚àí‚àû) = (‚àí‚àû) + ùë° = (‚àí‚àû) + (‚àí‚àû) = ‚àí‚àû, ‚àû + (‚àí‚àû) = (‚àí‚àû) + ‚àû = 0. With these operations of addition and scalar multiplication, is ùêë ‚à™ {‚àû, ‚àí‚àû} a vector space over ùêë? Explain. 7 Suppose ùëÜ is a nonempty set. Let ùëâùëÜ denote the set of functions from ùëÜ to ùëâ. Define a natural addition and scalar multiplication onùëâùëÜ, and show that ùëâùëÜ is a vector space with these definitions. 8 Suppose ùëâ is a real vector space. ‚Ä¢ The complexification of ùëâ, denoted by ùëâùêÇ, equals ùëâ√ó ùëâ. An element of ùëâùêÇ is an ordered pair (ùë¢, ùë£), where ùë¢, ùë£ ‚àà ùëâ, but we write this as ùë¢ + ùëñùë£. ‚Ä¢ Addition on ùëâùêÇ is defined by (ùë¢1 + ùëñùë£1) + (ùë¢2 + ùëñùë£2) = (ùë¢1 + ùë¢2) + ùëñ(ùë£1 + ùë£2) for all ùë¢1, ùë£1, ùë¢2, ùë£2 ‚àà ùëâ. ‚Ä¢ Complex scalar multiplication on ùëâùêÇ is defined by (ùëé + ùëèùëñ)(ùë¢ + ùëñùë£) = (ùëéùë¢ ‚àí ùëèùë£) + ùëñ(ùëéùë£ + ùëèùë¢) for all ùëé, ùëè ‚àà ùêë and all ùë¢, ùë£ ‚àà ùëâ. Prove that with the definitions of addition and scalar multiplication as above, ùëâùêÇ is a complex vector space. Think of ùëâ as a subset of ùëâùêÇ by identifying ùë¢ ‚àà ùëâ with ùë¢ + ùëñ0. The construc- tion of ùëâùêÇ from ùëâ can then be thought of as generalizing the construction of ùêÇ ùëõ from ùêëùëõ. 18 Chapter 1 Vector Spaces 1C Subspaces By considering subspaces, we can greatly expand our examples of vector spaces. 1.33 definition: subspace A subset ùëà of ùëâ is called a subspace of ùëâ if ùëà is also a vector space with the same additive identity, addition, and scalar multiplication as on ùëâ. Some people use the terminology linear subspace, which means the same as subspace. The next result gives the easiest way to check whether a subset of a vector space is a subspace. 1.34 conditions for a subspace A subset ùëà of ùëâ is a subspace of ùëâ if and only if ùëà satisfies the following three conditions. additive identity 0 ‚àà ùëà. closed under addition ùë¢, ùë§ ‚àà ùëà implies ùë¢ + ùë§ ‚àà ùëà. closed under scalar multiplication ùëé ‚àà ùêÖ and ùë¢ ‚àà ùëà implies ùëéùë¢ ‚àà ùëà. The additive identity condition above could be replaced with the condition that ùëà is nonempty (because then tak- ing ùë¢ ‚àà ùëà and multiplying it by 0 would imply that 0 ‚àà ùëà). However, if a subset ùëà of ùëâ is indeed a sub- space, then usually the quickest way to show that ùëà is nonempty is to show that 0 ‚àà ùëà. Proof If ùëà is a subspace of ùëâ, then ùëà satisfies the three conditions above by the definition of vector space. Conversely, suppose ùëà satisfies the three conditions above. The first condi- tion ensures that the additive identity of ùëâ is in ùëà. The second condition ensures that addition makes sense on ùëà. The third condition ensures that scalar multiplica- tion makes sense on ùëà. If ùë¢ ‚àà ùëà, then ‚àíùë¢ [which equals (‚àí1)ùë¢by 1.32]is also in ùëà by the third condition above. Hence every element of ùëà has an additive inverse in ùëà. The other parts of the definition of a vector space, such as associativity and commutativity, are automatically satisfied forùëà because they hold on the larger space ùëâ. Thus ùëà is a vector space and hence is a subspace of ùëâ. The three conditions in the result above usually enable us to determine quickly whether a given subset of ùëâ is a subspace of ùëâ. You should verify all assertions in the next example. Section 1C Subspaces 19 1.35 example: subspaces (a) If ùëè ‚àà ùêÖ, then {(ùë•1, ùë•2, ùë•3, ùë•4) ‚àà ùêÖ4 ‚à∂ ùë•3 = 5ùë•4 + ùëè} is a subspace of ùêÖ4 if and only if ùëè = 0. (b) The set of continuous real-valued functions on the interval [0, 1]is a subspace of ùêë[0, 1]. (c) The set of differentiable real-valued functions on ùêë is a subspace of ùêëùêë. (d) The set of differentiable real-valued functions ùëì on the interval (0, 3)such that ùëì ‚Ä≤(2) = ùëèis a subspace of ùêë(0, 3)if and only if ùëè = 0. (e) The set of all sequences of complex numbers with limit 0is a subspace of ùêÇ ‚àû. The set {0}is the smallest subspace of ùëâ, and ùëâ itself is the largest subspace of ùëâ. The empty set is not a subspace of ùëâ because a subspace must be a vector space and hence must contain at least one element, namely, an additive identity. Verifying some of the items above shows the linear structure underlying parts of calculus. For example, (b) above requires the result that the sum of two continuous functions is continuous. As another example, (d) above requires the result that for a constant ùëê, the derivative of ùëê ùëì equals ùëê times the derivative of ùëì. The subspaces of ùêë2 are precisely {0}, all lines in ùêë2 containing the origin, and ùêë2. The subspaces of ùêë3 are precisely {0}, all lines in ùêë3 containing the origin, all planes in ùêë3 containing the origin, and ùêë3. To prove that all these objects are indeed subspaces is straightforward‚Äîthe hard part is to show that they are the only subspaces of ùêë2 and ùêë3. That task will be easier after we introduce some additional tools in the next chapter. Sums of Subspaces The union of subspaces is rarely a sub- space (see Exercise 12), which is why we usually work with sums rather than unions. When dealing with vector spaces, we are usually interested only in subspaces, as opposed to arbitrary subsets. The notion of the sum of subspaces will be useful. 1.36 definition:sum of subspaces Suppose ùëâ1, ‚Ä¶, ùëâùëö are subspaces of ùëâ. The sum of ùëâ1, ‚Ä¶, ùëâùëö, denoted by ùëâ1 + ‚ãØ + ùëâùëö, is the set of all possible sums of elements of ùëâ1, ‚Ä¶, ùëâùëö. More precisely, ùëâ1 + ‚ãØ + ùëâùëö = {ùë£1 + ‚ãØ + ùë£ùëö ‚à∂ ùë£1 ‚àà ùëâ1, ‚Ä¶, ùë£ùëö ‚àà ùëâùëö}. 20 Chapter 1 Vector Spaces Let‚Äôs look at some examples of sums of subspaces. 1.37 example:a sum of subspaces of ùêÖ3 Suppose ùëà is the set of all elements of ùêÖ3 whose second and third coordinates equal 0, and ùëä is the set of all elements of ùêÖ3 whose first and third coordinates equal 0: ùëà = {(ùë•, 0, 0) ‚àà ùêÖ 3 ‚à∂ ùë• ‚àà ùêÖ} and ùëä = {(0, ùë¶, 0) ‚àà ùêÖ 3 ‚à∂ ùë¶ ‚àà ùêÖ}. Then ùëà + ùëä = {(ùë•, ùë¶, 0) ‚àà ùêÖ 3 ‚à∂ ùë•, ùë¶ ‚àà ùêÖ}, as you should verify. 1.38 example: a sum of subspaces of ùêÖ4 Suppose ùëà = {(ùë•, ùë•, ùë¶, ùë¶) ‚àà ùêÖ4 ‚à∂ ùë•, ùë¶ ‚àà ùêÖ} and ùëä = {(ùë•, ùë•, ùë•, ùë¶) ‚àà ùêÖ4 ‚à∂ ùë•, ùë¶ ‚àà ùêÖ}. Using words rather than symbols, we could say that ùëà is the set of elements of ùêÖ4 whose first two coordinates equal each other and whose third and fourth coordinates equal each other. Similarly, ùëä is the set of elements of ùêÖ4 whose first three coordinates equal each other. To find a description ofùëà + ùëä, consider a typical element (ùëé, ùëé, ùëè, ùëè) of ùëà and a typical element (ùëê, ùëê, ùëê, ùëë) of ùëä, where ùëé, ùëè, ùëê, ùëë ‚àà ùêÖ. We have (ùëé, ùëé, ùëè, ùëè) + (ùëê, ùëê, ùëê, ùëë) = (ùëé + ùëê, ùëé + ùëê, ùëè + ùëê, ùëè + ùëë), which shows that every element of ùëà + ùëä has its first two coordinates equal to each other. Thus 1.39 ùëà + ùëä ‚äÜ{(ùë•, ùë•, ùë¶, ùëß) ‚àà ùêÖ4 ‚à∂ ùë•, ùë¶, ùëß ‚àà ùêÖ}. To prove the inclusion in the other direction, suppose ùë•, ùë¶, ùëß ‚àà ùêÖ. Then (ùë•, ùë•, ùë¶, ùëß) = (ùë•, ùë•, ùë¶, ùë¶) + (0, 0, 0, ùëß ‚àí ùë¶), where the first vector on the right is inùëà and the second vector on the right is in ùëä. Thus (ùë•, ùë•, ùë¶, ùëß) ‚àà ùëà + ùëä, showing that the inclusion 1.39 also holds in the opposite direction. Hence ùëà + ùëä = {(ùë•, ùë•, ùë¶, ùëß) ‚àà ùêÖ4 ‚à∂ ùë•, ùë¶, ùëß ‚àà ùêÖ}, which shows that ùëà + ùëä is the set of elements of ùêÖ4 whose first two coordinates equal each other. The next result states that the sum of subspaces is a subspace, and is in fact the smallest subspace containing all the summands (which means that every subspace containing all the summands also contains the sum). Section 1C Subspaces 21 1.40 sum of subspaces is the smallest containing subspace Suppose ùëâ1, ‚Ä¶, ùëâùëö are subspaces of ùëâ. Then ùëâ1 + ‚ãØ + ùëâùëö is the smallest subspace of ùëâ containing ùëâ1, ‚Ä¶, ùëâùëö. Proof The reader can verify that ùëâ1 + ‚ãØ + ùëâùëö contains the additive identity 0 and is closed under addition and scalar multiplication. Thus 1.34 implies that ùëâ1 + ‚ãØ + ùëâùëö is a subspace of ùëâ. Sums of subspaces in the theory of vec- tor spaces are analogous to unions of subsets in set theory. Given two sub- spaces of a vector space, the smallest subspace containing them is their sum. Analogously, given two subsets of a set, the smallest subset containing them is their union. The subspaces ùëâ1, ‚Ä¶, ùëâùëö are all con- tained in ùëâ1+‚ãØ+ùëâùëö (to see this, consider sums ùë£1 + ‚ãØ + ùë£ùëö where all except one of the ùë£ùëò‚Äôs are 0). Conversely, every sub- space of ùëâ containing ùëâ1, ‚Ä¶, ùëâùëö contains ùëâ1 + ‚ãØ + ùëâùëö (because subspaces must contain all finite sums of their elements). Thus ùëâ1+‚ãØ+ùëâùëö is the smallest subspace of ùëâ containing ùëâ1, ‚Ä¶, ùëâùëö. Direct Sums Suppose ùëâ1, ‚Ä¶, ùëâùëö are subspaces of ùëâ. Every element of ùëâ1 + ‚ãØ + ùëâùëö can be written in the form ùë£1 + ‚ãØ + ùë£ùëö, where each ùë£ùëò ‚àà ùëâùëò. Of special interest are cases in which each vector in ùëâ1 + ‚ãØ + ùëâùëö can be represented in the form above in only one way. This situation is so important that it gets a special name (direct sum) and a special symbol (‚äï). 1.41 definition: direct sum, ‚äï Suppose ùëâ1, ‚Ä¶, ùëâùëö are subspaces of ùëâ. ‚Ä¢ The sum ùëâ1 + ‚ãØ + ùëâùëö is called a direct sum if each element of ùëâ1 + ‚ãØ + ùëâùëö can be written in only one way as a sum ùë£1 + ‚ãØ + ùë£ùëö, where each ùë£ùëò ‚àà ùëâùëò. ‚Ä¢ If ùëâ1 + ‚ãØ + ùëâùëö is a direct sum, then ùëâ1 ‚äï ‚ãØ ‚äï ùëâùëö denotes ùëâ1 + ‚ãØ + ùëâùëö, with the ‚äï notation serving as an indication that this is a direct sum. 1.42 example: a direct sum of two subspaces Suppose ùëà is the subspace of ùêÖ3 of those vectors whose last coordinate equals 0, and ùëä is the subspace of ùêÖ3 of those vectors whose first two coordinates equal0: ùëà = {(ùë•, ùë¶, 0) ‚àà ùêÖ 3 ‚à∂ ùë•, ùë¶ ‚àà ùêÖ} and ùëä = {(0, 0, ùëß) ‚àà ùêÖ3 ‚à∂ ùëß ‚àà ùêÖ}. Then ùêÖ3 = ùëà ‚äï ùëä, as you should verify. ‚âà 7ùúã Chapter 1 Vector Spaces 1.43 example: a direct sum of multiple subspaces To produce ‚äï in TEX, type \\oplus.Suppose ùëâùëò is the subspace of ùêÖùëõ of those vectors whose coordinates are all 0, except possibly in the ùëòth slot; for example, ùëâ2 = {(0, ùë•, 0, ‚Ä¶, 0) ‚àà ùêÖ ùëõ ‚à∂ ùë• ‚àà ùêÖ}. Then ùêÖùëõ = ùëâ1 ‚äï ‚ãØ ‚äï ùëâùëõ, as you should verify. Sometimes nonexamples add to our understanding as much as examples. 1.44 example: a sum that is not a direct sum Suppose ùëâ1 = {(ùë•, ùë¶, 0) ‚àà ùêÖ 3 ‚à∂ ùë•, ùë¶ ‚àà ùêÖ}, ùëâ2 = {(0, 0, ùëß) ‚àà ùêÖ3 ‚à∂ ùëß ‚àà ùêÖ}, ùëâ3 = {(0, ùë¶, ùë¶) ‚àà ùêÖ3 ‚à∂ ùë¶ ‚àà ùêÖ}. Then ùêÖ3 = ùëâ1 + ùëâ2 + ùëâ3 because every vector (ùë•, ùë¶, ùëß) ‚àà ùêÖ3 can be written as (ùë•, ùë¶, ùëß) = (ùë•, ùë¶, 0)+ (0, 0, ùëß) + (0, 0, 0), where the first vector on the right side is inùëâ1, the second vector is in ùëâ2, and the third vector is in ùëâ3. However, ùêÖ3 does not equal the direct sum of ùëâ1, ùëâ2, ùëâ3, because the vector (0, 0, 0)can be written in more than one way as a sum ùë£1 + ùë£2 + ùë£3, with each ùë£ùëò ‚àà ùëâùëò. Specifically, we have (0, 0, 0) = (0, 1, 0)+ (0, 0, 1)+ (0, ‚àí1, ‚àí1) and, of course, (0, 0, 0) = (0, 0, 0)+ (0, 0, 0)+ (0, 0, 0), where the first vector on the right side of each equation above is inùëâ1, the second vector is in ùëâ2, and the third vector is in ùëâ3. Thus the sum ùëâ1 + ùëâ2 + ùëâ3 is not a direct sum. The symbol ‚äï, which is a plus sign inside a circle, reminds us that we are dealing with a special type of sum of subspaces‚Äîeach element in the direct sum can be represented in only one way as a sum of elements from the specified subspaces. The definition of direct sum requires every vector in the sum to have a unique representation as an appropriate sum. The next result shows that when deciding whether a sum of subspaces is a direct sum, we only need to consider whether 0 can be uniquely written as an appropriate sum. Section 1C Subspaces 23 1.45 condition for a direct sum Suppose ùëâ1, ‚Ä¶, ùëâùëö are subspaces of ùëâ. Then ùëâ1 + ‚ãØ + ùëâùëö is a direct sum if and only if the only way to write 0as a sum ùë£1 + ‚ãØ + ùë£ùëö, where each ùë£ùëò ‚àà ùëâùëò, is by taking each ùë£ùëò equal to 0. Proof First suppose ùëâ1 + ‚ãØ + ùëâùëö is a direct sum. Then the definition of direct sum implies that the only way to write 0as a sum ùë£1 + ‚ãØ+ ùë£ùëö, where each ùë£ùëò ‚àà ùëâùëò, is by taking each ùë£ùëò equal to 0. Now suppose that the only way to write 0as a sum ùë£1 + ‚ãØ + ùë£ùëö, where each ùë£ùëò ‚àà ùëâùëò, is by taking each ùë£ùëò equal to 0. To show that ùëâ1 + ‚ãØ + ùëâùëö is a direct sum, let ùë£ ‚àà ùëâ1 + ‚ãØ + ùëâùëö. We can write ùë£ = ùë£1 + ‚ãØ + ùë£ùëö for some ùë£1 ‚àà ùëâ1, ‚Ä¶, ùë£ùëö ‚àà ùëâùëö. To show that this representation is unique, suppose we also have ùë£ = ùë¢1 + ‚ãØ + ùë¢ùëö, where ùë¢1 ‚àà ùëâ1, ‚Ä¶, ùë¢ùëö ‚àà ùëâùëö. Subtracting these two equations, we have 0 = (ùë£1 ‚àí ùë¢1) + ‚ãØ + (ùë£ùëö ‚àí ùë¢ùëö). Because ùë£1 ‚àí ùë¢1 ‚àà ùëâ1, ‚Ä¶, ùë£ùëö ‚àí ùë¢ùëö ‚àà ùëâùëö, the equation above implies that each ùë£ùëò ‚àí ùë¢ùëò equals 0. Thus ùë£1 = ùë¢1, ‚Ä¶, ùë£ùëö = ùë¢ùëö, as desired. The symbol ‚ü∫ used below means ‚Äúif and only if ‚Äù; this symbol could also be read to mean ‚Äúis equivalent to‚Äù. The next result gives a simple con- dition for testing whether a sum of two subspaces is a direct sum. 1.46 direct sum of two subspaces Suppose ùëà and ùëä are subspaces of ùëâ. Then ùëà + ùëä is a direct sum ‚ü∫ ùëà ‚à© ùëä = {0}. Proof First suppose that ùëà + ùëä is a direct sum. If ùë£ ‚àà ùëà ‚à© ùëä, then 0 = ùë£+ (‚àíùë£), where ùë£ ‚àà ùëà and ‚àíùë£ ‚àà ùëä. By the unique representation of 0as the sum of a vector in ùëà and a vector in ùëä, we have ùë£ = 0. Thus ùëà ‚à© ùëä = {0}, completing the proof in one direction. To prove the other direction, now suppose ùëà ‚à© ùëä = {0}. To prove that ùëà + ùëä is a direct sum, suppose ùë¢ ‚àà ùëà, ùë§ ‚àà ùëä, and 0 = ùë¢+ ùë§. To complete the proof, we only need to show that ùë¢ = ùë§ = 0(by 1.45). The equation above implies that ùë¢ = ‚àíùë§ ‚àà ùëä. Thus ùë¢ ‚àà ùëà ‚à© ùëä. Hence ùë¢ = 0, which by the equation above implies that ùë§ = 0, completing the proof. 24 Chapter 1 Vector Spaces Sums of subspaces are analogous to unions of subsets. Similarly, direct sums of subspaces are analogous to disjoint unions of subsets. No two sub- spaces of a vector space can be disjoint, because both contain 0. So disjoint- ness is replaced, at least in the case of two subspaces, with the requirement that the intersection equal {0}. The result above deals only with the case of two subspaces. When ask- ing about a possible direct sum with more than two subspaces, it is not enough to test that each pair of the subspaces intersect only at 0. To see this, consider Example 1.44. In that nonexample of a direct sum, we have ùëâ1 ‚à© ùëâ2 = ùëâ1 ‚à© ùëâ3 = ùëâ2 ‚à© ùëâ3 = {0}. Exercises 1C 1 For each of the following subsets of ùêÖ3, determine whether it is a subspace of ùêÖ3. (a) {(ùë•1, ùë•2, ùë•3) ‚àà ùêÖ3 ‚à∂ ùë•1 + 2ùë•2 + 3ùë•3 = 0} (b) {(ùë•1, ùë•2, ùë•3) ‚àà ùêÖ3 ‚à∂ ùë•1 + 2ùë•2 + 3ùë•3 = 4} (c) {(ùë•1, ùë•2, ùë•3) ‚àà ùêÖ3 ‚à∂ ùë•1ùë•2ùë•3 = 0} (d) {(ùë•1, ùë•2, ùë•3) ‚àà ùêÖ3 ‚à∂ ùë•1 = 5ùë•3} 2 Verify all assertions about subspaces in Example 1.35. 3 Show that the set of differentiable real-valued functions ùëì on the interval (‚àí4, 4)such that ùëì ‚Ä≤(‚àí1) = 3 ùëì (2)is a subspace of ùêë(‚àí4, 4). 4 Suppose ùëè ‚àà ùêë. Show that the set of continuous real-valued functions ùëì on the interval [0, 1]such that ‚à´1 0 ùëì = ùëè is a subspace of ùêë[0, 1] if and only if ùëè = 0. 5 Is ùêë2 a subspace of the complex vector space ùêÇ 2? 6 (a) Is {(ùëé, ùëè, ùëê) ‚àà ùêë3 ‚à∂ ùëé3 = ùëè3}a subspace of ùêë3? (b) Is {(ùëé, ùëè, ùëê) ‚àà ùêÇ3 ‚à∂ ùëé3 = ùëè3}a subspace of ùêÇ 3? 7 Prove or give a counterexample: If ùëà is a nonempty subset of ùêë2 such that ùëà is closed under addition and under taking additive inverses (meaning ‚àíùë¢ ‚àà ùëà whenever ùë¢ ‚àà ùëà), then ùëà is a subspace of ùêë2. 8 Give an example of a nonempty subset ùëà of ùêë2 such that ùëà is closed under scalar multiplication, but ùëà is not a subspace of ùêë2. 9 A function ùëì‚à∂ ùêë ‚Üí ùêë is called periodic if there exists a positive number ùëù such that ùëì (ùë•) = ùëì (ùë• + ùëù) for all ùë• ‚àà ùêë. Is the set of periodic functions from ùêë to ùêë a subspace of ùêëùêë? Explain. 10 Suppose ùëâ1 and ùëâ2 are subspaces of ùëâ. Prove that the intersection ùëâ1 ‚à© ùëâ2 is a subspace of ùëâ. Section 1C Subspaces 25 11 Prove that the intersection of every collection of subspaces of ùëâ is a subspace of ùëâ. 12 Prove that the union of two subspaces of ùëâ is a subspace of ùëâ if and only if one of the subspaces is contained in the other. 13 Prove that the union of three subspaces of ùëâ is a subspace of ùëâ if and only if one of the subspaces contains the other two. This exercise is surprisingly harder than Exercise 12, possibly because this exercise is not true if we replace ùêÖ with a field containing only two elements. 14 Suppose ùëà = {(ùë•, ‚àíùë•, 2ùë•) ‚àà ùêÖ 3 ‚à∂ ùë• ‚àà ùêÖ} and ùëä = {(ùë•, ùë•, 2ùë•) ‚àà ùêÖ 3 ‚à∂ ùë• ‚àà ùêÖ}. Describe ùëà + ùëä using symbols, and also give a description of ùëà + ùëä that uses no symbols. 15 Suppose ùëà is a subspace of ùëâ. What is ùëà + ùëà? 16 Is the operation of addition on the subspaces of ùëâ commutative? In other words, if ùëà and ùëä are subspaces of ùëâ, is ùëà + ùëä = ùëä + ùëà? 17 Is the operation of addition on the subspaces of ùëâ associative? In other words, if ùëâ1, ùëâ2, ùëâ3 are subspaces of ùëâ, is (ùëâ1 + ùëâ2) + ùëâ3 = ùëâ1 + (ùëâ2 + ùëâ3)? 18 Does the operation of addition on the subspaces of ùëâ have an additive identity? Which subspaces have additive inverses? 19 Prove or give a counterexample: If ùëâ1, ùëâ2, ùëà are subspaces of ùëâ such that ùëâ1 + ùëà = ùëâ2 + ùëà, then ùëâ1 = ùëâ2. 20 Suppose ùëà = {(ùë•, ùë•, ùë¶, ùë¶) ‚àà ùêÖ4 ‚à∂ ùë•, ùë¶ ‚àà ùêÖ}. Find a subspace ùëä of ùêÖ4 such that ùêÖ4 = ùëà ‚äï ùëä. 21 Suppose ùëà = {(ùë•, ùë¶, ùë• + ùë¶, ùë• ‚àí ùë¶, 2ùë•) ‚àà ùêÖ 5 ‚à∂ ùë•, ùë¶ ‚àà ùêÖ}. Find a subspace ùëä of ùêÖ5 such that ùêÖ5 = ùëà ‚äï ùëä. 22 Suppose ùëà = {(ùë•, ùë¶, ùë• + ùë¶, ùë• ‚àí ùë¶, 2ùë•) ‚àà ùêÖ 5 ‚à∂ ùë•, ùë¶ ‚àà ùêÖ}. Find three subspaces ùëä1, ùëä2, ùëä3 of ùêÖ5, none of which equals {0}, such that ùêÖ5 = ùëà ‚äï ùëä1 ‚äï ùëä2 ‚äï ùëä3. 26 Chapter 1 Vector Spaces 23 Prove or give a counterexample: If ùëâ1, ùëâ2, ùëà are subspaces of ùëâ such that ùëâ = ùëâ1 ‚äï ùëà and ùëâ = ùëâ2 ‚äï ùëà, then ùëâ1 = ùëâ2. Hint: When trying to discover whether a conjecture in linear algebra is true or false, it is often useful to start by experimenting in ùêÖ2. 24 A function ùëì‚à∂ ùêë ‚Üí ùêë is called even if ùëì (‚àíùë•) = ùëì (ùë•) for all ùë• ‚àà ùêë. A function ùëì‚à∂ ùêë ‚Üí ùêë is called odd if ùëì (‚àíùë•) = ‚àí ùëì (ùë•) for all ùë• ‚àà ùêë. Let ùëâe denote the set of real-valued even functions on ùêë and let ùëâo denote the set of real-valued odd functions on ùêë. Show that ùêëùêë = ùëâe ‚äï ùëâo. Open Access This chapter is licensed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (https://creativecommons.org/licenses/by-nc/4.0), which permits any noncommercial use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to original author and source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this chapter are included in the chapter‚Äôs Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter‚Äôs Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. Chapter 2 Finite-Dimensional Vector Spaces In the last chapter we learned about vector spaces. Linear algebra focuses not on arbitrary vector spaces, but on finite-dimensional vector spaces, which we introduce in this chapter. We begin this chapter by considering linear combinations of lists of vectors. This leads us to the crucial concept of linear independence. The linear dependence lemma will become one of our most useful tools. A list of vectors in a vector space that is small enough to be linearly independent and big enough so the linear combinations of the list fill up the vector space is called a basis of the vector space. We will see that every basis of a vector space has the same length, which will allow us to define the dimension of a vector space. This chapter ends with a formula for the dimension of the sum of two subspaces. standing assumptions for this chapter ‚Ä¢ ùêÖ denotes ùêë or ùêÇ. ‚Ä¢ ùëâ denotes a vector space over ùêÖ. The main building of the Institute for Advanced Study, in Princeton, New Jersey. Paul Halmos (1916‚Äì2006) wrote the first modern linear algebra book in this building. Halmos‚Äôs linear algebra book was published in 1942 (second edition published in 1958). The title of Halmos‚Äôs book was the same as the title of this chapter. 27 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0_2 ¬© Sheldon Axler 2024 28 Chapter 2 Finite-Dimensional Vector Spaces 2A Span and Linear Independence We have been writing lists of numbers surrounded by parentheses, and we will continue to do so for elements of ùêÖùëõ; for example, (2, ‚àí7, 8) ‚àà ùêÖ 3. However, now we need to consider lists of vectors (which may be elements of ùêÖùëõ or of other vector spaces). To avoid confusion, we will usually write lists of vectors without surrounding parentheses. For example, (4, 1, 6), (9, 5, 7)is a list of length two of vectors in ùêë3. 2.1 notation: list of vectors We will usually write lists of vectors without surrounding parentheses. Linear Combinations and Span A sum of scalar multiples of the vectors in a list is called a linear combination of the list. Here is the formal definition. 2.2 definition: linear combination A linear combination of a list ùë£1, ‚Ä¶, ùë£ùëö of vectors in ùëâ is a vector of the form ùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö, where ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ. 2.3 example: linear combinations in ùêë3 ‚Ä¢ (17, ‚àí4, 2)is a linear combination of (2, 1, ‚àí3), (1, ‚àí2, 4), which is a list of length two of vectors in ùêë3, because (17, ‚àí4, 2) = 6(2, 1, ‚àí3)+ 5(1, ‚àí2, 4). ‚Ä¢ (17, ‚àí4, 5)is not a linear combination of (2, 1, ‚àí3), (1, ‚àí2, 4), which is a list of length two of vectors in ùêë3, because there do not exist numbers ùëé1, ùëé2 ‚àà ùêÖ such that (17, ‚àí4, 5) = ùëé1(2, 1, ‚àí3)+ ùëé2(1, ‚àí2, 4). In other words, the system of equations 17 = 2ùëé1 + ùëé2 ‚àí4 = ùëé1 ‚àí 2ùëé2 5 = ‚àí3ùëé1 + 4ùëé2 has no solutions (as you should verify). Section 2A Span and Linear Independence 29 2.4 definition: span The set of all linear combinations of a list of vectors ùë£1, ‚Ä¶, ùë£ùëö in ùëâ is called the span of ùë£1, ‚Ä¶, ùë£ùëö, denoted by span(ùë£1, ‚Ä¶, ùë£ùëö). In other words, span(ùë£1, ‚Ä¶, ùë£ùëö) = {ùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö ‚à∂ ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ}. The span of the empty list ( ) is defined to be{0}. 2.5 example: span The previous example shows that in ùêÖ3, ‚Ä¢ (17, ‚àí4, 2) ‚ààspan((2, 1, ‚àí3), (1, ‚àí2, 4)); ‚Ä¢ (17, ‚àí4, 5) ‚àâspan((2, 1, ‚àí3), (1, ‚àí2, 4)). Some mathematicians use the term linear span, which means the same as span. 2.6 span is the smallest containing subspace The span of a list of vectors in ùëâ is the smallest subspace of ùëâ containing all vectors in the list. Proof Suppose ùë£1, ‚Ä¶, ùë£ùëö is a list of vectors in ùëâ. First we show that span(ùë£1, ‚Ä¶, ùë£ùëö) is a subspace of ùëâ. The additive identity is in span(ùë£1, ‚Ä¶, ùë£ùëö) because 0 = 0ùë£1 + ‚ãØ + 0ùë£ùëö. Also, span(ùë£1, ‚Ä¶, ùë£ùëö) is closed under addition because (ùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö) + (ùëê1ùë£1 + ‚ãØ + ùëêùëöùë£ùëö) = (ùëé1 + ùëê1)ùë£1 + ‚ãØ + (ùëéùëö + ùëêùëö)ùë£ùëö. Furthermore, span(ùë£1, ‚Ä¶, ùë£ùëö) is closed under scalar multiplication because ùúÜ(ùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö) = ùúÜùëé1ùë£1 + ‚ãØ + ùúÜùëéùëöùë£ùëö. Thus span(ùë£1, ‚Ä¶, ùë£ùëö) is a subspace of ùëâ (by 1.34). Each ùë£ùëò is a linear combination of ùë£1, ‚Ä¶, ùë£ùëö (to show this, set ùëéùëò = 1and let the other ùëé‚Äôs in 2.2 equal 0). Thus span(ùë£1, ‚Ä¶, ùë£ùëö) contains each ùë£ùëò. Conversely, because subspaces are closed under scalar multiplication and addition, every sub- space of ùëâ that contains each ùë£ùëò contains span(ùë£1, ‚Ä¶, ùë£ùëö). Thus span(ùë£1, ‚Ä¶, ùë£ùëö) is the smallest subspace of ùëâ containing all the vectors ùë£1, ‚Ä¶, ùë£ùëö. 2.7 definition:spans If span(ùë£1, ‚Ä¶, ùë£ùëö) equals ùëâ, we say that the list ùë£1, ‚Ä¶, ùë£ùëö spans ùëâ. 30 Chapter 2 Finite-Dimensional Vector Spaces 2.8 example: a list that spans ùêÖùëõ Suppose ùëõ is a positive integer. We want to show that (1, 0, ‚Ä¶, 0), (0, 1, 0, ‚Ä¶, 0), ‚Ä¶, (0, ‚Ä¶, 0, 1) spans ùêÖùëõ. Here the ùëòth vector in the list above has 1in the ùëòth slot and 0in all other slots. Suppose (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêÖùëõ. Then (ùë•1, ‚Ä¶, ùë•ùëõ) = ùë•1(1, 0, ‚Ä¶, 0)+ ùë•2(0, 1, 0, ‚Ä¶, 0)+ ‚ãØ + ùë•ùëõ(0, ‚Ä¶, 0, 1). Thus (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà span((1, 0, ‚Ä¶, 0), (0, 1, 0, ‚Ä¶, 0), ‚Ä¶, (0, ‚Ä¶, 0, 1)), as desired. Now we can make one of the key definitions in linear algebra. 2.9 definition: finite-dimensional vector space A vector space is called finite-dimensional if some list of vectors in it spans the space. Recall that by definition every list has finite length. Example 2.8 above shows that ùêÖùëõ is a finite-dimensional vector space for every positive integer ùëõ. The definition of a polynomial is no doubt already familiar to you. 2.10 definition: polynomial, ùí´(ùêÖ) ‚Ä¢ A function ùëù‚à∂ ùêÖ ‚Üí ùêÖ is called a polynomial with coefficients in ùêÖ if there exist ùëé0, ‚Ä¶, ùëéùëö ‚àà ùêÖ such that ùëù(ùëß) = ùëé0 + ùëé1ùëß + ùëé2ùëß2 + ‚ãØ + ùëéùëöùëßùëö for all ùëß ‚àà ùêÖ. ‚Ä¢ ùí´(ùêÖ) is the set of all polynomials with coefficients in ùêÖ. With the usual operations of addition and scalar multiplication, ùí´(ùêÖ) is a vector space over ùêÖ, as you should verify. Hence ùí´(ùêÖ) is a subspace of ùêÖùêÖ, the vector space of functions from ùêÖ to ùêÖ. If a polynomial (thought of as a function from ùêÖ to ùêÖ) is represented by two sets of coefficients, then subtracting one representation of the polynomial from the other produces a polynomial that is identically zero as a function on ùêÖ and hence has all zero coefficients (if you are unfamiliar with this fact, just believe it for now; we will prove it later‚Äîsee 4.8). Conclusion: the coefficients of a polynomial are uniquely determined by the polynomial. Thus the next definition uniquely defines the degree of a polynomial. Section 2A Span and Linear Independence 31 2.11 definition: degree of a polynomial, deg ùëù ‚Ä¢ A polynomial ùëù ‚àà ùí´(ùêÖ) is said to have degree ùëö if there exist scalars ùëé0, ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ with ùëéùëö ‚â† 0such that for every ùëß ‚àà ùêÖ, we have ùëù(ùëß) = ùëé0 + ùëé1ùëß + ‚ãØ + ùëéùëöùëß ùëö. ‚Ä¢ The polynomial that is identically 0is said to have degree ‚àí‚àû. ‚Ä¢ The degree of a polynomial ùëù is denoted by deg ùëù. In the next definition, we use the convention that‚àí‚àû < ùëö, which means that the polynomial 0is in ùí´ùëö(ùêÖ). 2.12 notation: ùí´ùëö(ùêÖ) For ùëö a nonnegative integer, ùí´ùëö(ùêÖ) denotes the set of all polynomials with coefficients in ùêÖ and degree at most ùëö. If ùëö is a nonnegative integer, then ùí´ùëö(ùêÖ) = span(1, ùëß, ‚Ä¶, ùëß ùëö) [here we slightly abuse notation by letting ùëß ùëò denote a function]. Thus ùí´ùëö(ùêÖ) is a finite-dimensional vector space for each nonnegative integer ùëö. 2.13 definition: infinite-dimensional vector space A vector space is called infinite-dimensional if it is not finite-dimensional. 2.14 example: ùí´(ùêÖ) is infinite-dimensional. Consider any list of elements of ùí´(ùêÖ). Let ùëö denote the highest degree of the polynomials in this list. Then every polynomial in the span of this list has degree at most ùëö. Thus ùëß ùëö + 1 is not in the span of our list. Hence no list spans ùí´(ùêÖ). Thus ùí´(ùêÖ) is infinite-dimensional. Linear Independence Suppose ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ and ùë£ ‚àà span(ùë£1, ‚Ä¶, ùë£ùëö). By the definition of span, there exist ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ such that ùë£ = ùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö. Consider the question of whether the choice of scalars in the equation above is unique. Suppose ùëê1, ‚Ä¶, ùëêùëö is another set of scalars such that ùë£ = ùëê1ùë£1 + ‚ãØ + ùëêùëöùë£ùëö. Subtracting the last two equations, we have 0 = (ùëé1 ‚àí ùëê1)ùë£1 + ‚ãØ + (ùëéùëö ‚àí ùëêùëö)ùë£ùëö. 32 Chapter 2 Finite-Dimensional Vector Spaces Thus we have written 0as a linear combination of (ùë£1, ‚Ä¶, ùë£ùëö). If the only way to do this is by using 0for all the scalars in the linear combination, then each ùëéùëò ‚àí ùëêùëò equals 0, which means that each ùëéùëò equals ùëêùëò (and thus the choice of scalars was indeed unique). This situation is so important that we give it a special name‚Äîlinear independence‚Äîwhich we now define. 2.15 definition: linearly independent ‚Ä¢ A list ùë£1, ‚Ä¶, ùë£ùëö of vectors in ùëâ is called linearly independent if the only choice of ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ that makes ùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö = 0 is ùëé1 = ‚ãØ = ùëéùëö = 0. ‚Ä¢ The empty list ( ) is also declared to be linearly independent. The reasoning above shows that ùë£1, ‚Ä¶, ùë£ùëö is linearly independent if and only if each vector in span(ùë£1, ‚Ä¶, ùë£ùëö) has only one representation as a linear combination of ùë£1, ‚Ä¶, ùë£ùëö. 2.16 example:linearly independent lists (a) To see that the list (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0)is linearly independent in ùêÖ4, suppose ùëé1, ùëé2, ùëé3 ‚àà ùêÖ and ùëé1(1, 0, 0, 0)+ ùëé2(0, 1, 0, 0)+ ùëé3(0, 0, 1, 0) = (0, 0, 0, 0). Thus (ùëé1, ùëé2, ùëé3, 0) = (0, 0, 0, 0). Hence ùëé1 = ùëé2 = ùëé3 = 0. Thus the list (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0)is linearly independent in ùêÖ4. (b) Suppose ùëö is a nonnegative integer. To see that the list 1, ùëß, ‚Ä¶, ùëß ùëö is linearly independent in ùí´(ùêÖ), suppose ùëé0, ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ and ùëé0 + ùëé1ùëß + ‚ãØ + ùëéùëöùëßùëö = 0, where we think of both sides as elements of ùí´(ùêÖ). Then ùëé0 + ùëé1ùëß + ‚ãØ + ùëéùëöùëß ùëö = 0 for all ùëß ‚àà ùêÖ. As discussed earlier (and as follows from 4.8), this implies that ùëé0 = ùëé1 = ‚ãØ = ùëéùëö = 0. Thus 1, ùëß, ‚Ä¶, ùëß ùëö is a linearly independent list in ùí´(ùêÖ). (c) A list of length one in a vector space is linearly independent if and only if the vector in the list is not 0. (d) A list of length two in a vector space is linearly independent if and only if neither of the two vectors in the list is a scalar multiple of the other. Section 2A Span and Linear Independence 33 If some vectors are removed from a linearly independent list, the remaining list is also linearly independent, as you should verify. 2.17 definition:linearly dependent ‚Ä¢ A list of vectors in ùëâ is called linearly dependent if it is not linearly inde- pendent. ‚Ä¢ In other words, a list ùë£1, ‚Ä¶, ùë£ùëö of vectors in ùëâ is linearly dependent if there exist ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ, not all 0, such that ùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö = 0. 2.18 example: linearly dependent lists ‚Ä¢ (2, 3, 1), (1, ‚àí1, 2), (7, 3, 8)is linearly dependent in ùêÖ3 because 2(2, 3, 1)+ 3(1, ‚àí1, 2)+ (‚àí1)(7, 3, 8) = (0, 0, 0). ‚Ä¢ The list (2, 3, 1), (1, ‚àí1, 2), (7, 3, ùëê) is linearly dependent in ùêÖ3 if and only if ùëê = 8, as you should verify. ‚Ä¢ If some vector in a list of vectors in ùëâ is a linear combination of the other vectors, then the list is linearly dependent. (Proof: After writing one vector in the list as equal to a linear combination of the other vectors, move that vector to the other side of the equation, where it will be multiplied by ‚àí1.) ‚Ä¢ Every list of vectors in ùëâ containing the 0vector is linearly dependent. (This is a special case of the previous bullet point.) The next lemma is a terrific tool. It states that given a linearly dependent list of vectors, one of the vectors is in the span of the previous ones. Furthermore, we can throw out that vector without changing the span of the original list. 2.19 linear dependence lemma Suppose ùë£1, ‚Ä¶, ùë£ùëö is a linearly dependent list in ùëâ. Then there exists ùëò ‚àà {1, 2, ‚Ä¶, ùëö} such that ùë£ùëò ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1). Furthermore, if ùëò satisfies the condition above and theùëòth term is removed from ùë£1, ‚Ä¶, ùë£ùëö, then the span of the remaining list equals span(ùë£1, ‚Ä¶, ùë£ùëö). Proof Because the list ùë£1, ‚Ä¶, ùë£ùëö is linearly dependent, there exist numbers ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ, not all 0, such that ùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö = 0. Let ùëò be the largest element of {1, ‚Ä¶, ùëö} such that ùëéùëò ‚â† 0. Then ùë£ùëò = ‚àí ùëé1 ùëéùëò ùë£1 ‚àí ‚ãØ ‚àí ùëéùëò ‚àí 1 ùëéùëò ùë£ùëò ‚àí 1, which proves that ùë£ùëò ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1), as desired. 34 Chapter 2 Finite-Dimensional Vector Spaces Now suppose ùëò is any element of {1, ‚Ä¶, ùëö} such that ùë£ùëò ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1). Let ùëè1, ‚Ä¶, ùëèùëò ‚àí 1 ‚àà ùêÖ be such that 2.20 ùë£ùëò = ùëè1ùë£1 + ‚ãØ + ùëèùëò ‚àí 1ùë£ùëò ‚àí 1. Suppose ùë¢ ‚àà span(ùë£1, ‚Ä¶, ùë£ùëö). Then there exist ùëê1, ‚Ä¶, ùëêùëö ‚àà ùêÖ such that ùë¢ = ùëê1ùë£1 + ‚ãØ + ùëêùëöùë£ùëö. In the equation above, we can replace ùë£ùëò with the right side of 2.20, which shows that ùë¢ is in the span of the list obtained by removing the ùëòth term from ùë£1, ‚Ä¶, ùë£ùëö. Thus removing the ùëòth term of the list ùë£1, ‚Ä¶, ùë£ùëö does not change the span of the list. If ùëò = 1in the linear dependence lemma, then ùë£ùëò ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1) means that ùë£1 = 0, because span( ) = {0}. Note also that parts of the proof of the linear dependence lemma need to be modified ifùëò = 1. In general, the proofs in the rest of the book will not call attention to special cases that must be considered involving lists of length 0, the subspace {0}, or other trivial cases for which the result is true but needs a slightly different proof. Be sure to check these special cases yourself. 2.21 example: smallest ùëò in linear dependence lemma Consider the list (1, 2, 3), (6, 5, 4), (15, 16, 17), (8, 9, 7) in ùêë3. This list of length four is linearly dependent, as we will soon see. Thus the linear dependence lemma implies that there exists ùëò ‚àà {1, 2, 3, 4}such that the ùëòth vector in this list is a linear combination of the previous vectors in the list. Let‚Äôs see how to find the smallest value ofùëò that works. Taking ùëò = 1in the linear dependence lemma works if and only if the first vector in the list equals 0. Because (1, 2, 3)is not the 0vector, we cannot take ùëò = 1for this list. Taking ùëò = 2in the linear dependence lemma works if and only if the second vector in the list is a scalar multiple of the first vector. However, there does not exist ùëê ‚àà ùêë such that (6, 5, 4) = ùëê(1, 2, 3). Thus we cannot take ùëò = 2for this list. Taking ùëò = 3in the linear dependence lemma works if and only if the third vector in the list is a linear combination of the first two vectors. Thus for the list in this example, we want to know whether there exist ùëé, ùëè ‚àà ùêë such that (15, 16, 17) = ùëé(1, 2, 3)+ ùëè(6, 5, 4). The equation above is equivalent to a system of three linear equations in the two unknowns ùëé, ùëè. Using Gaussian elimination or appropriate software, we find that ùëé = 3, ùëè = 2is a solution of the equation above, as you can verify. Thus for the list in this example, taking ùëò = 3is the smallest value of ùëò that works in the linear dependence lemma. Section 2A Span and Linear Independence 35 Now we come to a key result. It says that no linearly independent list in ùëâ is longer than a spanning list in ùëâ. 2.22 length of linearly independent list ‚â§ length of spanning list In a finite-dimensional vector space, the length of every linearly independent list of vectors is less than or equal to the length of every spanning list of vectors. Proof Suppose that ùë¢1, ‚Ä¶, ùë¢ùëö is linearly independent in ùëâ. Suppose also that ùë§1, ‚Ä¶, ùë§ùëõ spans ùëâ. We need to prove that ùëö ‚â§ ùëõ. We do so through the process described below with ùëö steps; note that in each step we add one of the ùë¢‚Äôs and remove one of the ùë§‚Äôs. Step 1 Let ùêµ be the list ùë§1, ‚Ä¶, ùë§ùëõ, which spans ùëâ. Adjoining ùë¢1 at the beginning of this list produces a linearly dependent list (because ùë¢1 can be written as a linear combination of ùë§1, ‚Ä¶, ùë§ùëö). In other words, the list ùë¢1, ùë§1, ‚Ä¶, ùë§ùëõ is linearly dependent. Thus by the linear dependence lemma (2.19), one of the vectors in the list above is a linear combination of the previous vectors in the list. We know that ùë¢1 ‚â† 0 because the list ùë¢1, ‚Ä¶, ùë¢ùëö is linearly independent. Thus ùë¢1 is not in the span of the previous vectors in the list above (because ùë¢1 is not in {0}, which is the span of the empty list). Hence the linear dependence lemma implies that we can remove one of the ùë§‚Äôs so that the new list ùêµ (of length ùëõ) consisting of ùë¢1 and the remaining ùë§‚Äôs spans ùëâ. Step k, for k = 2, ‚Ä¶, m The list ùêµ (of length ùëõ) from step ùëò ‚àí 1spans ùëâ. In particular, ùë¢ùëò is in the span of the list ùêµ. Thus the list of length (ùëõ + 1)obtained by adjoining ùë¢ùëò to ùêµ, placing it just after ùë¢1, ‚Ä¶, ùë¢ùëò ‚àí 1, is linearly dependent. By the linear dependence lemma (2.19), one of the vectors in this list is in the span of the previous ones, and because ùë¢1, ‚Ä¶, ùë¢ùëò is linearly independent, this vector cannot be one of the ùë¢‚Äôs. Hence there still must be at least one remaining ùë§ at this step. We can remove from our new list (after adjoining ùë¢ùëò in the proper place) a ùë§ that is a linear combination of the previous vectors in the list, so that the new list ùêµ (of length ùëõ) consisting of ùë¢1, ‚Ä¶, ùë¢ùëò and the remaining ùë§‚Äôs spans ùëâ. After step ùëö, we have added all the ùë¢‚Äôs and the process stops. At each step as we add a ùë¢ to ùêµ, the linear dependence lemma implies that there is some ùë§ to remove. Thus there are at least as many ùë§‚Äôs as ùë¢‚Äôs. 36 Chapter 2 Finite-Dimensional Vector Spaces The next two examples show how the result above can be used to show, without any computations, that certain lists are not linearly independent and that certain lists do not span a given vector space. 2.23 example: no list of length 4is linearly independent in ùêë3 The list (1, 0, 0), (0, 1, 0), (0, 0, 1), which has length three, spans ùêë3. Thus no list of length larger than three is linearly independent in ùêë3. For example, we now know that (1, 2, 3), (4, 5, 8), (9, 6, 7), (‚àí3, 2, 8), which is a list of length four, is not linearly independent in ùêë3. 2.24 example: no list of length 3spans ùêë4 The list (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0), (0, 0, 0, 1), which has length four, is linearly independent in ùêë4. Thus no list of length less than four spans ùêë4. For example, we now know that (1, 2, 3, ‚àí5), (4, 5, 8, 3), (9, 6, 7, ‚àí1), which is a list of length three, does not span ùêë4. Our intuition suggests that every subspace of a finite-dimensional vector space should also be finite-dimensional. We now prove that this intuition is correct. 2.25 finite-dimensional subspaces Every subspace of a finite-dimensional vector space is finite-dimensional. Proof Suppose ùëâ is finite-dimensional andùëà is a subspace of ùëâ. We need to prove that ùëà is finite-dimensional. We do this through the following multistep construction. Step 1 If ùëà = {0}, then ùëà is finite-dimensional and we are done. Ifùëà ‚â† {0}, then choose a nonzero vector ùë¢1 ‚àà ùëà. Step k If ùëà = span(ùë¢1, ‚Ä¶, ùë¢ùëò ‚àí 1), then ùëà is finite-dimensional and we are done. If ùëà ‚â† span(ùë¢1, ‚Ä¶, ùë¢ùëò ‚àí 1), then choose a vector ùë¢ùëò ‚àà ùëà such that ùë¢ùëò ‚àâ span(ùë¢1, ‚Ä¶, ùë¢ùëò ‚àí 1). After each step, as long as the process continues, we have constructed a list of vectors such that no vector in this list is in the span of the previous vectors. Thus after each step we have constructed a linearly independent list, by the linear dependence lemma (2.19). This linearly independent list cannot be longer than any spanning list of ùëâ (by 2.22). Thus the process eventually terminates, which means that ùëà is finite-dimensional. Section 2A Span and Linear Independence 37 Exercises 2A 1 Find a list of four distinct vectors in ùêÖ3 whose span equals {(ùë•, ùë¶, ùëß) ‚àà ùêÖ3 ‚à∂ ùë• + ùë¶ + ùëß = 0}. 2 Prove or give a counterexample: If ùë£1, ùë£2, ùë£3, ùë£4 spans ùëâ, then the list ùë£1 ‚àí ùë£2, ùë£2 ‚àí ùë£3, ùë£3 ‚àí ùë£4, ùë£4 also spans ùëâ. 3 Suppose ùë£1, ‚Ä¶, ùë£ùëö is a list of vectors in ùëâ. For ùëò ‚àà {1, ‚Ä¶, ùëö}, let ùë§ùëò = ùë£1 + ‚ãØ + ùë£ùëò. Show that span(ùë£1, ‚Ä¶, ùë£ùëö) = span(ùë§1, ‚Ä¶, ùë§ùëö). 4 (a) Show that a list of length one in a vector space is linearly independent if and only if the vector in the list is not 0. (b) Show that a list of length two in a vector space is linearly independent if and only if neither of the two vectors in the list is a scalar multiple of the other. 5 Find a number ùë° such that (3, 1, 4), (2, ‚àí3, 5), (5, 9, ùë°) is not linearly independent in ùêë3. 6 Show that the list (2, 3, 1), (1, ‚àí1, 2), (7, 3, ùëê) is linearly dependent in ùêÖ3 if and only if ùëê = 8. 7 (a) Show that if we think of ùêÇ as a vector space over ùêë, then the list 1+ ùëñ, 1 ‚àí ùëñis linearly independent. (b) Show that if we think of ùêÇ as a vector space over ùêÇ, then the list 1+ ùëñ, 1 ‚àí ùëñis linearly dependent. 8 Suppose ùë£1, ùë£2, ùë£3, ùë£4 is linearly independent in ùëâ. Prove that the list ùë£1 ‚àí ùë£2, ùë£2 ‚àí ùë£3, ùë£3 ‚àí ùë£4, ùë£4 is also linearly independent. 9 Prove or give a counterexample: If ùë£1, ùë£2, ‚Ä¶, ùë£ùëö is a linearly independent list of vectors in ùëâ, then 5ùë£1 ‚àí 4ùë£2, ùë£2, ùë£3, ‚Ä¶, ùë£ùëö is linearly independent. 38 Chapter 2 Finite-Dimensional Vector Spaces 10 Prove or give a counterexample: If ùë£1, ùë£2, ‚Ä¶, ùë£ùëö is a linearly independent list of vectors in ùëâ and ùúÜ ‚àà ùêÖ with ùúÜ ‚â† 0, then ùúÜùë£1, ùúÜùë£2, ‚Ä¶, ùúÜùë£ùëö is linearly independent. 11 Prove or give a counterexample: If ùë£1, ‚Ä¶, ùë£ùëö and ùë§1, ‚Ä¶, ùë§ùëö are linearly independent lists of vectors in ùëâ, then the list ùë£1 + ùë§1, ‚Ä¶, ùë£ùëö + ùë§ùëö is linearly independent. 12 Suppose ùë£1, ‚Ä¶, ùë£ùëö is linearly independent in ùëâ and ùë§ ‚àà ùëâ. Prove that if ùë£1 + ùë§, ‚Ä¶, ùë£ùëö + ùë§ is linearly dependent, then ùë§ ‚àà span(ùë£1, ‚Ä¶, ùë£ùëö). 13 Suppose ùë£1, ‚Ä¶, ùë£ùëö is linearly independent in ùëâ and ùë§ ‚àà ùëâ. Show that ùë£1, ‚Ä¶, ùë£ùëö, ùë§ is linearly independent ‚ü∫ ùë§ ‚àâ span(ùë£1, ‚Ä¶, ùë£ùëö). 14 Suppose ùë£1, ‚Ä¶, ùë£ùëö is a list of vectors in ùëâ. For ùëò ‚àà {1, ‚Ä¶, ùëö}, let ùë§ùëò = ùë£1 + ‚ãØ + ùë£ùëò. Show that the list ùë£1, ‚Ä¶, ùë£ùëö is linearly independent if and only if the list ùë§1, ‚Ä¶, ùë§ùëö is linearly independent. 15 Explain why there does not exist a list of six polynomials that is linearly independent in ùí´4(ùêÖ). 16 Explain why no list of four polynomials spans ùí´4(ùêÖ). 17 Prove that ùëâ is infinite-dimensional if and only if there is a sequenceùë£1, ùë£2, ‚Ä¶ of vectors in ùëâ such that ùë£1, ‚Ä¶, ùë£ùëö is linearly independent for every positive integer ùëö. 18 Prove that ùêÖ‚àû is infinite-dimensional. 19 Prove that the real vector space of all continuous real-valued functions on the interval [0, 1]is infinite-dimensional. 20 Suppose ùëù0, ùëù1, ‚Ä¶, ùëùùëö are polynomials in ùí´ùëö(ùêÖ) such that ùëùùëò(2) = 0for each ùëò ‚àà {0, ‚Ä¶, ùëö}. Prove that ùëù0, ùëù1, ‚Ä¶, ùëùùëö is not linearly independent in ùí´ùëö(ùêÖ). Open Access This chapter is licensed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (https://creativecommons.org/licenses/by-nc/4.0), which permits any noncommercial use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to original author and source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this chapter are included in the chapter‚Äôs Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter‚Äôs Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. Section 2B Bases 39 2B Bases In the previous section, we discussed linearly independent lists and we also discussed spanning lists. Now we bring these concepts together by considering lists that have both properties. 2.26 definition:basis A basis of ùëâ is a list of vectors in ùëâ that is linearly independent and spans ùëâ. 2.27 example:bases (a) The list (1, 0, ‚Ä¶, 0), (0, 1, 0, ‚Ä¶, 0), ‚Ä¶, (0, ‚Ä¶, 0, 1)is a basis of ùêÖùëõ, called the standard basis of ùêÖùëõ. (b) The list (1, 2), (3, 5)is a basis of ùêÖ2. Note that this list has length two, which is the same as the length of the standard basis of ùêÖ2. In the next section, we will see that this is not a coincidence. (c) The list (1, 2, ‚àí4), (7, ‚àí5, 6)is linearly independent in ùêÖ3 but is not a basis of ùêÖ3 because it does not span ùêÖ3. (d) The list (1, 2), (3, 5), (4, 13)spans ùêÖ2 but is not a basis of ùêÖ2 because it is not linearly independent. (e) The list (1, 1, 0), (0, 0, 1)is a basis of {(ùë•, ùë•, ùë¶) ‚àà ùêÖ3 ‚à∂ ùë•, ùë¶ ‚àà ùêÖ}. (f) The list (1, ‚àí1, 0), (1, 0, ‚àí1)is a basis of {(ùë•, ùë¶, ùëß) ‚àà ùêÖ3 ‚à∂ ùë• + ùë¶ + ùëß = 0}. (g) The list 1, ùëß, ‚Ä¶, ùëß ùëö is a basis of ùí´ùëö(ùêÖ), called the standard basis of ùí´ùëö(ùêÖ). In addition to the standard basis, ùêÖùëõ has many other bases. For example, (7, 5), (‚àí4, 9) and (1, 2), (3, 5) are both bases of ùêÖ2. The next result helps explain why bases are useful. Recall that ‚Äúuniquely‚Äù means ‚Äúin only one way‚Äù. 2.28 criterion for basis A list ùë£1, ‚Ä¶, ùë£ùëõ of vectors in ùëâ is a basis of ùëâ if and only if every ùë£ ‚àà ùëâ can be written uniquely in the form 2.29 ùë£ = ùëé1ùë£1 + ‚ãØ + ùëéùëõùë£ùëõ, where ùëé1, ‚Ä¶, ùëéùëõ ‚àà ùêÖ. 40 Chapter 2 Finite-Dimensional Vector Spaces This proof is essentially a repetition of the ideas that led us to the definition of linear independence. Proof First suppose that ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Let ùë£ ‚àà ùëâ. Because ùë£1, ‚Ä¶, ùë£ùëõ spans ùëâ, there exist ùëé1, ‚Ä¶, ùëéùëõ ‚àà ùêÖ such that 2.29 holds. To show that the repre- sentation in 2.29 is unique, suppose ùëê1, ‚Ä¶, ùëêùëõ are scalars such that we also have ùë£ = ùëê1ùë£1 + ‚ãØ + ùëêùëõùë£ùëõ. Subtracting the last equation from 2.29, we get 0 = (ùëé1 ‚àí ùëê1)ùë£1 + ‚ãØ + (ùëéùëõ ‚àí ùëêùëõ)ùë£ùëõ. This implies that each ùëéùëò ‚àí ùëêùëò equals 0(because ùë£1, ‚Ä¶, ùë£ùëõ is linearly independent). Hence ùëé1 = ùëê1, ‚Ä¶, ùëéùëõ = ùëêùëõ. We have the desired uniqueness, completing the proof in one direction. For the other direction, suppose every ùë£ ‚àà ùëâ can be written uniquely in the form given by 2.29. This implies that the list ùë£1, ‚Ä¶, ùë£ùëõ spans ùëâ. To show that ùë£1, ‚Ä¶, ùë£ùëõ is linearly independent, suppose ùëé1, ‚Ä¶, ùëéùëõ ‚àà ùêÖ are such that 0 = ùëé1ùë£1 + ‚ãØ + ùëéùëõùë£ùëõ. The uniqueness of the representation 2.29 (taking ùë£ = 0) now implies that ùëé1 = ‚ãØ = ùëéùëõ = 0. Thus ùë£1, ‚Ä¶, ùë£ùëõ is linearly independent and hence is a basis of ùëâ. A spanning list in a vector space may not be a basis because it is not linearly independent. Our next result says that given any spanning list, some (possibly none) of the vectors in it can be discarded so that the remaining list is linearly independent and still spans the vector space. As an example in the vector space ùêÖ2, if the procedure in the proof below is applied to the list (1, 2), (3, 6), (4, 7), (5, 9), then the second and fourth vectors will be removed. This leaves (1, 2), (4, 7), which is a basis of ùêÖ2. 2.30 every spanning list contains a basis Every spanning list in a vector space can be reduced to a basis of the vector space. Proof Suppose ùë£1, ‚Ä¶, ùë£ùëõ spans ùëâ. We want to remove some of the vectors from ùë£1, ‚Ä¶, ùë£ùëõ so that the remaining vectors form a basis of ùëâ. We do this through the multistep process described below. Start with ùêµ equal to the list ùë£1, ‚Ä¶, ùë£ùëõ. Step 1 If ùë£1 = 0, then delete ùë£1 from ùêµ. If ùë£1 ‚â† 0, then leave ùêµ unchanged. Step k If ùë£ùëò is in span(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1), then delete ùë£ùëò from the list ùêµ. If ùë£ùëò is not in span(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1), then leave ùêµ unchanged. Section 2B Bases 41 Stop the process after step ùëõ, getting a list ùêµ. This list ùêµ spans ùëâ because our original list spanned ùëâ and we have discarded only vectors that were already in the span of the previous vectors. The process ensures that no vector in ùêµ is in the span of the previous ones. Thus ùêµ is linearly independent, by the linear dependence lemma (2.19). Hence ùêµ is a basis of ùëâ. We now come to an important corollary of the previous result. 2.31 basis of finite-dimensional vector space Every finite-dimensional vector space has a basis. Proof By definition, a finite-dimensional vector space has a spanning list. The previous result tells us that each spanning list can be reduced to a basis. Our next result is in some sense a dual of 2.30, which said that every spanning list can be reduced to a basis. Now we show that given any linearly independent list, we can adjoin some additional vectors (this includes the possibility of adjoining no additional vectors) so that the extended list is still linearly independent but also spans the space. 2.32 every linearly independent list extends to a basis Every linearly independent list of vectors in a finite-dimensional vector space can be extended to a basis of the vector space. Proof Suppose ùë¢1, ‚Ä¶, ùë¢ùëö is linearly independent in a finite-dimensional vector space ùëâ. Let ùë§1, ‚Ä¶, ùë§ùëõ be a list of vectors in ùëâ that spans ùëâ. Thus the list ùë¢1, ‚Ä¶, ùë¢ùëö, ùë§1, ‚Ä¶, ùë§ùëõ spans ùëâ. Applying the procedure of the proof of 2.30 to reduce this list to a basis of ùëâ produces a basis consisting of the vectors ùë¢1, ‚Ä¶, ùë¢ùëö and some of the ùë§‚Äôs (none of the ùë¢‚Äôs get deleted in this procedure because ùë¢1, ‚Ä¶, ùë¢ùëö is linearly independent). As an example in ùêÖ3, suppose we start with the linearly independent list (2, 3, 4), (9, 6, 8). If we take ùë§1, ùë§2, ùë§3 to be the standard basis of ùêÖ3, then applying the procedure in the proof above produces the list (2, 3, 4), (9, 6, 8), (0, 1, 0), which is a basis of ùêÖ3. Using the same ideas but more ad- vanced tools, the next result can be proved without the hypothesis that ùëâ is finite-dimensional. As an application of the result above, we now show that every subspace of a finite-dimensional vector space can be paired with another subspace to form a direct sum of the whole space. 42 Chapter 2 Finite-Dimensional Vector Spaces 2.33 every subspace of ùëâ is part of a direct sum equal to ùëâ Suppose ùëâ is finite-dimensional andùëà is a subspace of ùëâ. Then there is a subspace ùëä of ùëâ such that ùëâ = ùëà ‚äï ùëä. Proof Because ùëâ is finite-dimensional, so isùëà (see 2.25). Thus there is a basis ùë¢1, ‚Ä¶, ùë¢ùëö of ùëà (by 2.31). Of course ùë¢1, ‚Ä¶, ùë¢ùëö is a linearly independent list of vectors in ùëâ. Hence this list can be extended to a basis ùë¢1, ‚Ä¶, ùë¢ùëö, ùë§1, ‚Ä¶, ùë§ùëõ of ùëâ (by 2.32). Let ùëä = span(ùë§1, ‚Ä¶, ùë§ùëõ). To prove that ùëâ = ùëà ‚äï ùëä, by 1.46 we only need to show that ùëâ = ùëà + ùëä and ùëà ‚à© ùëä = {0}. To prove the first equation above, supposeùë£ ‚àà ùëâ. Then, because the list ùë¢1, ‚Ä¶, ùë¢ùëö, ùë§1, ‚Ä¶, ùë§ùëõ spans ùëâ, there exist ùëé1, ‚Ä¶, ùëéùëö, ùëè1, ‚Ä¶, ùëèùëõ ‚àà ùêÖ such that ùë£ = ùëé1ùë¢1 + ‚ãØ + ùëéùëöùë¢ùëö‚èü‚èü‚èü‚èü‚èü‚èü‚èü ùë¢ + ùëè1ùë§1 + ‚ãØ + ùëèùëõùë§ùëõ‚èü‚èü‚èü‚èü‚èü‚èü‚èü ùë§ . We have ùë£ = ùë¢ + ùë§, where ùë¢ ‚àà ùëà and ùë§ ‚àà ùëä are defined as above. Thus ùë£ ‚àà ùëà + ùëä, completing the proof that ùëâ = ùëà + ùëä. To show that ùëà ‚à© ùëä = {0}, suppose ùë£ ‚àà ùëà ‚à© ùëä. Then there exist scalars ùëé1, ‚Ä¶, ùëéùëö, ùëè1, ‚Ä¶, ùëèùëõ ‚àà ùêÖ such that ùë£ = ùëé1ùë¢1 + ‚ãØ + ùëéùëöùë¢ùëö = ùëè1ùë§1 + ‚ãØ + ùëèùëõùë§ùëõ. Thus ùëé1ùë¢1 + ‚ãØ + ùëéùëöùë¢ùëö ‚àí ùëè1ùë§1 ‚àí ‚ãØ ‚àí ùëèùëõùë§ùëõ = 0. Because ùë¢1, ‚Ä¶, ùë¢ùëö, ùë§1, ‚Ä¶, ùë§ùëõ is linearly independent, this implies that ùëé1 = ‚ãØ = ùëéùëö = ùëè1 = ‚ãØ = ùëèùëõ = 0. Thus ùë£ = 0, completing the proof that ùëà ‚à© ùëä = {0}. Exercises 2B 1 Find all vector spaces that have exactly one basis. 2 Verify all assertions in Example 2.27. 3 (a) Let ùëà be the subspace of ùêë5 defined by ùëà = {(ùë•1, ùë•2, ùë•3, ùë•4, ùë•5) ‚àà ùêë5 ‚à∂ ùë•1 = 3ùë•2 and ùë•3 = 7ùë•4}. Find a basis of ùëà. (b) Extend the basis in (a) to a basis of ùêë5. (c) Find a subspace ùëä of ùêë5 such that ùêë5 = ùëà ‚äï ùëä. Section 2B Bases 43 4 (a) Let ùëà be the subspace of ùêÇ 5 defined by ùëà = {(ùëß1, ùëß2, ùëß3, ùëß4, ùëß5) ‚àà ùêÇ5 ‚à∂ 6ùëß1 = ùëß2 and ùëß3 + 2ùëß4 + 3ùëß5 = 0}. Find a basis of ùëà. (b) Extend the basis in (a) to a basis of ùêÇ 5. (c) Find a subspace ùëä of ùêÇ 5 such that ùêÇ 5 = ùëà ‚äï ùëä. 5 Suppose ùëâ is finite-dimensional andùëà, ùëä are subspaces of ùëâ such that ùëâ = ùëà + ùëä. Prove that there exists a basis of ùëâ consisting of vectors in ùëà ‚à™ ùëä. 6 Prove or give a counterexample: If ùëù0, ùëù1, ùëù2, ùëù3 is a list in ùí´3(ùêÖ) such that none of the polynomials ùëù0, ùëù1, ùëù2, ùëù3 has degree 2, then ùëù0, ùëù1, ùëù2, ùëù3 is not a basis of ùí´3(ùêÖ). 7 Suppose ùë£1, ùë£2, ùë£3, ùë£4 is a basis of ùëâ. Prove that ùë£1 + ùë£2, ùë£2 + ùë£3, ùë£3 + ùë£4, ùë£4 is also a basis of ùëâ. 8 Prove or give a counterexample: If ùë£1, ùë£2, ùë£3, ùë£4 is a basis of ùëâ and ùëà is a subspace of ùëâ such that ùë£1, ùë£2 ‚àà ùëà and ùë£3 ‚àâ ùëà and ùë£4 ‚àâ ùëà, then ùë£1, ùë£2 is a basis of ùëà. 9 Suppose ùë£1, ‚Ä¶, ùë£ùëö is a list of vectors in ùëâ. For ùëò ‚àà {1, ‚Ä¶, ùëö}, let ùë§ùëò = ùë£1 + ‚ãØ + ùë£ùëò. Show that ùë£1, ‚Ä¶, ùë£ùëö is a basis of ùëâ if and only if ùë§1, ‚Ä¶, ùë§ùëö is a basis of ùëâ. 10 Suppose ùëà and ùëä are subspaces of ùëâ such that ùëâ = ùëà ‚äï ùëä. Suppose also that ùë¢1, ‚Ä¶, ùë¢ùëö is a basis of ùëà and ùë§1, ‚Ä¶, ùë§ùëõ is a basis of ùëä. Prove that ùë¢1, ‚Ä¶, ùë¢ùëö, ùë§1, ‚Ä¶, ùë§ùëõ is a basis of ùëâ. 11 Suppose ùëâ is a real vector space. Show that if ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ (as a real vector space), then ùë£1, ‚Ä¶, ùë£ùëõ is also a basis of the complexificationùëâùêÇ (as a complex vector space). See Exercise 8 in Section 1B for the definition of the complexification ùëâùêÇ. 44 Chapter 2 Finite-Dimensional Vector Spaces 2C Dimension Although we have been discussing finite-dimensional vector spaces, we have not yet defined the dimension of such an object. How should dimension be defined? A reasonable definition should force the dimension ofùêÖùëõ to equal ùëõ. Notice that the standard basis (1, 0, ‚Ä¶, 0), (0, 1, 0, ‚Ä¶, 0), ‚Ä¶, (0, ‚Ä¶, 0, 1) of ùêÖùëõ has length ùëõ. Thus we are tempted to define the dimension as the length of a basis. However, a finite-dimensional vector space in general has many different bases, and our attempted definition makes sense only if all bases in a given vector space have the same length. Fortunately that turns out to be the case, as we now show. 2.34 basis length does not depend on basis Any two bases of a finite-dimensional vector space have the same length. Proof Suppose ùëâ is finite-dimensional. Letùêµ1 and ùêµ2 be two bases of ùëâ. Then ùêµ1 is linearly independent in ùëâ and ùêµ2 spans ùëâ, so the length of ùêµ1 is at most the length of ùêµ2 (by 2.22). Interchanging the roles of ùêµ1 and ùêµ2, we also see that the length of ùêµ2 is at most the length of ùêµ1. Thus the length of ùêµ1 equals the length of ùêµ2, as desired. Now that we know that any two bases of a finite-dimensional vector space have the same length, we can formally define the dimension of such spaces. 2.35 definition: dimension, dim ùëâ ‚Ä¢ The dimension of a finite-dimensional vector space is the length of any basis of the vector space. ‚Ä¢ The dimension of a finite-dimensional vector spaceùëâ is denoted by dim ùëâ. 2.36 example:dimensions ‚Ä¢ dim ùêÖùëõ = ùëõ because the standard basis of ùêÖùëõ has length ùëõ. ‚Ä¢ dim ùí´ùëö(ùêÖ) = ùëö + 1because the standard basis 1, ùëß, ‚Ä¶, ùëß ùëö of ùí´ùëö(ùêÖ) has length ùëö + 1. ‚Ä¢ If ùëà = {(ùë•, ùë•, ùë¶) ‚àà ùêÖ3 ‚à∂ ùë•, ùë¶ ‚àà ùêÖ}, then dim ùëà = 2because (1, 1, 0), (0, 0, 1)is a basis of ùëà. ‚Ä¢ If ùëà = {(ùë•, ùë¶, ùëß) ‚àà ùêÖ3 ‚à∂ ùë• + ùë¶ + ùëß = 0}, then dim ùëà = 2because the list (1, ‚àí1, 0), (1, 0, ‚àí1)is a basis of ùëà. Section 2C Dimension 45 Every subspace of a finite-dimensional vector space is finite-dimensional (by 2.25) and so has a dimension. The next result gives the expected inequality about the dimension of a subspace. 2.37 dimension of a subspace If ùëâ is finite-dimensional andùëà is a subspace of ùëâ, then dim ùëà ‚â§dim ùëâ. Proof Suppose ùëâ is finite-dimensional andùëà is a subspace of ùëâ. Think of a basis of ùëà as a linearly independent list in ùëâ, and think of a basis of ùëâ as a spanning list in ùëâ. Now use 2.22 to conclude that dim ùëà ‚â§dim ùëâ. The real vector space ùêë2 has dimen- sion two; the complex vector space ùêÇ has dimension one. As sets, ùêë2 can be identified with ùêÇ (and addition is the same on both spaces, as is scalar multiplication by real numbers). Thus when we talk about the dimension of a vector space, the role played by the choice of ùêÖ cannot be neglected. To check that a list of vectors in ùëâ is a basis of ùëâ, we must, according to the definition, show that the list in ques- tion satisfies two properties: it must be linearly independent and it must span ùëâ. The next two results show that if the list in question has the right length, then we only need to check that it satisfies one of the two required properties. First we prove that every linearly independent list of the right length is a basis. 2.38 linearly independent list of the right length is a basis Suppose ùëâ is finite-dimensional. Then every linearly independent list of vectors in ùëâ of length dim ùëâ is a basis of ùëâ. Proof Suppose dim ùëâ = ùëõ and ùë£1, ‚Ä¶, ùë£ùëõ is linearly independent in ùëâ. The list ùë£1, ‚Ä¶, ùë£ùëõ can be extended to a basis of ùëâ (by 2.32). However, every basis of ùëâ has length ùëõ, so in this case the extension is the trivial one, meaning that no elements are adjoined to ùë£1, ‚Ä¶, ùë£ùëõ. Thus ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ, as desired. The next result is a useful consequence of the previous result. 2.39 subspace of full dimension equals the whole space Suppose that ùëâ is finite-dimensional andùëà is a subspace of ùëâ such that dim ùëà = dim ùëâ. Then ùëà = ùëâ. Proof Let ùë¢1, ‚Ä¶, ùë¢ùëõ be a basis of ùëà. Thus ùëõ = dim ùëà, and by hypothesis we also have ùëõ = dim ùëâ. Thus ùë¢1, ‚Ä¶, ùë¢ùëõ is a linearly independent list of vectors in ùëâ (because it is a basis of ùëà) of length dim ùëâ. From 2.38, we see that ùë¢1, ‚Ä¶, ùë¢ùëõ is a basis of ùëâ. In particular every vector in ùëâ is a linear combination of ùë¢1, ‚Ä¶, ùë¢ùëõ. Thus ùëà = ùëâ. 46 Chapter 2 Finite-Dimensional Vector Spaces 2.40 example: a basis of ùêÖ2 Consider the list (5, 7), (4, 3)of vectors in ùêÖ2. This list of length two is linearly independent in ùêÖ2 (because neither vector is a scalar multiple of the other). Note that ùêÖ2 has dimension two. Thus 2.38 implies that the linearly independent list (5, 7), (4, 3)of length two is a basis of ùêÖ2 (we do not need to bother checking that it spans ùêÖ2). 2.41 example: a basis of a subspace of ùí´3(ùêë) Let ùëà be the subspace of ùí´3(ùêë) defined by ùëà = {ùëù ‚àà ùí´3(ùêë) ‚à∂ ùëù ‚Ä≤(5) = 0}. To find a basis ofùëà, first note that each of the polynomials1, (ùë• ‚àí 5) 2, and (ùë• ‚àí 5) 3 is in ùëà. Suppose ùëé, ùëè, ùëê ‚àà ùêë and ùëé + ùëè(ùë• ‚àí 5) 2 + ùëê(ùë• ‚àí 5) 3 = 0 for every ùë• ‚àà ùêë. Without explicitly expanding the left side of the equation above, we can see that the left side has a ùëêùë•3 term. Because the right side has no ùë•3 term, this implies that ùëê = 0. Because ùëê = 0, we see that the left side has a ùëèùë•2 term, which implies that ùëè = 0. Because ùëè = ùëê = 0, we can also conclude that ùëé = 0. Thus the equation above implies that ùëé = ùëè = ùëê = 0. Hence the list 1, (ùë• ‚àí 5) 2, (ùë• ‚àí 5) 3 is linearly independent in ùëà. Thus 3 ‚â§dim ùëà. Hence 3 ‚â§dim ùëà ‚â§dim ùí´3(ùêë) = 4, where we have used 2.37. The polynomial ùë• is not in ùëà because its derivative is the constant function 1. Thus ùëà ‚â† ùí´3(ùêë). Hence dim ùëà ‚â† 4(by 2.39). The inequality above now implies that dim ùëà = 3. Thus the linearly independent list 1, (ùë• ‚àí 5) 2, (ùë• ‚àí 5) 3 in ùëà has length dim ùëà and hence is a basis of ùëà (by 2.38). Now we prove that a spanning list of the right length is a basis. 2.42 spanning list of the right length is a basis Suppose ùëâ is finite-dimensional. Then every spanning list of vectors inùëâ of length dim ùëâ is a basis of ùëâ. Proof Suppose dim ùëâ = ùëõ and ùë£1, ‚Ä¶, ùë£ùëõ spans ùëâ. The list ùë£1, ‚Ä¶, ùë£ùëõ can be reduced to a basis of ùëâ (by 2.30). However, every basis of ùëâ has length ùëõ, so in this case the reduction is the trivial one, meaning that no elements are deleted from ùë£1, ‚Ä¶, ùë£ùëõ. Thus ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ, as desired. Section 2C Dimension 47 The next result gives a formula for the dimension of the sum of two subspaces of a finite-dimensional vector space. This formula is analogous to a familiar counting formula: the number of elements in the union of two finite sets equals the number of elements in the first set, plus the number of elements in the second set, minus the number of elements in the intersection of the two sets. 2.43 dimension of a sum If ùëâ1 and ùëâ2 are subspaces of a finite-dimensional vector space, then dim(ùëâ1 + ùëâ2) = dim ùëâ1 + dim ùëâ2 ‚àí dim(ùëâ1 ‚à© ùëâ2). Proof Let ùë£1, ‚Ä¶, ùë£ùëö be a basis of ùëâ1 ‚à© ùëâ2; thus dim(ùëâ1 ‚à© ùëâ2) = ùëö. Because ùë£1, ‚Ä¶, ùë£ùëö is a basis of ùëâ1 ‚à© ùëâ2, it is linearly independent in ùëâ1. Hence this list can be extended to a basis ùë£1, ‚Ä¶, ùë£ùëö, ùë¢1, ‚Ä¶, ùë¢ùëó of ùëâ1 (by 2.32). Thus dim ùëâ1 = ùëö + ùëó. Also extend ùë£1, ‚Ä¶, ùë£ùëö to a basis ùë£1, ‚Ä¶, ùë£ùëö, ùë§1, ‚Ä¶, ùë§ùëò of ùëâ2; thus dim ùëâ2 = ùëö + ùëò. We will show that 2.44 ùë£1, ‚Ä¶, ùë£ùëö, ùë¢1, ‚Ä¶, ùë¢ùëó, ùë§1, ‚Ä¶, ùë§ùëò is a basis of ùëâ1 + ùëâ2. This will complete the proof, because then we will have dim(ùëâ1 + ùëâ2) = ùëö + ùëó + ùëò = (ùëö + ùëó) + (ùëö + ùëò) ‚àí ùëö = dim ùëâ1 + dim ùëâ2 ‚àí dim(ùëâ1 ‚à© ùëâ2). The list 2.44 is contained in ùëâ1 ‚à™ ùëâ2 and thus is contained in ùëâ1 + ùëâ2. The span of this list contains ùëâ1 and contains ùëâ2 and hence is equal to ùëâ1 + ùëâ2. Thus to show that 2.44 is a basis of ùëâ1 + ùëâ2 we only need to show that it is linearly independent. To prove that 2.44 is linearly independent, suppose ùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö + ùëè1ùë¢1 + ‚ãØ + ùëèùëóùë¢ùëó + ùëê1ùë§1 + ‚ãØ + ùëêùëòùë§ùëò = 0, where all the ùëé‚Äôs, ùëè‚Äôs, and ùëê‚Äôs are scalars. We need to prove that all the ùëé‚Äôs, ùëè‚Äôs, and ùëê‚Äôs equal 0. The equation above can be rewritten as 2.45 ùëê1ùë§1 + ‚ãØ + ùëêùëòùë§ùëò = ‚àíùëé1ùë£1 ‚àí ‚ãØ ‚àí ùëéùëöùë£ùëö ‚àí ùëè1ùë¢1 ‚àí ‚ãØ ‚àí ùëèùëóùë¢ùëó, which shows that ùëê1ùë§1 + ‚ãØ + ùëêùëòùë§ùëò ‚àà ùëâ1. All the ùë§‚Äôs are in ùëâ2, so this implies that ùëê1ùë§1 + ‚ãØ + ùëêùëòùë§ùëò ‚àà ùëâ1 ‚à© ùëâ2. Because ùë£1, ‚Ä¶, ùë£ùëö is a basis of ùëâ1 ‚à© ùëâ2, we have ùëê1ùë§1 + ‚ãØ + ùëêùëòùë§ùëò = ùëë1ùë£1 + ‚ãØ + ùëëùëöùë£ùëö for some scalars ùëë1, ‚Ä¶, ùëëùëö. But ùë£1, ‚Ä¶, ùë£ùëö, ùë§1, ‚Ä¶, ùë§ùëò is linearly independent, so the last equation implies that all the ùëê‚Äôs (and ùëë‚Äôs) equal 0. Thus 2.45 becomes the equation ùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö + ùëè1ùë¢1 + ‚ãØ + ùëèùëóùë¢ùëó = 0. Because the list ùë£1, ‚Ä¶, ùë£ùëö, ùë¢1, ‚Ä¶, ùë¢ùëó is linearly independent, this equation implies that all the ùëé‚Äôs and ùëè‚Äôs are 0, completing the proof. 48 Chapter 2 Finite-Dimensional Vector Spaces For ùëÜ a finite set, let#ùëÜ denote the number of elements of ùëÜ. The table below compares finite sets with finite-dimensional vector spaces, showing the analogy between #ùëÜ (for sets) and dim ùëâ (for vector spaces), as well as the analogy between unions of subsets (in the context of sets) and sums of subspaces (in the context of vector spaces). sets vector spaces ùëÜ is a finite set ùëâ is a finite-dimensional vector space #ùëÜ dim ùëâ for subsets ùëÜ1, ùëÜ2 of ùëÜ, the union ùëÜ1 ‚à™ ùëÜ2 is the smallest subset of ùëÜ containing ùëÜ1 and ùëÜ2 for subspaces ùëâ1, ùëâ2 of ùëâ, the sum ùëâ1 +ùëâ2 is the smallest subspace of ùëâ containing ùëâ1 and ùëâ2 #(ùëÜ1 ‚à™ ùëÜ2) dim(ùëâ1 + ùëâ2) = #ùëÜ1 + #ùëÜ2 ‚àí #(ùëÜ1 ‚à© ùëÜ2) = dim ùëâ1 + dim ùëâ2 ‚àí dim(ùëâ1 ‚à© ùëâ2) #(ùëÜ1 ‚à™ ùëÜ2) = #ùëÜ1 + #ùëÜ2 dim(ùëâ1 + ùëâ2) = dim ùëâ1 + dim ùëâ2 ‚ü∫ ùëÜ1 ‚à© ùëÜ2 = ‚àÖ ‚ü∫ ùëâ1 ‚à© ùëâ2 = {0} ùëÜ1 ‚à™ ‚ãØ ‚à™ ùëÜùëö is a disjoint union ‚ü∫ #(ùëÜ1 ‚à™ ‚ãØ ‚à™ ùëÜùëö) = #ùëÜ1 + ‚ãØ + #ùëÜùëö ùëâ1 + ‚ãØ + ùëâùëö is a direct sum ‚ü∫ dim(ùëâ1 + ‚ãØ + ùëâùëö) = dim ùëâ1 + ‚ãØ + dim ùëâùëö The last row above focuses on the analogy between disjoint unions (for sets) and direct sums (for vector spaces). The proof of the result in the last box above will be given in 3.94. You should be able to find results about sets that correspond, via analogy, to the results about vector spaces in Exercises 12 through 18. Exercises 2C 1 Show that the subspaces of ùêë2 are precisely {0}, all lines in ùêë2 containing the origin, and ùêë2. 2 Show that the subspaces of ùêë3 are precisely {0}, all lines in ùêë3 containing the origin, all planes in ùêë3 containing the origin, and ùêë3. 3 (a) Let ùëà = {ùëù ‚àà ùí´4(ùêÖ) ‚à∂ ùëù(6) = 0}. Find a basis of ùëà. (b) Extend the basis in (a) to a basis of ùí´4(ùêÖ). (c) Find a subspace ùëä of ùí´4(ùêÖ) such that ùí´4(ùêÖ) = ùëà ‚äï ùëä. 4 (a) Let ùëà = {ùëù ‚àà ùí´4(ùêë) ‚à∂ ùëù ‚Ä≥(6) = 0}. Find a basis of ùëà. (b) Extend the basis in (a) to a basis of ùí´4(ùêë). (c) Find a subspace ùëä of ùí´4(ùêë) such that ùí´4(ùêë) = ùëà ‚äï ùëä. 5 (a) Let ùëà = {ùëù ‚àà ùí´4(ùêÖ) ‚à∂ ùëù(2) = ùëù(5)}. Find a basis of ùëà. (b) Extend the basis in (a) to a basis of ùí´4(ùêÖ). (c) Find a subspace ùëä of ùí´4(ùêÖ) such that ùí´4(ùêÖ) = ùëà ‚äï ùëä. Section 2C Dimension 49 6 (a) Let ùëà = {ùëù ‚àà ùí´4(ùêÖ) ‚à∂ ùëù(2) = ùëù(5) = ùëù(6)}. Find a basis of ùëà. (b) Extend the basis in (a) to a basis of ùí´4(ùêÖ). (c) Find a subspace ùëä of ùí´4(ùêÖ) such that ùí´4(ùêÖ) = ùëà ‚äï ùëä. 7 (a) Let ùëà = {ùëù ‚àà ùí´4(ùêë) ‚à∂ ‚à´ 1 ‚àí1 ùëù = 0}. Find a basis of ùëà. (b) Extend the basis in (a) to a basis of ùí´4(ùêë). (c) Find a subspace ùëä of ùí´4(ùêë) such that ùí´4(ùêë) = ùëà ‚äï ùëä. 8 Suppose ùë£1, ‚Ä¶, ùë£ùëö is linearly independent in ùëâ and ùë§ ‚àà ùëâ. Prove that dim span(ùë£1 + ùë§, ‚Ä¶, ùë£ùëö + ùë§) ‚â• ùëö ‚àí 1. 9 Suppose ùëö is a positive integer and ùëù0, ùëù1, ‚Ä¶, ùëùùëö ‚àà ùí´(ùêÖ) are such that each ùëùùëò has degree ùëò. Prove that ùëù0, ùëù1, ‚Ä¶, ùëùùëö is a basis of ùí´ùëö(ùêÖ). 10 Suppose ùëö is a positive integer. For 0 ‚â§ ùëò ‚â§ ùëö, let ùëùùëò(ùë•) = ùë•ùëò(1 ‚àí ùë•) ùëö ‚àí ùëò. Show that ùëù0, ‚Ä¶, ùëùùëö is a basis of ùí´ùëö(ùêÖ). The basis in this exercise leads to what are called Bernstein polynomials. You can do a web search to learn how Bernstein polynomials are used to approximate continuous functions on [0, 1]. 11 Suppose ùëà and ùëä are both four-dimensional subspaces of ùêÇ 6. Prove that there exist two vectors in ùëà ‚à© ùëäsuch that neither of these vectors is a scalar multiple of the other. 12 Suppose that ùëà and ùëä are subspaces of ùêë8 such that dim ùëà = 3, dim ùëä = 5, and ùëà + ùëä = ùêë8. Prove that ùêë8 = ùëà ‚äï ùëä. 13 Suppose ùëà and ùëä are both five-dimensional subspaces ofùêë9. Prove that ùëà ‚à© ùëä ‚â† {0}. 14 Suppose ùëâ is a ten-dimensional vector space and ùëâ1, ùëâ2, ùëâ3 are subspaces of ùëâ with dim ùëâ1 = dim ùëâ2 = dim ùëâ3 = 7. Prove that ùëâ1 ‚à© ùëâ2 ‚à© ùëâ3 ‚â† {0}. 15 Suppose ùëâ is finite-dimensional andùëâ1, ùëâ2, ùëâ3 are subspaces of ùëâ with dim ùëâ1 + dim ùëâ2 + dim ùëâ3 > 2dim ùëâ. Prove that ùëâ1 ‚à© ùëâ2 ‚à© ùëâ3 ‚â† {0}. 16 Suppose ùëâ is finite-dimensional andùëà is a subspace of ùëâ with ùëà ‚â† ùëâ. Let ùëõ = dim ùëâ and ùëö = dim ùëà. Prove that there exist ùëõ ‚àí ùëö subspaces of ùëâ, each of dimension ùëõ ‚àí 1, whose intersection equals ùëà. 17 Suppose that ùëâ1, ‚Ä¶, ùëâùëö are finite-dimensional subspaces ofùëâ. Prove that ùëâ1 + ‚ãØ + ùëâùëö is finite-dimensional and dim(ùëâ1 + ‚ãØ + ùëâùëö) ‚â§dim ùëâ1 + ‚ãØ + dim ùëâùëö. The inequality above is an equality if and only if ùëâ1 + ‚ãØ + ùëâùëö is a direct sum, as will be shown in 3.94. 50 Chapter 2 Finite-Dimensional Vector Spaces 18 Suppose ùëâ is finite-dimensional, withdim ùëâ = ùëõ ‚â• 1. Prove that there exist one-dimensional subspaces ùëâ1, ‚Ä¶, ùëâùëõ of ùëâ such that ùëâ = ùëâ1 ‚äï ‚ãØ ‚äï ùëâùëõ. 19 Explain why you might guess, motivated by analogy with the formula for the number of elements in the union of three finite sets, that ifùëâ1, ùëâ2, ùëâ3 are subspaces of a finite-dimensional vector space, then dim(ùëâ1 + ùëâ2 + ùëâ3) = dim ùëâ1 + dim ùëâ2 + dim ùëâ3 ‚àí dim(ùëâ1 ‚à© ùëâ2) ‚àí dim(ùëâ1 ‚à© ùëâ3) ‚àí dim(ùëâ2 ‚à© ùëâ3) + dim(ùëâ1 ‚à© ùëâ2 ‚à© ùëâ3). Then either prove the formula above or give a counterexample. 20 Prove that if ùëâ1, ùëâ2, and ùëâ3 are subspaces of a finite-dimensional vector space, then dim(ùëâ1 + ùëâ2 + ùëâ3) = dim ùëâ1 + dim ùëâ2 + dim ùëâ3 ‚àí dim(ùëâ1 ‚à© ùëâ2) + dim(ùëâ1 ‚à© ùëâ3) + dim(ùëâ2 ‚à© ùëâ3) 3 ‚àí dim((ùëâ1+ùëâ2)‚à©ùëâ3)+ dim((ùëâ1+ùëâ3)‚à©ùëâ2)+ dim((ùëâ2 +ùëâ3)‚à©ùëâ1) 3 . The formula above may seem strange because the right side does not look like an integer. I at once gave up my former occupations, set down natural history and all its progeny as a deformed and abortive creation, and entertained the greatest disdain for a would-be science which could never even step within the threshold of real knowledge. In this mood I betook myself to the mathematics and the branches of study appertaining to that science as being built upon secure foundations, and so worthy of my consideration. ‚ÄîFrankenstein, Mary Wollstonecraft Shelley Chapter 3 Linear Maps So far our attention has focused on vector spaces. No one gets excited about vector spaces. The interesting part of linear algebra is the subject to which we now turn‚Äîlinear maps. We will frequently use the powerful fundamental theorem of linear maps, which states that the dimension of the domain of a linear map equals the dimension of the subspace that gets sent to 0plus the dimension of the range. This will imply the striking result that a linear map from a finite-dimensional vector space to itself is one-to-one if and only if its range is the whole space. A major concept that we will introduce in this chapter is the matrix associated with a linear map and with a basis of the domain space and a basis of the target space. This correspondence between linear maps and matrices provides much insight into key aspects of linear algebra. This chapter concludes by introducing product, quotient, and dual spaces. In this chapter we will need additional vector spaces, which we call ùëà and ùëä, in addition to ùëâ. Thus our standing assumptions are now as follows. standing assumptions for this chapter ‚Ä¢ ùêÖ denotes ùêë or ùêÇ. ‚Ä¢ ùëà, ùëâ, and ùëä denote vector spaces over ùêÖ.StefanSch√§ferCCBY-SA The twelfth-century Dankwarderode Castle in Brunswick (Braunschweig), where Carl Friedrich Gauss (1777‚Äì1855) was born and grew up. In 1809 Gauss published a method for solving systems of linear equations. This method, now called Gaussian elimination, was used in a Chinese book written over 1600 years earlier. 51 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0_3 ¬© Sheldon Axler 2024 52 Chapter 3 Linear Maps 3A Vector Space of Linear Maps Definition and Examples of Linear Maps Now we are ready for one of the key definitions in linear algebra. 3.1 definition: linear map A linear map from ùëâ to ùëä is a function ùëá‚à∂ ùëâ ‚Üí ùëä with the following properties. additivity ùëá(ùë¢ + ùë£) = ùëáùë¢ + ùëáùë£ for all ùë¢, ùë£ ‚àà ùëâ. homogeneity ùëá(ùúÜùë£) = ùúÜ(ùëáùë£) for all ùúÜ ‚àà ùêÖ and all ùë£ ‚àà ùëâ. Some mathematicians use the phrase linear transformation, which means the same as linear map. Note that for linear maps we often use the notation ùëáùë£ as well as the usual function notation ùëá(ùë£). 3.2 notation: ‚Ñí(ùëâ, ùëä), ‚Ñí(ùëâ) ‚Ä¢ The set of linear maps from ùëâ to ùëä is denoted by ‚Ñí(ùëâ, ùëä). ‚Ä¢ The set of linear maps from ùëâ to ùëâ is denoted by ‚Ñí(ùëâ). In other words, ‚Ñí(ùëâ) = ‚Ñí(ùëâ, ùëâ). Let‚Äôs look at some examples of linear maps. Make sure you verify that each of the functions defined in the next example is indeed a linear map: 3.3 example: linear maps zero In addition to its other uses, we let the symbol 0denote the linear map that takes every element of some vector space to the additive identity of another (or possibly the same) vector space. To be specific,0 ‚àà‚Ñí(ùëâ, ùëä) is defined by 0ùë£ = 0. The 0on the left side of the equation above is a function from ùëâ to ùëä, whereas the 0on the right side is the additive identity in ùëä. As usual, the context should allow you to distinguish between the many uses of the symbol 0. identity operator The identity operator, denoted by ùêº, is the linear map on some vector space that takes each element to itself. To be specific,ùêº ‚àà ‚Ñí(ùëâ) is defined by ùêºùë£ = ùë£. Section 3A Vector Space of Linear Maps 53 differentiation Defineùê∑ ‚àà ‚Ñí(ùí´(ùêë))by ùê∑ùëù = ùëù‚Ä≤. The assertion that this function is a linear map is another way of stating a basic result about differentiation: ( ùëì + ùëî) ‚Ä≤ = ùëì ‚Ä≤ + ùëî‚Ä≤ and (ùúÜ ùëì )‚Ä≤ = ùúÜ ùëì ‚Ä≤ whenever ùëì, ùëî are differentiable and ùúÜ is a constant. integration Defineùëá ‚àà ‚Ñí(ùí´(ùêë), ùêë)by ùëáùëù = ‚à´1 0 ùëù. The assertion that this function is linear is another way of stating a basic result about integration: the integral of the sum of two functions equals the sum of the integrals, and the integral of a constant times a function equals the constant times the integral of the function. multiplication by ùë•2 Define a linear mapùëá ‚àà ‚Ñí(ùí´(ùêë))by (ùëáùëù)(ùë•) = ùë•2ùëù(ùë•) for each ùë• ‚àà ùêë. backward shift Recall that ùêÖ‚àû denotes the vector space of all sequences of elements of ùêÖ. Define a linear map ùëá ‚àà ‚Ñí(ùêÖ‚àû)by ùëá(ùë•1, ùë•2, ùë•3, ‚Ä¶ ) = (ùë•2, ùë•3, ‚Ä¶ ). from ùêë3 to ùêë2 Define a linear mapùëá ‚àà ‚Ñí(ùêë3, ùêë2)by ùëá(ùë•, ùë¶, ùëß) = (2ùë• ‚àí ùë¶+ 3ùëß, 7ùë•+ 5ùë¶ ‚àí 6ùëß). from ùêÖùëõ to ùêÖùëö To generalize the previous example, let ùëö and ùëõ be positive integers, let ùê¥ùëó, ùëò ‚àà ùêÖ for each ùëó = 1, ‚Ä¶, ùëö and each ùëò = 1, ‚Ä¶, ùëõ, and define a linear mapùëá ‚àà ‚Ñí(ùêÖùëõ, ùêÖùëö) by ùëá(ùë•1, ‚Ä¶, ùë•ùëõ) = (ùê¥1, 1ùë•1 + ‚ãØ + ùê¥1, ùëõ ùë•ùëõ, ‚Ä¶, ùê¥ùëö, 1ùë•1 + ‚ãØ + ùê¥ùëö, ùëõ ùë•ùëõ). Actually every linear map from ùêÖùëõ to ùêÖùëö is of this form. composition Fix a polynomial ùëû ‚àà ùí´(ùêë). Define a linear mapùëá ‚àà ‚Ñí(ùí´(ùêë))by (ùëáùëù)(ùë•) = ùëù(ùëû(ùë•)). The existence part of the next result means that we can find a linear map that takes on whatever values we wish on the vectors in a basis. The uniqueness part of the next result means that a linear map is completely determined by its values on a basis. 54 Chapter 3 Linear Maps 3.4 linear map lemma Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùë§1, ‚Ä¶, ùë§ùëõ ‚àà ùëä. Then there exists a unique linear map ùëá‚à∂ ùëâ ‚Üí ùëä such that ùëáùë£ùëò = ùë§ùëò for each ùëò = 1, ‚Ä¶, ùëõ. Proof First we show the existence of a linear map ùëá with the desired property. Defineùëá‚à∂ ùëâ ‚Üí ùëä by ùëá(ùëê1ùë£1 + ‚ãØ + ùëêùëõùë£ùëõ) = ùëê1ùë§1 + ‚ãØ + ùëêùëõùë§ùëõ, where ùëê1, ‚Ä¶, ùëêùëõ are arbitrary elements of ùêÖ. The list ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Thus the equation above does indeed define a functionùëá from ùëâ to ùëä (because each element of ùëâ can be uniquely written in the form ùëê1ùë£1 + ‚ãØ + ùëêùëõùë£ùëõ). For each ùëò, taking ùëêùëò = 1and the other ùëê‚Äôs equal to 0in the equation above shows that ùëáùë£ùëò = ùë§ùëò. If ùë¢, ùë£ ‚àà ùëâ with ùë¢ = ùëé1ùë£1 + ‚ãØ + ùëéùëõùë£ùëõ and ùë£ = ùëê1ùë£1 + ‚ãØ + ùëêùëõùë£ùëõ, then ùëá(ùë¢ + ùë£) = ùëá((ùëé1 + ùëê1)ùë£1 + ‚ãØ + (ùëéùëõ + ùëêùëõ)ùë£ùëõ) = (ùëé1 + ùëê1)ùë§1 + ‚ãØ + (ùëéùëõ + ùëêùëõ)ùë§ùëõ = (ùëé1ùë§1 + ‚ãØ + ùëéùëõùë§ùëõ) + (ùëê1ùë§1 + ‚ãØ + ùëêùëõùë§ùëõ) = ùëáùë¢ + ùëáùë£. Similarly, if ùúÜ ‚àà ùêÖ and ùë£ = ùëê1ùë£1 + ‚ãØ + ùëêùëõùë£ùëõ, then ùëá(ùúÜùë£) = ùëá(ùúÜùëê1ùë£1 + ‚ãØ + ùúÜùëêùëõùë£ùëõ) = ùúÜùëê1ùë§1 + ‚ãØ + ùúÜùëêùëõùë§ùëõ = ùúÜ(ùëê1ùë§1 + ‚ãØ + ùëêùëõùë§ùëõ) = ùúÜùëáùë£. Thus ùëá is a linear map from ùëâ to ùëä. To prove uniqueness, now suppose that ùëá ‚àà ‚Ñí(ùëâ, ùëä) and that ùëáùë£ùëò = ùë§ùëò for each ùëò = 1, ‚Ä¶, ùëõ. Let ùëê1, ‚Ä¶, ùëêùëõ ‚àà ùêÖ. Then the homogeneity of ùëá implies that ùëá(ùëêùëòùë£ùëò) = ùëêùëòùë§ùëò for each ùëò = 1, ‚Ä¶, ùëõ. The additivity of ùëá now implies that ùëá(ùëê1ùë£1 + ‚ãØ + ùëêùëõùë£ùëõ) = ùëê1ùë§1 + ‚ãØ + ùëêùëõùë§ùëõ. Thus ùëá is uniquely determined on span(ùë£1, ‚Ä¶, ùë£ùëõ) by the equation above. Because ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ, this implies that ùëá is uniquely determined on ùëâ, as desired. Section 3A Vector Space of Linear Maps 55 Algebraic Operations on ‚Ñí(ùëâ, ùëä) We begin by defining addition and scalar multiplication on‚Ñí(ùëâ, ùëä). 3.5 definition: addition and scalar multiplication on ‚Ñí(ùëâ, ùëä) Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùúÜ ‚àà ùêÖ. The sum ùëÜ + ùëá and the product ùúÜùëá are the linear maps from ùëâ to ùëä defined by (ùëÜ + ùëá)(ùë£) = ùëÜùë£ + ùëáùë£ and (ùúÜùëá)(ùë£) = ùúÜ(ùëáùë£) for all ùë£ ‚àà ùëâ. Linear maps are pervasive throughout mathematics. However, they are not as ubiquitous as imagined by people who seem to think cos is a linear map from ùêë to ùêë when they incorrectly write that cos(ùë•+ùë¶) equals cos ùë•+cos ùë¶ and that cos 2ùë•equals 2cos ùë•. You should verify that ùëÜ + ùëá and ùúÜùëá as defined above are indeed linear maps. In other words, if ùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùúÜ ‚àà ùêÖ, then ùëÜ + ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùúÜùëá ‚àà ‚Ñí(ùëâ, ùëä). Because we took the trouble to de- fine addition and scalar multiplication on ‚Ñí(ùëâ, ùëä), the next result should not be a surprise. 3.6 ‚Ñí(ùëâ, ùëä) is a vector space With the operations of addition and scalar multiplication as defined above, ‚Ñí(ùëâ, ùëä) is a vector space. The routine proof of the result above is left to the reader. Note that the additive identity of ‚Ñí(ùëâ, ùëä) is the zero linear map defined in Example3.3. Usually it makes no sense to multiply together two elements of a vector space, but for some pairs of linear maps a useful product exists, as in the next definition. 3.7 definition:product of linear maps If ùëá ‚àà ‚Ñí(ùëà, ùëâ) and ùëÜ ‚àà ‚Ñí(ùëâ, ùëä), then the product ùëÜùëá ‚àà ‚Ñí(ùëà, ùëä) is defined by (ùëÜùëá)(ùë¢) = ùëÜ(ùëáùë¢) for all ùë¢ ‚àà ùëà. Thus ùëÜùëá is just the usual composition ùëÜ ‚àò ùëá of two functions, but when both functions are linear, we usually write ùëÜùëá instead of ùëÜ ‚àò ùëá. The product notation ùëÜùëá helps make the distributive properties (see next result) seem natural. Note that ùëÜùëá is defined only whenùëá maps into the domain of ùëÜ. You should verify that ùëÜùëá is indeed a linear map from ùëà to ùëä whenever ùëá ‚àà ‚Ñí(ùëà, ùëâ) and ùëÜ ‚àà ‚Ñí(ùëâ, ùëä). 56 Chapter 3 Linear Maps 3.8 algebraic properties of products of linear maps associativity (ùëá1ùëá2)ùëá3 = ùëá1(ùëá2ùëá3) whenever ùëá1, ùëá2, and ùëá3 are linear maps such that the products make sense (meaning ùëá3 maps into the domain of ùëá2, and ùëá2 maps into the domain of ùëá1). identity ùëáùêº = ùêºùëá = ùëá whenever ùëá ‚àà ‚Ñí(ùëâ, ùëä); here the firstùêº is the identity operator on ùëâ, and the second ùêº is the identity operator on ùëä. distributive properties (ùëÜ1 + ùëÜ2)ùëá = ùëÜ1ùëá + ùëÜ2ùëá and ùëÜ(ùëá1 + ùëá2) = ùëÜùëá1 + ùëÜùëá2 whenever ùëá, ùëá1, ùëá2 ‚àà ‚Ñí(ùëà, ùëâ) and ùëÜ, ùëÜ1, ùëÜ2 ‚àà ‚Ñí(ùëâ, ùëä). The routine proof of the result above is left to the reader. Multiplication of linear maps is not commutative. In other words, it is not necessarily true that ùëÜùëá = ùëáùëÜ, even if both sides of the equation make sense. 3.9 example: two noncommuting linear maps from ùí´(ùêë) to ùí´(ùêë) Suppose ùê∑ ‚àà ‚Ñí(ùí´(ùêë))is the differentiation map defined in Example3.3 and ùëá ‚àà ‚Ñí(ùí´(ùêë))is the multiplication by ùë•2 map defined earlier in this section. Then ((ùëáùê∑)ùëù)(ùë•) = ùë•2ùëù ‚Ä≤(ùë•) but ((ùê∑ùëá)ùëù)(ùë•) = ùë•2ùëù‚Ä≤(ùë•) + 2ùë•ùëù(ùë•). Thus ùëáùê∑ ‚â† ùê∑ùëá‚Äîdifferentiating and then multiplying by ùë•2 is not the same as multiplying by ùë•2 and then differentiating. 3.10 linear maps take 0to 0 Suppose ùëá is a linear map from ùëâ to ùëä. Then ùëá(0) = 0. Proof By additivity, we have ùëá(0) = ùëá(0+ 0) = ùëá(0)+ ùëá(0). Add the additive inverse of ùëá(0)to each side of the equation above to conclude that ùëá(0) = 0. Suppose ùëö, ùëè ‚àà ùêë. The function ùëì‚à∂ ùêë ‚Üí ùêë defined by ùëì (ùë•) = ùëöùë• + ùëè is a linear map if and only if ùëè = 0(use 3.10). Thus the linear functions of high school algebra are not the same as linear maps in the context of linear algebra. Section 3A Vector Space of Linear Maps 57 Exercises 3A 1 Suppose ùëè, ùëê ‚àà ùêë. Defineùëá‚à∂ ùêë3 ‚Üí ùêë2 by ùëá(ùë•, ùë¶, ùëß) = (2ùë• ‚àí 4ùë¶+ 3ùëß+ ùëè, 6ùë•+ ùëêùë•ùë¶ùëß). Show that ùëá is linear if and only if ùëè = ùëê = 0. 2 Suppose ùëè, ùëê ‚àà ùêë. Defineùëá‚à∂ ùí´(ùêë) ‚Üí ùêë2 by ùëáùëù = (3ùëù(4)+ 5ùëù ‚Ä≤(6)+ ùëèùëù(1)ùëù(2), ‚à´2 ‚àí1 ùë•3ùëù(ùë•) ùëëùë• + ùëê sin ùëù(0)). Show that ùëá is linear if and only if ùëè = ùëê = 0. 3 Suppose that ùëá ‚àà ‚Ñí(ùêÖùëõ, ùêÖùëö). Show that there exist scalars ùê¥ùëó, ùëò ‚àà ùêÖ for ùëó = 1, ‚Ä¶, ùëö and ùëò = 1, ‚Ä¶, ùëõ such that ùëá(ùë•1, ‚Ä¶, ùë•ùëõ) = (ùê¥1, 1ùë•1 + ‚ãØ + ùê¥1, ùëõ ùë•ùëõ, ‚Ä¶, ùê¥ùëö, 1ùë•1 + ‚ãØ + ùê¥ùëö, ùëõ ùë•ùëõ) for every (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêÖùëõ. This exercise shows that the linear map ùëá has the form promised in the second to last item of Example 3.3. 4 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùë£1, ‚Ä¶, ùë£ùëö is a list of vectors in ùëâ such that ùëáùë£1, ‚Ä¶, ùëáùë£ùëö is a linearly independent list in ùëä. Prove that ùë£1, ‚Ä¶, ùë£ùëö is linearly independent. 5 Prove that ‚Ñí(ùëâ, ùëä) is a vector space, as was asserted in 3.6. 6 Prove that multiplication of linear maps has the associative, identity, and distributive properties asserted in 3.8. 7 Show that every linear map from a one-dimensional vector space to itself is multiplication by some scalar. More precisely, prove that if dim ùëâ = 1and ùëá ‚àà ‚Ñí(ùëâ), then there exists ùúÜ ‚àà ùêÖ such that ùëáùë£ = ùúÜùë£ for all ùë£ ‚àà ùëâ. 8 Give an example of a function ùúë‚à∂ ùêë2 ‚Üí ùêë such that ùúë(ùëéùë£) = ùëéùúë(ùë£) for all ùëé ‚àà ùêë and all ùë£ ‚àà ùêë2 but ùúë is not linear. This exercise and the next exercise show that neither homogeneity nor additivity alone is enough to imply that a function is a linear map. 9 Give an example of a function ùúë‚à∂ ùêÇ ‚Üí ùêÇ such that ùúë(ùë§ + ùëß) = ùúë(ùë§) + ùúë(ùëß) for all ùë§, ùëß ‚àà ùêÇ but ùúë is not linear. (Here ùêÇ is thought of as a complex vector space.) There also exists a function ùúë‚à∂ ùêë ‚Üí ùêë such that ùúë satisfies the additivity condition above but ùúë is not linear. However, showing the existence of such a function involves considerably more advanced tools. 58 Chapter 3 Linear Maps 10 Prove or give a counterexample: If ùëû ‚àà ùí´(ùêë) and ùëá‚à∂ ùí´(ùêë) ‚Üí ùí´(ùêë) is defined byùëáùëù = ùëû ‚àò ùëù, then ùëá is a linear map. The function ùëá defined here differs from the function ùëá defined in the last bullet point of 3.3 by the order of the functions in the compositions. 11 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is a scalar multiple of the identity if and only if ùëÜùëá = ùëáùëÜ for every ùëÜ ‚àà ‚Ñí(ùëâ). 12 Suppose ùëà is a subspace of ùëâ with ùëà ‚â† ùëâ. Suppose ùëÜ ‚àà ‚Ñí(ùëà, ùëä) and ùëÜ ‚â† 0(which means that ùëÜùë¢ ‚â† 0for some ùë¢ ‚àà ùëà). Defineùëá‚à∂ ùëâ ‚Üí ùëä by ùëáùë£ = ‚éß{ ‚é®{‚é© ùëÜùë£ if ùë£ ‚àà ùëà, 0 if ùë£ ‚àà ùëâ and ùë£ ‚àâ ùëà. Prove that ùëá is not a linear map on ùëâ. 13 Suppose ùëâ is finite-dimensional. Prove that every linear map on a subspace of ùëâ can be extended to a linear map on ùëâ. In other words, show that if ùëà is a subspace of ùëâ and ùëÜ ‚àà ‚Ñí(ùëà, ùëä), then there exists ùëá ‚àà ‚Ñí(ùëâ, ùëä) such that ùëáùë¢ = ùëÜùë¢ for all ùë¢ ‚àà ùëà. The result in this exercise is used in the proof of 3.125. 14 Suppose ùëâ is finite-dimensional withdim ùëâ > 0, and suppose ùëä is infinite- dimensional. Prove that ‚Ñí(ùëâ, ùëä) is infinite-dimensional. 15 Suppose ùë£1, ‚Ä¶, ùë£ùëö is a linearly dependent list of vectors in ùëâ. Suppose also that ùëä ‚â† {0}. Prove that there exist ùë§1, ‚Ä¶, ùë§ùëö ‚àà ùëä such that no ùëá ‚àà ‚Ñí(ùëâ, ùëä) satisfiesùëáùë£ùëò = ùë§ùëò for each ùëò = 1, ‚Ä¶, ùëö. 16 Suppose ùëâ is finite-dimensional withdim ùëâ > 1. Prove that there exist ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) such that ùëÜùëá ‚â† ùëáùëÜ. 17 Suppose ùëâ is finite-dimensional. Show that the only two-sided ideals of ‚Ñí(ùëâ) are {0}and ‚Ñí(ùëâ). A subspace ‚Ñ∞ of ‚Ñí(ùëâ) is called a two-sided ideal of ‚Ñí(ùëâ) if ùëáùê∏ ‚àà ‚Ñ∞ and ùê∏ùëá ‚àà ‚Ñ∞ for all ùê∏ ‚àà ‚Ñ∞ and all ùëá ‚àà ‚Ñí(ùëâ). Open Access This chapter is licensed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (https://creativecommons.org/licenses/by-nc/4.0), which permits any noncommercial use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to original author and source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this chapter are included in the chapter‚Äôs Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter‚Äôs Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. Section 3B Null Spaces and Ranges 59 3B Null Spaces and Ranges Null Space and Injectivity In this section we will learn about two subspaces that are intimately connected with each linear map. We begin with the set of vectors that get mapped to 0. 3.11 definition: null space, null ùëá For ùëá ‚àà ‚Ñí(ùëâ, ùëä), the null space of ùëá, denoted by null ùëá, is the subset of ùëâ consisting of those vectors that ùëá maps to 0: null ùëá = {ùë£ ‚àà ùëâ ‚à∂ ùëáùë£ = 0}. 3.12 example: null space ‚Ä¢ If ùëá is the zero map from ùëâ to ùëä, meaning that ùëáùë£ = 0for every ùë£ ‚àà ùëâ, then null ùëá = ùëâ. ‚Ä¢ Suppose ùúë ‚àà ‚Ñí(ùêÇ 3, ùêÇ)is defined byùúë(ùëß1, ùëß2, ùëß3) = ùëß1 + 2ùëß2 + 3ùëß3. Then null ùúë equals {(ùëß1, ùëß2, ùëß3) ‚àà ùêÇ3 ‚à∂ ùëß1 + 2ùëß2 + 3ùëß3 = 0}, which is a subspace of the domain of ùúë. We will soon see that the null space of each linear map is a subspace of its domain. ‚Ä¢ The word ‚Äúnull‚Äù means zero. Thus the term ‚Äúnull space‚Äùshould remind you of the connection to 0. Some mathe- maticians use the term kernel instead of null space. Suppose ùê∑ ‚àà ‚Ñí(ùí´(ùêë))is the dif- ferentiation map defined byùê∑ùëù = ùëù‚Ä≤. The only functions whose derivative equals the zero function are the con- stant functions. Thus the null space of ùê∑ equals the set of constant functions. ‚Ä¢ Suppose that ùëá ‚àà ‚Ñí(ùí´(ùêë))is the multiplication by ùë•2 map defined by (ùëáùëù)(ùë•) = ùë•2ùëù(ùë•). The only polynomial ùëù such that ùë•2ùëù(ùë•) = 0for all ùë• ‚àà ùêë is the 0polynomial. Thus null ùëá = {0}. ‚Ä¢ Suppose ùëá ‚àà ‚Ñí(ùêÖ‚àû)is the backward shift defined by ùëá(ùë•1, ùë•2, ùë•3, ‚Ä¶ ) = (ùë•2, ùë•3, ‚Ä¶ ). Then ùëá(ùë•1, ùë•2, ùë•3, ‚Ä¶ ) equals 0if and only if the numbers ùë•2, ùë•3, ‚Ä¶ are all 0. Thus null ùëá = {(ùëé, 0, 0, ‚Ä¶ ) ‚à∂ ùëé ‚àà ùêÖ}. The next result shows that the null space of each linear map is a subspace of the domain. In particular, 0is in the null space of every linear map. 3.13 the null space is a subspace Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then null ùëá is a subspace of ùëâ. 60 Chapter 3 Linear Maps Proof Because ùëá is a linear map, ùëá(0) = 0(by 3.10). Thus 0 ‚àànull ùëá. Suppose ùë¢, ùë£ ‚àà null ùëá. Then ùëá(ùë¢ + ùë£) = ùëáùë¢ + ùëáùë£ = 0+ 0 = 0. Hence ùë¢ + ùë£ ‚àà null ùëá. Thus null ùëá is closed under addition. Suppose ùë¢ ‚àà null ùëá and ùúÜ ‚àà ùêÖ. Then ùëá(ùúÜùë¢) = ùúÜùëáùë¢ = ùúÜ0 = 0. Hence ùúÜùë¢ ‚àà null ùëá. Thus null ùëá is closed under scalar multiplication. We have shown that null ùëá contains 0and is closed under addition and scalar multiplication. Thus null ùëá is a subspace of ùëâ (by 1.34). As we will soon see, for a linear map the next definition is closely connected to the null space. 3.14 definition: injective A function ùëá‚à∂ ùëâ ‚Üí ùëä is called injective if ùëáùë¢ = ùëáùë£ implies ùë¢ = ùë£. The term one-to-one means the same as injective. We could rephrase the definition above to say that ùëá is injective if ùë¢ ‚â† ùë£ implies that ùëáùë¢ ‚â† ùëáùë£. Thus ùëá is injective if and only if it maps distinct inputs to distinct outputs. The next result says that we can check whether a linear map is injective by checking whether 0is the only vector that gets mapped to 0. As a simple application of this result, we see that of the linear maps whose null spaces we computed in 3.12, only multiplication by ùë•2 is injective (except that the zero map is injective in the special case ùëâ = {0}). 3.15 injectivity ‚ü∫ null space equals {0} Let ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then ùëá is injective if and only if null ùëá = {0}. Proof First suppose ùëá is injective. We want to prove that null ùëá = {0}. We already know that {0} ‚äÜnull ùëá (by 3.10). To prove the inclusion in the other direction, suppose ùë£ ‚àà null ùëá. Then ùëá(ùë£) = 0 = ùëá(0). Because ùëá is injective, the equation above implies that ùë£ = 0. Thus we can conclude that null ùëá = {0}, as desired. To prove the implication in the other direction, now suppose null ùëá = {0}. We want to prove that ùëá is injective. To do this, suppose ùë¢, ùë£ ‚àà ùëâ and ùëáùë¢ = ùëáùë£. Then 0 = ùëáùë¢ ‚àí ùëáùë£ = ùëá(ùë¢ ‚àí ùë£). Thus ùë¢ ‚àí ùë£ is in null ùëá, which equals {0}. Hence ùë¢ ‚àí ùë£ = 0, which implies that ùë¢ = ùë£. Hence ùëá is injective, as desired. Section 3B Null Spaces and Ranges 61 Range and Surjectivity Now we give a name to the set of outputs of a linear map. 3.16 definition:range For ùëá ‚àà ‚Ñí(ùëâ, ùëä), the range of ùëá is the subset of ùëä consisting of those vectors that are equal to ùëáùë£ for some ùë£ ‚àà ùëâ: range ùëá = {ùëáùë£ ‚à∂ ùë£ ‚àà ùëâ}. 3.17 example:range ‚Ä¢ If ùëá is the zero map from ùëâ to ùëä, meaning that ùëáùë£ = 0for every ùë£ ‚àà ùëâ, then range ùëá = {0}. ‚Ä¢ Suppose ùëá ‚àà ‚Ñí(ùêë2, ùêë3)is defined byùëá(ùë•, ùë¶) = (2ùë•, 5ùë¶, ùë• + ùë¶). Then range ùëá = {(2ùë•, 5ùë¶, ùë• + ùë¶) ‚à∂ ùë•, ùë¶ ‚àà ùêë}. Note that range ùëá is a subspace of ùêë3. We will soon see that the range of each element of ‚Ñí(ùëâ, ùëä) is a subspace of ùëä. ‚Ä¢ Suppose ùê∑ ‚àà ‚Ñí(ùí´(ùêë))is the differentiation map defined byùê∑ùëù = ùëù‚Ä≤. Because for every polynomial ùëû ‚àà ùí´(ùêë) there exists a polynomial ùëù ‚àà ùí´(ùêë) such that ùëù ‚Ä≤ = ùëû, the range of ùê∑ is ùí´(ùêë). The next result shows that the range of each linear map is a subspace of the vector space into which it is being mapped. 3.18 the range is a subspace If ùëá ‚àà ‚Ñí(ùëâ, ùëä), then range ùëá is a subspace of ùëä. Proof Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then ùëá(0) = 0(by 3.10), which implies that 0 ‚ààrange ùëá. If ùë§1, ùë§2 ‚àà range ùëá, then there exist ùë£1, ùë£2 ‚àà ùëâ such that ùëáùë£1 = ùë§1 and ùëáùë£2 = ùë§2. Thus ùëá(ùë£1 + ùë£2) = ùëáùë£1 + ùëáùë£2 = ùë§1 + ùë§2. Hence ùë§1 + ùë§2 ‚àà range ùëá. Thus range ùëá is closed under addition. If ùë§ ‚àà range ùëá and ùúÜ ‚àà ùêÖ, then there exists ùë£ ‚àà ùëâ such that ùëáùë£ = ùë§. Thus ùëá(ùúÜùë£) = ùúÜùëáùë£ = ùúÜùë§. Hence ùúÜùë§ ‚àà range ùëá. Thus range ùëá is closed under scalar multiplication. We have shown that range ùëá contains 0and is closed under addition and scalar multiplication. Thus range ùëá is a subspace of ùëä (by 1.34). 62 Chapter 3 Linear Maps 3.19 definition: surjective A function ùëá‚à∂ ùëâ ‚Üí ùëä is called surjective if its range equals ùëä. To illustrate the definition above, note that of the ranges we computed in3.17, only the differentiation map is surjective (except that the zero map is surjective in the special case ùëä = {0}). Some people use the term onto, which means the same as surjective. Whether a linear map is surjective de- pends on what we are thinking of as the vector space into which it maps. 3.20 example: surjectivity depends on the target space The differentiation map ùê∑ ‚àà ‚Ñí(ùí´5(ùêë))defined byùê∑ùëù = ùëù‚Ä≤ is not surjective, because the polynomial ùë•5 is not in the range of ùê∑. However, the differentiation map ùëÜ ‚àà ‚Ñí(ùí´5(ùêë), ùí´4(ùêë))defined byùëÜùëù = ùëù‚Ä≤ is surjective, because its range equals ùí´4(ùêë), which is the vector space into which ùëÜ maps. Fundamental Theorem of Linear Maps The next result is so important that it gets a dramatic name. 3.21 fundamental theorem of linear maps Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Then range ùëá is finite- dimensional and dim ùëâ = dim null ùëá + dim range ùëá. Proof Let ùë¢1, ‚Ä¶, ùë¢ùëö be a basis of null ùëá; thus dim null ùëá = ùëö. The linearly independent list ùë¢1, ‚Ä¶, ùë¢ùëö can be extended to a basis ùë¢1, ‚Ä¶, ùë¢ùëö, ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ (by 2.32). Thus dim ùëâ = ùëö + ùëõ. To complete the proof, we need to show that range ùëá is finite-dimensional anddim range ùëá = ùëõ. We will do this by proving that ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ is a basis of range ùëá. Let ùë£ ‚àà ùëâ. Because ùë¢1, ‚Ä¶, ùë¢ùëö, ùë£1, ‚Ä¶, ùë£ùëõ spans ùëâ, we can write ùë£ = ùëé1ùë¢1 + ‚ãØ + ùëéùëöùë¢ùëö + ùëè1ùë£1 + ‚ãØ + ùëèùëõùë£ùëõ, where the ùëé‚Äôs and ùëè‚Äôs are in ùêÖ. Applying ùëá to both sides of this equation, we get ùëáùë£ = ùëè1ùëáùë£1 + ‚ãØ + ùëèùëõùëáùë£ùëõ, where the terms of the form ùëáùë¢ùëò disappeared because each ùë¢ùëò is in null ùëá. The last equation implies that the list ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ spans range ùëá. In particular, range ùëá is finite-dimensional. Section 3B Null Spaces and Ranges 63 To show ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ is linearly independent, suppose ùëê1, ‚Ä¶, ùëêùëõ ‚àà ùêÖ and ùëê1ùëáùë£1 + ‚ãØ + ùëêùëõùëáùë£ùëõ = 0. Then ùëá(ùëê1ùë£1 + ‚ãØ + ùëêùëõùë£ùëõ) = 0. Hence ùëê1ùë£1 + ‚ãØ + ùëêùëõùë£ùëõ ‚àà null ùëá. Because ùë¢1, ‚Ä¶, ùë¢ùëö spans null ùëá, we can write ùëê1ùë£1 + ‚ãØ + ùëêùëõùë£ùëõ = ùëë1ùë¢1 + ‚ãØ + ùëëùëöùë¢ùëö, where the ùëë‚Äôs are in ùêÖ. This equation implies that all the ùëê‚Äôs (and ùëë‚Äôs) are 0 (because ùë¢1, ‚Ä¶, ùë¢ùëö, ùë£1, ‚Ä¶, ùë£ùëõ is linearly independent). Thus ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ is linearly independent and hence is a basis of range ùëá, as desired. Now we can show that no linear map from a finite-dimensional vector space to a ‚Äúsmaller‚Äù vector space can be injective, where ‚Äúsmaller‚Äù is measured by dimension. 3.22 linear map to a lower-dimensional space is not injective Suppose ùëâ and ùëä are finite-dimensional vector spaces such that dim ùëâ > dim ùëä. Then no linear map from ùëâ to ùëä is injective. Proof Let ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then dim null ùëá = dim ùëâ ‚àí dim range ùëá ‚â•dim ùëâ ‚àí dim ùëä > 0, where the first line above comes from the fundamental theorem of linear maps (3.21) and the second line follows from 2.37. The inequality above states that dim null ùëá > 0. This means that null ùëá contains vectors other than 0. Thus ùëá is not injective (by 3.15). 3.23 example: linear map from ùêÖ4 to ùêÖ3 is not injective Define a linear mapùëá‚à∂ ùêÖ4 ‚Üí ùêÖ3 by ùëá(ùëß1, ùëß2, ùëß3, ùëß4) = (‚àö7ùëß1 + ùúãùëß2 + ùëß4, 97ùëß1 + 3ùëß2 + 2ùëß3, ùëß2 + 6ùëß3 + 7ùëß4). Because dim ùêÖ4 > dim ùêÖ3, we can use 3.22 to assert that ùëá is not injective, without doing any calculations. 64 Chapter 3 Linear Maps The next result shows that no linear map from a finite-dimensional vector space to a ‚Äúbigger‚Äù vector space can be surjective, where ‚Äúbigger‚Äù is measured by dimension. 3.24 linear map to a higher-dimensional space is not surjective Suppose ùëâ and ùëä are finite-dimensional vector spaces such that dim ùëâ < dim ùëä. Then no linear map from ùëâ to ùëä is surjective. Proof Let ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then dim range ùëá = dim ùëâ ‚àí dim null ùëá ‚â§dim ùëâ < dim ùëä, where the equality above comes from the fundamental theorem of linear maps (3.21). The inequality above states that dim range ùëá < dim ùëä. This means that range ùëá cannot equal ùëä. Thus ùëá is not surjective. As we will soon see, 3.22 and 3.24 have important consequences in the theory of linear equations. The idea is to express questions about systems of linear equations in terms of linear maps. Let‚Äôs begin by rephrasing in terms of linear maps the question of whether a homogeneous system of linear equations has a nonzero solution. Homogeneous, in this context, means that the constant term on the right side of each equation below is 0. Fix positive integers ùëö and ùëõ, and let ùê¥ùëó, ùëò ‚àà ùêÖ for ùëó = 1, ‚Ä¶, ùëö and ùëò = 1, ‚Ä¶, ùëõ. Consider the homogeneous system of lin- ear equations ùëõ ‚àë ùëò = 1 ùê¥1, ùëò ùë•ùëò = 0 ‚ãÆ ùëõ ‚àë ùëò = 1 ùê¥ùëö, ùëò ùë•ùëò = 0. Clearly ùë•1 = ‚ãØ = ùë•ùëõ = 0is a solution of the system of equations above; the question here is whether any other solutions exist. Defineùëá‚à∂ ùêÖùëõ ‚Üí ùêÖùëö by 3.25 ùëá(ùë•1, ‚Ä¶, ùë•ùëõ) = ( ùëõ ‚àë ùëò = 1 ùê¥1, ùëò ùë•ùëò, ‚Ä¶, ùëõ ‚àë ùëò = 1 ùê¥ùëö, ùëò ùë•ùëò). The equation ùëá(ùë•1, ‚Ä¶, ùë•ùëõ) = 0(the 0here is the additive identity in ùêÖùëö, namely, the list of length ùëö of all 0‚Äôs) is the same as the homogeneous system of linear equations above. Thus we want to know if null ùëá is strictly bigger than {0}, which is equivalent to ùëá not being injective (by 3.15). The next result gives an important condition for ensuring that ùëá is not injective. Section 3B Null Spaces and Ranges 65 3.26 homogeneous system of linear equations A homogeneous system of linear equations with more variables than equations has nonzero solutions. Proof Use the notation and result from the discussion above. Thus ùëá is a linear map from ùêÖùëõ to ùêÖùëö, and we have a homogeneous system of ùëö linear equations with ùëõ variables ùë•1, ‚Ä¶, ùë•ùëõ. From 3.22 we see that ùëá is not injective if ùëõ > ùëö. Example of the result above: a homogeneous system of four linear equations with five variables has nonzero solutions. Inhomogeneous, as used in this con- text, means that the constant term on the right side of at least one equation below does not equal 0. Now we consider the question of whether an inhomogeneous system of lin- ear equations has no solutions for some choice of the constant terms. To rephrase this question in terms of a linear map, fix positive integers ùëö and ùëõ, and let ùê¥ùëó, ùëò ‚àà ùêÖ for all ùëó = 1, ‚Ä¶, ùëö and all ùëò = 1, ‚Ä¶, ùëõ. For ùëê1, ‚Ä¶, ùëêùëö ‚àà ùêÖ, consider the system of linear equations ùëõ ‚àë ùëò = 1 ùê¥1, ùëò ùë•ùëò = ùëê1 ‚ãÆ3.27 ùëõ ‚àë ùëò = 1 ùê¥ùëö, ùëò ùë•ùëò = ùëêùëö. The question here is whether there is some choice of ùëê1, ‚Ä¶, ùëêùëö ‚àà ùêÖ such that no solution exists to the system above. The results 3.26 and 3.28, which com- pare the number of variables and the number of equations, can also be proved using Gaussian elimina- tion. The abstract approach taken here seems to provide cleaner proofs. Defineùëá‚à∂ ùêÖùëõ ‚Üí ùêÖùëö as in 3.25. The equation ùëá(ùë•1, ‚Ä¶, ùë•ùëõ) = (ùëê1, ‚Ä¶, ùëêùëö) is the same as the system of equations 3.27. Thus we want to know if range ùëá ‚â† ùêÖùëö. Hence we can rephrase our question about not having a solution for some choice of ùëê1, ‚Ä¶, ùëêùëö ‚àà ùêÖ as follows: What condition ensures that ùëá is not surjective? The next result gives one such condition. 3.28 inhomogeneous system of linear equations An inhomogeneous system of linear equations with more equations than variables has no solution for some choice of the constant terms. Proof Use the notation and result from the example above. Thus ùëá is a linear map from ùêÖùëõ to ùêÖùëö, and we have a system of ùëö equations with ùëõ variables ùë•1, ‚Ä¶, ùë•ùëõ. From 3.24 we see that ùëá is not surjective if ùëõ < ùëö. Example of the result above: an inhomogeneous system of five linear equations with four variables has no solution for some choice of the constant terms. 66 Chapter 3 Linear Maps Exercises 3B 1 Give an example of a linear map ùëá with dim null ùëá = 3and dim range ùëá = 2. 2 Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) are such that range ùëÜ ‚äÜnull ùëá. Prove that (ùëÜùëá)2 = 0. 3 Suppose ùë£1, ‚Ä¶, ùë£ùëö is a list of vectors in ùëâ. Defineùëá ‚àà ‚Ñí(ùêÖùëö, ùëâ)by ùëá(ùëß1, ‚Ä¶, ùëßùëö) = ùëß1ùë£1 + ‚ãØ + ùëßùëöùë£ùëö. (a) What property of ùëá corresponds to ùë£1, ‚Ä¶, ùë£ùëö spanning ùëâ? (b) What property of ùëá corresponds to the list ùë£1, ‚Ä¶, ùë£ùëö being linearly independent? 4 Show that {ùëá ‚àà ‚Ñí(ùêë5, ùêë4)‚à∂ dim null ùëá > 2}is not a subspace of ‚Ñí(ùêë5, ùêë4). 5 Give an example of ùëá ‚àà ‚Ñí(ùêë4)such that range ùëá = null ùëá. 6 Prove that there does not exist ùëá ‚àà ‚Ñí(ùêë5)such that range ùëá = null ùëá. 7 Suppose ùëâ and ùëä are finite-dimensional with2 ‚â§dim ùëâ ‚â§dim ùëä. Show that {ùëá ‚àà ‚Ñí(ùëâ, ùëä) ‚à∂ ùëá is not injective}is not a subspace of ‚Ñí(ùëâ, ùëä). 8 Suppose ùëâ and ùëä are finite-dimensional withdim ùëâ ‚â•dim ùëä ‚â• 2. Show that {ùëá ‚àà ‚Ñí(ùëâ, ùëä) ‚à∂ ùëá is not surjective}is not a subspace of ‚Ñí(ùëâ, ùëä). 9 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) is injective and ùë£1, ‚Ä¶, ùë£ùëõ is linearly independent in ùëâ. Prove that ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ is linearly independent in ùëä. 10 Suppose ùë£1, ‚Ä¶, ùë£ùëõ spans ùëâ and ùëá ‚àà ‚Ñí(ùëâ, ùëä). Show that ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ spans range ùëá. 11 Suppose that ùëâ is finite-dimensional and thatùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that there exists a subspace ùëà of ùëâ such that ùëà ‚à©null ùëá = {0} and range ùëá = {ùëáùë¢ ‚à∂ ùë¢ ‚àà ùëà}. 12 Suppose ùëá is a linear map from ùêÖ4 to ùêÖ2 such that null ùëá = {(ùë•1, ùë•2, ùë•3, ùë•4) ‚àà ùêÖ4 ‚à∂ ùë•1 = 5ùë•2 and ùë•3 = 7ùë•4}. Prove that ùëá is surjective. 13 Suppose ùëà is a three-dimensional subspace of ùêë8 and that ùëá is a linear map from ùêë8 to ùêë5 such that null ùëá = ùëà. Prove that ùëá is surjective. 14 Prove that there does not exist a linear map from ùêÖ5 to ùêÖ2 whose null space equals {(ùë•1, ùë•2, ùë•3, ùë•4, ùë•5) ‚àà ùêÖ5 ‚à∂ ùë•1 = 3ùë•2 and ùë•3 = ùë•4 = ùë•5}. 15 Suppose there exists a linear map on ùëâ whose null space and range are both finite-dimensional. Prove thatùëâ is finite-dimensional. Section 3B Null Spaces and Ranges 67 16 Suppose ùëâ and ùëä are both finite-dimensional. Prove that there exists an injective linear map from ùëâ to ùëä if and only if dim ùëâ ‚â§dim ùëä. 17 Suppose ùëâ and ùëä are both finite-dimensional. Prove that there exists a surjective linear map from ùëâ onto ùëä if and only if dim ùëâ ‚â•dim ùëä. 18 Suppose ùëâ and ùëä are finite-dimensional and thatùëà is a subspace of ùëâ. Prove that there exists ùëá ‚àà ‚Ñí(ùëâ, ùëä) such that null ùëá = ùëà if and only if dim ùëà ‚â•dim ùëâ ‚àí dim ùëä. 19 Suppose ùëä is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that ùëá is injective if and only if there exists ùëÜ ‚àà ‚Ñí(ùëä, ùëâ) such that ùëÜùëá is the identity operator on ùëâ. 20 Suppose ùëä is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that ùëá is surjective if and only if there exists ùëÜ ‚àà ‚Ñí(ùëä, ùëâ) such that ùëáùëÜ is the identity operator on ùëä. 21 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ, ùëä), and ùëà is a subspace of ùëä. Prove that {ùë£ ‚àà ùëâ ‚à∂ ùëáùë£ ‚àà ùëà} is a subspace of ùëâ and dim{ùë£ ‚àà ùëâ ‚à∂ ùëáùë£ ‚àà ùëà} = dim null ùëá + dim(ùëà ‚à©range ùëá). 22 Suppose ùëà and ùëâ are finite-dimensional vector spaces andùëÜ ‚àà ‚Ñí(ùëâ, ùëä) and ùëá ‚àà ‚Ñí(ùëà, ùëâ). Prove that dim null ùëÜùëá ‚â§dim null ùëÜ + dim null ùëá. 23 Suppose ùëà and ùëâ are finite-dimensional vector spaces andùëÜ ‚àà ‚Ñí(ùëâ, ùëä) and ùëá ‚àà ‚Ñí(ùëà, ùëâ). Prove that dim range ùëÜùëá ‚â§min{dim range ùëÜ, dim range ùëá}. 24 (a) Suppose dim ùëâ = 5and ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) are such that ùëÜùëá = 0. Prove that dim range ùëáùëÜ ‚â§ 2. (b) Give an example of ùëÜ, ùëá ‚àà ‚Ñí(ùêÖ5)with ùëÜùëá = 0and dim range ùëáùëÜ = 2. 25 Suppose that ùëä is finite-dimensional andùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that null ùëÜ ‚äÜnull ùëá if and only if there exists ùê∏ ‚àà ‚Ñí(ùëä) such that ùëá = ùê∏ùëÜ. 26 Suppose that ùëâ is finite-dimensional andùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that range ùëÜ ‚äÜrange ùëá if and only if there exists ùê∏ ‚àà ‚Ñí(ùëâ) such that ùëÜ = ùëáùê∏. 27 Suppose ùëÉ ‚àà ‚Ñí(ùëâ) and ùëÉ2 = ùëÉ. Prove that ùëâ = null ùëÉ ‚äï range ùëÉ. 28 Suppose ùê∑ ‚àà ‚Ñí(ùí´(ùêë))is such that deg ùê∑ùëù = (deg ùëù) ‚àí 1for every non- constant polynomial ùëù ‚àà ùí´(ùêë). Prove that ùê∑ is surjective. The notation ùê∑ is used above to remind you of the differentiation map that sends a polynomial ùëù to ùëù ‚Ä≤. 68 Chapter 3 Linear Maps 29 Suppose ùëù ‚àà ùí´(ùêë). Prove that there exists a polynomial ùëû ‚àà ùí´(ùêë) such that 5ùëû ‚Ä≥ + 3ùëû ‚Ä≤ = ùëù. This exercise can be done without linear algebra, but it‚Äôs more fun to do it using linear algebra. 30 Suppose ùúë ‚àà ‚Ñí(ùëâ, ùêÖ) and ùúë ‚â† 0. Suppose ùë¢ ‚àà ùëâ is not in null ùúë. Prove that ùëâ = null ùúë ‚äï {ùëéùë¢ ‚à∂ ùëé ‚àà ùêÖ}. 31 Suppose ùëâ is finite-dimensional,ùëã is a subspace of ùëâ, and ùëå is a finite- dimensional subspace of ùëä. Prove that there exists ùëá ‚àà ‚Ñí(ùëâ, ùëä) such that null ùëá = ùëã and range ùëá = ùëå if and only if dim ùëã + dim ùëå = dim ùëâ. 32 Suppose ùëâ is finite-dimensional withdim ùëâ > 1. Show that if ùúë‚à∂ ‚Ñí(ùëâ) ‚Üí ùêÖ is a linear map such that ùúë(ùëÜùëá) = ùúë(ùëÜ)ùúë(ùëá) for all ùëÜ, ùëá ‚àà ‚Ñí(ùëâ), then ùúë = 0. Hint: The description of the two-sided ideals of ‚Ñí(ùëâ) given by Exercise 17 in Section 3A might be useful. 33 Suppose that ùëâ and ùëä are real vector spaces and ùëá ‚àà ‚Ñí(ùëâ, ùëä). Define ùëáùêÇ ‚à∂ ùëâùêÇ ‚Üí ùëäùêÇ by ùëáùêÇ(ùë¢ + ùëñùë£) = ùëáùë¢ + ùëñùëáùë£ for all ùë¢, ùë£ ‚àà ùëâ. (a) Show that ùëáùêÇ is a (complex) linear map from ùëâùêÇ to ùëäùêÇ. (b) Show that ùëáùêÇ is injective if and only if ùëá is injective. (c) Show that range ùëáùêÇ = ùëäùêÇ if and only if range ùëá = ùëä. See Exercise 8 in Section 1B for the definition of the complexification ùëâùêÇ. The linear map ùëáùêÇ is called the complexification of the linear map ùëá. Section 3C Matrices 69 3C Matrices Representing a Linear Map by a Matrix We know that if ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùëá‚à∂ ùëâ ‚Üí ùëä is linear, then the values of ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ determine the values of ùëá on arbitrary vectors in ùëâ‚Äîsee the linear map lemma (3.4). As we will soon see, matrices provide an efficient method of recording the values of the ùëáùë£ùëò‚Äôs in terms of a basis of ùëä. 3.29 definition: matrix, ùê¥ùëó, ùëò Suppose ùëö and ùëõ are nonnegative integers. An ùëö-by-ùëõ matrix ùê¥ is a rectangular array of elements of ùêÖ with ùëö rows and ùëõ columns: ùê¥ = ‚éõ‚éú‚éú‚éú ‚éù ùê¥1, 1 ‚ãØ ùê¥1, ùëõ ‚ãÆ ‚ãÆ ùê¥ùëö, 1 ‚ãØ ùê¥ùëö, ùëõ ‚éû‚éü‚éü‚éü ‚é† . The notation ùê¥ùëó, ùëò denotes the entry in row ùëó, column ùëò of ùê¥. 3.30 example: ùê¥ùëó, ùëò equals entry in row ùëó, column ùëò of ùê¥ When dealing with matrices, the first index refers to the row number; the sec- ond index refers to the column number. Suppose ùê¥ = ( 8 4 5 ‚àí 3ùëñ 1 9 7). Thus ùê¥2, 3 refers to the entry in the sec- ond row, third column of ùê¥, which means that ùê¥2, 3 = 7. Now we come to the key definition in this section. 3.31 definition: matrix of a linear map, ‚Ñ≥(ùëá) Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùë§1, ‚Ä¶, ùë§ùëö is a basis of ùëä. The matrix of ùëá with respect to these bases is the ùëö-by-ùëõ matrix ‚Ñ≥(ùëá) whose entries ùê¥ùëó, ùëò are defined by ùëáùë£ùëò = ùê¥1, ùëòùë§1 + ‚ãØ + ùê¥ùëö, ùëòùë§ùëö. If the bases ùë£1, ‚Ä¶, ùë£ùëõ and ùë§1, ‚Ä¶, ùë§ùëö are not clear from the context, then the notation ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ), (ùë§1, ‚Ä¶, ùë§ùëö))is used. The matrix ‚Ñ≥(ùëá) of a linear map ùëá ‚àà ‚Ñí(ùëâ, ùëä) depends on the basis ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ and the basis ùë§1, ‚Ä¶, ùë§ùëö of ùëä, as well as on ùëá. However, the bases should be clear from the context, and thus they are often not included in the notation. To remember how ‚Ñ≥(ùëá) is constructed from ùëá, you might write across the top of the matrix the basis vectors ùë£1, ‚Ä¶, ùë£ùëõ for the domain and along the left the basis vectors ùë§1, ‚Ä¶, ùë§ùëö for the vector space into which ùëá maps, as follows: 70 Chapter 3 Linear Maps ùë£1 ‚ãØ ùë£ùëò ‚ãØ ùë£ùëõ ùë§1 ‚Ñ≥(ùëá) = ‚ãÆ ùë§ùëö ‚éõ‚éú‚éú‚éú ‚éù ùê¥1, ùëò ‚ãÆ ùê¥ùëö, ùëò ‚éû‚éü‚éü‚éü ‚é† . The ùëòth column of ‚Ñ≥(ùëá) consists of the scalars needed to write ùëáùë£ùëò as a linear combination of ùë§1, ‚Ä¶, ùë§ùëö: ùëáùë£ùëò = ùëö ‚àë ùëó = 1 ùê¥ùëó, ùëòùë§ùëó. In the matrix above only the ùëòth col- umn is shown. Thus the second index of each displayed entry of the matrix above is ùëò. The picture above should remind you that ùëáùë£ùëò can be computed from ‚Ñ≥(ùëá) by multiplying each entry in the ùëòth column by the corresponding ùë§ùëó from the left col- umn, and then adding up the resulting vectors. If ùëá is a linear map from an ùëõ-dimensional vector space to an ùëö-dimensional vector space, then ‚Ñ≥(ùëá) is an ùëö-by-ùëõ matrix. If ùëá is a linear map from ùêÖùëõ to ùêÖùëö, then unless stated otherwise, assume the bases in question are the standard ones (where the ùëòth basis vector is 1in the ùëòth slot and 0in all other slots). If you think of elements of ùêÖùëö as columns of ùëö numbers, then you can think of the ùëòth column of ‚Ñ≥(ùëá) as ùëá applied to the ùëòth standard basis vector. 3.32 example: the matrix of a linear map from ùêÖ2 to ùêÖ3 Suppose ùëá ‚àà ‚Ñí(ùêÖ2, ùêÖ3)is defined by ùëá(ùë•, ùë¶) = (ùë• + 3ùë¶, 2ùë•+ 5ùë¶, 7ùë•+ 9ùë¶). Because ùëá(1, 0) = (1, 2, 7)and ùëá(0, 1) = (3, 5, 9), the matrix of ùëá with respect to the standard bases is the 3-by-2matrix below: ‚Ñ≥(ùëá) = ‚éõ‚éú‚éú‚éú ‚éù 1 3 2 5 7 9 ‚éû‚éü‚éü‚éü ‚é† . When working with ùí´ùëö(ùêÖ), use the standard basis 1, ùë•, ùë•2, ‚Ä¶, ùë•ùëö unless the context indicates otherwise. 3.33 example: matrix of the differentiation map from ùí´3(ùêë) to ùí´2(ùêë) Suppose ùê∑ ‚àà ‚Ñí(ùí´3(ùêë), ùí´2(ùêë))is the differentiation map defined byùê∑ùëù = ùëù‚Ä≤. Because (ùë•ùëõ) ‚Ä≤ = ùëõùë•ùëõ ‚àí 1, the matrix of ùê∑ with respect to the standard bases is the 3-by-4matrix below: ‚Ñ≥(ùê∑) = ‚éõ‚éú‚éú‚éú ‚éù 0 1 0 0 0 0 2 0 0 0 0 3 ‚éû‚éü‚éü‚éü ‚é† . Section 3C Matrices 71 Addition and Scalar Multiplication of Matrices For the rest of this section, assume that ùëà, ùëâ, and ùëä are finite-dimensional and that a basis has been chosen for each of these vector spaces. Thus for each linear map from ùëâ to ùëä, we can talk about its matrix (with respect to the chosen bases). Is the matrix of the sum of two linear maps equal to the sum of the matrices of the two maps? Right now this question does not yet make sense because although we have defined the sum of two linear maps, we have not defined the sum of two matrices. Fortunately, the natural definition of the sum of two matrices has the right properties. Specifically, we make the following definition. 3.34 definition: matrix addition The sum of two matrices of the same size is the matrix obtained by adding corresponding entries in the matrices: ‚éõ‚éú‚éú‚éú ‚éù ùê¥1, 1 ‚ãØ ùê¥1, ùëõ ‚ãÆ ‚ãÆ ùê¥ùëö, 1 ‚ãØ ùê¥ùëö, ùëõ ‚éû‚éü‚éü‚éü ‚é† + ‚éõ‚éú‚éú‚éú ‚éù ùê∂1, 1 ‚ãØ ùê∂1, ùëõ ‚ãÆ ‚ãÆ ùê∂ùëö, 1 ‚ãØ ùê∂ùëö, ùëõ ‚éû‚éü‚éü‚éü ‚é† = ‚éõ‚éú‚éú‚éú ‚éù ùê¥1, 1 + ùê∂1, 1 ‚ãØ ùê¥1, ùëõ + ùê∂1, ùëõ ‚ãÆ ‚ãÆ ùê¥ùëö, 1 + ùê∂ùëö, 1 ‚ãØ ùê¥ùëö, ùëõ + ùê∂ùëö, ùëõ ‚éû‚éü‚éü‚éü ‚é† . In the next result, the assumption is that the same bases are used for all three linear maps ùëÜ + ùëá, ùëÜ, and ùëá. 3.35 matrix of the sum of linear maps Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then ‚Ñ≥(ùëÜ + ùëá) = ‚Ñ≥(ùëÜ) + ‚Ñ≥(ùëá). The verification of the result above follows from the definitions and is left to the reader. Still assuming that we have some bases in mind, is the matrix of a scalar times a linear map equal to the scalar times the matrix of the linear map? Again, the question does not yet make sense because we have not defined scalar multiplication on matrices. Fortunately, the natural definition again has the right properties. 3.36 definition:scalar multiplication of a matrix The product of a scalar and a matrix is the matrix obtained by multiplying each entry in the matrix by the scalar: ùúÜ‚éõ‚éú‚éú‚éú ‚éù ùê¥1, 1 ‚ãØ ùê¥1, ùëõ ‚ãÆ ‚ãÆ ùê¥ùëö, 1 ‚ãØ ùê¥ùëö, ùëõ ‚éû‚éü‚éü‚éü ‚é† = ‚éõ‚éú‚éú‚éú ‚éù ùúÜùê¥1, 1 ‚ãØ ùúÜùê¥1, ùëõ ‚ãÆ ‚ãÆ ùúÜùê¥ùëö, 1 ‚ãØ ùúÜùê¥ùëö, ùëõ ‚éû‚éü‚éü‚éü ‚é† . 72 Chapter 3 Linear Maps 3.37 example:addition and scalar multiplication of matrices 2( 3 1 ‚àí1 5 )+ ( 4 2 1 6 )= ( 6 2 ‚àí2 10 )+ ( 4 2 1 6 )= ( 10 4 ‚àí1 16 ) In the next result, the assumption is that the same bases are used for both the linear maps ùúÜùëá and ùëá. 3.38 the matrix of a scalar times a linear map Suppose ùúÜ ‚àà ùêÖ and ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then ‚Ñ≥(ùúÜùëá) = ùúÜ‚Ñ≥(ùëá). The verification of the result above is also left to the reader. Because addition and scalar multiplication have now been defined for matrices, you should not be surprised that a vector space is about to appear. First we introduce a bit of notation so that this new vector space has a name, and then we find the dimension of this new vector space. 3.39 notation: ùêÖùëö, ùëõ For ùëö and ùëõ positive integers, the set of all ùëö-by-ùëõ matrices with entries in ùêÖ is denoted by ùêÖùëö, ùëõ. 3.40 dim ùêÖùëö, ùëõ = ùëöùëõ Suppose ùëö and ùëõ are positive integers. With addition and scalar multiplication defined as above,ùêÖùëö, ùëõ is a vector space of dimension ùëöùëõ. Proof The verification thatùêÖùëö, ùëõ is a vector space is left to the reader. Note that the additive identity of ùêÖùëö, ùëõ is the ùëö-by-ùëõ matrix all of whose entries equal 0. The reader should also verify that the list of distinct ùëö-by-ùëõ matrices that have 0in all entries except for a 1in one entry is a basis of ùêÖùëö, ùëõ. There are ùëöùëõ such matrices, so the dimension of ùêÖùëö, ùëõ equals ùëöùëõ. Matrix Multiplication Suppose, as previously, that ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùë§1, ‚Ä¶, ùë§ùëö is a basis of ùëä. Suppose also that ùë¢1, ‚Ä¶, ùë¢ùëù is a basis of ùëà. Consider linear maps ùëá‚à∂ ùëà ‚Üí ùëâ and ùëÜ‚à∂ ùëâ ‚Üí ùëä. The composition ùëÜùëá is a linear map from ùëà to ùëä. Does ‚Ñ≥(ùëÜùëá) equal ‚Ñ≥(ùëÜ)‚Ñ≥(ùëá)? This question does not yet make sense because we have not defined the product of two matrices. We will choose a definition of matrix multiplication that forces this question to have a positive answer. Let‚Äôs see how to do this. Section 3C Matrices 73 Suppose ‚Ñ≥(ùëÜ) = ùê¥ and ‚Ñ≥(ùëá) = ùêµ. For 1 ‚â§ ùëò ‚â§ ùëù, we have (ùëÜùëá)ùë¢ùëò = ùëÜ( ùëõ ‚àë ùëü = 1 ùêµùëü, ùëòùë£ùëü) = ùëõ ‚àë ùëü = 1 ùêµùëü, ùëòùëÜùë£ùëü = ùëõ ‚àë ùëü = 1 ùêµùëü, ùëò ùëö ‚àë ùëó = 1 ùê¥ùëó, ùëüùë§ùëó = ùëö ‚àë ùëó = 1( ùëõ ‚àë ùëü = 1 ùê¥ùëó, ùëüùêµùëü, ùëò)ùë§ùëó. Thus ‚Ñ≥(ùëÜùëá) is the ùëö-by-ùëù matrix whose entry in row ùëó, column ùëò, equals ùëõ ‚àë ùëü = 1 ùê¥ùëó, ùëüùêµùëü, ùëò. Now we see how to define matrix multiplication so that the desired equation ‚Ñ≥(ùëÜùëá) = ‚Ñ≥(ùëÜ)‚Ñ≥(ùëá) holds. 3.41 definition: matrix multiplication Suppose ùê¥ is an ùëö-by-ùëõ matrix and ùêµ is an ùëõ-by-ùëù matrix. Then ùê¥ùêµ is defined to be the ùëö-by-ùëù matrix whose entry in row ùëó, column ùëò, is given by the equation (ùê¥ùêµ)ùëó, ùëò = ùëõ ‚àë ùëü = 1 ùê¥ùëó, ùëüùêµùëü, ùëò. Thus the entry in row ùëó, column ùëò, of ùê¥ùêµ is computed by taking row ùëó of ùê¥ and column ùëò of ùêµ, multiplying together corresponding entries, and then summing. You may have learned this definition of matrix multiplication in an earlier course, although you may not have seen this motivation for it. Note that we define the product of two matrices only when the number of columns of the first matrix equals the number of rows of the second matrix. 3.42 example: matrix multiplication Here we multiply together a 3-by-2matrix and a 2-by-4matrix, obtaining a 3-by-4matrix: ‚éõ‚éú‚éú‚éú ‚éù 1 2 3 4 5 6 ‚éû‚éü‚éü‚éü ‚é† ( 6 5 4 3 2 1 0 ‚àí1 )= ‚éõ‚éú‚éú‚éú ‚éù 10 7 4 1 26 19 12 5 42 31 20 9 ‚éû‚éü‚éü‚éü ‚é† . Matrix multiplication is not commutative‚Äîùê¥ùêµ is not necessarily equal to ùêµùê¥ even if both products are defined (see Exercise10). Matrix multiplication is distributive and associative (see Exercises 11 and 12). 74 Chapter 3 Linear Maps In the next result, we assume that the same basis of ùëâ is used in considering ùëá ‚àà ‚Ñí(ùëà, ùëâ) and ùëÜ ‚àà ‚Ñí(ùëâ, ùëä), the same basis of ùëä is used in considering ùëÜ ‚àà ‚Ñí(ùëâ, ùëä) and ùëÜùëá ‚àà ‚Ñí(ùëà, ùëä), and the same basis of ùëà is used in considering ùëá ‚àà ‚Ñí(ùëà, ùëâ) and ùëÜùëá ‚àà ‚Ñí(ùëà, ùëä). 3.43 matrix of product of linear maps If ùëá ‚àà ‚Ñí(ùëà, ùëâ) and ùëÜ ‚àà ‚Ñí(ùëâ, ùëä), then ‚Ñ≥(ùëÜùëá) = ‚Ñ≥(ùëÜ)‚Ñ≥(ùëá). The proof of the result above is the calculation that was done as motivation before the definition of matrix multiplication. In the next piece of notation, note that as usual the first index refers to a row and the second index refers to a column, with a vertically centered dot used as a placeholder. 3.44 notation: ùê¥ùëó, ‚ãÖ , ùê¥‚ãÖ, ùëò Suppose ùê¥ is an ùëö-by-ùëõ matrix. ‚Ä¢ If 1 ‚â§ ùëó ‚â§ ùëö, then ùê¥ùëó, ‚ãÖ denotes the 1-by-ùëõ matrix consisting of row ùëó of ùê¥. ‚Ä¢ If 1 ‚â§ ùëò ‚â§ ùëõ, then ùê¥‚ãÖ, ùëò denotes the ùëö-by-1matrix consisting of column ùëò of ùê¥. 3.45 example: ùê¥ùëó, ‚ãÖ equals ùëóth row of ùê¥ and ùê¥‚ãÖ, ùëò equals ùëòth column of ùê¥ The notation ùê¥2, ‚ãÖ denotes the second row of ùê¥ and ùê¥‚ãÖ, 2 denotes the second column of ùê¥. Thus if ùê¥ = ( 8 4 5 1 9 7 ), then ùê¥2, ‚ãÖ = (1 9 7) and ùê¥‚ãÖ, 2 = ( 4 9). The product of a 1-by-ùëõ matrix and an ùëõ-by-1matrix is a 1-by-1matrix. How- ever, we will frequently identify a 1-by-1matrix with its entry. For example, (3 4)( 6 2)= (26) because 3 ‚ãÖ 6+ 4 ‚ãÖ 2 = 26. However, we can identify (26)with 26, writing (3 4)( 6 2)= 26. The next result uses the convention discussed in the paragraph above to give another way to think of matrix multiplication. For example, the next result and the calculation in the paragraph above explain why the entry in row 2, column 1, of the product in Example 3.42 equals 26. Section 3C Matrices 75 3.46 entry of matrix product equals row times column Suppose ùê¥ is an ùëö-by-ùëõ matrix and ùêµ is an ùëõ-by-ùëù matrix. Then (ùê¥ùêµ)ùëó, ùëò = ùê¥ùëó, ‚ãÖ ùêµ‚ãÖ, ùëò if 1 ‚â§ ùëó ‚â§ ùëöand 1 ‚â§ ùëò ‚â§ ùëù. In other words, the entry in row ùëó, column ùëò, of ùê¥ùêµ equals (row ùëó of ùê¥) times (column ùëò of ùêµ). Proof Suppose 1 ‚â§ ùëó ‚â§ ùëöand 1 ‚â§ ùëò ‚â§ ùëù. The definition of matrix multiplication states that 3.47 (ùê¥ùêµ)ùëó, ùëò = ùê¥ùëó, 1ùêµ1, ùëò + ‚ãØ + ùê¥ùëó, ùëõùêµùëõ, ùëò. The definition of matrix multiplication also implies that the product of the1-by-ùëõ matrix ùê¥ùëó, ‚ãÖ and the ùëõ-by-1matrix ùêµ‚ãÖ, ùëò is the 1-by-1matrix whose entry is the number on the right side of the equation above. Thus the entry in row ùëó, column ùëò, of ùê¥ùêµ equals (row ùëó of ùê¥) times (column ùëò of ùêµ). The next result gives yet another way to think of matrix multiplication. In the result below, (ùê¥ùêµ)‚ãÖ, ùëò is column ùëò of the ùëö-by-ùëù matrix ùê¥ùêµ. Thus (ùê¥ùêµ)‚ãÖ, ùëò is an ùëö-by-1matrix. Also, ùê¥ùêµ‚ãÖ, ùëò is an ùëö-by-1matrix because it is the product of an ùëö-by-ùëõ matrix and an ùëõ-by-1matrix. Thus the two sides of the equation in the result below have the same size, making it reasonable that they might be equal. 3.48 column of matrix product equals matrix times column Suppose ùê¥ is an ùëö-by-ùëõ matrix and ùêµ is an ùëõ-by-ùëù matrix. Then (ùê¥ùêµ)‚ãÖ, ùëò = ùê¥ùêµ‚ãÖ, ùëò if 1 ‚â§ ùëò ‚â§ ùëù. In other words, column ùëò of ùê¥ùêµ equals ùê¥ times column ùëò of ùêµ. Proof As discussed above, (ùê¥ùêµ)‚ãÖ, ùëò and ùê¥ùêµ‚ãÖ, ùëò are both ùëö-by-1matrices. If 1 ‚â§ ùëó ‚â§ ùëö, then the entry in row ùëó of (ùê¥ùêµ)‚ãÖ, ùëò is the left side of 3.47 and the entry in row ùëó of ùê¥ùêµ‚ãÖ, ùëò is the right side of 3.47. Thus (ùê¥ùêµ)‚ãÖ, ùëò = ùê¥ùêµ‚ãÖ, ùëò. Our next result will give another way of thinking about the product of an ùëö-by-ùëõ matrix and an ùëõ-by-1matrix, motivated by the next example. 3.49 example: product of a 3-by-2matrix and a 2-by-1matrix Use our definitions and basic arithmetic to verify that ‚éõ‚éú‚éú‚éú ‚éù 1 2 3 4 5 6 ‚éû‚éü‚éü‚éü ‚é† ( 5 1)= ‚éõ‚éú‚éú‚éú ‚éù 7 19 31 ‚éû‚éü‚éü‚éü ‚é† = 5 ‚éõ‚éú‚éú‚éú ‚éù 1 3 5 ‚éû‚éü‚éü‚éü ‚é† + 1 ‚éõ‚éú‚éú‚éú ‚éù 2 4 6 ‚éû‚éü‚éü‚éü ‚é† . Thus in this example, the product of a 3-by-2matrix and a 2-by-1matrix is a linear combination of the columns of the 3-by-2matrix, with the scalars (5and 1) that multiply the columns coming from the 2-by-1matrix. 76 Chapter 3 Linear Maps The next result generalizes the example above. 3.50 linear combination of columns Suppose ùê¥ is an ùëö-by-ùëõ matrix and ùëè = ‚éõ‚éú‚éú‚éú ‚éù ùëè1 ‚ãÆ ùëèùëõ ‚éû‚éü‚éü‚éü ‚é† is an ùëõ-by-1matrix. Then ùê¥ùëè = ùëè1ùê¥‚ãÖ, 1 + ‚ãØ + ùëèùëõ ùê¥‚ãÖ, ùëõ. In other words, ùê¥ùëè is a linear combination of the columns of ùê¥, with the scalars that multiply the columns coming from ùëè. Proof If ùëò ‚àà {1, ‚Ä¶, ùëö}, then the definition of matrix multiplication implies that the entry in row ùëò of the ùëö-by-1matrix ùê¥ùëè is ùê¥ùëò, 1ùëè1 + ‚ãØ + ùê¥ùëò, ùëõùëèùëõ. The entry in row ùëò of ùëè1ùê¥‚ãÖ, 1 + ‚ãØ + ùëèùëõ ùê¥‚ãÖ, ùëõ also equals the number displayed above. Because ùê¥ùëè and ùëè1ùê¥‚ãÖ, 1 + ‚ãØ + ùëèùëõ ùê¥‚ãÖ, ùëõ have the same entry in row ùëò for each ùëò ‚àà {1, ‚Ä¶, ùëö}, we conclude that ùê¥ùëè = ùëè1ùê¥‚ãÖ, 1 + ‚ãØ + ùëèùëõ ùê¥‚ãÖ, ùëõ. Our two previous results focus on the columns of a matrix. Analogous results hold for the rows of a matrix. Specifically, see Exercises8 and 9, which can be proved using appropriate modifications of the proofs of3.48 and 3.50. The next result is the main tool used in the next subsection to prove the column‚Äìrow factorization (3.56) and to prove that the column rank of a matrix equals the row rank (3.57). To be consistent with the notation often used with the column‚Äìrow factorization, including in the next subsection, the matrices in the next result are called ùê∂ and ùëÖ instead of ùê¥ and ùêµ. 3.51 matrix multiplication as linear combinations of columns Suppose ùê∂ is an ùëö-by-ùëê matrix and ùëÖ is a ùëê-by-ùëõ matrix. (a) If ùëò ‚àà {1, ‚Ä¶, ùëõ}, then column ùëò of ùê∂ùëÖ is a linear combination of the columns of ùê∂, with the coefficients of this linear combination coming from column ùëò of ùëÖ. (b) If ùëó ‚àà {1, ‚Ä¶, ùëö}, then row ùëó of ùê∂ùëÖ is a linear combination of the rows of ùëÖ, with the coefficients of this linear combination coming from row ùëó of ùê∂. Proof Suppose ùëò ‚àà {1, ‚Ä¶, ùëõ}. Then column ùëò of ùê∂ùëÖ equals ùê∂ùëÖ‚ãÖ, ùëò (by 3.48), which equals the linear combination of the columns of ùê∂ with coefficients coming from ùëÖ‚ãÖ, ùëò (by 3.50). Thus (a) holds. To prove (b), follow the pattern of the proof of (a) but use rows instead of columns and use Exercises 8 and 9 instead of 3.48 and 3.50. Section 3C Matrices 77 Column‚ÄìRow Factorization and Rank of a Matrix We begin by defining two nonnegative integers associated with each matrix. 3.52 definition: column rank, row rank Suppose ùê¥ is an ùëö-by-ùëõ matrix with entries in ùêÖ. ‚Ä¢ The column rank of ùê¥ is the dimension of the span of the columns of ùê¥ in ùêÖùëö, 1. ‚Ä¢ The row rank of ùê¥ is the dimension of the span of the rows of ùê¥ in ùêÖ1, ùëõ. If ùê¥ is an ùëö-by-ùëõ matrix, then the column rank of ùê¥ is at most ùëõ (because ùê¥ has ùëõ columns) and the column rank of ùê¥ is also at most ùëö (because dim ùêÖùëö, 1 = ùëö). Similarly, the row rank of ùê¥ is also at most min{ùëö, ùëõ}. 3.53 example: column rank and row rank of a 2-by-4matrix Suppose ùê¥ = ( 4 7 1 8 3 5 2 9 ). The column rank of ùê¥ is the dimension of span ‚éõ‚éú‚éú ‚éù ( 4 3), ( 7 5), ( 1 2), ( 8 9)‚éû‚éü‚éü ‚é† in ùêÖ2, 1. Neither of the first two vectors listed above inùêÖ2, 1 is a scalar multiple of the other. Thus the span of this list of length four has dimension at least two. The span of this list of vectors in ùêÖ2, 1 cannot have dimension larger than two because dim ùêÖ2, 1 = 2. Thus the span of this list has dimension two, which means that the column rank of ùê¥ is two. The row rank of ùê¥ is the dimension of span((4 7 1 8), (3 5 2 9)) in ùêÖ1, 4. Neither of the two vectors listed above in ùêÖ1, 4 is a scalar multiple of the other. Thus the span of this list of length two has dimension two, which means that the row rank of ùê¥ is two. We now define the transpose of a matrix. 3.54 definition: transpose, ùê¥ t The transpose of a matrix ùê¥, denoted by ùê¥ t, is the matrix obtained from ùê¥ by interchanging rows and columns. Specifically, ifùê¥ is an ùëö-by-ùëõ matrix, then ùê¥ t is the ùëõ-by-ùëö matrix whose entries are given by the equation (ùê¥ t) ùëò, ùëó = ùê¥ùëó, ùëò. 78 Chapter 3 Linear Maps 3.55 example: transpose of a matrix If ùê¥ = ‚éõ‚éú‚éú‚éú ‚éù 5 ‚àí7 3 8 ‚àí4 2 ‚éû‚éü‚éü‚éü ‚é† , then ùê¥ t = ( 5 3 ‚àí4 ‚àí7 8 2 ). Note that here ùê¥ is a 3-by-2matrix and ùê¥ t is a 2-by-3matrix. The transpose has nice algebraic properties: (ùê¥ + ùêµ)t = ùê¥t + ùêµ t, (ùúÜùê¥)t = ùúÜùê¥t, and (ùê¥ùê∂) t = ùê∂ tùê¥ t for all ùëö-by-ùëõ matrices ùê¥, ùêµ, all ùúÜ ‚àà ùêÖ, and all ùëõ-by-ùëù matrices ùê∂ (see Exercises 14 and 15). The next result will be the main tool used to prove that the column rank equals the row rank (see 3.57). 3.56 column‚Äìrow factorization Suppose ùê¥ is an ùëö-by-ùëõ matrix with entries in ùêÖ and column rank ùëê ‚â• 1. Then there exist an ùëö-by-ùëê matrix ùê∂ and a ùëê-by-ùëõ matrix ùëÖ, both with entries in ùêÖ, such that ùê¥ = ùê∂ùëÖ. Proof Each column of ùê¥ is an ùëö-by-1matrix. The list ùê¥‚ãÖ, 1, ‚Ä¶, ùê¥‚ãÖ, ùëõ of columns of ùê¥ can be reduced to a basis of the span of the columns of ùê¥ (by 2.30). This basis has length ùëê, by the definition of the column rank. Theùëê columns in this basis can be put together to form an ùëö-by-ùëê matrix ùê∂. If ùëò ‚àà {1, ‚Ä¶, ùëõ}, then column ùëò of ùê¥ is a linear combination of the columns of ùê∂. Make the coefficients of this linear combination into column ùëò of a ùëê-by-ùëõ matrix that we call ùëÖ. Then ùê¥ = ùê∂ùëÖ, as follows from 3.51(a). In Example 3.53, the column rank and row rank turned out to equal each other. The next result states that this happens for all matrices. 3.57 column rank equals row rank Suppose ùê¥ ‚àà ùêÖùëö, ùëõ. Then the column rank of ùê¥ equals the row rank of ùê¥. Proof Let ùëê denote the column rank of ùê¥. Let ùê¥ = ùê∂ùëÖ be the column‚Äìrow factorization of ùê¥ given by 3.56, where ùê∂ is an ùëö-by-ùëê matrix and ùëÖ is a ùëê-by-ùëõ matrix. Then 3.51(b) tells us that every row of ùê¥ is a linear combination of the rows of ùëÖ. Because ùëÖ has ùëê rows, this implies that the row rank of ùê¥ is less than or equal to the column rank ùëê of ùê¥. To prove the inequality in the other direction, apply the result in the previous paragraph to ùê¥ t, getting column rank of ùê¥ = row rank of ùê¥ t ‚â§column rank of ùê¥ t = row rank of ùê¥. Thus the column rank of ùê¥ equals the row rank of ùê¥. Section 3C Matrices 79 Because the column rank equals the row rank, the last result allows us to dispense with the terms ‚Äúcolumn rank‚Äù and ‚Äúrow rank‚Äù and just use the simpler term ‚Äúrank‚Äù. 3.58 definition: rank The rank of a matrix ùê¥ ‚àà ùêÖùëö, ùëõ is the column rank of ùê¥. See 3.133 and Exercise 8 in Section 7A for alternative proofs that the column rank equals the row rank. Exercises 3C 1 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Show that with respect to each choice of bases of ùëâ and ùëä, the matrix of ùëá has at least dim range ùëá nonzero entries. 2 Suppose ùëâ and ùëä are finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that dim range ùëá = 1if and only if there exist a basis of ùëâ and a basis of ùëä such that with respect to these bases, all entries of ‚Ñ≥(ùëá) equal 1. 3 Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùë§1, ‚Ä¶, ùë§ùëö is a basis of ùëä. (a) Show that if ùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä), then ‚Ñ≥(ùëÜ + ùëá) = ‚Ñ≥(ùëÜ) + ‚Ñ≥(ùëá). (b) Show that if ùúÜ ‚àà ùêÖ and ùëá ‚àà ‚Ñí(ùëâ, ùëä), then ‚Ñ≥(ùúÜùëá) = ùúÜ‚Ñ≥(ùëá). This exercise asks you to verify 3.35 and 3.38. 4 Suppose that ùê∑ ‚àà ‚Ñí(ùí´3(ùêë), ùí´2(ùêë))is the differentiation map defined by ùê∑ùëù = ùëù‚Ä≤. Find a basis of ùí´3(ùêë) and a basis of ùí´2(ùêë) such that the matrix of ùê∑ with respect to these bases is ‚éõ‚éú‚éú‚éú ‚éù 1 0 0 0 0 1 0 0 0 0 1 0 ‚éû‚éü‚éü‚éü ‚é† . Compare with Example 3.33. The next exercise generalizes this exercise. 5 Suppose ùëâ and ùëä are finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that there exist a basis of ùëâ and a basis of ùëä such that with respect to these bases, all entries of ‚Ñ≥(ùëá) are 0except that the entries in row ùëò, column ùëò, equal 1if 1 ‚â§ ùëò ‚â§dim range ùëá. 6 Suppose ùë£1, ‚Ä¶, ùë£ùëö is a basis of ùëâ and ùëä is finite-dimensional. Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that there exists a basis ùë§1, ‚Ä¶, ùë§ùëõ of ùëä such that all entries in the first column of‚Ñ≥(ùëá) [with respect to the basesùë£1, ‚Ä¶, ùë£ùëö and ùë§1, ‚Ä¶, ùë§ùëõ] are0except for possibly a 1in the first row, first column. In this exercise, unlike Exercise 5, you are given the basis of ùëâ instead of being able to choose a basis of ùëâ. 80 Chapter 3 Linear Maps 7 Suppose ùë§1, ‚Ä¶, ùë§ùëõ is a basis of ùëä and ùëâ is finite-dimensional. Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that there exists a basis ùë£1, ‚Ä¶, ùë£ùëö of ùëâ such that all entries in the first row of‚Ñ≥(ùëá) [with respect to the basesùë£1, ‚Ä¶, ùë£ùëö and ùë§1, ‚Ä¶, ùë§ùëõ] are0except for possibly a 1in the first row, first column. In this exercise, unlike Exercise 5, you are given the basis of ùëä instead of being able to choose a basis of ùëä. 8 Suppose ùê¥ is an ùëö-by-ùëõ matrix and ùêµ is an ùëõ-by-ùëù matrix. Prove that (ùê¥ùêµ)ùëó, ‚ãÖ = ùê¥ùëó, ‚ãÖ ùêµ for each 1 ‚â§ ùëó ‚â§ ùëö. In other words, show that row ùëó of ùê¥ùêµ equals (row ùëó of ùê¥) times ùêµ. This exercise gives the row version of 3.48. 9 Suppose ùëé = (ùëé1 ‚ãØ ùëéùëõ )is a 1-by-ùëõ matrix and ùêµ is an ùëõ-by-ùëù matrix. Prove that ùëéùêµ = ùëé1ùêµ1, ‚ãÖ + ‚ãØ + ùëéùëõùêµùëõ, ‚ãÖ . In other words, show that ùëéùêµ is a linear combination of the rows of ùêµ, with the scalars that multiply the rows coming from ùëé. This exercise gives the row version of 3.50. 10 Give an example of 2-by-2matrices ùê¥ and ùêµ such that ùê¥ùêµ ‚â† ùêµùê¥. 11 Prove that the distributive property holds for matrix addition and matrix multiplication. In other words, suppose ùê¥, ùêµ, ùê∂, ùê∑, ùê∏, and ùêπ are matrices whose sizes are such that ùê¥(ùêµ + ùê∂) and (ùê∑ + ùê∏)ùêπ make sense. Explain why ùê¥ùêµ + ùê¥ùê∂ and ùê∑ùêπ + ùê∏ùêπ both make sense and prove that ùê¥(ùêµ + ùê∂) = ùê¥ùêµ + ùê¥ùê∂ and (ùê∑ + ùê∏)ùêπ = ùê∑ùêπ + ùê∏ùêπ. 12 Prove that matrix multiplication is associative. In other words, suppose ùê¥, ùêµ, and ùê∂ are matrices whose sizes are such that (ùê¥ùêµ)ùê∂ makes sense. Explain why ùê¥(ùêµùê∂) makes sense and prove that (ùê¥ùêµ)ùê∂ = ùê¥(ùêµùê∂). Try to find a clean proof that illustrates the following quote from Emil Artin: ‚ÄúIt is my experience that proofs involving matrices can be shortened by 50% if one throws the matrices out.‚Äù 13 Suppose ùê¥ is an ùëõ-by-ùëõ matrix and 1 ‚â§ ùëó, ùëò ‚â§ ùëõ. Show that the entry in row ùëó, column ùëò, of ùê¥ 3 (which is defined to meanùê¥ùê¥ùê¥) is ùëõ ‚àë ùëù = 1 ùëõ ‚àë ùëü = 1 ùê¥ùëó, ùëù ùê¥ùëù, ùëü ùê¥ùëü, ùëò. 14 Suppose ùëö and ùëõ are positive integers. Prove that the function ùê¥ ‚Ü¶ ùê¥t is a linear map from ùêÖùëö, ùëõ to ùêÖùëõ, ùëö. Section 3C Matrices 81 15 Prove that if ùê¥ is an ùëö-by-ùëõ matrix and ùê∂ is an ùëõ-by-ùëù matrix, then (ùê¥ùê∂) t = ùê∂ tùê¥ t. This exercise shows that the transpose of the product of two matrices is the product of the transposes in the opposite order. 16 Suppose ùê¥ is an ùëö-by-ùëõ matrix with ùê¥ ‚â† 0. Prove that the rank of ùê¥ is 1 if and only if there exist (ùëê1, ‚Ä¶, ùëêùëö) ‚àà ùêÖùëö and (ùëë1, ‚Ä¶, ùëëùëõ) ‚àà ùêÖùëõ such that ùê¥ùëó, ùëò = ùëêùëóùëëùëò for every ùëó = 1, ‚Ä¶, ùëö and every ùëò = 1, ‚Ä¶, ùëõ. 17 Suppose ùëá ‚àà ‚Ñí(ùëâ), and ùë¢1, ‚Ä¶, ùë¢ùëõ and ùë£1, ‚Ä¶, ùë£ùëõ are bases of ùëâ. Prove that the following are equivalent. (a) ùëá is injective. (b) The columns of ‚Ñ≥(ùëá) are linearly independent in ùêÖùëõ, 1. (c) The columns of ‚Ñ≥(ùëá) span ùêÖùëõ, 1. (d) The rows of ‚Ñ≥(ùëá) span ùêÖ1, ùëõ. (e) The rows of ‚Ñ≥(ùëá) are linearly independent in ùêÖ1, ùëõ. Here ‚Ñ≥(ùëá) means ‚Ñ≥(ùëá, (ùë¢1, ‚Ä¶, ùë¢ùëõ), (ùë£1, ‚Ä¶, ùë£ùëõ)). 82 Chapter 3 Linear Maps 3D Invertibility and Isomorphisms Invertible Linear Maps We begin this section by defining the notions of invertible and inverse in the context of linear maps. 3.59 definition: invertible, inverse ‚Ä¢ A linear map ùëá ‚àà ‚Ñí(ùëâ, ùëä) is called invertible if there exists a linear map ùëÜ ‚àà ‚Ñí(ùëä, ùëâ) such that ùëÜùëá equals the identity operator on ùëâ and ùëáùëÜ equals the identity operator on ùëä. ‚Ä¢ A linear map ùëÜ ‚àà ‚Ñí(ùëä, ùëâ) satisfying ùëÜùëá = ùêº and ùëáùëÜ = ùêº is called an inverse of ùëá (note that the firstùêº is the identity operator on ùëâ and the second ùêº is the identity operator on ùëä). The definition above mentions ‚Äúan inverse‚Äù. However, the next result shows that we can change this terminology to ‚Äúthe inverse‚Äù. 3.60 inverse is unique An invertible linear map has a unique inverse. Proof Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) is invertible and ùëÜ1 and ùëÜ2 are inverses of ùëá. Then ùëÜ1 = ùëÜ1ùêº = ùëÜ1(ùëáùëÜ2) = (ùëÜ1ùëá)ùëÜ2 = ùêºùëÜ2 = ùëÜ2. Thus ùëÜ1 = ùëÜ2. Now that we know that the inverse is unique, we can give it a notation. 3.61 notation:ùëá‚àí1 If ùëá is invertible, then its inverse is denoted by ùëá‚àí1. In other words, if ùëá ‚àà ‚Ñí(ùëâ, ùëä) is invertible, then ùëá‚àí1 is the unique element of ‚Ñí(ùëä, ùëâ) such that ùëá‚àí1ùëá = ùêº and ùëáùëá‚àí1 = ùêº. 3.62 example:inverse of a linear map from ùêë3 to ùêë3 Suppose ùëá ‚àà ‚Ñí(ùêë3)is defined byùëá(ùë•, ùë¶, ùëß) = (‚àíùë¶, ùë•, 4ùëß). Thus ùëá is a counterclockwise rotation by 90 ‚àò in the ùë•ùë¶-plane and a stretch by a factor of 4in the direction of the ùëß-axis. Hence the inverse map ùëá‚àí1 ‚àà ‚Ñí(ùêë3)is the clockwise rotation by 90 ‚àò in the ùë•ùë¶-plane and a stretch by a factor of 1 4 in the direction of the ùëß-axis: ùëá‚àí1(ùë•, ùë¶, ùëß) = (ùë¶, ‚àíùë•, 1 4 ùëß). Section 3D Invertibility and Isomorphisms 83 The next result shows that a linear map is invertible if and only if it is one-to- one and onto. 3.63 invertibility ‚ü∫ injectivity and surjectivity A linear map is invertible if and only if it is injective and surjective. Proof Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). We need to show that ùëá is invertible if and only if it is injective and surjective. First suppose ùëá is invertible. To show that ùëá is injective, suppose ùë¢, ùë£ ‚àà ùëâ and ùëáùë¢ = ùëáùë£. Then ùë¢ = ùëá‚àí1(ùëáùë¢) = ùëá‚àí1(ùëáùë£) = ùë£, so ùë¢ = ùë£. Hence ùëá is injective. We are still assuming that ùëá is invertible. Now we want to prove that ùëá is surjective. To do this, let ùë§ ‚àà ùëä. Then ùë§ = ùëá(ùëá‚àí1ùë§), which shows that ùë§ is in the range of ùëá. Thus range ùëá = ùëä. Hence ùëá is surjective, completing this direction of the proof. Now suppose ùëá is injective and surjective. We want to prove that ùëá is invertible. For each ùë§ ‚àà ùëä, defineùëÜ(ùë§) to be the unique element of ùëâ such that ùëá(ùëÜ(ùë§))= ùë§ (the existence and uniqueness of such an element follow from the surjectivity and injectivity of ùëá). The definition ofùëÜ implies that ùëá ‚àò ùëÜ equals the identity operator on ùëä. To prove that ùëÜ ‚àò ùëá equals the identity operator on ùëâ, let ùë£ ‚àà ùëâ. Then ùëá((ùëÜ ‚àò ùëá)ùë£)= (ùëá ‚àò ùëÜ)(ùëáùë£) = ùêº(ùëáùë£) = ùëáùë£. This equation implies that (ùëÜ ‚àò ùëá)ùë£ = ùë£ (because ùëá is injective). Thus ùëÜ ‚àò ùëá equals the identity operator on ùëâ. To complete the proof, we need to show that ùëÜ is linear. To do this, suppose ùë§1, ùë§2 ‚àà ùëä. Then ùëá(ùëÜ(ùë§1) + ùëÜ(ùë§2))= ùëá(ùëÜ(ùë§1))+ ùëá(ùëÜ(ùë§2))= ùë§1 + ùë§2. Thus ùëÜ(ùë§1) + ùëÜ(ùë§2) is the unique element of ùëâ that ùëá maps to ùë§1 + ùë§2. By the definition ofùëÜ, this implies that ùëÜ(ùë§1 + ùë§2) = ùëÜ(ùë§1) + ùëÜ(ùë§2). Hence ùëÜ satisfies the additive property required for linearity. The proof of homogeneity is similar. Specifically, ifùë§ ‚àà ùëä and ùúÜ ‚àà ùêÖ, then ùëá(ùúÜùëÜ(ùë§))= ùúÜùëá(ùëÜ(ùë§))= ùúÜùë§. Thus ùúÜùëÜ(ùë§) is the unique element of ùëâ that ùëá maps to ùúÜùë§. By the definition ofùëÜ, this implies that ùëÜ(ùúÜùë§) = ùúÜùëÜ(ùë§). Hence ùëÜ is linear, as desired. For a linear map from a vector space to itself, you might wonder whether injectivity alone, or surjectivity alone, is enough to imply invertibility. On infinite- dimensional vector spaces, neither condition alone implies invertibility, as illus- trated by the next example, which uses two familiar linear maps from Example 3.3. 84 Chapter 3 Linear Maps 3.64 example:neither injectivity nor surjectivity implies invertibility ‚Ä¢ The multiplication by ùë•2 linear map from ùí´(ùêë) to ùí´(ùêë) (see 3.3) is injective but it is not invertible because it is not surjective (the polynomial 1is not in the range). ‚Ä¢ The backward shift linear map from ùêÖ‚àû to ùêÖ‚àû (see 3.3) is surjective but it is not invertible because it is not injective [the vector (1, 0, 0, 0, ‚Ä¶ ) is in the null space]. In view of the example above, the next result is remarkable‚Äîit states that for a linear map from a finite-dimensional vector space to a vector space of the same dimension, either injectivity or surjectivity alone implies the other condition. Note that the hypothesis below that dim ùëâ = dim ùëä is automatically satisfied in the important special case where ùëâ is finite-dimensional andùëä = ùëâ. 3.65 injectivity is equivalent to surjectivity (if dim ùëâ = dim ùëä < ‚àû) Suppose that ùëâ and ùëä are finite-dimensional vector spaces,dim ùëâ = dim ùëä, and ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then ùëá is invertible ‚ü∫ ùëá is injective ‚ü∫ ùëá is surjective. Proof The fundamental theorem of linear maps (3.21) states that 3.66 dim ùëâ = dim null ùëá + dim range ùëá. If ùëá is injective (which by 3.15 is equivalent to the condition dim null ùëá = 0), then the equation above implies that dim range ùëá = dim ùëâ ‚àí dim null ùëá = dim ùëâ = dim ùëä, which implies that ùëá is surjective (by 2.39). Conversely, if ùëá is surjective, then 3.66 implies that dim null ùëá = dim ùëâ ‚àí dim range ùëá = dim ùëâ ‚àí dim ùëä = 0, which implies that ùëá is injective. Thus we have shown that ùëá is injective if and only if ùëá is surjective. Thus if ùëá is either injective or surjective, then ùëá is both injective and surjective, which implies that ùëá is invertible. Hence ùëá is invertible if and only if ùëá is injective if and only if ùëá is surjective. The next example illustrates the power of the previous result. Although it is possible to prove the result in the example below without using linear algebra, the proof using linear algebra is cleaner and easier. Section 3D Invertibility and Isomorphisms 85 3.67 example:there exists a polynomial ùëù such that ((ùë•2 + 5ùë•+ 7)ùëù) ‚Ä≥ = ùëû The linear map ùëù ‚Ü¶ ((ùë•2 + 5ùë•+ 7)ùëù) ‚Ä≥ from ùí´(ùêë) to itself is injective, as you can show. Thus we are tempted to use 3.65 to show that this map is surjective. However, Example 3.64 shows that the magic of 3.65 does not apply to the infinite-dimensional vector spaceùí´(ùêë). We will get around this problem by restricting attention to the finite-dimensional vector space ùí´ùëö(ùêë). Suppose ùëû ‚àà ùí´(ùêë). There exists a nonnegative integer ùëö such that ùëû ‚àà ùí´ùëö(ùêë). Defineùëá‚à∂ ùí´ùëö(ùêë) ‚Üí ùí´ùëö(ùêë) by ùëáùëù = ((ùë•2 + 5ùë•+ 7)ùëù) ‚Ä≥ . Multiplying a nonzero polynomial by (ùë•2 + 5ùë•+ 7)increases the degree by 2, and then differentiating twice reduces the degree by 2. Thus ùëá is indeed a linear map from ùí´ùëö(ùêë) to itself. Every polynomial whose second derivative equals 0is of the form ùëéùë• + ùëè, where ùëé, ùëè ‚àà ùêë. Thus null ùëá = {0}. Hence ùëá is injective. Thus ùëá is surjective (by 3.65), which means that there exists a polynomial ùëù ‚àà ùí´ùëö(ùêë) such that ((ùë•2 + 5ùë•+ 7)ùëù) ‚Ä≥ = ùëû, as claimed in the title of this example. Exercise 35 in Section 6A gives a similar but more spectacular example of using 3.65. The hypothesis in the result below that dim ùëâ = dim ùëä holds in the important special case in which ùëâ is finite-dimensional andùëä = ùëâ. Thus in that case, the equation ùëÜùëá = ùêº implies that ùëÜùëá = ùëáùëÜ, even though we do not have multiplicative commutativity of arbitrary linear maps from ùëâ to ùëâ. 3.68 ùëÜùëá = ùêº ‚ü∫ ùëáùëÜ = ùêº (on vector spaces of the same dimension) Suppose ùëâ and ùëä are finite-dimensional vector spaces of the same dimension, ùëÜ ‚àà ‚Ñí(ùëâ, ùëä), and ùëá ‚àà ‚Ñí(ùëä, ùëâ). Then ùëÜùëá = ùêº if and only if ùëáùëÜ = ùêº. Proof First suppose ùëÜùëá = ùêº. If ùë£ ‚àà ùëâ and ùëáùë£ = 0, then ùë£ = ùêºùë£ = (ùëÜùëá)ùë£ = ùëÜ(ùëáùë£) = ùëÜ(0) = 0. Thus ùëá is injective (by 3.15). Because ùëâ and ùëä have the same dimension, this implies that ùëá is invertible (by 3.65). Now multiply both sides of the equation ùëÜùëá = ùêº by ùëá‚àí1 on the right, getting ùëÜ = ùëá‚àí1. Thus ùëáùëÜ = ùëáùëá‚àí1 = ùêº, as desired. To prove the implication in the other direction, simply reverse the roles of ùëÜ and ùëá (and ùëâ and ùëä) in the direction we have already proved, showing that if ùëáùëÜ = ùêº, then ùëÜùëá = ùêº. 86 Chapter 3 Linear Maps Isomorphic Vector Spaces The next definition captures the idea of two vector spaces that are essentially the same, except for the names of their elements. 3.69 definition:isomorphism, isomorphic ‚Ä¢ An isomorphism is an invertible linear map. ‚Ä¢ Two vector spaces are called isomorphic if there is an isomorphism from one vector space onto the other one. Think of an isomorphism ùëá‚à∂ ùëâ ‚Üí ùëä as relabeling ùë£ ‚àà ùëâ as ùëáùë£ ‚àà ùëä. This viewpoint explains why two isomorphic vector spaces have the same vector space properties. The terms ‚Äúisomorphism‚Äù and ‚Äúinvertible linear map‚Äù mean the same thing. Use ‚Äúisomorphism‚Äù when you want to emphasize that the two spaces are essentially the same. It can be difficult to determine whether two mathematical structures (such as groups or topological spaces) are essentially the same, differing only in the names of the elements of underlying sets. However, the next result shows that we need to look at only a single number (the dimension) to determine whether two vector spaces are isomorphic. 3.70 dimension shows whether vector spaces are isomorphic Two finite-dimensional vector spaces overùêÖ are isomorphic if and only if they have the same dimension. Proof First suppose ùëâ and ùëä are isomorphic finite-dimensional vector spaces. Thus there exists an isomorphism ùëá from ùëâ onto ùëä. Because ùëá is invertible, we have null ùëá = {0}and range ùëá = ùëä. Thus dim null ùëá = 0 and dim range ùëá = dim ùëä. The formula dim ùëâ = dim null ùëá + dim range ùëá (the fundamental theorem of linear maps, which is 3.21) thus becomes the equation dim ùëâ = dim ùëä, completing the proof in one direction. To prove the other direction, suppose ùëâ and ùëä are finite-dimensional vector spaces of the same dimension. Let ùë£1, ‚Ä¶, ùë£ùëõ be a basis of ùëâ and ùë§1, ‚Ä¶, ùë§ùëõ be a basis of ùëä. Let ùëá ‚àà ‚Ñí(ùëâ, ùëä) be defined by ùëá(ùëê1ùë£1 + ‚ãØ + ùëêùëõùë£ùëõ) = ùëê1ùë§1 + ‚ãØ + ùëêùëõùë§ùëõ. Then ùëá is a well-defined linear map becauseùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Also, ùëá is surjective because ùë§1, ‚Ä¶, ùë§ùëõ spans ùëä. Furthermore, null ùëá = {0}because ùë§1, ‚Ä¶, ùë§ùëõ is linearly independent. Thus ùëá is injective. Because ùëá is injective and surjective, it is an isomorphism (see 3.63). Hence ùëâ and ùëä are isomorphic. Section 3D Invertibility and Isomorphisms 87 Every finite-dimensional vector space is isomorphic to some ùêÖùëõ. Thus why not just study ùêÖùëõ instead of more general vector spaces? To answer this ques- tion, note that an investigation of ùêÖùëõ would soon lead to other vector spaces. For example, we would encounter the null space and range of linear maps. Although each of these vector spaces is isomorphic to some ùêÖùëö, thinking of them that way often adds complexity but no new insight. The previous result implies that each finite-dimensional vector spaceùëâ is iso- morphic to ùêÖùëõ, where ùëõ = dim ùëâ. For example, if ùëö is a nonnegative integer, then ùí´ùëö(ùêÖ) is isomorphic to ùêÖùëö + 1. Recall that the notation ùêÖùëö, ùëõ denotes the vector space of ùëö-by-ùëõ matrices with entries in ùêÖ. If ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùë§1, ‚Ä¶, ùë§ùëö is a basis of ùëä, then for each ùëá ‚àà ‚Ñí(ùëâ, ùëä), we have a matrix ‚Ñ≥(ùëá) ‚àà ùêÖùëö, ùëõ. Thus once bases have been fixed forùëâ and ùëä, ‚Ñ≥ becomes a function from ‚Ñí(ùëâ, ùëä) to ùêÖùëö, ùëõ. Notice that 3.35 and 3.38 show that ‚Ñ≥ is a lin- ear map. This linear map is actually an isomorphism, as we now show. 3.71 ‚Ñí(ùëâ, ùëä) and ùêÖùëö, ùëõ are isomorphic Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùë§1, ‚Ä¶, ùë§ùëö is a basis of ùëä. Then ‚Ñ≥ is an isomorphism between ‚Ñí(ùëâ, ùëä) and ùêÖùëö, ùëõ. Proof We already noted that ‚Ñ≥ is linear. We need to prove that ‚Ñ≥ is injective and surjective. We begin with injectivity. If ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ‚Ñ≥(ùëá) = 0, then ùëáùë£ùëò = 0for each ùëò = 1, ‚Ä¶, ùëõ. Because ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ, this implies ùëá = 0. Thus ‚Ñ≥ is injective (by 3.15). To prove that ‚Ñ≥ is surjective, suppose ùê¥ ‚àà ùêÖùëö, ùëõ. By the linear map lemma (3.4), there exists ùëá ‚àà ‚Ñí(ùëâ, ùëä) such that ùëáùë£ùëò = ùëö ‚àë ùëó = 1 ùê¥ùëó, ùëòùë§ùëó for each ùëò = 1, ‚Ä¶, ùëõ. Because ‚Ñ≥(ùëá) equals ùê¥, the range of ‚Ñ≥ equals ùêÖùëö, ùëõ, as desired. Now we can determine the dimension of the vector space of linear maps from one finite-dimensional vector space to another. 3.72 dim ‚Ñí(ùëâ, ùëä) = (dim ùëâ)(dim ùëä) Suppose ùëâ and ùëä are finite-dimensional. Then‚Ñí(ùëâ, ùëä) is finite-dimensional and dim ‚Ñí(ùëâ, ùëä) = (dim ùëâ)(dim ùëä). Proof The desired result follows from 3.71, 3.70, and 3.40. 88 Chapter 3 Linear Maps Linear Maps Thought of as Matrix Multiplication Previously we defined the matrix of a linear map. Now we define the matrix of a vector. 3.73 definition:matrix of a vector, ‚Ñ≥(ùë£) Suppose ùë£ ‚àà ùëâ and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. The matrix of ùë£ with respect to this basis is the ùëõ-by-1matrix ‚Ñ≥(ùë£) = ‚éõ‚éú‚éú‚éú ‚éù ùëè1 ‚ãÆ ùëèùëõ ‚éû‚éü‚éü‚éü ‚é† , where ùëè1, ‚Ä¶, ùëèùëõ are the scalars such that ùë£ = ùëè1ùë£1 + ‚ãØ + ùëèùëõùë£ùëõ. The matrix ‚Ñ≥(ùë£) of a vector ùë£ ‚àà ùëâ depends on the basis ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ, as well as on ùë£. However, the basis should be clear from the context and thus it is not included in the notation. 3.74 example:matrix of a vector ‚Ä¢ The matrix of the polynomial 2 ‚àí 7ùë•+ 5ùë• 3 + ùë•4 with respect to the standard basis of ùí´4(ùêë) is ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 2 ‚àí7 0 5 1 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . ‚Ä¢ The matrix of a vector ùë• ‚àà ùêÖùëõ with respect to the standard basis is obtained by writing the coordinates of ùë• as the entries in an ùëõ-by-1matrix. In other words, if ùë• = (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêÖùëõ, then ‚Ñ≥(ùë•) = ‚éõ‚éú‚éú‚éú ‚éù ùë•1 ‚ãÆ ùë•ùëõ ‚éû‚éü‚éü‚éü ‚é† . Occasionally we want to think of elements of ùëâ as relabeled to be ùëõ-by-1 matrices. Once a basis ùë£1, ‚Ä¶, ùë£ùëõ is chosen, the function ‚Ñ≥ that takes ùë£ ‚àà ùëâ to ‚Ñ≥(ùë£) is an isomorphism of ùëâ onto ùêÖùëõ, 1 that implements this relabeling. Recall that if ùê¥ is an ùëö-by-ùëõ matrix, then ùê¥‚ãÖ, ùëò denotes the ùëòth column of ùê¥, thought of as an ùëö-by-1matrix. In the next result, ‚Ñ≥(ùëáùë£ùëò) is computed with respect to the basis ùë§1, ‚Ä¶, ùë§ùëö of ùëä. Section 3D Invertibility and Isomorphisms 89 3.75 ‚Ñ≥(ùëá)‚ãÖ, ùëò = ‚Ñ≥(ùëáùë£ùëò). Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùë§1, ‚Ä¶, ùë§ùëö is a basis of ùëä. Let 1 ‚â§ ùëò ‚â§ ùëõ. Then the ùëòth column of ‚Ñ≥(ùëá), which is denoted by ‚Ñ≥(ùëá)‚ãÖ, ùëò, equals ‚Ñ≥(ùëáùë£ùëò). Proof The desired result follows immediately from the definitions of‚Ñ≥(ùëá) and ‚Ñ≥(ùëáùë£ùëò). The next result shows how the notions of the matrix of a linear map, the matrix of a vector, and matrix multiplication fit together. 3.76 linear maps act like matrix multiplication Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùë£ ‚àà ùëâ. Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùë§1, ‚Ä¶, ùë§ùëö is a basis of ùëä. Then ‚Ñ≥(ùëáùë£) = ‚Ñ≥(ùëá)‚Ñ≥(ùë£). Proof Suppose ùë£ = ùëè1ùë£1 + ‚ãØ + ùëèùëõùë£ùëõ, where ùëè1, ‚Ä¶, ùëèùëõ ‚àà ùêÖ. Thus 3.77 ùëáùë£ = ùëè1ùëáùë£1 + ‚ãØ + ùëèùëõùëáùë£ùëõ. Hence ‚Ñ≥(ùëáùë£) = ùëè1‚Ñ≥(ùëáùë£1) + ‚ãØ + ùëèùëõ‚Ñ≥(ùëáùë£ùëõ) = ùëè1‚Ñ≥(ùëá)‚ãÖ, 1 + ‚ãØ + ùëèùëõ‚Ñ≥(ùëá)‚ãÖ, ùëõ = ‚Ñ≥(ùëá)‚Ñ≥(ùë£), where the first equality follows from3.77 and the linearity of ‚Ñ≥, the second equality comes from 3.75, and the last equality comes from 3.50. Each ùëö-by-ùëõ matrix ùê¥ induces a linear map from ùêÖùëõ, 1 to ùêÖùëö, 1, namely the matrix multiplication function that takes ùë• ‚àà ùêÖùëõ, 1 to ùê¥ùë• ‚àà ùêÖùëö, 1. The result above can be used to think of every linear map (from a finite-dimensional vector space to another finite-dimensional vector space) as a matrix multiplication map after suitable relabeling via the isomorphisms given by ‚Ñ≥. Specifically, ifùëá ‚àà ‚Ñí(ùëâ, ùëä) and we identify ùë£ ‚àà ùëâ with ‚Ñ≥(ùë£) ‚àà ùêÖùëõ, 1, then the result above says that we can identify ùëáùë£ with ‚Ñ≥(ùëá)‚Ñ≥(ùë£). Because the result above allows us to think (via isomorphisms) of each linear map as multiplication on ùêÖùëõ, 1 by some matrix ùê¥, keep in mind that the specific matrix ùê¥ depends not only on the linear map but also on the choice of bases. One of the themes of many of the most important results in later chapters will be the choice of a basis that makes the matrix ùê¥ as simple as possible. In this book, we concentrate on linear maps rather than on matrices. However, sometimes thinking of linear maps as matrices (or thinking of matrices as linear maps) gives important insights that we will find useful. 90 Chapter 3 Linear Maps Notice that no bases are in sight in the statement of the next result. Although ‚Ñ≥(ùëá) in the next result depends on a choice of bases of ùëâ and ùëä, the next result shows that the column rank of ‚Ñ≥(ùëá) is the same for all such choices (because range ùëá does not depend on a choice of basis). 3.78 dimension of range ùëá equals column rank of ‚Ñ≥(ùëá) Suppose ùëâ and ùëä are finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Then dim range ùëá equals the column rank of ‚Ñ≥(ùëá). Proof Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùë§1, ‚Ä¶, ùë§ùëö is a basis of ùëä. The linear map that takes ùë§ ‚àà ùëä to ‚Ñ≥(ùë§) is an isomorphism from ùëä onto the space ùêÖùëö, 1 of ùëö-by-1column vectors. The restriction of this isomorphism to range ùëá [which equals span(ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ) by Exercise 10 in Section 3B]is an isomorphism from range ùëá onto span(‚Ñ≥(ùëáùë£1), ‚Ä¶, ‚Ñ≥(ùëáùë£ùëõ)). For each ùëò ‚àà {1, ‚Ä¶, ùëõ}, the ùëö-by-1 matrix ‚Ñ≥(ùëáùë£ùëò) equals column ùëò of ‚Ñ≥(ùëá). Thus dim range ùëá = the column rank of ‚Ñ≥(ùëá), as desired. Change of Basis In Section 3C we defined the matrix ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ), (ùë§1, ‚Ä¶, ùë§ùëö)) of a linear map ùëá from ùëâ to a possibly different vector space ùëä, where ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùë§1, ‚Ä¶, ùë§ùëö is a basis of ùëä. For linear maps from a vector space to itself, we usually use the same basis for both the domain vector space and the target vector space. When using a single basis in both capacities, we often write the basis only once. In other words, if ùëá ‚àà ‚Ñí(ùëâ) and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ, then the notation ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ))is defined by the equation ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ))= ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ), (ùë£1, ‚Ä¶, ùë£ùëõ)). If the basis ùë£1, ‚Ä¶, ùë£ùëõ is clear from the context, then we can write just ‚Ñ≥(ùëá). 3.79 definition:identity matrix, I Suppose ùëõ is a positive integer. The ùëõ-by-ùëõ matrix ‚éõ‚éú‚éú‚éú ‚éù 1 0 ‚ã± 0 1 ‚éû‚éü‚éü‚éü ‚é† with 1‚Äôs on the diagonal (the entries where the row number equals the column number) and 0‚Äôs elsewhere is called the identity matrix and is denoted by ùêº. Section 3D Invertibility and Isomorphisms 91 In the definition above, the0in the lower left corner of the matrix indicates that all entries below the diagonal are 0, and the 0in the upper right corner indicates that all entries above the diagonal are 0. With respect to each basis of ùëâ, the matrix of the identity operator ùêº ‚àà ‚Ñí(ùëâ) is the identity matrix ùêº. Note that the symbol ùêº is used to denote both the identity operator and the identity matrix. The context indicates which meaning of ùêº is intended. For example, consider the equation ‚Ñ≥(ùêº) = ùêº; on the left side ùêº denotes the identity operator, and on the right side ùêº denotes the identity matrix. If ùê¥ is a square matrix (with entries in ùêÖ, as usual) of the same size as ùêº, then ùê¥ùêº = ùêºùê¥ = ùê¥, as you should verify. 3.80 definition: invertible, inverse, ùê¥ ‚àí1 A square matrix ùê¥ is called invertible if there is a square matrix ùêµ of the same size such that ùê¥ùêµ = ùêµùê¥ = ùêº; we call ùêµ the inverse of ùê¥ and denote it by ùê¥ ‚àí1. Some mathematicians use the terms nonsingular and singular, which mean the same as invertible and non- invertible. The same proof as used in 3.60 shows that if ùê¥ is an invertible square matrix, then there is a unique matrix ùêµ such that ùê¥ùêµ = ùêµùê¥ = ùêº (and thus the notation ùêµ = ùê¥‚àí1 is justified). If ùê¥ is an invertible matrix, then (ùê¥ ‚àí1) ‚àí1 = ùê¥ because ùê¥ ‚àí1ùê¥ = ùê¥ùê¥‚àí1 = ùêº. Also, if ùê¥ and ùê∂ are invertible square matrices of the same size, then ùê¥ùê∂ is invertible and (ùê¥ùê∂) ‚àí1 = ùê∂‚àí1ùê¥ ‚àí1 because (ùê¥ùê∂)(ùê∂‚àí1ùê¥ ‚àí1)= ùê¥(ùê∂ùê∂‚àí1)ùê¥ ‚àí1 = ùê¥ùêºùê¥‚àí1 = ùê¥ùê¥‚àí1 = ùêº, and similarly (ùê∂‚àí1ùê¥ ‚àí1)(ùê¥ùê∂) = ùêº. The next result holds because we defined matrix multiplication to make it true‚Äîsee 3.43 and the material preceding it. Now we are just being more explicit about the bases involved. 3.81 matrix of product of linear maps Suppose ùëá ‚àà ‚Ñí(ùëà, ùëâ) and ùëÜ ‚àà ‚Ñí(ùëâ, ùëä). If ùë¢1, ‚Ä¶, ùë¢ùëö is a basis of ùëà, ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ, and ùë§1, ‚Ä¶, ùë§ùëù is a basis of ùëä, then ‚Ñ≥(ùëÜùëá, (ùë¢1, ‚Ä¶, ùë¢ùëö), (ùë§1, ‚Ä¶, ùë§ùëù))= ‚Ñ≥(ùëÜ, (ùë£1, ‚Ä¶, ùë£ùëõ), (ùë§1, ‚Ä¶, ùë§ùëù))‚Ñ≥(ùëá, (ùë¢1, ‚Ä¶, ùë¢ùëö), (ùë£1, ‚Ä¶, ùë£ùëõ)). 92 Chapter 3 Linear Maps The next result deals with the matrix of the identity operator ùêº with respect to two different bases. Note that the ùëòth column of ‚Ñ≥(ùêº, (ùë¢1, ‚Ä¶, ùë¢ùëõ), (ùë£1, ‚Ä¶, ùë£ùëõ)) consists of the scalars needed to write ùë¢ùëò as a linear combination of the basis ùë£1, ‚Ä¶, ùë£ùëõ. In the statement of the next result, ùêº denotes the identity operator from ùëâ to ùëâ. In the proof, ùêº also denotes the ùëõ-by-ùëõ identity matrix. 3.82 matrix of identity operator with respect to two bases Suppose that ùë¢1, ‚Ä¶, ùë¢ùëõ and ùë£1, ‚Ä¶, ùë£ùëõ are bases of ùëâ. Then the matrices ‚Ñ≥(ùêº, (ùë¢1, ‚Ä¶, ùë¢ùëõ), (ùë£1, ‚Ä¶, ùë£ùëõ)) and ‚Ñ≥(ùêº, (ùë£1, ‚Ä¶, ùë£ùëõ), (ùë¢1, ‚Ä¶, ùë¢ùëõ)) are invertible, and each is the inverse of the other. Proof In 3.81, replace ùë§ùëò with ùë¢ùëò, and replace ùëÜ and ùëá with ùêº, getting ùêº = ‚Ñ≥(ùêº, (ùë£1, ‚Ä¶, ùë£ùëõ), (ùë¢1, ‚Ä¶, ùë¢ùëõ))‚Ñ≥(ùêº, (ùë¢1, ‚Ä¶, ùë¢ùëõ), (ùë£1, ‚Ä¶, ùë£ùëõ)). Now interchange the roles of the ùë¢‚Äôs and ùë£‚Äôs, getting ùêº = ‚Ñ≥(ùêº, (ùë¢1, ‚Ä¶, ùë¢ùëõ), (ùë£1, ‚Ä¶, ùë£ùëõ))‚Ñ≥(ùêº, (ùë£1, ‚Ä¶, ùë£ùëõ), (ùë¢1, ‚Ä¶, ùë¢ùëõ)). These two equations above give the desired result. 3.83 example: matrix of identity on ùêÖ2 with respect to two bases Consider the bases (4, 2), (5, 3)and (1, 0), (0, 1)of ùêÖ2. Because ùêº(4, 2) = 4(1, 0)+ 2(0, 1)and ùêº(5, 3) = 5(1, 0)+ 3(0, 1), we have ‚Ñ≥(ùêº, ((4, 2), (5, 3)), ((1, 0), (0, 1)))= ( 4 5 2 3 ). The inverse of the matrix above is ‚éõ‚éú ‚éù 3 2 ‚àí 5 2 ‚àí1 2 ‚éû‚éü ‚é† , as you should verify. Thus 3.82 implies that ‚Ñ≥(ùêº, ((1, 0), (0, 1)), ((4, 2), (5, 3)))= ‚éõ‚éú ‚éù 3 2 ‚àí 5 2 ‚àí1 2 ‚éû‚éü ‚é† . Our next result shows how the matrix of ùëá changes when we change bases. In the next result, we have two different bases of ùëâ, each of which is used as a basis for the domain space and as a basis for the target space. Recall our shorthand notation that allows us to display a basis only once when it is used in both capacities: ‚Ñ≥(ùëá, (ùë¢1, ‚Ä¶, ùë¢ùëõ))= ‚Ñ≥(ùëá, (ùë¢1, ‚Ä¶, ùë¢ùëõ), (ùë¢1, ‚Ä¶, ùë¢ùëõ)). Section 3D Invertibility and Isomorphisms 93 3.84 change-of-basis formula Suppose ùëá ‚àà ‚Ñí(ùëâ). Suppose ùë¢1, ‚Ä¶, ùë¢ùëõ and ùë£1, ‚Ä¶, ùë£ùëõ are bases of ùëâ. Let ùê¥ = ‚Ñ≥(ùëá, (ùë¢1, ‚Ä¶, ùë¢ùëõ)) and ùêµ = ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ)) and ùê∂ = ‚Ñ≥(ùêº, (ùë¢1, ‚Ä¶, ùë¢ùëõ), (ùë£1, ‚Ä¶, ùë£ùëõ)). Then ùê¥ = ùê∂‚àí1ùêµùê∂. Proof In 3.81, replace ùë§ùëò with ùë¢ùëò and replace ùëÜ with ùêº, getting 3.85 ùê¥ = ùê∂‚àí1‚Ñ≥(ùëá, (ùë¢1, ‚Ä¶, ùë¢ùëõ), (ùë£1, ‚Ä¶, ùë£ùëõ)), where we have used 3.82. Again use 3.81, this time replacing ùë§ùëò with ùë£ùëò. Also replace ùëá with ùêº and replace ùëÜ with ùëá, getting ‚Ñ≥(ùëá, (ùë¢1, ‚Ä¶, ùë¢ùëõ), (ùë£1, ‚Ä¶, ùë£ùëõ))= ùêµùê∂. Substituting the equation above into 3.85 gives the equation ùê¥ = ùê∂‚àí1ùêµùê∂. The proof of the next result is left as an exercise. 3.86 matrix of inverse equals inverse of matrix Suppose that ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùëá ‚àà ‚Ñí(ùëâ) is invertible. Then ‚Ñ≥(ùëá‚àí1)= (‚Ñ≥(ùëá)) ‚àí1, where both matrices are with respect to the basis ùë£1, ‚Ä¶, ùë£ùëõ. Exercises 3D 1 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) is invertible. Show that ùëá‚àí1 is invertible and (ùëá‚àí1) ‚àí1 = ùëá. 2 Suppose ùëá ‚àà ‚Ñí(ùëà, ùëâ) and ùëÜ ‚àà ‚Ñí(ùëâ, ùëä) are both invertible linear maps. Prove that ùëÜùëá ‚àà ‚Ñí(ùëà, ùëä) is invertible and that (ùëÜùëá) ‚àí1 = ùëá‚àí1ùëÜ ‚àí1. 3 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Prove that the following are equivalent. (a) ùëá is invertible. (b) ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ is a basis of ùëâ for every basis ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ. (c) ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ is a basis of ùëâ for some basis ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ. 4 Suppose ùëâ is finite-dimensional anddim ùëâ > 1. Prove that the set of noninvertible linear maps from ùëâ to itself is not a subspace of ‚Ñí(ùëâ). 94 Chapter 3 Linear Maps 5 Suppose ùëâ is finite-dimensional,ùëà is a subspace of ùëâ, and ùëÜ ‚àà ‚Ñí(ùëà, ùëâ). Prove that there exists an invertible linear map ùëá from ùëâ to itself such that ùëáùë¢ = ùëÜùë¢ for every ùë¢ ‚àà ùëà if and only if ùëÜ is injective. 6 Suppose that ùëä is finite-dimensional andùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that null ùëÜ = null ùëá if and only if there exists an invertible ùê∏ ‚àà ‚Ñí(ùëä) such that ùëÜ = ùê∏ùëá. 7 Suppose that ùëâ is finite-dimensional andùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that range ùëÜ = range ùëá if and only if there exists an invertible ùê∏ ‚àà ‚Ñí(ùëâ) such that ùëÜ = ùëáùê∏. 8 Suppose ùëâ and ùëä are finite-dimensional andùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that there exist invertible ùê∏1 ‚àà ‚Ñí(ùëâ) and ùê∏2 ‚àà ‚Ñí(ùëä) such that ùëÜ = ùê∏2ùëáùê∏1 if and only if dim null ùëÜ = dim null ùëá. 9 Suppose ùëâ is finite-dimensional andùëá‚à∂ ùëâ ‚Üí ùëä is a surjective linear map of ùëâ onto ùëä. Prove that there is a subspace ùëà of ùëâ such that ùëá|ùëà is an isomorphism of ùëà onto ùëä. Here ùëá|ùëà means the function ùëá restricted to ùëà. Thus ùëá|ùëà is the function whose domain is ùëà, with ùëá|ùëà defined by ùëá|ùëà(ùë¢) = ùëáùë¢ for every ùë¢ ‚àà ùëà. 10 Suppose ùëâ and ùëä are finite-dimensional andùëà is a subspace of ùëâ. Let ‚Ñ∞ = {ùëá ‚àà ‚Ñí(ùëâ, ùëä) ‚à∂ ùëà ‚äÜnull ùëá}. (a) Show that ‚Ñ∞ is a subspace of ‚Ñí(ùëâ, ùëä). (b) Find a formula for dim ‚Ñ∞ in terms of dim ùëâ, dim ùëä, and dim ùëà. Hint: Define Œ¶‚à∂ ‚Ñí(ùëâ, ùëä) ‚Üí ‚Ñí(ùëà, ùëä) by Œ¶(ùëá) = ùëá|ùëà. What is null Œ¶? What is range Œ¶? 11 Suppose ùëâ is finite-dimensional andùëÜ, ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëÜùëá is invertible ‚ü∫ ùëÜ and ùëá are invertible. 12 Suppose ùëâ is finite-dimensional andùëÜ, ùëá, ùëà ‚àà ‚Ñí(ùëâ) and ùëÜùëáùëà = ùêº. Show that ùëá is invertible and that ùëá‚àí1 = ùëàùëÜ. 13 Show that the result in Exercise 12 can fail without the hypothesis that ùëâ is finite-dimensional. 14 Prove or give a counterexample: If ùëâ is a finite-dimensional vector space and ùëÖ, ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) are such that ùëÖùëÜùëá is surjective, then ùëÜ is injective. 15 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùë£1, ‚Ä¶, ùë£ùëö is a list in ùëâ such that ùëáùë£1, ‚Ä¶, ùëáùë£ùëö spans ùëâ. Prove that ùë£1, ‚Ä¶, ùë£ùëö spans ùëâ. 16 Prove that every linear map from ùêÖùëõ, 1 to ùêÖùëö, 1 is given by a matrix multipli- cation. In other words, prove that if ùëá ‚àà ‚Ñí(ùêÖùëõ, 1, ùêÖùëö, 1), then there exists an ùëö-by-ùëõ matrix ùê¥ such that ùëáùë• = ùê¥ùë• for every ùë• ‚àà ùêÖùëõ, 1. Section 3D Invertibility and Isomorphisms 95 17 Suppose ùëâ is finite-dimensional andùëÜ ‚àà ‚Ñí(ùëâ). Defineùíú ‚àà ‚Ñí(‚Ñí(ùëâ))by ùíú(ùëá) = ùëÜùëá for ùëá ‚àà ‚Ñí(ùëâ). (a) Show that dim null ùíú = (dim ùëâ)(dim null ùëÜ). (b) Show that dim range ùíú = (dim ùëâ)(dim range ùëÜ). 18 Show that ùëâ and ‚Ñí(ùêÖ, ùëâ) are isomorphic vector spaces. 19 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá has the same matrix with respect to every basis of ùëâ if and only if ùëá is a scalar multiple of the identity operator. 20 Suppose ùëû ‚àà ùí´(ùêë). Prove that there exists a polynomial ùëù ‚àà ùí´(ùêë) such that ùëû(ùë•) = (ùë•2 + ùë•)ùëù ‚Ä≥(ùë•) + 2ùë•ùëù ‚Ä≤(ùë•) + ùëù(3) for all ùë• ‚àà ùêë. 21 Suppose ùëõ is a positive integer and ùê¥ùëó, ùëò ‚àà ùêÖ for all ùëó, ùëò = 1, ‚Ä¶, ùëõ. Prove that the following are equivalent (note that in both parts below, the number of equations equals the number of variables). (a) The trivial solution ùë•1 = ‚ãØ = ùë•ùëõ = 0is the only solution to the homogeneous system of equations ùëõ ‚àë ùëò = 1 ùê¥1, ùëò ùë•ùëò = 0 ‚ãÆ ùëõ ‚àë ùëò = 1 ùê¥ùëõ, ùëò ùë•ùëò = 0. (b) For every ùëê1, ‚Ä¶, ùëêùëõ ‚àà ùêÖ, there exists a solution to the system of equations ùëõ ‚àë ùëò = 1 ùê¥1, ùëò ùë•ùëò = ùëê1 ‚ãÆ ùëõ ‚àë ùëò = 1 ùê¥ùëõ, ùëò ùë•ùëò = ùëêùëõ. 22 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Prove that ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ))is invertible ‚ü∫ ùëá is invertible. 23 Suppose that ùë¢1, ‚Ä¶, ùë¢ùëõ and ùë£1, ‚Ä¶, ùë£ùëõ are bases of ùëâ. Let ùëá ‚àà ‚Ñí(ùëâ) be such that ùëáùë£ùëò = ùë¢ùëò for each ùëò = 1, ‚Ä¶, ùëõ. Prove that ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ))= ‚Ñ≥(ùêº, (ùë¢1, ‚Ä¶, ùë¢ùëõ), (ùë£1, ‚Ä¶, ùë£ùëõ)). 24 Suppose ùê¥ and ùêµ are square matrices of the same size and ùê¥ùêµ = ùêº. Prove that ùêµùê¥ = ùêº. 96 Chapter 3 Linear Maps 3E Products and Quotients of Vector Spaces Products of Vector Spaces As usual when dealing with more than one vector space, all vector spaces in use should be over the same field. 3.87 definition:product of vector spaces Suppose ùëâ1, ‚Ä¶, ùëâùëö are vector spaces over ùêÖ. ‚Ä¢ The product ùëâ1 √ó ‚ãØ √ó ùëâùëö is defined by ùëâ1 √ó ‚ãØ √ó ùëâùëö = {(ùë£1, ‚Ä¶, ùë£ùëö) ‚à∂ ùë£1 ‚àà ùëâ1, ‚Ä¶, ùë£ùëö ‚àà ùëâùëö}. ‚Ä¢ Addition on ùëâ1 √ó ‚ãØ √ó ùëâùëö is defined by (ùë¢1, ‚Ä¶, ùë¢ùëö) + (ùë£1, ‚Ä¶, ùë£ùëö) = (ùë¢1 + ùë£1, ‚Ä¶, ùë¢ùëö + ùë£ùëö). ‚Ä¢ Scalar multiplication on ùëâ1 √ó ‚ãØ √ó ùëâùëö is defined by ùúÜ(ùë£1, ‚Ä¶, ùë£ùëö) = (ùúÜùë£1, ‚Ä¶, ùúÜùë£ùëö). (5 ‚àí 6ùë•+ 4ùë• 2, (3, 8, 7))+ (ùë• + 9ùë• 5, (2, 2, 2)) = (5 ‚àí 5ùë•+ 4ùë• 2 + 9ùë• 5, (5, 10, 9)). Also, 2(5 ‚àí 6ùë•+ 4ùë• 2, (3, 8, 7))= (10 ‚àí 12ùë•+ 8ùë• 2, (6, 16, 14)). The next result should be interpreted to mean that the product of vector spaces is a vector space with the operations of addition and scalar multiplication as defined by3.87. 3.89 product of vector spaces is a vector space Suppose ùëâ1, ‚Ä¶, ùëâùëö are vector spaces over ùêÖ. Then ùëâ1 √ó ‚ãØ √ó ùëâùëö is a vector space over ùêÖ. The proof of the result above is left to the reader. Note that the additive identity of ùëâ1 √ó ‚ãØ √ó ùëâùëö is (0, ‚Ä¶, 0), where the 0in the ùëòth slot is the additive identity of ùëâùëò. The additive inverse of (ùë£1, ‚Ä¶, ùë£ùëö) ‚àà ùëâ1 √ó ‚ãØ √ó ùëâùëö is (‚àíùë£1, ‚Ä¶, ‚àíùë£ùëö). 3.88 example:product of the vector spaces ùí´5(ùêë)and ùêë3 Elements of ùí´5(ùêë) √ó ùêë 3 are lists of length two, with the first item in the list an element of ùí´5(ùêë)and the second item in the list an element of ùêë3. For example, (5 ‚àí 6ùë•+ 4ùë• 2, (3, 8, 7))and (ùë•+ 9ùë• 5, (2, 2, 2))are elements of ùí´5(ùêë) √ó ùêë 3. Their sum is defined by Section 3E Products and Quotients of Vector Spaces 97 3.90 example: ùêë2 √ó ùêë3 ‚â† ùêë5 but ùêë2 √ó ùêë3 is isomorphic to ùêë5 Elements of the vector space ùêë2 √ó ùêë3 are lists ((ùë•1, ùë•2), (ùë•3, ùë•4, ùë•5)), where ùë•1, ùë•2, ùë•3, ùë•4, ùë•5 ‚àà ùêë. Elements of ùêë5 are lists (ùë•1, ùë•2, ùë•3, ùë•4, ùë•5), where ùë•1, ùë•2, ùë•3, ùë•4, ùë•5 ‚àà ùêë. Although elements of ùêë2 √ó ùêë3 and ùêë5 look similar, they are not the same kind of object. Elements of ùêë2 √ó ùêë3 are lists of length two (with the first item itself a list of length two and the second item a list of length three), and elements of ùêë5 are lists of length five. Thusùêë2 √ó ùêë3 does not equal ùêë5. This isomorphism is so natural that we should think of it as a relabel- ing. Some people informally say that ùêë2√óùêë3 equals ùêë5, which is not techni- cally correct but which captures the spirit of identification via relabeling. The linear map ((ùë•1, ùë•2), (ùë•3, ùë•4, ùë•5))‚Ü¶ (ùë•1, ùë•2, ùë•3, ùë•4, ùë•5) is an isomorphism of the vector space ùêë2 √ó ùêë3 onto the vector space ùêë5. Thus these two vector spaces are isomorphic, al- though they are not equal. The next example illustrates the idea that we will use in the proof of 3.92. 3.91 example: a basis of ùí´2(ùêë) √ó ùêë2 Consider this list of length five of elements ofùí´2(ùêë) √ó ùêë2: (1, (0, 0)), (ùë•, (0, 0)), (ùë•2, (0, 0)), (0, (1, 0)), (0, (0, 1)). The list above is linearly independent and it spans ùí´2(ùêë) √ó ùêë2. Thus it is a basis of ùí´2(ùêë) √ó ùêë2. 3.92 dimension of a product is the sum of dimensions Suppose ùëâ1, ‚Ä¶, ùëâùëö are finite-dimensional vector spaces. Thenùëâ1 √ó ‚ãØ √ó ùëâùëö is finite-dimensional and dim(ùëâ1 √ó ‚ãØ √ó ùëâùëö) = dim ùëâ1 + ‚ãØ + dim ùëâùëö. Proof Choose a basis of each ùëâùëò. For each basis vector of each ùëâùëò, consider the element of ùëâ1 √ó ‚ãØ √ó ùëâùëö that equals the basis vector in the ùëòth slot and 0in the other slots. The list of all such vectors is linearly independent and spans ùëâ1 √ó ‚ãØ √ó ùëâùëö. Thus it is a basis of ùëâ1 √ó ‚ãØ √ó ùëâùëö. The length of this basis is dim ùëâ1 + ‚ãØ + dim ùëâùëö, as desired. 98 Chapter 3 Linear Maps In the next result, the map Œì is surjective by the definition ofùëâ1 +‚ãØ+ùëâùëö. Thus the last word in the result below could be changed from ‚Äúinjective‚Äù to ‚Äúinvertible‚Äù. 3.93 products and direct sums Suppose that ùëâ1, ‚Ä¶, ùëâùëö are subspaces of ùëâ. Define a linear map Œì ‚à∂ ùëâ1 √ó ‚ãØ √ó ùëâùëö ‚Üí ùëâ1 + ‚ãØ + ùëâùëö by Œì(ùë£1, ‚Ä¶, ùë£ùëö) = ùë£1 + ‚ãØ + ùë£ùëö. Then ùëâ1 + ‚ãØ + ùëâùëö is a direct sum if and only if Œì is injective. Proof By 3.15, Œì is injective if and only if the only way to write 0as a sum ùë£1 + ‚ãØ + ùë£ùëö, where each ùë£ùëò is in ùëâùëò, is by taking each ùë£ùëò equal to 0. Thus 1.45 shows that Œì is injective if and only if ùëâ1 + ‚ãØ + ùëâùëö is a direct sum, as desired. 3.94 a sum is a direct sum if and only if dimensions add up Suppose ùëâ is finite-dimensional andùëâ1, ‚Ä¶, ùëâùëö are subspaces of ùëâ. Then ùëâ1 + ‚ãØ + ùëâùëö is a direct sum if and only if dim(ùëâ1 + ‚ãØ + ùëâùëö) = dim ùëâ1 + ‚ãØ + dim ùëâùëö. Proof The map Œì in 3.93 is surjective. Thus by the fundamental theorem of linear maps (3.21), Œì is injective if and only if dim(ùëâ1 + ‚ãØ + ùëâùëö) = dim(ùëâ1 √ó ‚ãØ √ó ùëâùëö). Combining 3.93 and 3.92 now shows that ùëâ1 + ‚ãØ + ùëâùëö is a direct sum if and only if dim(ùëâ1 + ‚ãØ + ùëâùëö) = dim ùëâ1 + ‚ãØ + dim ùëâùëö, as desired. In the special case ùëö = 2, an alternative proof that ùëâ1 + ùëâ2 is a direct sum if and only if dim(ùëâ1 + ùëâ2) = dim ùëâ1 + dim ùëâ2 can be obtained by combining 1.46 and 2.43. Quotient Spaces We begin our approach to quotient spaces by defining the sum of a vector and a subset. 3.95 notation: ùë£ + ùëà Suppose ùë£ ‚àà ùëâ and ùëà ‚äÜ ùëâ. Then ùë£ + ùëà is the subset of ùëâ defined by ùë£ + ùëà = {ùë£ + ùë¢ ‚à∂ ùë¢ ‚àà ùëà}. Section 3E Products and Quotients of Vector Spaces 99 3.96 example:sum of a vector and a one-dimensional subspace of ùêë2 (17, 20)+ ùëà is parallel to the subspace ùëà. Suppose ùëà = {(ùë•, 2ùë•) ‚àà ùêë 2 ‚à∂ ùë• ‚àà ùêë}. Hence ùëà is the line in ùêë2 through the origin with slope 2. Thus (17, 20)+ ùëà is the line in ùêë2 that contains the point (17, 20) and has slope 2. Because (10, 20) ‚àà ùëàand (17, 20) ‚àà (17, 20)+ ùëà, we see that (17, 20)+ ùëà is obtained by moving ùëà to the right by 7units. 3.97 definition:translate For ùë£ ‚àà ùëâ and ùëà a subset of ùëâ, the set ùë£ + ùëà is said to be a translate of ùëà. 3.98 example: translates ‚Ä¢ If ùëà is the line in ùêë2 defined byùëà = {(ùë•, 2ùë•) ‚àà ùêë 2 ‚à∂ ùë• ‚àà ùêë}, then all lines in ùêë2 with slope 2are translates of ùëà. See Example 3.96 above for a drawing of ùëà and one of its translates. ‚Ä¢ More generally, if ùëà is a line in ùêë2, then the set of all translates of ùëà is the set of all lines in ùêë2 that are parallel to ùëà. ‚Ä¢ If ùëà = {(ùë•, ùë¶, 0) ‚àà ùêë 3 ‚à∂ ùë•, ùë¶ ‚àà ùêë}, then the translates of ùëà are the planes in ùêë3 that are parallel to the ùë•ùë¶-plane ùëà. ‚Ä¢ More generally, if ùëà is a plane in ùêë3, then the set of all translates of ùëà is the set of all planes in ùêë3 that are parallel to ùëà (see, for example, Exercise 7). 3.99 definition: quotient space, ùëâ/ùëà Suppose ùëà is a subspace of ùëâ. Then the quotient space ùëâ/ùëà is the set of all translates of ùëà. Thus ùëâ/ùëà = {ùë£ + ùëà ‚à∂ ùë£ ‚àà ùëâ}. 100 Chapter 3 Linear Maps 3.100 example: quotient spaces ‚Ä¢ If ùëà = {(ùë•, 2ùë•) ‚àà ùêë 2 ‚à∂ ùë• ‚àà ùêë}, then ùêë2/ùëà is the set of all lines in ùêë2 that have slope 2. ‚Ä¢ If ùëà is a line in ùêë3 containing the origin, then ùêë3/ùëà is the set of all lines in ùêë3 parallel to ùëà. ‚Ä¢ If ùëà is a plane in ùêë3 containing the origin, then ùêë3/ùëà is the set of all planes in ùêë3 parallel to ùëà. Our next goal is to make ùëâ/ùëà into a vector space. To do this, we will need the next result. 3.101 two translates of a subspace are equal or disjoint Suppose ùëà is a subspace of ùëâ and ùë£, ùë§ ‚àà ùëâ. Then ùë£ ‚àí ùë§ ‚àà ùëà ‚ü∫ ùë£ + ùëà = ùë§ + ùëà ‚ü∫ (ùë£ + ùëà) ‚à© (ùë§+ ùëà) ‚â† ‚àÖ. Proof First suppose ùë£ ‚àí ùë§ ‚àà ùëà. If ùë¢ ‚àà ùëà, then ùë£ + ùë¢ = ùë§ + ((ùë£ ‚àí ùë§) + ùë¢)‚àà ùë§ + ùëà. Thus ùë£ + ùëà ‚äÜ ùë§+ ùëà. Similarly, ùë§ + ùëà ‚äÜ ùë£+ ùëà. Thus ùë£ + ùëà = ùë§ + ùëà, completing the proof that ùë£ ‚àí ùë§ ‚àà ùëà implies ùë£ + ùëà = ùë§ + ùëà. The equation ùë£ + ùëà = ùë§ + ùëà implies that (ùë£ + ùëà) ‚à© (ùë§+ ùëà) ‚â† ‚àÖ. Now suppose (ùë£ + ùëà) ‚à© (ùë§+ ùëà) ‚â† ‚àÖ. Thus there exist ùë¢1, ùë¢2 ‚àà ùëà such that ùë£ + ùë¢1 = ùë§ + ùë¢2. Thus ùë£ ‚àí ùë§ = ùë¢2 ‚àí ùë¢1. Hence ùë£ ‚àí ùë§ ‚àà ùëà, showing that (ùë£ + ùëà) ‚à© (ùë§+ ùëà) ‚â† ‚àÖ implies ùë£ ‚àí ùë§ ‚àà ùëà, which completes the proof. Now we can define addition and scalar multiplication onùëâ/ùëà. 3.102 definition: addition and scalar multiplication on ùëâ/ùëà Suppose ùëà is a subspace of ùëâ. Then addition and scalar multiplication are defined onùëâ/ùëà by (ùë£ + ùëà) + (ùë§ + ùëà) = (ùë£ + ùë§) + ùëà ùúÜ(ùë£ + ùëà) = (ùúÜùë£) + ùëà for all ùë£, ùë§ ‚àà ùëâ and all ùúÜ ‚àà ùêÖ. As part of the proof of the next result, we will show that the definitions above make sense. Section 3E Products and Quotients of Vector Spaces 101 3.103 quotient space is a vector space Suppose ùëà is a subspace of ùëâ. Then ùëâ/ùëà, with the operations of addition and scalar multiplication as defined above, is a vector space. Proof The potential problem with the definitions above of addition and scalar multiplication on ùëâ/ùëà is that the representation of a translate of ùëà is not unique. Specifically, supposeùë£1, ùë£2, ùë§1, ùë§2 ‚àà ùëâ are such that ùë£1 + ùëà = ùë£2 + ùëà and ùë§1 + ùëà = ùë§2 + ùëà. To show that the definition of addition onùëâ/ùëà given above makes sense, we must show that (ùë£1 + ùë§1) + ùëà = (ùë£2 + ùë§2) + ùëà. By 3.101, we have ùë£1 ‚àí ùë£2 ‚àà ùëà and ùë§1 ‚àí ùë§2 ‚àà ùëà. Because ùëà is a subspace of ùëâ and thus is closed under addition, this implies that (ùë£1 ‚àí ùë£2) + (ùë§1 ‚àí ùë§2) ‚àà ùëà. Thus (ùë£1 + ùë§1) ‚àí (ùë£2 + ùë§2) ‚àà ùëà. Using 3.101 again, we see that (ùë£1 + ùë§1) + ùëà = (ùë£2 + ùë§2) + ùëà, as desired. Thus the definition of addition onùëâ/ùëà makes sense. Similarly, suppose ùúÜ ‚àà ùêÖ. We are still assuming that ùë£1 + ùëà = ùë£2 + ùëà. Because ùëà is a subspace of ùëâ and thus is closed under scalar multiplication, we have ùúÜ(ùë£1 ‚àí ùë£2) ‚àà ùëà. Thus ùúÜùë£1 ‚àí ùúÜùë£2 ‚àà ùëà. Hence 3.101 implies that (ùúÜùë£1) + ùëà = (ùúÜùë£2) + ùëà. Thus the definition of scalar multiplication onùëâ/ùëà makes sense. Now that addition and scalar multiplication have been defined onùëâ/ùëà, the verification that these operations makeùëâ/ùëà into a vector space is straightforward and is left to the reader. Note that the additive identity of ùëâ/ùëà is 0+ ùëà (which equals ùëà) and that the additive inverse of ùë£ + ùëà is (‚àíùë£) + ùëà. The next concept will lead to a computation of the dimension of ùëâ/ùëà. 3.104 definition: quotient map, ùúã Suppose ùëà is a subspace of ùëâ. The quotient map ùúã‚à∂ ùëâ ‚Üí ùëâ/ùëà is the linear map defined by ùúã(ùë£) = ùë£ + ùëà for each ùë£ ‚àà ùëâ. The reader should verify that ùúã is indeed a linear map. Although ùúã depends on ùëà as well as ùëâ, these spaces are left out of the notation because they should be clear from the context. 102 Chapter 3 Linear Maps 3.105 dimension of quotient space Suppose ùëâ is finite-dimensional andùëà is a subspace of ùëâ. Then dim ùëâ/ùëà = dim ùëâ ‚àí dim ùëà. Proof Let ùúã denote the quotient map from ùëâ to ùëâ/ùëà. If ùë£ ‚àà ùëâ, then ùë£+ùëà = 0+ùëà if and only if ùë£ ‚àà ùëà (by 3.101), which implies that null ùúã = ùëà. The definition of ùúã implies range ùúã = ùëâ/ùëà. The fundamental theorem of linear maps (3.21) now implies dim ùëâ = dim ùëà + dim ùëâ/ùëà, which gives the desired result. Each linear map ùëá on ùëâ induces a linear map ÃÉùëá on ùëâ/(null ùëá), which we now define. 3.106 notation:ÃÉùëá Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). DefineÃÉùëá‚à∂ ùëâ/(null ùëá) ‚Üí ùëä by ÃÉùëá(ùë£ + null ùëá) = ùëáùë£. To show that the definition ofÃÉùëá makes sense, suppose ùë¢, ùë£ ‚àà ùëâ are such that ùë¢ + null ùëá = ùë£ + null ùëá. By 3.101, we have ùë¢ ‚àí ùë£ ‚àà null ùëá. Thus ùëá(ùë¢ ‚àí ùë£) = 0. Hence ùëáùë¢ = ùëáùë£. Thus the definition ofÃÉùëá indeed makes sense. The routine verification thatÃÉùëá is a linear map from ùëâ/(null ùëá) to ùëä is left to the reader. The next result shows that we can think of ÃÉùëá as a modified version ofùëá, with a domain that produces a one-to-one map. 3.107 null space and range of ÃÉùëá Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then (a) ÃÉùëá ‚àò ùúã = ùëá, where ùúã is the quotient map of ùëâ onto ùëâ/(null ùëá); (b) ÃÉùëá is injective; (c) range ÃÉùëá = range ùëá; (d) ùëâ/(null ùëá) and range ùëá are isomorphic vector spaces. Proof (a) If ùë£ ‚àà ùëâ, then (ÃÉùëá ‚àò ùúã)(ùë£) = ÃÉùëá(ùúã(ùë£))= ÃÉùëá(ùë£ + null ùëá) = ùëáùë£, as desired. (b) Suppose ùë£ ‚àà ùëâ and ÃÉùëá(ùë£ + null ùëá) = 0. Then ùëáùë£ = 0. Thus ùë£ ‚àà null ùëá. Hence 3.101 implies that ùë£ + null ùëá = 0+ null ùëá. This implies that null ÃÉùëá = {0+ null ùëá}. Hence ÃÉùëá is injective, as desired. (c) The definition ofÃÉùëá shows that range ÃÉùëá = range ùëá. (d) Now (b) and (c) imply that if we think of ÃÉùëá as mapping into range ùëá, then ÃÉùëá is an isomorphism from ùëâ/(null ùëá) onto range ùëá. Section 3E Products and Quotients of Vector Spaces 103 Exercises 3E 1 Suppose ùëá is a function from ùëâ to ùëä. The graph of ùëá is the subset of ùëâ√ó ùëä defined by graph of ùëá = {(ùë£, ùëáùë£) ‚àà ùëâ √ó ùëä ‚à∂ ùë£ ‚àà ùëâ}. Prove that ùëá is a linear map if and only if the graph of ùëá is a subspace of ùëâ √ó ùëä. Formally, a function ùëá from ùëâ to ùëä is a subset ùëá of ùëâ √ó ùëä such that for each ùë£ ‚àà ùëâ, there exists exactly one element (ùë£, ùë§) ‚àà ùëá. In other words, formally a function is what is called above its graph. We do not usually think of functions in this formal manner. However, if we do become formal, then this exercise could be rephrased as follows: Prove that a function ùëá from ùëâ to ùëä is a linear map if and only if ùëá is a subspace of ùëâ √ó ùëä. 2 Suppose that ùëâ1, ‚Ä¶, ùëâùëö are vector spaces such that ùëâ1 √ó ‚ãØ √ó ùëâùëö is finite- dimensional. Prove that ùëâùëò is finite-dimensional for eachùëò = 1, ‚Ä¶, ùëö. 3 Suppose ùëâ1, ‚Ä¶, ùëâùëö are vector spaces. Prove that ‚Ñí(ùëâ1 √ó ‚ãØ √ó ùëâùëö, ùëä) and ‚Ñí(ùëâ1, ùëä) √ó ‚ãØ √ó ‚Ñí(ùëâùëö, ùëä) are isomorphic vector spaces. 4 Suppose ùëä1, ‚Ä¶, ùëäùëö are vector spaces. Prove that ‚Ñí(ùëâ, ùëä1 √ó ‚ãØ √ó ùëäùëö) and ‚Ñí(ùëâ, ùëä1) √ó ‚ãØ √ó ‚Ñí(ùëâ, ùëäùëö) are isomorphic vector spaces. 5 For ùëö a positive integer, defineùëâùëö by ùëâùëö = ùëâ √ó ‚ãØ √ó ùëâ‚èü ùëö times . Prove that ùëâùëö and ‚Ñí(ùêÖùëö, ùëâ)are isomorphic vector spaces. 6 Suppose that ùë£, ùë• are vectors in ùëâ and that ùëà, ùëä are subspaces of ùëâ such that ùë£ + ùëà = ùë• + ùëä. Prove that ùëà = ùëä. 7 Let ùëà = {(ùë•, ùë¶, ùëß) ‚àà ùêë3 ‚à∂ 2ùë•+ 3ùë¶+ 5ùëß = 0}. Suppose ùê¥ ‚äÜ ùêë 3. Prove that ùê¥ is a translate of ùëà if and only if there exists ùëê ‚àà ùêë such that ùê¥ = {(ùë•, ùë¶, ùëß) ‚àà ùêë3 ‚à∂ 2ùë•+ 3ùë¶+ 5ùëß = ùëê}. 8 (a) Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùëê ‚àà ùëä. Prove that {ùë• ‚àà ùëâ ‚à∂ ùëáùë• = ùëê} is either the empty set or is a translate of null ùëá. (b) Explain why the set of solutions to a system of linear equations such as 3.27 is either the empty set or is a translate of some subspace of ùêÖùëõ. 9 Prove that a nonempty subset ùê¥ of ùëâ is a translate of some subspace of ùëâ if and only if ùúÜùë£ + (1 ‚àí ùúÜ)ùë§ ‚àà ùê¥for all ùë£, ùë§ ‚àà ùê¥ and all ùúÜ ‚àà ùêÖ. 10 Suppose ùê¥1 = ùë£ + ùëà1 and ùê¥2 = ùë§ + ùëà2 for some ùë£, ùë§ ‚àà ùëâ and some subspaces ùëà1, ùëà2 of ùëâ. Prove that the intersection ùê¥1 ‚à© ùê¥2 is either a translate of some subspace of ùëâ or is the empty set. 104 Chapter 3 Linear Maps 11 Suppose ùëà = {(ùë•1, ùë•2, ‚Ä¶ ) ‚àà ùêÖ‚àû ‚à∂ ùë•ùëò ‚â† 0for only finitely manyùëò}. (a) Show that ùëà is a subspace of ùêÖ‚àû. (b) Prove that ùêÖ‚àû/ùëà is infinite-dimensional. 12 Suppose ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ. Let ùê¥ = {ùúÜ1ùë£1 + ‚ãØ + ùúÜùëöùë£ùëö ‚à∂ ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÖ and ùúÜ1 + ‚ãØ + ùúÜùëö = 1}. (a) Prove that ùê¥ is a translate of some subspace of ùëâ. (b) Prove that if ùêµ is a translate of some subspace of ùëâ and {ùë£1, ‚Ä¶, ùë£ùëö} ‚äÜ ùêµ, then ùê¥ ‚äÜ ùêµ. (c) Prove that ùê¥ is a translate of some subspace of ùëâ of dimension less than ùëö. 13 Suppose ùëà is a subspace of ùëâ such that ùëâ/ùëà is finite-dimensional. Prove that ùëâ is isomorphic to ùëà √ó (ùëâ/ùëà). 14 Suppose ùëà and ùëä are subspaces of ùëâ and ùëâ = ùëà ‚äï ùëä. Suppose ùë§1, ‚Ä¶, ùë§ùëö is a basis of ùëä. Prove that ùë§1 + ùëà, ‚Ä¶, ùë§ùëö + ùëà is a basis of ùëâ/ùëà. 15 Suppose ùëà is a subspace of ùëâ and ùë£1 + ùëà, ‚Ä¶, ùë£ùëö + ùëà is a basis of ùëâ/ùëà and ùë¢1, ‚Ä¶, ùë¢ùëõ is a basis of ùëà. Prove that ùë£1, ‚Ä¶, ùë£ùëö, ùë¢1, ‚Ä¶, ùë¢ùëõ is a basis of ùëâ. 16 Suppose ùúë ‚àà ‚Ñí(ùëâ, ùêÖ) and ùúë ‚â† 0. Prove that dim ùëâ/(null ùúë) = 1. 17 Suppose ùëà is a subspace of ùëâ such that dim ùëâ/ùëà = 1. Prove that there exists ùúë ‚àà ‚Ñí(ùëâ, ùêÖ) such that null ùúë = ùëà. 18 Suppose that ùëà is a subspace of ùëâ such that ùëâ/ùëà is finite-dimensional. (a) Show that if ùëä is a finite-dimensional subspace ofùëâ and ùëâ = ùëà + ùëä, then dim ùëä ‚â•dim ùëâ/ùëà. (b) Prove that there exists a finite-dimensional subspaceùëä of ùëâ such that dim ùëä = dim ùëâ/ùëà and ùëâ = ùëà ‚äï ùëä. 19 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùëà is a subspace of ùëâ. Let ùúã denote the quotient map from ùëâ onto ùëâ/ùëà. Prove that there exists ùëÜ ‚àà ‚Ñí(ùëâ/ùëà, ùëä) such that ùëá = ùëÜ ‚àò ùúã if and only if ùëà ‚äÜnull ùëá. Section 3F Duality 105 3F Duality Dual Space and Dual Map Linear maps into the scalar fieldùêÖ play a special role in linear algebra, and thus they get a special name. 3.108 definition: linear functional A linear functional on ùëâ is a linear map from ùëâ to ùêÖ. In other words, a linear functional is an element of ‚Ñí(ùëâ, ùêÖ). 3.109 example: linear functionals ‚Ä¢ Defineùúë‚à∂ ùêë3 ‚Üí ùêë by ùúë(ùë•, ùë¶, ùëß) = 4ùë• ‚àí 5ùë¶+ 2ùëß. Then ùúë is a linear functional on ùêë3. ‚Ä¢ Fix (ùëê1, ‚Ä¶, ùëêùëõ) ‚àà ùêÖùëõ. Defineùúë‚à∂ ùêÖùëõ ‚Üí ùêÖ by ùúë(ùë•1, ‚Ä¶, ùë•ùëõ) = ùëê1ùë•1 + ‚ãØ + ùëêùëõ ùë•ùëõ. Then ùúë is a linear functional on ùêÖùëõ. ‚Ä¢ Defineùúë‚à∂ ùí´(ùêë) ‚Üí ùêë by ùúë(ùëù) = 3ùëù ‚Ä≥(5)+ 7ùëù(4). Then ùúë is a linear functional on ùí´(ùêë). ‚Ä¢ Defineùúë‚à∂ ùí´(ùêë) ‚Üí ùêë by ùúë(ùëù) = ‚à´ 1 0 ùëù for each ùëù ‚àà ùí´(ùêë). Then ùúë is a linear functional on ùí´(ùêë). The vector space ‚Ñí(ùëâ, ùêÖ) also gets a special name and special notation. 3.110 definition: dual space, ùëâ‚Ä≤ The dual space of ùëâ, denoted by ùëâ‚Ä≤, is the vector space of all linear functionals on ùëâ. In other words, ùëâ‚Ä≤ = ‚Ñí(ùëâ, ùêÖ). 3.111 dim ùëâ‚Ä≤ = dim ùëâ Suppose ùëâ is finite-dimensional. Thenùëâ‚Ä≤ is also finite-dimensional and dim ùëâ‚Ä≤ = dim ùëâ. Proof By 3.72 we have dim ùëâ‚Ä≤ = dim ‚Ñí(ùëâ, ùêÖ) = (dim ùëâ)(dim ùêÖ) = dim ùëâ, as desired. 106 Chapter 3 Linear Maps In the following definition, the linear map lemma (3.4) implies that each ùúëùëó is well defined. 3.112 definition: dual basis If ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ, then the dual basis of ùë£1, ‚Ä¶, ùë£ùëõ is the list ùúë1, ‚Ä¶, ùúëùëõ of elements of ùëâ‚Ä≤, where each ùúëùëó is the linear functional on ùëâ such that ùúëùëó(ùë£ùëò) = ‚éß{ ‚é®{‚é© 1 if ùëò = ùëó, 0 if ùëò ‚â† ùëó. 3.113 example: the dual basis of the standard basis of ùêÖùëõ Suppose ùëõ is a positive integer. For 1 ‚â§ ùëó ‚â§ ùëõ, defineùúëùëó to be the linear functional on ùêÖùëõ that selects the ùëóth coordinate of a vector in ùêÖùëõ. Thus ùúëùëó(ùë•1, ‚Ä¶, ùë•ùëõ) = ùë•ùëó for each (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêÖùëõ. Let ùëí1, ‚Ä¶, ùëíùëõ be the standard basis of ùêÖùëõ. Then ùúëùëó(ùëíùëò) = ‚éß{ ‚é®{‚é© 1 if ùëò = ùëó, 0 if ùëò ‚â† ùëó. Thus ùúë1, ‚Ä¶, ùúëùëõ is the dual basis of the standard basis ùëí1, ‚Ä¶, ùëíùëõ of ùêÖùëõ. The next result shows that the dual basis of a basis of ùëâ consists of the linear functionals on ùëâ that give the coefficients for expressing a vector in ùëâ as a linear combination of the basis vectors. 3.114 dual basis gives coefficients for linear combination Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùúë1, ‚Ä¶, ùúëùëõ is the dual basis. Then ùë£ = ùúë1(ùë£)ùë£1 + ‚ãØ + ùúëùëõ(ùë£)ùë£ùëõ for each ùë£ ‚àà ùëâ. Proof Suppose ùë£ ‚àà ùëâ. Then there exist ùëê1, ‚Ä¶, ùëêùëõ ‚àà ùêÖ such that 3.115 ùë£ = ùëê1ùë£1 + ‚ãØ + ùëêùëõùë£ùëõ. If ùëó ‚àà {1, ‚Ä¶, ùëõ}, then applying ùúëùëó to both sides of the equation above gives ùúëùëó(ùë£) = ùëêùëó. Substituting the values for ùëê1, ‚Ä¶, ùëêùëõ given by the equation above into 3.115 shows that ùë£ = ùúë1(ùë£)ùë£1 + ‚ãØ + ùúëùëõ(ùë£)ùë£ùëõ. Section 3F Duality 107 The next result shows that the dual basis is indeed a basis of the dual space. Thus the terminology ‚Äúdual basis‚Äù is justified. 3.116 dual basis is a basis of the dual space Suppose ùëâ is finite-dimensional. Then the dual basis of a basis ofùëâ is a basis of ùëâ‚Ä≤. Proof Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Let ùúë1, ‚Ä¶, ùúëùëõ denote the dual basis. To show that ùúë1, ‚Ä¶, ùúëùëõ is a linearly independent list of elements of ùëâ‚Ä≤, suppose ùëé1, ‚Ä¶, ùëéùëõ ‚àà ùêÖ are such that 3.117 ùëé1ùúë1 + ‚ãØ + ùëéùëõùúëùëõ = 0. Now (ùëé1ùúë1 + ‚ãØ + ùëéùëõùúëùëõ)(ùë£ùëò) = ùëéùëò for each ùëò = 1, ‚Ä¶, ùëõ. Thus 3.117 shows that ùëé1 = ‚ãØ = ùëéùëõ = 0. Hence ùúë1, ‚Ä¶, ùúëùëõ is linearly independent. Because ùúë1, ‚Ä¶, ùúëùëõ is a linearly independent list in ùëâ‚Ä≤ whose length equals dim ùëâ‚Ä≤ (by 3.111), we can conclude that ùúë1, ‚Ä¶, ùúëùëõ is a basis of ùëâ‚Ä≤ (see 2.38). In the definition below, note that ifùëá is a linear map from ùëâ to ùëä then ùëá‚Ä≤ is a linear map from ùëä‚Ä≤ to ùëâ‚Ä≤. 3.118 definition: dual map, ùëá‚Ä≤ Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). The dual map of ùëá is the linear map ùëá‚Ä≤ ‚àà ‚Ñí(ùëä‚Ä≤, ùëâ‚Ä≤) defined for eachùúë ‚àà ùëä‚Ä≤ by ùëá‚Ä≤(ùúë) = ùúë ‚àò ùëá. If ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùúë ‚àà ùëä‚Ä≤, then ùëá‚Ä≤(ùúë) is defined above to be the composition of the linear maps ùúë and ùëá. Thus ùëá‚Ä≤(ùúë) is indeed a linear map from ùëâ to ùêÖ; in other words, ùëá‚Ä≤(ùúë) ‚àà ùëâ‚Ä≤. The following two bullet points show that ùëá‚Ä≤ is a linear map from ùëä‚Ä≤ to ùëâ‚Ä≤. ‚Ä¢ If ùúë, ùúì ‚àà ùëä‚Ä≤, then ùëá‚Ä≤(ùúë + ùúì) = (ùúë + ùúì) ‚àò ùëá = ùúë ‚àò ùëá + ùúì ‚àò ùëá = ùëá‚Ä≤(ùúë) + ùëá‚Ä≤(ùúì). ‚Ä¢ If ùúÜ ‚àà ùêÖ and ùúë ‚àà ùëä‚Ä≤, then ùëá‚Ä≤(ùúÜùúë) = (ùúÜùúë) ‚àò ùëá = ùúÜ(ùúë ‚àò ùëá) = ùúÜùëá‚Ä≤(ùúë). The prime notation appears with two unrelated meanings in the next example: ùê∑‚Ä≤ denotes the dual of the linear map ùê∑, and ùëù ‚Ä≤ denotes the derivative of a polynomial ùëù. 108 Chapter 3 Linear Maps 3.119 example: dual map of the differentiation linear map Defineùê∑‚à∂ ùí´(ùêë) ‚Üí ùí´(ùêë) by ùê∑ùëù = ùëù‚Ä≤. ‚Ä¢ Suppose ùúë is the linear functional on ùí´(ùêë) defined byùúë(ùëù) = ùëù(3). Then ùê∑ ‚Ä≤(ùúë) is the linear functional on ùí´(ùêë) given by (ùê∑‚Ä≤(ùúë))(ùëù) = (ùúë ‚àò ùê∑)(ùëù) = ùúë(ùê∑ùëù) = ùúë(ùëù ‚Ä≤)= ùëù‚Ä≤(3). Thus ùê∑‚Ä≤(ùúë) is the linear functional on ùí´(ùêë) taking ùëù to ùëù ‚Ä≤(3). ‚Ä¢ Suppose ùúë is the linear functional on ùí´(ùêë) defined byùúë(ùëù) = ‚à´ 1 0 ùëù. Then ùê∑ ‚Ä≤(ùúë) is the linear functional on ùí´(ùêë) given by (ùê∑ ‚Ä≤(ùúë))(ùëù) = (ùúë ‚àò ùê∑)(ùëù) = ùúë(ùê∑ùëù) = ùúë(ùëù ‚Ä≤) = ‚à´1 0 ùëù‚Ä≤ = ùëù(1) ‚àí ùëù(0). Thus ùê∑‚Ä≤(ùúë) is the linear functional on ùí´(ùêë) taking ùëù to ùëù(1) ‚àí ùëù(0). In the next result, (a) and (b) imply that the function that takes ùëá to ùëá‚Ä≤ is a linear map from ‚Ñí(ùëâ, ùëä) to ‚Ñí(ùëä‚Ä≤, ùëâ‚Ä≤). In (c) below, note the reversal of order from ùëÜùëá on the left to ùëá‚Ä≤ùëÜ ‚Ä≤ on the right. 3.120 algebraic properties of dual maps Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then (a) (ùëÜ + ùëá) ‚Ä≤ = ùëÜ‚Ä≤ + ùëá‚Ä≤ for all ùëÜ ‚àà ‚Ñí(ùëâ, ùëä); (b) (ùúÜùëá)‚Ä≤ = ùúÜùëá‚Ä≤ for all ùúÜ ‚àà ùêÖ; (c) (ùëÜùëá) ‚Ä≤ = ùëá‚Ä≤ùëÜ ‚Ä≤ for all ùëÜ ‚àà ‚Ñí(ùëä, ùëà). Proof The proofs of (a) and (b) are left to the reader. To prove (c), suppose ùúë ‚àà ùëà‚Ä≤. Then (ùëÜùëá) ‚Ä≤(ùúë) = ùúë ‚àò (ùëÜùëá) = (ùúë ‚àò ùëÜ) ‚àò ùëá = ùëá‚Ä≤(ùúë ‚àò ùëÜ) = ùëá‚Ä≤(ùëÜ ‚Ä≤(ùúë))= (ùëá‚Ä≤ùëÜ‚Ä≤)(ùúë), Some books use the notation ùëâ‚àó and ùëá‚àó for duality instead of ùëâ‚Ä≤ and ùëá‚Ä≤. However, here we reserve the notation ùëá‚àó for the adjoint, which will be intro- duced when we study linear maps on inner product spaces in Chapter 7. where the first, third, and fourth equal- ities above hold because of the defini- tion of the dual map, the second equality holds because composition of functions is associative, and the last equality fol- lows from the definition of composition. The equation above shows that (ùëÜùëá) ‚Ä≤(ùúë) = (ùëá‚Ä≤ùëÜ ‚Ä≤)(ùúë) for all ùúë ‚àà ùëà‚Ä≤. Thus (ùëÜùëá)‚Ä≤ = ùëá‚Ä≤ùëÜ ‚Ä≤. Section 3F Duality 109 Null Space and Range of Dual of Linear Map Our goal in this subsection is to describe null ùëá‚Ä≤ and range ùëá‚Ä≤ in terms of range ùëá and null ùëá. To do this, we will need the next definition. 3.121 definition: annihilator, ùëà0 For ùëà ‚äÜ ùëâ, the annihilator of ùëà, denoted by ùëà0, is defined by ùëà0 = {ùúë ‚àà ùëâ‚Ä≤ ‚à∂ ùúë(ùë¢) = 0for all ùë¢ ‚àà ùëà}. 3.122 example: element of an annihilator Suppose ùëà is the subspace of ùí´(ùêë) consisting of polynomial multiples of ùë•2. If ùúë is the linear functional on ùí´(ùêë) defined byùúë(ùëù) = ùëù‚Ä≤(0), then ùúë ‚àà ùëà0. For ùëà ‚äÜ ùëâ, the annihilator ùëà0 is a subset of the dual space ùëâ‚Ä≤. Thus ùëà0 depends on the vector space containing ùëà, so a notation such as ùëà0 ùëâ would be more precise. However, the containing vector space will always be clear from the context, so we will use the simpler notation ùëà0. 3.123 example: the annihilator of a two-dimensional subspace of ùêë5 Let ùëí1, ùëí2, ùëí3, ùëí4, ùëí5 denote the standard basis of ùêë5; let ùúë1, ùúë2, ùúë3, ùúë4, ùúë5 ‚àà (ùêë5) ‚Ä≤ denote the dual basis of ùëí1, ùëí2, ùëí3, ùëí4, ùëí5. Suppose ùëà = span(ùëí1, ùëí2) = {(ùë•1, ùë•2, 0, 0, 0) ‚àà ùêë 5 ‚à∂ ùë•1, ùë•2 ‚àà ùêë}. We want to show that ùëà0 = span(ùúë3, ùúë4, ùúë5). Recall (see 3.113) that ùúëùëó is the linear functional on ùêë5 that selects the ùëóth coordinate: ùúëùëó(ùë•1, ùë•2, ùë•3, ùë•4, ùë•5) = ùë•ùëó. First suppose ùúë ‚àà span(ùúë3, ùúë4, ùúë5). Then there exist ùëê3, ùëê4, ùëê5 ‚àà ùêë such that ùúë = ùëê3ùúë3 + ùëê4ùúë4 + ùëê5ùúë5. If (ùë•1, ùë•2, 0, 0, 0) ‚àà ùëà, then ùúë(ùë•1, ùë•2, 0, 0, 0) = (ùëê3ùúë3 + ùëê4ùúë4 + ùëê5ùúë5)(ùë•1, ùë•2, 0, 0, 0) = 0. Thus ùúë ‚àà ùëà0. Hence we have shown that span(ùúë3, ùúë4, ùúë5) ‚äÜ ùëà 0. To show the inclusion in the other direction, suppose that ùúë ‚àà ùëà0. Be- cause the dual basis is a basis of (ùêë5) ‚Ä≤ , there exist ùëê1, ùëê2, ùëê3, ùëê4, ùëê5 ‚àà ùêë such that ùúë = ùëê1ùúë1 + ùëê2ùúë2 + ùëê3ùúë3 + ùëê4ùúë4 + ùëê5ùúë5. Because ùëí1 ‚àà ùëà and ùúë ‚àà ùëà0, we have 0 = ùúë(ùëí1) = (ùëê1ùúë1 + ùëê2ùúë2 + ùëê3ùúë3 + ùëê4ùúë4 + ùëê5ùúë5)(ùëí1) = ùëê1. Similarly, ùëí2 ‚àà ùëà and thus ùëê2 = 0. Hence ùúë = ùëê3ùúë3 + ùëê4ùúë4 + ùëê5ùúë5. Thus ùúë ‚àà span(ùúë3, ùúë4, ùúë5), which shows that ùëà0 ‚äÜspan(ùúë3, ùúë4, ùúë5). Thus ùëà0 = span(ùúë3, ùúë4, ùúë5). 110 Chapter 3 Linear Maps 3.124 the annihilator is a subspace Suppose ùëà ‚äÜ ùëâ. Then ùëà0 is a subspace of ùëâ‚Ä≤. Proof Note that 0 ‚àà ùëà 0 (here 0is the zero linear functional on ùëâ) because the zero linear functional applied to every vector in ùëà is the zero vector in ùëâ. Suppose ùúë, ùúì ‚àà ùëà0. Thus ùúë, ùúì ‚àà ùëâ‚Ä≤ and ùúë(ùë¢) = ùúì(ùë¢) = 0for every ùë¢ ‚àà ùëà. If ùë¢ ‚àà ùëà, then (ùúë + ùúì)(ùë¢) = ùúë(ùë¢) + ùúì(ùë¢) = 0+ 0 = 0. Thus ùúë + ùúì ‚àà ùëà0. Similarly, ùëà0 is closed under scalar multiplication. Thus 1.34 implies that ùëà0 is a subspace of ùëâ‚Ä≤. The next result shows that dim ùëà0 is the difference of dim ùëâ and dim ùëà. For example, this shows that if ùëà is a two-dimensional subspace of ùêë5, then ùëà0 is a three-dimensional subspace of (ùêë5) ‚Ä≤ , as in Example 3.123. The next result can be proved following the pattern of Example 3.123: choose a basis ùë¢1, ‚Ä¶, ùë¢ùëö of ùëà, extend to a basis ùë¢1, ‚Ä¶, ùë¢ùëö, ‚Ä¶, ùë¢ùëõ of ùëâ, let ùúë1, ‚Ä¶, ùúëùëö, ‚Ä¶, ùúëùëõ be the dual basis of ùëâ‚Ä≤, and then show that ùúëùëö + 1, ‚Ä¶, ùúëùëõ is a basis of ùëà0, which implies the desired result. You should construct the proof just outlined, even though a slicker proof is presented here. 3.125 dimension of the annihilator Suppose ùëâ is finite-dimensional andùëà is a subspace of ùëâ. Then dim ùëà0 = dim ùëâ ‚àí dim ùëà. Proof Let ùëñ ‚àà ‚Ñí(ùëà, ùëâ) be the inclusion map defined byùëñ(ùë¢) = ùë¢ for each ùë¢ ‚àà ùëà. Thus ùëñ‚Ä≤ is a linear map from ùëâ‚Ä≤ to ùëà‚Ä≤. The fundamental theorem of linear maps (3.21) applied to ùëñ‚Ä≤ shows that dim range ùëñ‚Ä≤ + dim null ùëñ‚Ä≤ = dim ùëâ‚Ä≤. However, null ùëñ‚Ä≤ = ùëà0 (as can be seen by thinking about the definitions) and dim ùëâ‚Ä≤ = dim ùëâ (by 3.111), so we can rewrite the equation above as 3.126 dim range ùëñ‚Ä≤ + dim ùëà0 = dim ùëâ. If ùúë ‚àà ùëà‚Ä≤, then ùúë can be extended to a linear functional ùúì on ùëâ (see, for example, Exercise 13 in Section 3A). The definition ofùëñ‚Ä≤ shows that ùëñ‚Ä≤(ùúì) = ùúë. Thus ùúë ‚àà range ùëñ‚Ä≤, which implies that range ùëñ‚Ä≤ = ùëà‚Ä≤. Hence dim range ùëñ‚Ä≤ = dim ùëà‚Ä≤ = dim ùëà, and then 3.126 becomes the equation dim ùëà + dim ùëà0 = dim ùëâ, as desired. Section 3F Duality 111 The next result can be a useful tool to show that a subspace is as big as possible‚Äîsee (a)‚Äîor to show that a subspace is as small as possible‚Äîsee (b). 3.127 condition for the annihilator to equal {0}or the whole space Suppose ùëâ is finite-dimensional andùëà is a subspace of ùëâ. Then (a) ùëà0 = {0} ‚ü∫ ùëà = ùëâ; (b) ùëà0 = ùëâ‚Ä≤ ‚ü∫ ùëà = {0}. Proof To prove (a), we have ùëà0 = {0} ‚ü∫dim ùëà0 = 0 ‚ü∫ dim ùëà = dim ùëâ ‚ü∫ ùëà = ùëâ, where the second equivalence follows from 3.125 and the third equivalence follows from 2.39. Similarly, to prove (b) we have ùëà0 = ùëâ‚Ä≤ ‚ü∫ dim ùëà0 = dim ùëâ‚Ä≤ ‚ü∫ dim ùëà0 = dim ùëâ ‚ü∫ dim ùëà = 0 ‚ü∫ ùëà = {0}, where one direction of the first equivalence follows from2.39, the second equiva- lence follows from 3.111, and the third equivalence follows from 3.125. The proof of (a) in the next result does not use the hypothesis that ùëâ and ùëä are finite-dimensional. 3.128 the null space of ùëá‚Ä≤ Suppose ùëâ and ùëä are finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Then (a) null ùëá‚Ä≤ = (range ùëá)0; (b) dim null ùëá‚Ä≤ = dim null ùëá + dim ùëä ‚àí dim ùëâ. Proof (a) First suppose ùúë ‚àà null ùëá‚Ä≤. Thus 0 = ùëá ‚Ä≤(ùúë) = ùúë ‚àò ùëá. Hence 0 = (ùúë ‚àò ùëá)(ùë£) = ùúë(ùëáùë£) for every ùë£ ‚àà ùëâ. Thus ùúë ‚àà (range ùëá) 0. This implies that null ùëá‚Ä≤ ‚äÜ (range ùëá) 0. To prove the inclusion in the opposite direction, now suppose ùúë ‚àà (range ùëá) 0. Thus ùúë(ùëáùë£) = 0for every vector ùë£ ‚àà ùëâ. Hence 0 = ùúë ‚àò ùëá = ùëá ‚Ä≤(ùúë). In other words, ùúë ‚àà null ùëá‚Ä≤, which shows that (range ùëá)0 ‚äÜ null ùëá‚Ä≤, completing the proof of (a). 112 Chapter 3 Linear Maps (b) We have dim null ùëá‚Ä≤ = dim(range ùëá) 0 = dim ùëä ‚àí dim range ùëá = dim ùëä ‚àí (dim ùëâ ‚àí dim null ùëá) = dim null ùëá + dim ùëä ‚àí dim ùëâ, where the first equality comes from (a), the second equality comes from 3.125, and the third equality comes from the fundamental theorem of linear maps (3.21). The next result can be useful because sometimes it is easier to verify that ùëá‚Ä≤ is injective than to show directly that ùëá is surjective. 3.129 ùëá surjective is equivalent to ùëá‚Ä≤ injective Suppose ùëâ and ùëä are finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Then ùëá is surjective ‚ü∫ ùëá‚Ä≤ is injective. Proof We have ùëá ‚àà ‚Ñí(ùëâ, ùëä) is surjective ‚ü∫ range ùëá = ùëä ‚ü∫ (range ùëá) 0 = {0} ‚ü∫ null ùëá‚Ä≤ = {0} ‚ü∫ ùëá‚Ä≤ is injective, where the second equivalence comes from 3.127(a) and the third equivalence comes from 3.128(a). 3.130 the range of ùëá‚Ä≤ Suppose ùëâ and ùëä are finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Then (a) dim range ùëá‚Ä≤ = dim range ùëá; (b) range ùëá‚Ä≤ = (null ùëá)0. Proof (a) We have dim range ùëá‚Ä≤ = dim ùëä‚Ä≤ ‚àí dim null ùëá‚Ä≤ = dim ùëä ‚àí dim(range ùëá) 0 = dim range ùëá, where the first equality comes from3.21, the second equality comes from 3.111 and 3.128(a), and the third equality comes from 3.125. Section 3F Duality 113 (b) First suppose ùúë ‚àà range ùëá‚Ä≤. Thus there exists ùúì ‚àà ùëä‚Ä≤ such that ùúë = ùëá‚Ä≤(ùúì). If ùë£ ‚àà null ùëá, then ùúë(ùë£) = (ùëá‚Ä≤(ùúì))ùë£ = (ùúì ‚àò ùëá)(ùë£) = ùúì(ùëáùë£) = ùúì(0) = 0. Hence ùúë ‚àà (null ùëá)0. This implies that range ùëá‚Ä≤ ‚äÜ (null ùëá)0. We will complete the proof by showing that range ùëá‚Ä≤ and (null ùëá) 0 have the same dimension. To do this, note that dim range ùëá‚Ä≤ = dim range ùëá = dim ùëâ ‚àí dim null ùëá = dim(null ùëá)0, where the first equality comes from (a), the second equality comes from3.21, and the third equality comes from 3.125. The next result should be compared to 3.129. 3.131 ùëá injective is equivalent to ùëá‚Ä≤ surjective Suppose ùëâ and ùëä are finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Then ùëá is injective ‚ü∫ ùëá‚Ä≤ is surjective. Proof We have ùëá is injective ‚ü∫ null ùëá = {0} ‚ü∫ (null ùëá) 0 = ùëâ‚Ä≤ ‚ü∫ range ùëá‚Ä≤ = ùëâ‚Ä≤, where the second equivalence follows from 3.127(b) and the third equivalence follows from 3.130(b). Matrix of Dual of Linear Map The setting for the next result is the assumption that we have a basis ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ, along with its dual basis ùúë1, ‚Ä¶, ùúëùëõ of ùëâ‚Ä≤. We also have a basis ùë§1, ‚Ä¶, ùë§ùëö of ùëä, along with its dual basis ùúì1, ‚Ä¶, ùúìùëö of ùëä‚Ä≤. Thus ‚Ñ≥(ùëá) is computed with respect to the bases just mentioned of ùëâ and ùëä, and ‚Ñ≥(ùëá‚Ä≤)is computed with respect to the dual bases just mentioned of ùëä‚Ä≤ and ùëâ‚Ä≤. Using these bases gives the following pretty result. 3.132 matrix of ùëá‚Ä≤ is transpose of matrix of ùëá Suppose ùëâ and ùëä are finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Then ‚Ñ≥(ùëá‚Ä≤)= (‚Ñ≥(ùëá)) t . 114 Chapter 3 Linear Maps Proof Let ùê¥ = ‚Ñ≥(ùëá) and ùê∂ = ‚Ñ≥(ùëá‚Ä≤). Suppose 1 ‚â§ ùëó ‚â§ ùëöand 1 ‚â§ ùëò ‚â§ ùëõ. From the definition of‚Ñ≥(ùëá‚Ä≤)we have ùëá‚Ä≤(ùúìùëó) = ùëõ ‚àë ùëü = 1 ùê∂ùëü, ùëóùúëùëü. The left side of the equation above equals ùúìùëó ‚àò ùëá. Thus applying both sides of the equation above to ùë£ùëò gives (ùúìùëó ‚àò ùëá)(ùë£ùëò) = ùëõ ‚àë ùëü = 1 ùê∂ùëü, ùëóùúëùëü(ùë£ùëò) = ùê∂ùëò, ùëó. We also have (ùúìùëó ‚àò ùëá)(ùë£ùëò) = ùúìùëó(ùëáùë£ùëò) = ùúìùëó(ùëö ‚àë ùëü = 1 ùê¥ùëü, ùëòùë§ùëü) = ùëö ‚àë ùëü = 1 ùê¥ùëü, ùëòùúìùëó(ùë§ùëü) = ùê¥ùëó, ùëò. Comparing the last line of the last two sets of equations, we have ùê∂ùëò, ùëó = ùê¥ùëó, ùëò. Thus ùê∂ = ùê¥t. In other words, ‚Ñ≥(ùëá‚Ä≤)= (‚Ñ≥(ùëá)) t, as desired. Now we use duality to give an alternative proof that the column rank of a matrix equals the row rank of the matrix. This result was previously proved using different tools‚Äîsee 3.57. 3.133 column rank equals row rank Suppose ùê¥ ‚àà ùêÖùëö, ùëõ. Then the column rank of ùê¥ equals the row rank of ùê¥. Proof Defineùëá‚à∂ ùêÖùëõ, 1 ‚Üí ùêÖùëö, 1 by ùëáùë• = ùê¥ùë•. Thus ‚Ñ≥(ùëá) = ùê¥, where ‚Ñ≥(ùëá) is computed with respect to the standard bases of ùêÖùëõ, 1 and ùêÖùëö, 1. Now column rank of ùê¥ = column rank of ‚Ñ≥(ùëá) = dim range ùëá = dim range ùëá‚Ä≤ = column rank of ‚Ñ≥(ùëá‚Ä≤) = column rank of ùê¥ t = row rank of ùê¥, where the second equality comes from 3.78, the third equality comes from 3.130(a), the fourth equality comes from 3.78, the fifth equality comes from3.132, and the last equality follows from the definitions of row and column rank. See Exercise 8 in Section 7A for another alternative proof of the result above. Section 3F Duality 115 Exercises 3F 1 Explain why each linear functional is surjective or is the zero map. 2 Give three distinct examples of linear functionals on ùêë[0, 1]. 3 Suppose ùëâ is finite-dimensional andùë£ ‚àà ùëâ with ùë£ ‚â† 0. Prove that there exists ùúë ‚àà ùëâ‚Ä≤ such that ùúë(ùë£) = 1. 4 Suppose ùëâ is finite-dimensional andùëà is a subspace of ùëâ such that ùëà ‚â† ùëâ. Prove that there exists ùúë ‚àà ùëâ‚Ä≤ such that ùúë(ùë¢) = 0for every ùë¢ ‚àà ùëà but ùúë ‚â† 0. 5 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùë§1, ‚Ä¶, ùë§ùëö is a basis of range ùëá. Hence for each ùë£ ‚àà ùëâ, there exist unique numbers ùúë1(ùë£), ‚Ä¶, ùúëùëö(ùë£) such that ùëáùë£ = ùúë1(ùë£)ùë§1 + ‚ãØ + ùúëùëö(ùë£)ùë§ùëö, thus defining functionsùúë1, ‚Ä¶, ùúëùëö from ùëâ to ùêÖ. Show that each of the func- tions ùúë1, ‚Ä¶, ùúëùëö is a linear functional on ùëâ. 6 Suppose ùúë, ùõΩ ‚àà ùëâ‚Ä≤. Prove that null ùúë ‚äÜ null ùõΩ if and only if there exists ùëê ‚àà ùêÖ such that ùõΩ = ùëêùúë. 7 Suppose that ùëâ1, ‚Ä¶, ùëâùëö are vector spaces. Prove that (ùëâ1 √ó ‚ãØ √ó ùëâùëö)‚Ä≤ and ùëâ1‚Ä≤ √ó ‚ãØ √ó ùëâùëö‚Ä≤ are isomorphic vector spaces. 8 Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùúë1, ‚Ä¶, ùúëùëõ is the dual basis of ùëâ‚Ä≤. Define Œì‚à∂ ùëâ ‚Üí ùêÖùëõ and Œõ‚à∂ ùêÖùëõ ‚Üí ùëâ by Œì(ùë£) = (ùúë1(ùë£), ‚Ä¶, ùúëùëõ(ùë£)) and Œõ(ùëé1, ‚Ä¶, ùëéùëõ) = ùëé1ùë£1 + ‚ãØ + ùëéùëõùë£ùëõ. Explain why Œì and Œõ are inverses of each other. 9 Suppose ùëö is a positive integer. Show that the dual basis of the basis 1, ùë•, ‚Ä¶, ùë•ùëö of ùí´ùëö(ùêë) is ùúë0, ùúë1, ‚Ä¶, ùúëùëö, where ùúëùëò(ùëù) = ùëù(ùëò)(0) ùëò! . Here ùëù(ùëò)denotes the ùëòth derivative of ùëù, with the understanding that the 0 th derivative of ùëù is ùëù. 10 Suppose ùëö is a positive integer. (a) Show that 1, ùë• ‚àí 5, ‚Ä¶, (ùë• ‚àí 5) ùëö is a basis of ùí´ùëö(ùêë). (b) What is the dual basis of the basis in (a)? 11 Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùúë1, ‚Ä¶, ùúëùëõ is the corresponding dual basis of ùëâ‚Ä≤. Suppose ùúì ‚àà ùëâ‚Ä≤. Prove that ùúì = ùúì(ùë£1)ùúë1 + ‚ãØ + ùúì(ùë£ùëõ)ùúëùëõ. 116 Chapter 3 Linear Maps 12 Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä). (a) Prove that (ùëÜ + ùëá) ‚Ä≤ = ùëÜ‚Ä≤ + ùëá‚Ä≤. (b) Prove that (ùúÜùëá)‚Ä≤ = ùúÜùëá‚Ä≤ for all ùúÜ ‚àà ùêÖ. This exercise asks you to verify (a) and (b) in 3.120. 13 Show that the dual map of the identity operator on ùëâ is the identity operator on ùëâ‚Ä≤. 14 Defineùëá‚à∂ ùêë3 ‚Üí ùêë2 by ùëá(ùë•, ùë¶, ùëß) = (4ùë•+ 5ùë¶+ 6ùëß, 7ùë•+ 8ùë¶+ 9ùëß). Suppose ùúë1, ùúë2 denotes the dual basis of the standard basis of ùêë2 and ùúì1, ùúì2, ùúì3 denotes the dual basis of the standard basis of ùêë3. (a) Describe the linear functionals ùëá‚Ä≤(ùúë1) and ùëá‚Ä≤(ùúë2). (b) Write ùëá‚Ä≤(ùúë1) and ùëá‚Ä≤(ùúë2) as linear combinations of ùúì1, ùúì2, ùúì3. 15 Defineùëá‚à∂ ùí´(ùêë) ‚Üí ùí´(ùêë) by (ùëáùëù)(ùë•) = ùë•2ùëù(ùë•) + ùëù ‚Ä≥(ùë•) for each ùë• ‚àà ùêë. (a) Suppose ùúë ‚àà ùí´(ùêë)‚Ä≤ is defined byùúë(ùëù) = ùëù‚Ä≤(4). Describe the linear functional ùëá‚Ä≤(ùúë) on ùí´(ùêë). (b) Suppose ùúë ‚àà ùí´(ùêë)‚Ä≤ is defined byùúë(ùëù) = ‚à´1 0 ùëù. Evaluate (ùëá‚Ä≤(ùúë))(ùë•3). 16 Suppose ùëä is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that ùëá‚Ä≤ = 0 ‚ü∫ ùëá = 0. 17 Suppose ùëâ and ùëä are finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that ùëá is invertible if and only if ùëá‚Ä≤ ‚àà ‚Ñí(ùëä‚Ä≤, ùëâ‚Ä≤)is invertible. 18 Suppose ùëâ and ùëä are finite-dimensional. Prove that the map that takes ùëá ‚àà ‚Ñí(ùëâ, ùëä) to ùëá‚Ä≤ ‚àà ‚Ñí(ùëä‚Ä≤, ùëâ‚Ä≤)is an isomorphism of ‚Ñí(ùëâ, ùëä) onto ‚Ñí(ùëä‚Ä≤, ùëâ‚Ä≤). 19 Suppose ùëà ‚äÜ ùëâ. Explain why ùëà0 = {ùúë ‚àà ùëâ‚Ä≤ ‚à∂ ùëà ‚äÜnull ùúë}. 20 Suppose ùëâ is finite-dimensional andùëà is a subspace of ùëâ. Show that ùëà = {ùë£ ‚àà ùëâ ‚à∂ ùúë(ùë£) = 0for every ùúë ‚àà ùëà0}. 21 Suppose ùëâ is finite-dimensional andùëà and ùëä are subspaces of ùëâ. (a) Prove that ùëä0 ‚äÜ ùëà 0 if and only if ùëà ‚äÜ ùëä. (b) Prove that ùëä0 = ùëà0 if and only if ùëà = ùëä. Section 3F Duality 117 22 Suppose ùëâ is finite-dimensional andùëà and ùëä are subspaces of ùëâ. (a) Show that (ùëà + ùëä) 0 = ùëà0 ‚à© ùëä 0. (b) Show that (ùëà ‚à© ùëä) 0 = ùëà0 + ùëä0. 23 Suppose ùëâ is finite-dimensional andùúë1, ‚Ä¶, ùúëùëö ‚àà ùëâ‚Ä≤. Prove that the follow- ing three sets are equal to each other. (a) span(ùúë1, ‚Ä¶, ùúëùëö) (b) ((null ùúë1) ‚à© ‚ãØ ‚à© (null ùúëùëö)) 0 (c) {ùúë ‚àà ùëâ‚Ä≤ ‚à∂ (null ùúë1) ‚à© ‚ãØ ‚à© (null ùúëùëö) ‚äÜnull ùúë} 24 Suppose ùëâ is finite-dimensional andùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ. Define a linear map Œì‚à∂ ùëâ‚Ä≤ ‚Üí ùêÖùëö by Œì(ùúë) = (ùúë(ùë£1), ‚Ä¶, ùúë(ùë£ùëö)). (a) Prove that ùë£1, ‚Ä¶, ùë£ùëö spans ùëâ if and only if Œì is injective. (b) Prove that ùë£1, ‚Ä¶, ùë£ùëö is linearly independent if and only if Œì is surjective. 25 Suppose ùëâ is finite-dimensional andùúë1, ‚Ä¶, ùúëùëö ‚àà ùëâ‚Ä≤. Define a linear map Œì‚à∂ ùëâ ‚Üí ùêÖùëö by Œì(ùë£) = (ùúë1(ùë£), ‚Ä¶, ùúëùëö(ùë£)). (a) Prove that ùúë1, ‚Ä¶, ùúëùëö spans ùëâ‚Ä≤ if and only if Œì is injective. (b) Prove that ùúë1, ‚Ä¶, ùúëùëö is linearly independent if and only if Œì is surjective. 26 Suppose ùëâ is finite-dimensional andŒ© is a subspace of ùëâ‚Ä≤. Prove that Œ© = {ùë£ ‚àà ùëâ ‚à∂ ùúë(ùë£) = 0for every ùúë ‚àà Œ©} 0 . 27 Suppose ùëá ‚àà ‚Ñí(ùí´5(ùêë))and null ùëá‚Ä≤ = span(ùúë), where ùúë is the linear functional on ùí´5(ùêë) defined byùúë(ùëù) = ùëù(8). Prove that range ùëá = {ùëù ‚àà ùí´5(ùêë) ‚à∂ ùëù(8) = 0}. 28 Suppose ùëâ is finite-dimensional andùúë1, ‚Ä¶, ùúëùëö is a linearly independent list in ùëâ‚Ä≤. Prove that dim((null ùúë1) ‚à© ‚ãØ ‚à© (null ùúëùëö))= (dim ùëâ) ‚àí ùëö. 29 Suppose ùëâ and ùëä are finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). (a) Prove that if ùúë ‚àà ùëä‚Ä≤ and null ùëá‚Ä≤ = span(ùúë), then range ùëá = null ùúë. (b) Prove that if ùúì ‚àà ùëâ‚Ä≤ and range ùëá‚Ä≤ = span(ùúì), then null ùëá = null ùúì. 30 Suppose ùëâ is finite-dimensional andùúë1, ‚Ä¶, ùúëùëõ is a basis of ùëâ‚Ä≤. Show that there exists a basis of ùëâ whose dual basis is ùúë1, ‚Ä¶, ùúëùëõ. 31 Suppose ùëà is a subspace of ùëâ. Let ùëñ‚à∂ ùëà ‚Üí ùëâ be the inclusion map defined by ùëñ(ùë¢) = ùë¢. Thus ùëñ‚Ä≤ ‚àà ‚Ñí(ùëâ‚Ä≤, ùëà‚Ä≤). (a) Show that null ùëñ‚Ä≤ = ùëà0. (b) Prove that if ùëâ is finite-dimensional, thenrange ùëñ‚Ä≤ = ùëà‚Ä≤. (c) Prove that if ùëâ is finite-dimensional, then ÃÉùëñ‚Ä≤ is an isomorphism from ùëâ‚Ä≤/ùëà0 onto ùëà‚Ä≤. The isomorphism in (c) is natural in that it does not depend on a choice of basis in either vector space. 118 Chapter 3 Linear Maps 32 The double dual space of ùëâ, denoted by ùëâ‚Ä≥, is defined to be the dual space of ùëâ‚Ä≤. In other words, ùëâ‚Ä≥ = (ùëâ‚Ä≤) ‚Ä≤. DefineŒõ‚à∂ ùëâ ‚Üí ùëâ‚Ä≥ by (Œõùë£)(ùúë) = ùúë(ùë£) for each ùë£ ‚àà ùëâ and each ùúë ‚àà ùëâ‚Ä≤. (a) Show that Œõ is a linear map from ùëâ to ùëâ‚Ä≥. (b) Show that if ùëá ‚àà ‚Ñí(ùëâ), then ùëá‚Ä≥ ‚àò Œõ = Œõ ‚àò ùëá, where ùëá‚Ä≥ = (ùëá‚Ä≤) ‚Ä≤. (c) Show that if ùëâ is finite-dimensional, thenŒõ is an isomorphism from ùëâ onto ùëâ‚Ä≥. Suppose ùëâ is finite-dimensional. Then ùëâ and ùëâ‚Ä≤ are isomorphic, but finding an isomorphism from ùëâ onto ùëâ‚Ä≤ generally requires choosing a basis of ùëâ. In contrast, the isomorphism Œõ from ùëâ onto ùëâ‚Ä≥ does not require a choice of basis and thus is considered more natural. 33 Suppose ùëà is a subspace of ùëâ. Let ùúã‚à∂ ùëâ ‚Üí ùëâ/ùëà be the usual quotient map. Thus ùúã‚Ä≤ ‚àà ‚Ñí((ùëâ/ùëà) ‚Ä≤, ùëâ‚Ä≤). (a) Show that ùúã‚Ä≤ is injective. (b) Show that range ùúã‚Ä≤ = ùëà0. (c) Conclude that ùúã‚Ä≤ is an isomorphism from (ùëâ/ùëà) ‚Ä≤ onto ùëà0. The isomorphism in (c) is natural in that it does not depend on a choice of basis in either vector space. In fact, there is no assumption here that any of these vector spaces are finite-dimensional. Chapter 4 Polynomials This chapter contains material on polynomials that we will use to investigate linear maps from a vector space to itself. Many results in this chapter will already be familiar to you from other courses; they are included here for completeness. Because this chapter is not about linear algebra, your instructor may go through it rapidly. You may not be asked to scrutinize all the proofs. Make sure, however, that you at least read and understand the statements of all results in this chapter‚Äî they will be used in later chapters. This chapter begins with a brief discussion of algebraic properties of the complex numbers. Then we prove that a nonconstant polynomial cannot have more zeros than its degree. We also give a linear-algebra-based proof of the division algorithm for polynomials, which is worth reading even if you are already familiar with a proof that does not use linear algebra. As we will see, the fundamental theorem of algebra leads to a factorization of every polynomial into degree-one factors if the scalar field isùêÇ or to factors of degree at most two if the scalar field isùêë. standing assumption for this chapter ‚Ä¢ ùêÖ denotes ùêë or ùêÇ.AlirezaJavaheriCCBY Statue of mathematician and poet Omar Khayyam (1048‚Äì1131), whose algebra book written in 1070 contained the first serious study of cubic polynomials. 119 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0_4 ¬© Sheldon Axler 2024 120 Chapter 4 Polynomials Before discussing polynomials with complex or real coefficients, we need to learn a bit more about the complex numbers. 4.1 definition: real part, Re ùëß, imaginary part, Im ùëß Suppose ùëß = ùëé + ùëèùëñ, where ùëé and ùëè are real numbers. ‚Ä¢ The real part of ùëß, denoted by Re ùëß, is defined byRe ùëß = ùëé. ‚Ä¢ The imaginary part of ùëß, denoted by Im ùëß, is defined byIm ùëß = ùëè. Thus for every complex number ùëß, we have ùëß = Re ùëß + (Im ùëß)ùëñ. 4.2 definition: complex conjugate, ùëß, absolute value, |ùëß| Suppose ùëß ‚àà ùêÇ. ‚Ä¢ The complex conjugate of ùëß ‚àà ùêÇ, denoted by ùëß, is defined by ùëß = Re ùëß ‚àí (Im ùëß)ùëñ. ‚Ä¢ The absolute value of a complex number ùëß, denoted by |ùëß|, is defined by |ùëß| = ‚àö(Re ùëß)2 + (Im ùëß)2. 4.3 example: real and imaginary part, complex conjugate, absolute value Suppose ùëß = 3+ 2ùëñ. Then ‚Ä¢ Re ùëß = 3and Im ùëß = 2; ‚Ä¢ ùëß = 3 ‚àí 2ùëñ; ‚Ä¢ |ùëß| = ‚àö32 + 22 = ‚àö13. Identifying a complex number ùëß ‚àà ùêÇ with the ordered pair (Re ùëß, Im ùëß) ‚àà ùêë2 identifiesùêÇ with ùêë2. Note that ùêÇ is a one-dimensional complex vector space, but we can also think of ùêÇ (identified withùêë2) as a two-dimensional real vector space. The absolute value of each complex number is a nonnegative number. Specif- ically, if ùëß ‚àà ùêÇ, then |ùëß| equals the distance from the origin in ùêë2 to the point (Re ùëß, Im ùëß) ‚àà ùêë2. You should verify that ùëß = ùëß if and only if ùëß is a real number. The real and imaginary parts, com- plex conjugate, and absolute value have the properties listed in the following multipart result. Chapter 4 Polynomials 121 4.4 properties of complex numbers Suppose ùë§, ùëß ‚àà ùêÇ. Then the following equalities and inequalities hold. sum of ùëß and ùëß ùëß + ùëß = 2Re ùëß. difference of ùëß and ùëß ùëß ‚àí ùëß = 2(Im ùëß)ùëñ. product of ùëß and ùëß ùëßùëß = |ùëß|2. additivity and multiplicativity of complex conjugate ùë§ + ùëß = ùë§ + ùëß and ùë§ùëß = ùë§ ùëß. double complex conjugate ùëß = ùëß. real and imaginary parts are bounded by |ùëß| | Re ùëß| ‚â§ |ùëß|and | Im ùëß| ‚â§ |ùëß|. absolute value of the complex conjugate ‚à£ùëß‚à£ = |ùëß|. multiplicativity of absolute value |ùë§ùëß| = |ùë§| |ùëß|. triangle inequality |ùë§ + ùëß| ‚â§ |ùë§|+ |ùëß|. Geometric interpretation of triangle in- equality: The length of each side of a triangle is less than or equal to the sum of the lengths of the two other sides. Proof Except for the last item above, the routine verifications of the assertions above are left to the reader. To verify the triangle inequality, we have |ùë§ + ùëß|2 = (ùë§ + ùëß)(ùë§ + ùëß) = ùë§ùë§ + ùëßùëß + ùë§ùëß + ùëßùë§ = |ùë§|2 + |ùëß|2 + ùë§ùëß + ùë§ùëß = |ùë§|2 + |ùëß|2 + 2Re(ùë§ùëß) ‚â§ |ùë§| 2 + |ùëß| 2 + 2‚à£ùë§ùëß‚à£ = |ùë§|2 + |ùëß|2 + 2|ùë§| |ùëß| = (|ùë§| + |ùëß|) 2. See Exercise 2 for the reverse triangle inequality. Taking square roots now gives the desired inequality |ùë§ + ùëß| ‚â§ |ùë§|+ |ùëß|. 122 Chapter 4 Polynomials Zeros of Polynomials Recall that a function ùëù‚à∂ ùêÖ ‚Üí ùêÖ is called a polynomial of degree ùëö if there exist ùëé0, ‚Ä¶, ùëéùëö ‚àà ùêÖ with ùëéùëö ‚â† 0such that ùëù(ùëß) = ùëé0 + ùëé1ùëß + ‚ãØ + ùëéùëöùëß ùëö for all ùëß ‚àà ùêÖ. A polynomial could have more than one degree if the representation of ùëù in the form above were not unique. Our first task is to show that this cannot happen. The solutions to the equation ùëù(ùëß) = 0play a crucial role in the study of a polynomial ùëù ‚àà ùí´(ùêÖ). Thus these solutions have a special name. 4.5 definition: zero of a polynomial A number ùúÜ ‚àà ùêÖ is called a zero (or root) of a polynomial ùëù ‚àà ùí´(ùêÖ) if ùëù(ùúÜ) = 0. The next result is the key tool that we will use to show that the degree of a polynomial is unique. 4.6 each zero of a polynomial corresponds to a degree-one factor Suppose ùëö is a positive integer and ùëù ‚àà ùí´(ùêÖ) is a polynomial of degree ùëö. Suppose ùúÜ ‚àà ùêÖ. Then ùëù(ùúÜ) = 0if and only if there exists a polynomial ùëû ‚àà ùí´(ùêÖ) of degree ùëö ‚àí 1such that ùëù(ùëß) = (ùëß ‚àí ùúÜ)ùëû(ùëß) for every ùëß ‚àà ùêÖ. Proof First suppose ùëù(ùúÜ) = 0. Let ùëé0, ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ be such that ùëù(ùëß) = ùëé0 + ùëé1ùëß + ‚ãØ + ùëéùëöùëß ùëö for all ùëß ‚àà ùêÖ. Then 4.7 ùëù(ùëß) = ùëù(ùëß) ‚àí ùëù(ùúÜ) = ùëé1(ùëß ‚àí ùúÜ) + ‚ãØ + ùëéùëö(ùëßùëö ‚àí ùúÜùëö) for all ùëß ‚àà ùêÖ. For each ùëò ‚àà {1, ‚Ä¶, ùëö}, the equation ùëß ùëò ‚àí ùúÜùëò = (ùëß ‚àí ùúÜ) ùëò ‚àë ùëó = 1 ùúÜùëó ‚àí 1ùëßùëò ‚àí ùëó shows that ùëßùëò ‚àí ùúÜùëò equals ùëß ‚àí ùúÜ times some polynomial of degree ùëò ‚àí 1. Thus 4.7 shows that ùëù equals ùëß ‚àí ùúÜ times some polynomial of degree ùëö ‚àí 1, as desired. To prove the implication in the other direction, now suppose that there is a polynomial ùëû ‚àà ùí´(ùêÖ) such that ùëù(ùëß) = (ùëß ‚àí ùúÜ)ùëû(ùëß) for every ùëß ‚àà ùêÖ. Then ùëù(ùúÜ) = (ùúÜ ‚àí ùúÜ)ùëû(ùúÜ) = 0, as desired. Chapter 4 Polynomials 123 Now we can prove that polynomials do not have too many zeros. 4.8 degree ùëö implies at most ùëö zeros Suppose ùëö is a positive integer and ùëù ‚àà ùí´(ùêÖ) is a polynomial of degree ùëö. Then ùëù has at most ùëö zeros in ùêÖ. Proof We will use induction on ùëö. The desired result holds if ùëö = 1because if ùëé1 ‚â† 0then the polynomial ùëé0 + ùëé1ùëß has only one zero (which equals ‚àíùëé0/ùëé1). Thus assume that ùëö > 1and the desired result holds for ùëö ‚àí 1. If ùëù has no zeros in ùêÖ, then the desired result holds and we are done. Thus suppose ùëù has a zero ùúÜ ‚àà ùêÖ. By 4.6, there is polynomial ùëû ‚àà ùí´(ùêÖ) of degree ùëö ‚àí 1such that ùëù(ùëß) = (ùëß ‚àí ùúÜ)ùëû(ùëß) for every ùëß ‚àà ùêÖ. Our induction hypothesis implies that ùëû has at most ùëö ‚àí 1zeros in ùêÖ. The equation above shows that the zeros of ùëù in ùêÖ are exactly the zeros of ùëû in ùêÖ along with ùúÜ. Thus ùëù has at most ùëö zeros in ùêÖ. The result above implies that the coefficients of a polynomial are uniquely determined (because if a polynomial had two different sets of coefficients, then subtracting the two representations of the polynomial would give a polynomial with some nonzero coefficients but infinitely many zeros). In particular, the degree of a polynomial is uniquely defined. The 0polynomial is declared to have degree ‚àí‚àû so that exceptions are not needed for various reasonable results such as deg(ùëùùëû) = deg ùëù + deg ùëû. Recall that the degree of the 0poly- nomial is defined to be‚àí‚àû. When necessary, use the expected arithmetic with ‚àí‚àû. For example, ‚àí‚àû < ùëö and ‚àí‚àû + ùëö = ‚àí‚àû for every integer ùëö. Division Algorithm for Polynomials If ùëù and ùë† are nonnegative integers, with ùë† ‚â† 0, then there exist nonnegative integers ùëû and ùëü such that ùëù = ùë†ùëû + ùëü and ùëü < ùë†. Think of dividing ùëù by ùë†, getting quotient ùëû with remainder ùëü. Our next result gives an analogous result for polynomials. Thus the next result is often called the division algorithm for polynomials, although as stated here it is not really an algorithm, just a useful result. Think of the division algorithm for poly- nomials as giving a remainder polyno- mial ùëü when the polynomial ùëù is divided by the polynomial ùë†. The division algorithm for polynomi- als could be proved without using any linear algebra. However, as is appropri- ate for a linear algebra textbook, the proof given here uses linear algebra techniques and makes nice use of a basis of ùí´ùëõ(ùêÖ), which is the (ùëõ + 1)-dimensional vector space of polynomials with coefficients in ùêÖ and of degree at most ùëõ. 124 Chapter 4 Polynomials 4.9 division algorithm for polynomials Suppose that ùëù, ùë† ‚àà ùí´(ùêÖ), with ùë† ‚â† 0. Then there exist unique polynomials ùëû, ùëü ‚àà ùí´(ùêÖ) such that ùëù = ùë†ùëû + ùëü and deg ùëü < deg ùë†. Proof Let ùëõ = deg ùëù and let ùëö = deg ùë†. If ùëõ < ùëö, then take ùëû = 0and ùëü = ùëù to get the desired equation ùëù = ùë†ùëû + ùëü with deg ùëü < deg ùë†. Thus we now assume that ùëõ ‚â• ùëö. The list 4.10 1, ùëß, ‚Ä¶, ùëß ùëö ‚àí 1, ùë†, ùëßùë†, ‚Ä¶, ùëß ùëõ ‚àí ùëöùë† is linearly independent in ùí´ùëõ(ùêÖ) because each polynomial in this list has a different degree. Also, the list 4.10 has length ùëõ + 1, which equals dim ùí´ùëõ(ùêÖ). Hence 4.10 is a basis of ùí´ùëõ(ùêÖ) [by2.38]. Because ùëù ‚àà ùí´ùëõ(ùêÖ) and 4.10 is a basis of ùí´ùëõ(ùêÖ), there exist unique constants ùëé0, ùëé1, ‚Ä¶, ùëéùëö ‚àí 1 ‚àà ùêÖ and ùëè0, ùëè1, ‚Ä¶, ùëèùëõ ‚àí ùëö ‚àà ùêÖ such that ùëù = ùëé0 + ùëé1ùëß + ‚ãØ + ùëéùëö ‚àí 1ùëß ùëö ‚àí 1 + ùëè0ùë† + ùëè1ùëßùë† + ‚ãØ + ùëèùëõ ‚àí ùëöùëßùëõ ‚àí ùëöùë†4.11 = ùëé0 + ùëé1ùëß + ‚ãØ + ùëéùëö ‚àí 1ùëßùëö ‚àí 1‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü ùëü + ùë†(ùëè0 + ùëè1ùëß + ‚ãØ + ùëèùëõ ‚àí ùëöùëßùëõ ‚àí ùëö‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü ùëû ). With ùëü and ùëû as defined above, we see thatùëù can be written as ùëù = ùë†ùëû + ùëü with deg ùëü < deg ùë†, as desired. The uniqueness of ùëû, ùëü ‚àà ùí´(ùêÖ) satisfying these conditions follows from the uniqueness of the constants ùëé0, ùëé1, ‚Ä¶, ùëéùëö ‚àí 1 ‚àà ùêÖ and ùëè0, ùëè1, ‚Ä¶, ùëèùëõ ‚àí ùëö ‚àà ùêÖ satisfy- ing 4.11. Factorization of Polynomials over ùêÇ The fundamental theorem of algebra is an existence theorem. Its proof does not lead to a method for finding zeros. The quadratic formula gives the zeros explicitly for polynomials of degree 2. Similar but more complicated formulas exist for polynomials of degree 3and 4. No such formulas exist for polynomials of degree 5and above. W have been handling polynomials with complex coefficients and polynomials with real coefficients simultaneously, let- ting ùêÖ denote ùêë or ùêÇ. Now we will see differences between these two cases. First we treat polynomials with complex coefficients. Then we will use those re- sults to prove corresponding results for polynomials with real coefficients. Our proof of the fundamental theorem of algebra implicitly uses the result that a continuous real-valued function on a closed disk in ùêë2 attains a minimum value. A web search can lead you to several Chapter 4 Polynomials 125 other proofs of the fundamental theorem of algebra. The proof using Liouville‚Äôs theorem is particularly nice if you are comfortable with analytic functions. All proofs of the fundamental theorem of algebra need to use some analysis, because the result is not true if ùêÇ is replaced, for example, with the set of numbers of the form ùëê + ùëëùëñ where ùëê, ùëë are rational numbers. 4.12 fundamental theorem of algebra, first version Every nonconstant polynomial with complex coefficients has a zero in ùêÇ. Proof De Moivre‚Äôs theorem, which you can prove using induction on ùëò and the addition formulas for cosine and sine, states that if ùëò is a positive integer and ùúÉ ‚àà ùêë, then (cos ùúÉ + ùëñ sin ùúÉ) ùëò = cos ùëòùúÉ + ùëñ sin ùëòùúÉ. Suppose ùë§ ‚àà ùêÇ and ùëò is a positive integer. Using polar coordinates, we know that there exist ùëü ‚â• 0and ùúÉ ‚àà ùêë such that ùëü(cos ùúÉ + ùëñ sin ùúÉ) = ùë§. De Moivre‚Äôs theorem implies that (ùëü1/ùëò(cos ùúÉ ùëò + ùëñ sin ùúÉ ùëò )) ùëò = ùë§. Thus every complex number has a ùëòth root, a fact that we will soon use. Suppose ùëù is a nonconstant polynomial with complex coefficients and highest- order nonzero term ùëêùëöùëßùëö. Then |ùëù(ùëß)| ‚Üí ‚àû as |ùëß| ‚Üí ‚àû (because |ùëù(ùëß)|/‚à£ùëß ùëö‚à£ ‚Üí |ùëêùëö| as |ùëß| ‚Üí ‚àû). Thus the continuous function ùëß ‚Ü¶ |ùëù(ùëß)| has a global minimum at some point ùúÅ ‚àà ùêÇ. To show that ùëù(ùúÅ ) = 0, suppose that ùëù(ùúÅ ) ‚â† 0. Define a new polynomialùëû by ùëû(ùëß) = ùëù(ùëß + ùúÅ ) ùëù(ùúÅ ) . The function ùëß ‚Ü¶ |ùëû(ùëß)| has a global minimum value of 1at ùëß = 0. Write ùëû(ùëß) = 1+ ùëéùëòùëßùëò + ‚ãØ + ùëéùëöùëß ùëö, where ùëò is the smallest positive integer such that the coefficient of ùëß ùëò is nonzero; in other words, ùëéùëò ‚â† 0. Let ùõΩ ‚àà ùêÇ be such that ùõΩùëò = ‚àí 1 ùëéùëò . There is a constant ùëê > 1such that if ùë° ‚àà (0, 1), then |ùëû(ùë°ùõΩ)| ‚â§‚à£1+ ùëéùëòùë°ùëòùõΩùëò‚à£ + ùë°ùëò + 1ùëê = 1 ‚àí ùë° ùëò(1 ‚àí ùë°ùëê). Thus taking ùë° to be 1/(2ùëê)in the inequality above, we have |ùëû(ùë°ùõΩ)| < 1, which contradicts the assumption that the global minimum of ùëß ‚Ü¶ |ùëû(ùëß)| is 1. This contradiction implies that ùëù(ùúÅ ) = 0, showing that ùëù has a zero, as desired. 126 Chapter 4 Polynomials Computers can use clever numerical methods to find good approximations to the zeros of any polynomial, even when exact zeros cannot be found. For example, no one will ever give an exact formula for a zero of the polynomial ùëù defined by ùëù(ùë•) = ùë•5 ‚àí 5ùë• 4 ‚àí 6ùë• 3 + 17ùë• 2 + 4ùë• ‚àí 7. However, a computer can find that the zeros ofùëù are approximately the five numbers ‚àí1.87, ‚àí0.74, 0.62, 1.47, 5.51. The first version of the fundamental theorem of algebra leads to the following factorization result for polynomials with complex coefficients. Note that in this factorization, the zeros of ùëù are the numbers ùúÜ1, ‚Ä¶, ùúÜùëö, which are the only values of ùëß for which the right side of the equation in the next result equals 0. 4.13 fundamental theorem of algebra, second version If ùëù ‚àà ùí´(ùêÇ) is a nonconstant polynomial, then ùëù has a unique factorization (except for the order of the factors) of the form ùëù(ùëß) = ùëê(ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö), where ùëê, ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÇ. Proof Let ùëù ‚àà ùí´(ùêÇ) and let ùëö = deg ùëù. We will use induction on ùëö. If ùëö = 1, then the desired factorization exists and is unique. So assume that ùëö > 1and that the desired factorization exists and is unique for all polynomials of degree ùëö ‚àí 1. First we will show that the desired factorization of ùëù exists. By the first version of the fundamental theorem of algebra (4.12), ùëù has a zero ùúÜ ‚àà ùêÇ. By 4.6, there is a polynomial ùëû of degree ùëö ‚àí 1such that ùëù(ùëß) = (ùëß ‚àí ùúÜ)ùëû(ùëß) for all ùëß ‚àà ùêÇ. Our induction hypothesis implies that ùëû has the desired factorization, which when plugged into the equation above gives the desired factorization of ùëù. Now we turn to the question of uniqueness. The number ùëê is uniquely deter- mined as the coefficient of ùëß ùëö in ùëù. So we only need to show that except for the order, there is only one way to choose ùúÜ1, ‚Ä¶, ùúÜùëö. If (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö) = (ùëß ‚àí ùúè1)‚ãØ(ùëß ‚àí ùúèùëö) for all ùëß ‚àà ùêÇ, then because the left side of the equation above equals 0when ùëß = ùúÜ1, one of the ùúè‚Äôs on the right side equals ùúÜ1. Relabeling, we can assume that ùúè1 = ùúÜ1. Now if ùëß ‚â† ùúÜ1, we can divide both sides of the equation above by ùëß ‚àí ùúÜ1, getting (ùëß ‚àí ùúÜ2)‚ãØ(ùëß ‚àí ùúÜùëö) = (ùëß ‚àí ùúè2)‚ãØ(ùëß ‚àí ùúèùëö) for all ùëß ‚àà ùêÇ except possibly ùëß = ùúÜ1. Actually the equation above holds for all ùëß ‚àà ùêÇ, because otherwise by subtracting the right side from the left side we would get a nonzero polynomial that has infinitely many zeros. The equation above and our induction hypothesis imply that except for the order, the ùúÜ‚Äôs are the same as the ùúè‚Äôs, completing the proof of uniqueness. Chapter 4 Polynomials 127 Factorization of Polynomials over ùêë The failure of the fundamental theorem of algebra for ùêë accounts for the differ- ences between linear algebra on real and complex vector spaces, as we will see in later chapters. A polynomial with real coefficients may have no real zeros. For example, the poly- nomial 1+ ùë•2 has no real zeros. To obtain a factorization theorem over ùêë, we will use our factorization theorem over ùêÇ. We begin with the next result. 4.14 polynomials with real coefficients have nonreal zeros in pairs Suppose ùëù ‚àà ùí´(ùêÇ) is a polynomial with real coefficients. If ùúÜ ‚àà ùêÇ is a zero of ùëù, then so is ùúÜ. Proof Let ùëù(ùëß) = ùëé0 + ùëé1ùëß + ‚ãØ + ùëéùëöùëß ùëö, where ùëé0, ‚Ä¶, ùëéùëö are real numbers. Suppose ùúÜ ‚àà ùêÇ is a zero of ùëù. Then ùëé0 + ùëé1 ùúÜ + ‚ãØ + ùëéùëö ùúÜ ùëö = 0. Take the complex conjugate of both sides of this equation, obtaining ùëé0 + ùëé1 ùúÜ + ‚ãØ + ùëéùëö ùúÜùëö = 0, where we have used basic properties of the complex conjugate (see 4.4). The equation above shows that ùúÜ is a zero of ùëù. Think about the quadratic formula in connection with the result below. We want a factorization theorem for polynomials with real coefficients. We begin with the following result. 4.15 factorization of a quadratic polynomial Suppose ùëè, ùëê ‚àà ùêë. Then there is a polynomial factorization of the form ùë•2 + ùëèùë• + ùëê = (ùë• ‚àí ùúÜ1)(ùë• ‚àí ùúÜ2) with ùúÜ1, ùúÜ2 ‚àà ùêë if and only if ùëè 2 ‚â• 4ùëê. Proof Notice that ùë•2 + ùëèùë• + ùëê = (ùë• + ùëè 2 ) 2 + (ùëê ‚àí ùëè 2 4 ). The equation above is the basis of the technique called completing the square. First suppose ùëè2 < 4ùëê. Then the right side of the equation above is positive for every ùë• ‚àà ùêë. Hence the polynomial ùë•2 + ùëèùë• + ùëê has no real zeros and thus cannot be factored in the form (ùë• ‚àí ùúÜ1)(ùë• ‚àí ùúÜ2) with ùúÜ1, ùúÜ2 ‚àà ùêë. 128 Chapter 4 Polynomials Conversely, now suppose ùëè 2 ‚â• 4ùëê. Then there is a real number ùëë such that ùëë2 = ùëè2 4 ‚àí ùëê. From the displayed equation above, we have ùë•2 + ùëèùë• + ùëê = (ùë• + ùëè 2 ) 2 ‚àí ùëë2 = (ùë• + ùëè 2 + ùëë)(ùë• + ùëè 2 ‚àí ùëë), which gives the desired factorization. The next result gives a factorization of a polynomial over ùêë. The idea of the proof is to use the second version of the fundamental theorem of algebra (4.13), which gives a factorization of ùëù as a polynomial with complex coefficients. Complex but nonreal zeros of ùëù come in pairs; see 4.14. Thus if the factorization of ùëù as an element of ùí´(ùêÇ) includes terms of the form (ùë• ‚àí ùúÜ) with ùúÜ a nonreal complex number, then (ùë• ‚àí ùúÜ) is also a term in the factorization. Multiplying together these two terms, we get (ùë•2 ‚àí 2(Re ùúÜ)ùë• + |ùúÜ|2), which is a quadratic term of the required form. The idea sketched in the paragraph above almost provides a proof of the existence of our desired factorization. However, we need to be careful about one point. Suppose ùúÜ is a nonreal complex number and (ùë• ‚àí ùúÜ) is a term in the factorization of ùëù as an element of ùí´(ùêÇ). We are guaranteed by 4.14 that (ùë• ‚àí ùúÜ) also appears as a term in the factorization, but 4.14 does not state that these two factors appear the same number of times, as needed to make the idea above work. However, the proof works around this point. In the next result, either ùëö or ùëÄ may equal 0. The numbers ùúÜ1, ‚Ä¶, ùúÜùëö are precisely the real zeros of ùëù, for these are the only real values of ùë• for which the right side of the equation in the next result equals 0. 4.16 factorization of a polynomial over ùêë Suppose ùëù ‚àà ùí´(ùêë) is a nonconstant polynomial. Then ùëù has a unique factor- ization (except for the order of the factors) of the form ùëù(ùë•) = ùëê(ùë• ‚àí ùúÜ1)‚ãØ(ùë• ‚àí ùúÜùëö)(ùë•2 + ùëè1ùë• + ùëê1)‚ãØ(ùë•2 + ùëèùëÄùë• + ùëêùëÄ), where ùëê, ùúÜ1, ‚Ä¶, ùúÜùëö, ùëè1, ‚Ä¶, ùëèùëÄ, ùëê1, ‚Ä¶, ùëêùëÄ ‚àà ùêë, with ùëèùëò 2 < 4ùëêùëò for each ùëò. Proof First we will prove that the desired factorization exists, and after that we will prove the uniqueness. Think of ùëù as an element of ùí´(ùêÇ). If all (complex) zeros of ùëù are real, then we have the desired factorization by 4.13. Thus suppose ùëù has a zero ùúÜ ‚àà ùêÇ with ùúÜ ‚àâ ùêë. By 4.14, ùúÜ is a zero of ùëù. Thus we can write Chapter 4 Polynomials 129 ùëù(ùë•) = (ùë• ‚àí ùúÜ)(ùë• ‚àí ùúÜ)ùëû(ùë•) = (ùë•2 ‚àí 2(Re ùúÜ)ùë• + |ùúÜ|2)ùëû(ùë•) for some polynomial ùëû ‚àà ùí´(ùêÇ) of degree two less than the degree of ùëù. If we can prove that ùëû has real coefficients, then using induction on the degree of ùëù completes the proof of the existence part of this result. To prove that ùëû has real coefficients, we solve the equation above for ùëû, getting ùëû(ùë•) = ùëù(ùë•) ùë•2 ‚àí 2(Re ùúÜ)ùë• + |ùúÜ|2 for all ùë• ‚àà ùêë. The equation above implies that ùëû(ùë•) ‚àà ùêë for all ùë• ‚àà ùêë. Writing ùëû(ùë•) = ùëé0 + ùëé1ùë• + ‚ãØ + ùëéùëõ ‚àí 2ùë•ùëõ ‚àí 2, where ùëõ = deg ùëù and ùëé0, ‚Ä¶, ùëéùëõ ‚àí 2 ‚àà ùêÇ, we thus have 0 =Im ùëû(ùë•) = (Im ùëé0) + (Im ùëé1)ùë• + ‚ãØ + (Im ùëéùëõ ‚àí 2)ùë•ùëõ ‚àí 2 for all ùë• ‚àà ùêë. This implies that Im ùëé0, ‚Ä¶, Im ùëéùëõ ‚àí 2 all equal 0(by 4.8). Thus all coefficients of ùëû are real, as desired. Hence the desired factorization exists. Now we turn to the question of uniqueness of our factorization. A factor of ùëù of the form ùë•2 + ùëèùëòùë•+ ùëêùëò with ùëèùëò 2 < 4ùëêùëò can be uniquely written as (ùë• ‚àí ùúÜùëò)(ùë• ‚àí ùúÜùëò) with ùúÜùëò ‚àà ùêÇ. A moment‚Äôs thought shows that two different factorizations of ùëù as an element of ùí´(ùêë) would lead to two different factorizations of ùëù as an element of ùí´(ùêÇ), contradicting 4.13. Exercises 4 1 Suppose ùë§, ùëß ‚àà ùêÇ. Verify the following equalities and inequalities. (a) ùëß + ùëß = 2Re ùëß (b) ùëß ‚àí ùëß = 2(Im ùëß)ùëñ (c) ùëßùëß = |ùëß|2 (d) ùë§ + ùëß = ùë§ + ùëß and ùë§ùëß = ùë§ ùëß (e) ùëß = ùëß (f) | Re ùëß| ‚â§ |ùëß|and | Im ùëß| ‚â§ |ùëß| (g) ‚à£ùëß‚à£ = |ùëß| (h) |ùë§ùëß| = |ùë§| |ùëß| The results above are the parts of 4.4 that were left to the reader. 2 Prove that if ùë§, ùëß ‚àà ùêÇ, then ‚à£ |ùë§| ‚àí |ùëß| ‚à£ ‚â§ |ùë§ ‚àí ùëß|. The inequality above is called the reverse triangle inequality. 130 Chapter 4 Polynomials 3 Suppose ùëâ is a complex vector space and ùúë ‚àà ùëâ‚Ä≤. Defineùúé‚à∂ ùëâ ‚Üí ùêë by ùúé(ùë£) = Re ùúë(ùë£) for each ùë£ ‚àà ùëâ. Show that ùúë(ùë£) = ùúé(ùë£) ‚àí ùëñùúé(ùëñùë£) for all ùë£ ‚àà ùëâ. 4 Suppose ùëö is a positive integer. Is the set {0} ‚à™{ùëù ‚àà ùí´(ùêÖ) ‚à∂ deg ùëù = ùëö} a subspace of ùí´(ùêÖ)? 5 Is the set {0} ‚à™{ùëù ‚àà ùí´(ùêÖ) ‚à∂ deg ùëù is even} a subspace of ùí´(ùêÖ)? 6 Suppose that ùëö and ùëõ are positive integers with ùëö ‚â§ ùëõ, and suppose ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÖ. Prove that there exists a polynomial ùëù ‚àà ùí´(ùêÖ) with deg ùëù = ùëõ such that 0 = ùëù(ùúÜ1) = ‚ãØ = ùëù(ùúÜùëö) and such that ùëù has no other zeros. 7 Suppose that ùëö is a nonnegative integer, ùëß1, ‚Ä¶, ùëßùëö + 1 are distinct elements of ùêÖ, and ùë§1, ‚Ä¶, ùë§ùëö + 1 ‚àà ùêÖ. Prove that there exists a unique polynomial ùëù ‚àà ùí´ùëö(ùêÖ) such that ùëù(ùëßùëò) = ùë§ùëò for each ùëò = 1, ‚Ä¶, ùëö + 1. This result can be proved without using linear algebra. However, try to find the clearer, shorter proof that uses some linear algebra. 8 Suppose ùëù ‚àà ùí´(ùêÇ) has degree ùëö. Prove that ùëù has ùëö distinct zeros if and only if ùëù and its derivative ùëù ‚Ä≤ have no zeros in common. 9 Prove that every polynomial of odd degree with real coefficients has a real zero. 10 For ùëù ‚àà ùí´(ùêë), defineùëáùëù‚à∂ ùêë ‚Üí ùêë by (ùëáùëù)(ùë•) = ‚éß{{ ‚é®{{‚é© ùëù(ùë•) ‚àí ùëù(3) ùë• ‚àí 3 if ùë• ‚â† 3, ùëù ‚Ä≤(3) if ùë• = 3 for each ùë• ‚àà ùêë. Show that ùëáùëù ‚àà ùí´(ùêë) for every polynomial ùëù ‚àà ùí´(ùêë) and also show that ùëá‚à∂ ùí´(ùêë) ‚Üí ùí´(ùêë) is a linear map. 11 Suppose ùëù ‚àà ùí´(ùêÇ). Defineùëû‚à∂ ùêÇ ‚Üí ùêÇ by ùëû(ùëß) = ùëù(ùëß) ùëù(ùëß). Prove that ùëû is a polynomial with real coefficients. Chapter 4 Polynomials 131 12 Suppose ùëö is a nonnegative integer and ùëù ‚àà ùí´ùëö(ùêÇ) is such that there are distinct real numbers ùë•0, ùë•1, ‚Ä¶, ùë•ùëö with ùëù(ùë•ùëò) ‚àà ùêë for each ùëò = 0, 1, ‚Ä¶, ùëö. Prove that all coefficients of ùëù are real. 13 Suppose ùëù ‚àà ùí´(ùêÖ) with ùëù ‚â† 0. Let ùëà = {ùëùùëû ‚à∂ ùëû ‚àà ùí´(ùêÖ)}. (a) Show that dim ùí´(ùêÖ)/ùëà = deg ùëù. (b) Find a basis of ùí´(ùêÖ)/ùëà. 14 Suppose ùëù, ùëû ‚àà ùí´(ùêÇ) are nonconstant polynomials with no zeros in common. Let ùëö = deg ùëù and ùëõ = deg ùëû. Use linear algebra as outlined below in (a)‚Äì(c) to prove that there exist ùëü ‚àà ùí´ùëõ ‚àí 1(ùêÇ) and ùë† ‚àà ùí´ùëö ‚àí 1(ùêÇ) such that ùëüùëù + ùë†ùëû = 1. (a) Defineùëá‚à∂ ùí´ùëõ ‚àí 1(ùêÇ) √ó ùí´ùëö ‚àí 1(ùêÇ) ‚Üí ùí´ùëö + ùëõ ‚àí 1(ùêÇ) by ùëá(ùëü, ùë†) = ùëüùëù + ùë†ùëû. Show that the linear map ùëá is injective. (b) Show that the linear map ùëá in (a) is surjective. (c) Use (b) to conclude that there exist ùëü ‚àà ùí´ùëõ ‚àí 1(ùêÇ) and ùë† ‚àà ùí´ùëö ‚àí 1(ùêÇ) such that ùëüùëù + ùë†ùëû = 1. Open Access This chapter is licensed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (https://creativecommons.org/licenses/by-nc/4.0), which permits any noncommercial use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to original author and source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this chapter are included in the chapter‚Äôs Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter‚Äôs Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. Chapter 5 Eigenvalues and Eigenvectors Linear maps from one vector space to another vector space were the objects of study in Chapter 3. Now we begin our investigation of operators, which are linear maps from a vector space to itself. Their study constitutes the most important part of linear algebra. To learn about an operator, we might try restricting it to a smaller subspace. Asking for that restriction to be an operator will lead us to the notion of invariant subspaces. Each one-dimensional invariant subspace arises from a vector that the operator maps into a scalar multiple of the vector. This path will lead us to eigenvectors and eigenvalues. We will then prove one of the most important results in linear algebra: every operator on a finite-dimensional nonzero complex vector space has an eigenvalue. This result will allow us to show that for each operator on a finite-dimensional complex vector space, there is a basis of the vector space with respect to which the matrix of the operator has at least almost half its entries equal to 0. standing assumptions for this chapter ‚Ä¢ ùêÖ denotes ùêë or ùêÇ. ‚Ä¢ ùëâ denotes a vector space over ùêÖ.Hans-PeterPostelCCBY Statue of Leonardo of Pisa (1170‚Äì1250, approximate dates), also known as Fibonacci. Exercise 21 in Section 5D shows how linear algebra can be used to find the explicit formula for the Fibonacci sequence shown on the front cover. 132 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0_5 ¬© Sheldon Axler 2024 Section 5A Invariant Subspaces 133 5A Invariant Subspaces Eigenvalues 5.1 definition: operator A linear map from a vector space to itself is called an operator. Recall that we defined the notation ‚Ñí(ùëâ) to mean ‚Ñí(ùëâ, ùëâ). Suppose ùëá ‚àà ‚Ñí(ùëâ). If ùëö ‚â• 2and ùëâ = ùëâ1 ‚äï ‚ãØ ‚äï ùëâùëö , where each ùëâùëò is a nonzero subspace of ùëâ, then to understand the behavior of ùëá we only need to understand the behavior of each ùëá|ùëâùëò; here ùëá|ùëâùëò denotes the restriction of ùëá to the smaller domain ùëâùëò. Dealing with ùëá|ùëâùëò should be easier than dealing with ùëá because ùëâùëò is a smaller vector space than ùëâ. However, if we intend to apply tools useful in the study of operators (such as taking powers), then we have a problem: ùëá|ùëâùëò may not map ùëâùëò into itself; in other words, ùëá|ùëâùëò may not be an operator on ùëâùëò. Thus we are led to consider only decompositions of ùëâ of the form above in which ùëá maps each ùëâùëò into itself. Hence we now give a name to subspaces of ùëâ that get mapped into themselves by ùëá. 5.2 definition: invariant subspace Suppose ùëá ‚àà ‚Ñí(ùëâ). A subspace ùëà of ùëâ is called invariant under ùëá if ùëáùë¢ ‚àà ùëà for every ùë¢ ‚àà ùëà. Thus ùëà is invariant under ùëá if ùëá|ùëà is an operator on ùëà. 5.3 example: subspace invariant under differentiation operator Suppose that ùëá ‚àà ‚Ñí(ùí´(ùêë))is defined byùëáùëù = ùëù ‚Ä≤. Then ùí´4(ùêë), which is a subspace of ùí´(ùêë), is invariant under ùëá because if ùëù ‚àà ùí´(ùêë) has degree at most 4, then ùëù ‚Ä≤ also has degree at most 4. 5.4 example: four invariant subspaces, not necessarily all different If ùëá ‚àà ‚Ñí(ùëâ), then the following subspaces of ùëâ are all invariant under ùëá. {0} The subspace {0}is invariant under ùëá because if ùë¢ ‚àà {0}, then ùë¢ = 0 and hence ùëáùë¢ = 0 ‚àà {0}. ùëâ The subspace ùëâ is invariant under ùëá because if ùë¢ ‚àà ùëâ, then ùëáùë¢ ‚àà ùëâ. null ùëá The subspace null ùëá is invariant under ùëá because if ùë¢ ‚àà null ùëá, then ùëáùë¢ = 0, and hence ùëáùë¢ ‚àà null ùëá. range ùëá The subspace range ùëá is invariant under ùëá because if ùë¢ ‚àà range ùëá, then ùëáùë¢ ‚àà range ùëá. 134 Chapter 5 Eigenvalues and Eigenvectors Must an operator ùëá ‚àà ‚Ñí(ùëâ) have any invariant subspaces other than {0} and ùëâ? Later we will see that this question has an affirmative answer if ùëâ is finite-dimensional anddim ùëâ > 1(for ùêÖ = ùêÇ) or dim ùëâ > 2(for ùêÖ = ùêë); see 5.19 and Exercise 29 in Section 5B. The previous example noted that null ùëá and range ùëá are invariant under ùëá. However, these subspaces do not necessarily provide easy answers to the question above about the existence of invariant subspaces other than {0}and ùëâ, because null ùëá may equal {0}and range ùëá may equal ùëâ (this happens when ùëá is invertible). We will return later to a deeper study of invariant subspaces. Now we turn to an investigation of the simplest possible nontrivial invariant subspaces‚Äîinvariant subspaces of dimension one. Take any ùë£ ‚àà ùëâ with ùë£ ‚â† 0and let ùëà equal the set of all scalar multiples of ùë£: ùëà = {ùúÜùë£ ‚à∂ ùúÜ ‚àà ùêÖ} = span(ùë£). Then ùëà is a one-dimensional subspace of ùëâ (and every one-dimensional subspace of ùëâ is of this form for an appropriate choice of ùë£). If ùëà is invariant under an operator ùëá ‚àà ‚Ñí(ùëâ), then ùëáùë£ ‚àà ùëà, and hence there is a scalar ùúÜ ‚àà ùêÖ such that ùëáùë£ = ùúÜùë£. Conversely, if ùëáùë£ = ùúÜùë£ for some ùúÜ ‚àà ùêÖ, then span(ùë£) is a one-dimensional subspace of ùëâ invariant under ùëá. The equation ùëáùë£ = ùúÜùë£, which we have just seen is intimately connected with one-dimensional invariant subspaces, is important enough that the scalars ùúÜ and vectors ùë£ satisfying it are given special names. 5.5 definition: eigenvalue Suppose ùëá ‚àà ‚Ñí(ùëâ). A number ùúÜ ‚àà ùêÖ is called an eigenvalue of ùëá if there exists ùë£ ‚àà ùëâ such that ùë£ ‚â† 0and ùëáùë£ = ùúÜùë£. The word eigenvalue is half-German, half-English. The German prefix eigen means ‚Äúown‚Äù in the sense of charac- terizing an intrinsic property. In the definition above, we require that ùë£ ‚â† 0because every scalar ùúÜ ‚àà ùêÖ satisfiesùëá0 = ùúÜ0. The comments above show that ùëâ has a one-dimensional subspace invariant under ùëá if and only if ùëá has an eigenvalue. 5.6 example:eigenvalue Define an operatorùëá ‚àà ‚Ñí(ùêÖ3)by ùëá(ùë•, ùë¶, ùëß) = (7ùë•+ 3ùëß, 3ùë•+ 6ùë¶+ 9ùëß, ‚àí6ùë¶) for (ùë•, ùë¶, ùëß) ‚àà ùêÖ3. Then ùëá(3, 1, ‚àí1) = (18, 6, ‚àí6) = 6(3, 1, ‚àí1). Thus 6is an eigenvalue of ùëá. Section 5A Invariant Subspaces 135 The equivalences in the next result, along with many deep results in linear algebra, are valid only in the context of finite-dimensional vector spaces. 5.7 equivalent conditions to be an eigenvalue Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùúÜ ‚àà ùêÖ. Then the following are equivalent. (a) ùúÜ is an eigenvalue of ùëá. (b) ùëá ‚àí ùúÜùêº is not injective. (c) ùëá ‚àí ùúÜùêº is not surjective. Reminder: ùêº ‚àà ‚Ñí(ùëâ) is the identity operator. Thus ùêºùë£ = ùë£ for all ùë£ ‚àà ùëâ. (d) ùëá ‚àí ùúÜùêº is not invertible. Proof Conditions (a) and (b) are equivalent because the equation ùëáùë£ = ùúÜùë£ is equivalent to the equation (ùëá ‚àí ùúÜùêº)ùë£ = 0. Conditions (b), (c), and (d) are equivalent by 3.65. 5.8 definition: eigenvector Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ ‚àà ùêÖ is an eigenvalue of ùëá. A vector ùë£ ‚àà ùëâ is called an eigenvector of ùëá corresponding to ùúÜ if ùë£ ‚â† 0and ùëáùë£ = ùúÜùë£. In other words, a nonzero vector ùë£ ‚àà ùëâ is an eigenvector of an operator ùëá ‚àà ‚Ñí(ùëâ) if and only if ùëáùë£ is a scalar multiple of ùë£. Because ùëáùë£ = ùúÜùë£ if and only if (ùëá ‚àí ùúÜùêº)ùë£ = 0, a vector ùë£ ‚àà ùëâ with ùë£ ‚â† 0is an eigenvector of ùëá corresponding to ùúÜ if and only if ùë£ ‚àà null(ùëá ‚àí ùúÜùêº). 5.9 example: eigenvalues and eigenvectors Suppose ùëá ‚àà ‚Ñí(ùêÖ2)is defined byùëá(ùë§, ùëß) = (‚àíùëß, ùë§). (a) First consider the case ùêÖ = ùêë. Then ùëá is a counterclockwise rotation by 90 ‚àò about the origin in ùêë2. An operator has an eigenvalue if and only if there exists a nonzero vector in its domain that gets sent by the operator to a scalar multiple of itself. A 90 ‚àò counterclockwise rotation of a nonzero vector in ùêë2 cannot equal a scalar multiple of itself. Conclusion: if ùêÖ = ùêë, then ùëá has no eigenvalues (and thus has no eigenvectors). (b) Now consider the case ùêÖ = ùêÇ. To find eigenvalues ofùëá, we must find the scalars ùúÜ such that ùëá(ùë§, ùëß) = ùúÜ(ùë§, ùëß) has some solution other than ùë§ = ùëß = 0. The equation ùëá(ùë§, ùëß) = ùúÜ(ùë§, ùëß) is equivalent to the simultaneous equations 5.10 ‚àíùëß = ùúÜùë§, ùë§ = ùúÜùëß. Substituting the value for ùë§ given by the second equation into the first equation gives ‚àíùëß = ùúÜ2ùëß. 136 Chapter 5 Eigenvalues and Eigenvectors Now ùëß cannot equal 0[otherwise 5.10 implies that ùë§ = 0; we are looking for solutions to 5.10 such that (ùë§, ùëß) is not the 0vector], so the equation above leads to the equation ‚àí1 = ùúÜ 2. The solutions to this equation are ùúÜ = ùëñ and ùúÜ = ‚àíùëñ. You can verify that ùëñ and ‚àíùëñ are eigenvalues of ùëá. Indeed, the eigenvectors corresponding to the eigenvalue ùëñ are the vectors of the form (ùë§, ‚àíùë§ùëñ), with ùë§ ‚àà ùêÇ and ùë§ ‚â† 0. Furthermore, the eigenvectors corresponding to the eigenvalue ‚àíùëñ are the vectors of the form (ùë§, ùë§ùëñ), with ùë§ ‚àà ùêÇ and ùë§ ‚â† 0. In the next proof, we again use the equivalence ùëáùë£ = ùúÜùë£ ‚ü∫ (ùëá ‚àí ùúÜùêº)ùë£ = 0. 5.11 linearly independent eigenvectors Suppose ùëá ‚àà ‚Ñí(ùëâ). Then every list of eigenvectors of ùëá corresponding to distinct eigenvalues of ùëá is linearly independent. Proof Suppose the desired result is false. Then there exists a smallest positive integer ùëö such that there exists a linearly dependent list ùë£1, ‚Ä¶, ùë£ùëö of eigenvectors of ùëá corresponding to distinct eigenvalues ùúÜ1, ‚Ä¶, ùúÜùëö of ùëá (note that ùëö ‚â• 2because an eigenvector is, by definition, nonzero). Thus there existùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ, none of which are 0(because of the minimality of ùëö), such that ùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö = 0. Apply ùëá ‚àí ùúÜùëöùêº to both sides of the equation above, getting ùëé1(ùúÜ1 ‚àí ùúÜùëö)ùë£1 + ‚ãØ + ùëéùëö ‚àí 1(ùúÜùëö ‚àí 1 ‚àí ùúÜùëö)ùë£ùëö ‚àí 1 = 0. Because the eigenvalues ùúÜ1, ‚Ä¶, ùúÜùëö are distinct, none of the coefficients above equal 0. Thus ùë£1, ‚Ä¶, ùë£ùëö ‚àí 1 is a linearly dependent list of ùëö ‚àí 1eigenvectors of ùëá corresponding to distinct eigenvalues, contradicting the minimality of ùëö. This contradiction completes the proof. The result above leads to a short proof of the result below, which puts an upper bound on the number of distinct eigenvalues that an operator can have. 5.12 operator cannot have more eigenvalues than dimension of vector space Suppose ùëâ is finite-dimensional. Then each operator onùëâ has at most dim ùëâ distinct eigenvalues. Proof Let ùëá ‚àà ‚Ñí(ùëâ). Suppose ùúÜ1, ‚Ä¶, ùúÜùëö are distinct eigenvalues of ùëá. Let ùë£1, ‚Ä¶, ùë£ùëö be corresponding eigenvectors. Then 5.11 implies that the list ùë£1, ‚Ä¶, ùë£ùëö is linearly independent. Thus ùëö ‚â§dim ùëâ (see 2.22), as desired. Section 5A Invariant Subspaces 137 Polynomials Applied to Operators The main reason that a richer theory exists for operators (which map a vector space into itself) than for more general linear maps is that operators can be raised to powers. In this subsection we define that notion and the concept of applying a polynomial to an operator. This concept will be the key tool that we use in the next section when we prove that every operator on a nonzero finite-dimensional complex vector space has an eigenvalue. If ùëá is an operator, then ùëáùëá makes sense (see 3.7) and is also an operator on the same vector space as ùëá. We usually write ùëá2 instead of ùëáùëá. More generally, we have the following definition ofùëáùëö. 5.13 notation: ùëáùëö Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëö is a positive integer. ‚Ä¢ ùëáùëö ‚àà ‚Ñí(ùëâ) is defined byùëáùëö = ùëá‚ãØùëá‚èü ùëö times . ‚Ä¢ ùëá0 is defined to be the identity operatorùêº on ùëâ. ‚Ä¢ If ùëá is invertible with inverse ùëá‚àí1, then ùëá‚àíùëö ‚àà ‚Ñí(ùëâ) is defined by ùëá‚àíùëö = (ùëá‚àí1) ùëö . You should verify that if ùëá is an operator, then ùëáùëöùëáùëõ = ùëáùëö + ùëõ and (ùëáùëö) ùëõ = ùëáùëöùëõ, where ùëö and ùëõ are arbitrary integers if ùëá is invertible and are nonnegative integers if ùëá is not invertible. Having defined powers of an operator, we can now define what it means to apply a polynomial to an operator. 5.14 notation: ùëù(ùëá) Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëù ‚àà ùí´(ùêÖ) is a polynomial given by ùëù(ùëß) = ùëé0 + ùëé1ùëß + ùëé2ùëß2 + ‚ãØ + ùëéùëöùëßùëö for all ùëß ‚àà ùêÖ. Then ùëù(ùëá) is the operator on ùëâ defined by ùëù(ùëá) = ùëé0ùêº + ùëé1ùëá + ùëé2ùëá2 + ‚ãØ + ùëéùëöùëáùëö. This is a new use of the symbol ùëù because we are applying ùëù to operators, not just elements of ùêÖ. The idea here is that to evaluate ùëù(ùëá), we simply replace ùëß with ùëá in the expression definingùëù. Note that the constant term ùëé0 in ùëù(ùëß) becomes the operator ùëé0ùêº (which is a reasonable choice because ùëé0 = ùëé0ùëß 0 and thus we should replace ùëé0 with ùëé0ùëá0, which equals ùëé0ùêº). 138 Chapter 5 Eigenvalues and Eigenvectors 5.15 example: a polynomial applied to the differentiation operator Suppose ùê∑ ‚àà ‚Ñí(ùí´(ùêë))is the differentiation operator defined byùê∑ùëû = ùëû‚Ä≤ and ùëù is the polynomial defined byùëù(ùë•) = 7 ‚àí 3ùë•+ 5ùë• 2. Then ùëù(ùê∑) = 7ùêº ‚àí 3ùê∑+ 5ùê∑ 2. Thus (ùëù(ùê∑))ùëû = 7ùëû ‚àí 3ùëû ‚Ä≤ + 5ùëû ‚Ä≥ for every ùëû ‚àà ùí´(ùêë). If we fix an operatorùëá ‚àà ‚Ñí(ùëâ), then the function from ùí´(ùêÖ) to ‚Ñí(ùëâ) given by ùëù ‚Ü¶ ùëù(ùëá) is linear, as you should verify. 5.16 definition:product of polynomials If ùëù, ùëû ‚àà ùí´(ùêÖ), then ùëùùëû ‚àà ùí´(ùêÖ) is the polynomial defined by (ùëùùëû)(ùëß) = ùëù(ùëß)ùëû(ùëß) for all ùëß ‚àà ùêÖ. The order does not matter in taking products of polynomials of a single operator, as shown by (b) in the next result. 5.17 multiplicative properties Suppose ùëù, ùëû ‚àà ùí´(ùêÖ) and ùëá ‚àà ‚Ñí(ùëâ). Then (a) (ùëùùëû)(ùëá) = ùëù(ùëá)ùëû(ùëá); (b) ùëù(ùëá)ùëû(ùëá) = ùëû(ùëá)ùëù(ùëá). Informal proof: When a product of polynomials is expanded using the dis- tributive property, it does not matter whether the symbol is ùëß or ùëá. Proof (a) Suppose ùëù(ùëß) = ùëö ‚àë ùëó = 0 ùëéùëóùëß ùëó and ùëû(ùëß) = ùëõ ‚àë ùëò = 0 ùëèùëòùëßùëò for all ùëß ‚àà ùêÖ. Then (ùëùùëû)(ùëß) = ùëö ‚àë ùëó = 0 ùëõ ‚àë ùëò = 0 ùëéùëóùëèùëòùëß ùëó + ùëò. Thus (ùëùùëû)(ùëá) = ùëö ‚àë ùëó = 0 ùëõ ‚àë ùëò = 0 ùëéùëóùëèùëòùëáùëó + ùëò = (ùëö ‚àë ùëó = 0 ùëéùëóùëáùëó)( ùëõ ‚àë ùëò = 0 ùëèùëòùëáùëò) = ùëù(ùëá)ùëû(ùëá). (b) Using (a) twice, we have ùëù(ùëá)ùëû(ùëá) = (ùëùùëû)(ùëá) = (ùëûùëù)(ùëá) = ùëû(ùëá)ùëù(ùëá). Section 5A Invariant Subspaces 139 We observed earlier that if ùëá ‚àà ‚Ñí(ùëâ), then the subspaces null ùëá and range ùëá are invariant under ùëá (see 5.4). Now we show that the null space and the range of every polynomial of ùëá are also invariant under ùëá. 5.18 null space and range of ùëù(ùëá) are invariant under ùëá Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëù ‚àà ùí´(ùêÖ). Then null ùëù(ùëá) and range ùëù(ùëá) are invariant under ùëá. Proof Suppose ùë¢ ‚àà null ùëù(ùëá). Then ùëù(ùëá)ùë¢ = 0. Thus (ùëù(ùëá))(ùëáùë¢) = ùëá(ùëù(ùëá)ùë¢)= ùëá(0) = 0. Hence ùëáùë¢ ‚àà null ùëù(ùëá). Thus null ùëù(ùëá) is invariant under ùëá, as desired. Suppose ùë¢ ‚àà range ùëù(ùëá). Then there exists ùë£ ‚àà ùëâ such that ùë¢ = ùëù(ùëá)ùë£. Thus ùëáùë¢ = ùëá(ùëù(ùëá)ùë£)= ùëù(ùëá)(ùëáùë£). Hence ùëáùë¢ ‚àà range ùëù(ùëá). Thus range ùëù(ùëá) is invariant under ùëá, as desired. Exercises 5A 1 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëà is a subspace of ùëâ. (a) Prove that if ùëà ‚äÜnull ùëá, then ùëà is invariant under ùëá. (b) Prove that if range ùëá ‚äÜ ùëà, then ùëà is invariant under ùëá. 2 Suppose that ùëá ‚àà ‚Ñí(ùëâ) and ùëâ1, ‚Ä¶, ùëâùëö are subspaces of ùëâ invariant under ùëá. Prove that ùëâ1 + ‚ãØ + ùëâùëö is invariant under ùëá. 3 Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that the intersection of every collection of subspaces of ùëâ invariant under ùëá is invariant under ùëá. 4 Prove or give a counterexample: If ùëâ is finite-dimensional andùëà is a sub- space of ùëâ that is invariant under every operator on ùëâ, then ùëà = {0}or ùëà = ùëâ. 5 Suppose ùëá ‚àà ‚Ñí(ùêë2)is defined byùëá(ùë•, ùë¶) = (‚àí3ùë¶, ùë•). Find the eigenvalues of ùëá. 6 Defineùëá ‚àà ‚Ñí(ùêÖ2)by ùëá(ùë§, ùëß) = (ùëß, ùë§). Find all eigenvalues and eigenvec- tors of ùëá. 7 Defineùëá ‚àà ‚Ñí(ùêÖ3)by ùëá(ùëß1, ùëß2, ùëß3) = (2ùëß2, 0, 5ùëß3). Find all eigenvalues and eigenvectors of ùëá. 8 Suppose ùëÉ ‚àà ‚Ñí(ùëâ) is such that ùëÉ2 = ùëÉ. Prove that if ùúÜ is an eigenvalue of ùëÉ, then ùúÜ = 0or ùúÜ = 1. 140 Chapter 5 Eigenvalues and Eigenvectors 9 Defineùëá‚à∂ ùí´(ùêë) ‚Üí ùí´(ùêë) by ùëáùëù = ùëù‚Ä≤. Find all eigenvalues and eigenvectors of ùëá. 10 Defineùëá ‚àà ‚Ñí(ùí´4(ùêë))by (ùëáùëù)(ùë•) = ùë•ùëù‚Ä≤(ùë•) for all ùë• ‚àà ùêë. Find all eigenval- ues and eigenvectors of ùëá. 11 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùõº ‚àà ùêÖ. Prove that there ex- ists ùõø > 0such that ùëá‚àí ùúÜùêº is invertible for all ùúÜ ‚àà ùêÖ such that 0 < |ùõº ‚àí ùúÜ| < ùõø. 12 Suppose ùëâ = ùëà ‚äï ùëä, where ùëà and ùëä are nonzero subspaces of ùëâ. Define ùëÉ ‚àà ‚Ñí(ùëâ) by ùëÉ(ùë¢ + ùë§) = ùë¢ for each ùë¢ ‚àà ùëà and each ùë§ ‚àà ùëä. Find all eigenvalues and eigenvectors of ùëÉ. 13 Suppose ùëá ‚àà ‚Ñí(ùëâ). Suppose ùëÜ ‚àà ‚Ñí(ùëâ) is invertible. (a) Prove that ùëá and ùëÜ ‚àí1ùëáùëÜ have the same eigenvalues. (b) What is the relationship between the eigenvectors of ùëá and the eigenvec- tors of ùëÜ‚àí1ùëáùëÜ? 14 Give an example of an operator on ùêë4 that has no (real) eigenvalues. 15 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùúÜ ‚àà ùêÖ. Show that ùúÜ is an eigenvalue of ùëá if and only if ùúÜ is an eigenvalue of the dual operator ùëá‚Ä≤ ‚àà ‚Ñí(ùëâ‚Ä≤). 16 Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùëá ‚àà ‚Ñí(ùëâ). Prove that if ùúÜ is an eigenvalue of ùëá, then |ùúÜ| ‚â§ ùëõmax{‚à£‚Ñ≥(ùëá)ùëó, ùëò‚à£ ‚à∂ 1 ‚â§ ùëó, ùëò ‚â§ ùëõ}, where ‚Ñ≥(ùëá)ùëó, ùëò denotes the entry in row ùëó, column ùëò of the matrix of ùëá with respect to the basis ùë£1, ‚Ä¶, ùë£ùëõ. See Exercise 19 in Section 6A for a different bound on |ùúÜ|. 17 Suppose ùêÖ = ùêë, ùëá ‚àà ‚Ñí(ùëâ), and ùúÜ ‚àà ùêë. Prove that ùúÜ is an eigenvalue of ùëá if and only if ùúÜ is an eigenvalue of the complexificationùëáùêÇ. See Exercise 33 in Section 3B for the definition of ùëáùêÇ. 18 Suppose ùêÖ = ùêë, ùëá ‚àà ‚Ñí(ùëâ), and ùúÜ ‚àà ùêÇ. Prove that ùúÜ is an eigenvalue of the complexificationùëáùêÇ if and only if ùúÜ is an eigenvalue of ùëáùêÇ. 19 Show that the forward shift operator ùëá ‚àà ‚Ñí(ùêÖ‚àû)defined by ùëá(ùëß1, ùëß2, ‚Ä¶ ) = (0, ùëß1, ùëß2, ‚Ä¶ ) has no eigenvalues. 20 Define the backward shift operatorùëÜ ‚àà ‚Ñí(ùêÖ‚àû)by ùëÜ(ùëß1, ùëß2, ùëß3, ‚Ä¶ ) = (ùëß2, ùëß3, ‚Ä¶ ). (a) Show that every element of ùêÖ is an eigenvalue of ùëÜ. (b) Find all eigenvectors of ùëÜ. Section 5A Invariant Subspaces ‚âà 100‚àö2 21 Suppose ùëá ‚àà ‚Ñí(ùëâ) is invertible. (a) Suppose ùúÜ ‚àà ùêÖ with ùúÜ ‚â† 0. Prove that ùúÜ is an eigenvalue of ùëá if and only if 1 ùúÜ is an eigenvalue of ùëá‚àí1. (b) Prove that ùëá and ùëá‚àí1 have the same eigenvectors. 22 Suppose ùëá ‚àà ‚Ñí(ùëâ) and there exist nonzero vectors ùë¢ and ùë§ in ùëâ such that ùëáùë¢ = 3ùë§ and ùëáùë§ = 3ùë¢. Prove that 3or ‚àí3is an eigenvalue of ùëá. 23 Suppose ùëâ is finite-dimensional andùëÜ, ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëÜùëá and ùëáùëÜ have the same eigenvalues. 24 Suppose ùê¥ is an ùëõ-by-ùëõ matrix with entries in ùêÖ. Defineùëá ‚àà ‚Ñí(ùêÖùëõ)by ùëáùë• = ùê¥ùë•, where elements of ùêÖùëõ are thought of as ùëõ-by-1column vectors. (a) Suppose the sum of the entries in each row of ùê¥ equals 1. Prove that 1 is an eigenvalue of ùëá. (b) Suppose the sum of the entries in each column of ùê¥ equals 1. Prove that 1is an eigenvalue of ùëá. 25 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùë¢, ùë§ are eigenvectors of ùëá such that ùë¢ + ùë§ is also an eigenvector of ùëá. Prove that ùë¢ and ùë§ are eigenvectors of ùëá corresponding to the same eigenvalue. 26 Suppose ùëá ‚àà ‚Ñí(ùëâ) is such that every nonzero vector in ùëâ is an eigenvector of ùëá. Prove that ùëá is a scalar multiple of the identity operator. 27 Suppose that ùëâ is finite-dimensional andùëò ‚àà {1, ‚Ä¶, dim ùëâ ‚àí 1}. Suppose ùëá ‚àà ‚Ñí(ùëâ) is such that every subspace of ùëâ of dimension ùëò is invariant under ùëá. Prove that ùëá is a scalar multiple of the identity operator. 28 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá has at most 1+ dim range ùëá distinct eigenvalues. 29 Suppose ùëá ‚àà ‚Ñí(ùêë3)and ‚àí4, 5, and ‚àö7are eigenvalues of ùëá. Prove that there exists ùë• ‚àà ùêë3 such that ùëáùë• ‚àí 9ùë• =(‚àí4, 5, ‚àö7). 30 Suppose ùëá ‚àà ‚Ñí(ùëâ) and (ùëá ‚àí 2ùêº)(ùëá ‚àí 3ùêº)(ùëá ‚àí 4ùêº) = 0. Suppose ùúÜ is an eigenvalue of ùëá. Prove that ùúÜ = 2or ùúÜ = 3or ùúÜ = 4. 31 Give an example of ùëá ‚àà ‚Ñí(ùêë2)such that ùëá4 = ‚àíùêº. 32 Suppose ùëá ‚àà ‚Ñí(ùëâ) has no eigenvalues and ùëá4 = ùêº. Prove that ùëá2 = ‚àíùêº. 33 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëö is a positive integer. (a) Prove that ùëá is injective if and only if ùëáùëö is injective. (b) Prove that ùëá is surjective if and only if ùëáùëö is surjective. 142 Chapter 5 Eigenvalues and Eigenvectors 34 Suppose ùëâ is finite-dimensional andùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ. Prove that the list ùë£1, ‚Ä¶, ùë£ùëö is linearly independent if and only if there exists ùëá ‚àà ‚Ñí(ùëâ) such that ùë£1, ‚Ä¶, ùë£ùëö are eigenvectors of ùëá corresponding to distinct eigenvalues. 35 Suppose that ùúÜ1, ‚Ä¶, ùúÜùëõ is a list of distinct real numbers. Prove that the list ùëí ùúÜ1ùë•, ‚Ä¶, ùëí ùúÜùëõùë• is linearly independent in the vector space of real-valued functions on ùêë. Hint: Let ùëâ = span(ùëí ùúÜ1ùë•, ‚Ä¶, ùëí ùúÜùëõùë•), and define an operator ùê∑ ‚àà ‚Ñí(ùëâ) by ùê∑ ùëì = ùëì ‚Ä≤. Find eigenvalues and eigenvectors of ùê∑. 36 Suppose that ùúÜ1, ‚Ä¶, ùúÜùëõ is a list of distinct positive numbers. Prove that the list cos(ùúÜ1ùë•), ‚Ä¶, cos(ùúÜùëõùë•) is linearly independent in the vector space of real-valued functions on ùêë. 37 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Defineùíú ‚àà ‚Ñí(‚Ñí(ùëâ))by ùíú(ùëÜ) = ùëáùëÜ for each ùëÜ ‚àà ‚Ñí(ùëâ). Prove that the set of eigenvalues of ùëá equals the set of eigenvalues of ùíú. 38 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùëà is a subspace of ùëâ invariant under ùëá. The quotient operator ùëá/ùëà ‚àà ‚Ñí(ùëâ/ùëà) is defined by (ùëá/ùëà)(ùë£ + ùëà) = ùëáùë£ + ùëà for each ùë£ ‚àà ùëâ. (a) Show that the definition ofùëá/ùëà makes sense (which requires using the condition that ùëà is invariant under ùëá) and show that ùëá/ùëà is an operator on ùëâ/ùëà. (b) Show that each eigenvalue of ùëá/ùëà is an eigenvalue of ùëá. 39 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá has an eigen- value if and only if there exists a subspace of ùëâ of dimension dim ùëâ ‚àí 1that is invariant under ùëá. 40 Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) and ùëÜ is invertible. Suppose ùëù ‚àà ùí´(ùêÖ) is a polynomial. Prove that ùëù(ùëÜùëáùëÜ ‚àí1)= ùëÜùëù(ùëá)ùëÜ‚àí1. 41 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëà is a subspace of ùëâ invariant under ùëá. Prove that ùëà is invariant under ùëù(ùëá) for every polynomial ùëù ‚àà ùí´(ùêÖ). 42 Defineùëá ‚àà ‚Ñí(ùêÖùëõ)by ùëá(ùë•1, ùë•2, ùë•3, ‚Ä¶, ùë•ùëõ) = (ùë•1, 2ùë•2, 3ùë•3, ‚Ä¶, ùëõùë•ùëõ). (a) Find all eigenvalues and eigenvectors of ùëá. (b) Find all subspaces of ùêÖùëõ that are invariant under ùëá. 43 Suppose that ùëâ is finite-dimensional,dim ùëâ > 1, and ùëá ‚àà ‚Ñí(ùëâ). Prove that {ùëù(ùëá) ‚à∂ ùëù ‚àà ùí´(ùêÖ)}‚â† ‚Ñí(ùëâ). Section 5B The Minimal Polynomial 143 5B The Minimal Polynomial Existence of Eigenvalues on Complex Vector Spaces Now we come to one of the central results about operators on finite-dimensional complex vector spaces. 5.19 existence of eigenvalues Every operator on a finite-dimensional nonzero complex vector space has an eigenvalue. Proof Suppose ùëâ is a finite-dimensional complex vector space of dimension ùëõ > 0and ùëá ‚àà ‚Ñí(ùëâ). Choose ùë£ ‚àà ùëâ with ùë£ ‚â† 0. Then ùë£, ùëáùë£, ùëá2ùë£, ‚Ä¶, ùëáùëõùë£ is not linearly independent, because ùëâ has dimension ùëõ and this list has length ùëõ + 1. Hence some linear combination (with not all the coefficients equal to 0) of the vectors above equals 0. Thus there exists a nonconstant polynomial ùëù of smallest degree such that ùëù(ùëá)ùë£ = 0. By the first version of the fundamental theorem of algebra (see4.12), there exists ùúÜ ‚àà ùêÇ such that ùëù(ùúÜ) = 0. Hence there exists a polynomial ùëû ‚àà ùí´(ùêÇ) such that ùëù(ùëß) = (ùëß ‚àí ùúÜ)ùëû(ùëß) for every ùëß ‚àà ùêÇ (see 4.6). This implies (using 5.17) that 0 = ùëù(ùëá)ùë£ = (ùëá ‚àí ùúÜùêº)(ùëû(ùëá)ùë£). Because ùëû has smaller degree than ùëù, we know that ùëû(ùëá)ùë£ ‚â† 0. Thus the equation above implies that ùúÜ is an eigenvalue of ùëá with eigenvector ùëû(ùëá)ùë£. The proof above makes crucial use of the fundamental theorem of algebra. The comment following Exercise 16 helps explain why the fundamental theorem of algebra is so tightly connected to the result above. The hypothesis in the result above that ùêÖ = ùêÇ cannot be replaced with the hypothesis that ùêÖ = ùêë, as shown by Example 5.9. The next example shows that the finite-dimensional hypothesis in the result above also cannot be deleted. 5.20 example: an operator on a complex vector space with no eigenvalues Defineùëá ‚àà ‚Ñí(ùí´(ùêÇ))by (ùëáùëù)(ùëß) = ùëßùëù(ùëß). If ùëù ‚àà ùí´(ùêÇ) is a nonzero poly- nomial, then the degree of ùëáùëù is one more than the degree of ùëù, and thus ùëáùëù cannot equal a scalar multiple of ùëù. Hence ùëá has no eigenvalues. Because ùí´(ùêÇ) is infinite-dimensional, this example does not contradict the result above. 144 Chapter 5 Eigenvalues and Eigenvectors Eigenvalues and the Minimal Polynomial In this subsection we introduce an important polynomial associated with each operator. We begin with the following definition. 5.21 definition: monic polynomial A monic polynomial is a polynomial whose highest-degree coefficient equals 1. For example, the polynomial 2+ 9ùëß 2 + ùëß7 is a monic polynomial of degree 7. 5.22 existence, uniqueness, and degree of minimal polynomial Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Then there is a unique monic polynomial ùëù ‚àà ùí´(ùêÖ) of smallest degree such that ùëù(ùëá) = 0. Furthermore, deg ùëù ‚â§dim ùëâ. Proof If dim ùëâ = 0, then ùêº is the zero operator on ùëâ and thus we take ùëù to be the constant polynomial 1. Now use induction on dim ùëâ. Thus assume that dim ùëâ > 0and that the desired result is true for all operators on all complex vector spaces of smaller dimension. Let ùë£ ‚àà ùëâ be such that ùë£ ‚â† 0. The list ùë£, ùëáùë£, ‚Ä¶, ùëádim ùëâùë£ has length 1+ dim ùëâ and thus is linearly dependent. By the linear dependence lemma (2.19), there is a smallest positive integer ùëö ‚â§dim ùëâ such that ùëáùëöùë£ is a linear combination of ùë£, ùëáùë£, ‚Ä¶, ùëáùëö ‚àí 1ùë£. Thus there exist scalars ùëê0, ùëê1, ùëê2, ‚Ä¶, ùëêùëö ‚àí 1 ‚àà ùêÖ such that 5.23 ùëê0ùë£ + ùëê1ùëáùë£ + ‚ãØ + ùëêùëö ‚àí 1ùëáùëö ‚àí 1ùë£ + ùëáùëöùë£ = 0. Define a monic polynomialùëû ‚àà ùí´ùëö(ùêÖ) by ùëû(ùëß) = ùëê0 + ùëê1ùëß + ‚ãØ + ùëêùëö ‚àí 1ùëß ùëö ‚àí 1 + ùëß ùëö. Then 5.23 implies that ùëû(ùëá)ùë£ = 0. If ùëò is a nonnegative integer, then ùëû(ùëá)(ùëáùëòùë£)= ùëáùëò(ùëû(ùëá)ùë£)= ùëáùëò(0) = 0. The linear dependence lemma (2.19) shows that ùë£, ùëáùë£, ‚Ä¶, ùëáùëö ‚àí 1ùë£ is linearly inde- pendent. Thus the equation above implies that dim null ùëû(ùëá) ‚â• ùëö. Hence dim range ùëû(ùëá) = dim ùëâ ‚àí dim null ùëû(ùëá) ‚â§dim ùëâ ‚àí ùëö. Because range ùëû(ùëá) is invariant under ùëá (by 5.18), we can apply our induction hypothesis to the operator ùëá|range ùëû(ùëá)on the vector space range ùëû(ùëá). Thus there is a monic polynomial ùë† ‚àà ùí´(ùêÖ) with deg ùë† ‚â§dim ùëâ ‚àí ùëö and ùë†(ùëá|range ùëû(ùëá)) = 0. Hence for all ùë£ ‚àà ùëâ we have (ùë†ùëû)(ùëá)(ùë£) = ùë†(ùëá)(ùëû(ùëá)ùë£)= 0 because ùëû(ùëá)ùë£ ‚àà range ùëû(ùëá) and ùë†(ùëá)|range ùëû(ùëá)= ùë†(ùëá|range ùëû(ùëá)) = 0. Thus ùë†ùëû is a monic polynomial such that deg ùë†ùëû ‚â§dim ùëâ and (ùë†ùëû)(ùëá) = 0. Section 5B The Minimal Polynomial 145 The paragraph above shows that there is a monic polynomial of degree at most dim ùëâ that when applied to ùëá gives the 0operator. Thus there is a monic polynomial of smallest degree with this property, completing the existence part of this result. Let ùëù ‚àà ùí´(ùêÖ) be a monic polynomial of smallest degree such that ùëù(ùëá) = 0. To prove the uniqueness part of the result, suppose ùëü ‚àà ùí´(ùêÖ) is a monic poly- nomial of the same degree as ùëù and ùëü(ùëá) = 0. Then (ùëù ‚àí ùëü)(ùëá) = 0and also deg(ùëù ‚àí ùëü) < deg ùëù. If ùëù ‚àí ùëü were not equal to 0, then we could divide ùëù ‚àí ùëü by the coefficient of the highest-order term in ùëù ‚àí ùëü to get a monic polynomial (of smaller degree than ùëù) that when applied to ùëá gives the 0operator. Thus ùëù ‚àí ùëü = 0, as desired. The previous result justifies the following definition. 5.24 definition: minimal polynomial Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Then the minimal polynomial of ùëá is the unique monic polynomial ùëù ‚àà ùí´(ùêÖ) of smallest degree such that ùëù(ùëá) = 0. To compute the minimal polynomial of an operator ùëá ‚àà ‚Ñí(ùëâ), we need to find the smallest positive integerùëö such that the equation ùëê0ùêº + ùëê1ùëá + ‚ãØ + ùëêùëö ‚àí 1ùëáùëö ‚àí 1 = ‚àíùëáùëö has a solution ùëê0, ùëê1, ‚Ä¶, ùëêùëö ‚àí 1 ‚àà ùêÖ. If we pick a basis of ùëâ and replace ùëá in the equation above with the matrix of ùëá, then the equation above can be thought of as a system of (dim ùëâ) 2 linear equations in the ùëö unknowns ùëê0, ùëê1, ‚Ä¶, ùëêùëö ‚àí 1 ‚àà ùêÖ. Gaussian elimination or another fast method of solving systems of linear equations can tell us whether a solution exists, testing successive values ùëö = 1, 2, ‚Ä¶ until a solution exists. By 5.22, a solution exists for some smallest positive integer ùëö ‚â§dim ùëâ. The minimal polynomial of ùëá is then ùëê0 + ùëê1ùëß + ‚ãØ + ùëêùëö ‚àí 1ùëß ùëö ‚àí 1 + ùëßùëö. Even faster (usually), pick ùë£ ‚àà ùëâ and consider the equation 5.25 ùëê0ùë£ + ùëê1ùëáùë£ + ‚ãØ + ùëêdim ùëâ ‚àí 1ùëádim ùëâ ‚àí 1ùë£ = ‚àíùëádim ùëâùë£. Use a basis of ùëâ to convert the equation above to a system of dim ùëâ linear equa- tions in dim ùëâ unknowns ùëê0, ùëê1, ‚Ä¶, ùëêdim ùëâ ‚àí 1. If this system of equations has a unique solution ùëê0, ùëê1, ‚Ä¶, ùëêdim ùëâ ‚àí 1 (as happens most of the time), then the scalars ùëê0, ùëê1, ‚Ä¶, ùëêdim ùëâ ‚àí 1, 1are the coefficients of the minimal polynomial of ùëá (because 5.22 states that the degree of the minimal polynomial is at most dim ùëâ). These estimates are based on testing millions of random matrices. Consider operators on ùêë4 (thought of as 4-by-4matrices with respect to the standard basis), and take ùë£ = (1, 0, 0, 0) in the paragraph above. The faster method described above works on over 99.8% of the 4-by-4matrices with integer entries in the interval [‚àí10, 10]and on over 99.999% of the 4-by-4matrices with integer entries in [‚àí100, 100]. 146 Chapter 5 Eigenvalues and Eigenvectors The next example illustrates the faster procedure discussed above. 5.26 example:minimal polynomial of an operator on ùêÖ5 Suppose ùëá ‚àà ‚Ñí(ùêÖ5)and ‚Ñ≥(ùëá) = ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 0 0 0 0 ‚àí3 1 0 0 0 6 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü ‚é† with respect to the standard basis ùëí1, ùëí2, ùëí3, ùëí4, ùëí5. Taking ùë£ = ùëí1 for 5.25, we have ùëáùëí1 = ùëí2, ùëá4ùëí1 = ùëá(ùëá3ùëí1)= ùëáùëí4 = ùëí5, ùëá2ùëí1 = ùëá(ùëáùëí1) = ùëáùëí2 = ùëí3, ùëá5ùëí1 = ùëá(ùëá4ùëí1)= ùëáùëí5 = ‚àí3ùëí1 + 6ùëí2. ùëá3ùëí1 = ùëá(ùëá2ùëí1)= ùëáùëí3 = ùëí4, Thus 3ùëí1 ‚àí 6ùëáùëí1 = ‚àíùëá5ùëí1. The list ùëí1, ùëáùëí1, ùëá2ùëí1, ùëá3ùëí1, ùëá4ùëí1, which equals the list ùëí1, ùëí2, ùëí3, ùëí4, ùëí5, is linearly independent, so no other linear combination of this list equals ‚àíùëá5ùëí1. Hence the minimal polynomial of ùëá is 3 ‚àí 6ùëß+ ùëß5. Recall that by definition, eigenvalues of operators onùëâ and zeros of polyno- mials in ùí´(ùêÖ) must be elements of ùêÖ. In particular, if ùêÖ = ùêë, then eigenvalues and zeros must be real numbers. 5.27 eigenvalues are the zeros of the minimal polynomial Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). (a) The zeros of the minimal polynomial of ùëá are the eigenvalues of ùëá. (b) If ùëâ is a complex vector space, then the minimal polynomial of ùëá has the form (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö), where ùúÜ1, ‚Ä¶, ùúÜùëö is a list of all eigenvalues of ùëá, possibly with repetitions. Proof Let ùëù be the minimal polynomial of ùëá. (a) First suppose ùúÜ ‚àà ùêÖ is a zero of ùëù. Then ùëù can be written in the form ùëù(ùëß) = (ùëß ‚àí ùúÜ)ùëû(ùëß), where ùëû is a monic polynomial with coefficients in ùêÖ (see 4.6). Because ùëù(ùëá) = 0, we have 0 = (ùëá ‚àí ùúÜùêº)(ùëû(ùëá)ùë£) for all ùë£ ‚àà ùëâ. Because the degree of ùëû is less than the degree of the minimal polynomial ùëù, there exists at least one vector ùë£ ‚àà ùëâ such that ùëû(ùëá)ùë£ ‚â† 0. The equation above thus implies that ùúÜ is an eigenvalue of ùëá, as desired. Section 5B The Minimal Polynomial 147 To prove that every eigenvalue of ùëá is a zero of ùëù, now suppose ùúÜ ‚àà ùêÖ is an eigenvalue of ùëá. Thus there exists ùë£ ‚àà ùëâ with ùë£ ‚â† 0such that ùëáùë£ = ùúÜùë£. Repeated applications of ùëá to both sides of this equation show that ùëáùëòùë£ = ùúÜùëòùë£ for every nonnegative integer ùëò. Thus ùëù(ùëá)ùë£ = ùëù(ùúÜ)ùë£. Because ùëù is the minimal polynomial of ùëá, we have ùëù(ùëá)ùë£ = 0. Hence the equation above implies that ùëù(ùúÜ) = 0. Thus ùúÜ is a zero of ùëù, as desired. (b) To get the desired result, use (a) and the second version of the fundamental theorem of algebra (see 4.13). A nonzero polynomial has at most as many distinct zeros as its degree (see 4.8). Thus (a) of the previous result, along with the result that the minimal polynomial of an operator on ùëâ has degree at most dim ùëâ, gives an alternative proof of 5.12, which states that an operator on ùëâ has at most dim ùëâ distinct eigenvalues. Every monic polynomial is the minimal polynomial of some operator, as shown by Exercise 16, which generalizes Example 5.26. Thus 5.27(a) shows that finding exact expressions for the eigenvalues of an operator is equivalent to the problem of finding exact expressions for the zeros of a polynomial (and thus is not possible for some operators). 5.28 example: An operator whose eigenvalues cannot be found exactly Let ùëá ‚àà ‚Ñí(ùêÇ 5)be the operator defined by ùëá(ùëß1, ùëß2, ùëß3, ùëß4, ùëß5) = (‚àí3ùëß5, ùëß1 + 6ùëß5, ùëß2, ùëß3, ùëß4). The matrix of ùëá with respect to the standard basis of ùêÇ 5 is the 5-by-5matrix in Example 5.26. As we showed in that example, the minimal polynomial of ùëá is the polynomial 3 ‚àí 6ùëß+ ùëß 5. No zero of the polynomial above can be expressed using rational numbers, roots of rational numbers, and the usual rules of arithmetic (a proof of this would take us considerably beyond linear algebra). Because the zeros of the polynomial above are the eigenvalues of ùëá [by 5.27(a)], we cannot find an exact expression for any eigenvalue of ùëá in any familiar form. Numeric techniques, which we will not discuss here, show that the zeros of the polynomial above, and thus the eigenvalues of ùëá, are approximately the following five complex numbers: ‚àí1.67, 0.51, 1.40, ‚àí0.12+ 1.59ùëñ, ‚àí0.12 ‚àí 1.59ùëñ. Note that the two nonreal zeros of this polynomial are complex conjugates of each other, as we expect for a polynomial with real coefficients (see 4.14). 148 Chapter 5 Eigenvalues and Eigenvectors The next result completely characterizes the polynomials that when applied to an operator give the 0operator. 5.29 ùëû(ùëá) = 0 ‚ü∫ ùëûis a polynomial multiple of the minimal polynomial Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùëû ‚àà ùí´(ùêÖ). Then ùëû(ùëá) = 0 if and only if ùëû is a polynomial multiple of the minimal polynomial of ùëá. Proof Let ùëù denote the minimal polynomial of ùëá. First suppose ùëû(ùëá) = 0. By the division algorithm for polynomials (4.9), there exist polynomials ùë†, ùëü ‚àà ùí´(ùêÖ) such that 5.30 ùëû = ùëùùë† + ùëü and deg ùëü < deg ùëù. We have 0 = ùëû(ùëá) = ùëù(ùëá)ùë†(ùëá)+ ùëü(ùëá) = ùëü(ùëá). The equation above implies that ùëü = 0(otherwise, dividing ùëü by its highest-degree coefficient would produce a monic polynomial that when applied to ùëá gives 0; this polynomial would have a smaller degree than the minimal polynomial, which would be a contradiction). Thus 5.30 becomes the equation ùëû = ùëùùë†. Hence ùëû is a polynomial multiple of ùëù, as desired. To prove the other direction, now suppose ùëû is a polynomial multiple of ùëù. Thus there exists a polynomial ùë† ‚àà ùí´(ùêÖ) such that ùëû = ùëùùë†. We have ùëû(ùëá) = ùëù(ùëá)ùë†(ùëá) = 0 ùë†(ùëá) = 0, as desired. The next result is a nice consequence of the result above. 5.31 minimal polynomial of a restriction operator Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùëà is a subspace of ùëâ that is invariant under ùëá. Then the minimal polynomial of ùëá is a polynomial multiple of the minimal polynomial of ùëá|ùëà. Proof Suppose ùëù is the minimal polynomial of ùëá. Thus ùëù(ùëá)ùë£ = 0for all ùë£ ‚àà ùëâ. In particular, ùëù(ùëá)ùë¢ = 0for all ùë¢ ‚àà ùëà. Thus ùëù(ùëá|ùëà) = 0. Now 5.29, applied to the operator ùëá|ùëà in place of ùëá, implies that ùëù is a polynomial multiple of the minimal polynomial of ùëá|ùëà. See Exercise 25 for a result about quotient operators that is analogous to the result above. The next result shows that the constant term of the minimal polynomial of an operator determines whether the operator is invertible. Section 5B The Minimal Polynomial 149 5.32 ùëá not invertible ‚ü∫ constant term of minimal polynomial of ùëá is 0 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Then ùëá is not invertible if and only if the constant term of the minimal polynomial of ùëá is 0. Proof Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëù is the minimal polynomial of ùëá. Then ùëá is not invertible ‚ü∫ 0is an eigenvalue of ùëá ‚ü∫ 0is a zero of ùëù ‚ü∫ the constant term of ùëù is 0, where the first equivalence holds by5.7, the second equivalence holds by 5.27(a), and the last equivalence holds because the constant term of ùëù equals ùëù(0). Eigenvalues on Odd-Dimensional Real Vector Spaces The next result will be the key tool that we use to show that every operator on an odd-dimensional real vector space has an eigenvalue. 5.33 even-dimensional null space Suppose ùêÖ = ùêë and ùëâ is finite-dimensional. Suppose also thatùëá ‚àà ‚Ñí(ùëâ) and ùëè, ùëê ‚àà ùêë with ùëè 2 < 4ùëê. Then dim null(ùëá2 + ùëèùëá + ùëêùêº)is an even number. Proof Recall that null(ùëá2 + ùëèùëá + ùëêùêº)is invariant under ùëá (by 5.18). By replacing ùëâ with null(ùëá2 + ùëèùëá + ùëêùêº)and replacing ùëá with ùëá restricted to null(ùëá2 + ùëèùëá + ùëêùêº), we can assume that ùëá2 + ùëèùëá + ùëêùêº = 0; we now need to prove that dim ùëâ is even. Suppose ùúÜ ‚àà ùêë and ùë£ ‚àà ùëâ are such that ùëáùë£ = ùúÜùë£. Then 0 =(ùëá2 + ùëèùëá + ùëêùêº)ùë£ = (ùúÜ2 + ùëèùúÜ + ùëê)ùë£ = ((ùúÜ + ùëè 2 ) 2 + ùëê ‚àí ùëè2 4 )ùë£. The term in large parentheses above is a positive number. Thus the equation above implies that ùë£ = 0. Hence we have shown that ùëá has no eigenvectors. Let ùëà be a subspace of ùëâ that is invariant under ùëá and has the largest dimension among all subspaces of ùëâ that are invariant under ùëá and have even dimension. If ùëà = ùëâ, then we are done; otherwise assume there exists ùë§ ‚àà ùëâ such that ùë§ ‚àâ ùëà. Let ùëä = span(ùë§, ùëáùë§). Then ùëä is invariant under ùëá because ùëá(ùëáùë§) = ‚àíùëèùëáùë§ ‚àí ùëêùë§. Furthermore, dim ùëä = 2because otherwise ùë§ would be an eigen- vector of ùëá. Now dim(ùëà + ùëä) = dim ùëà + dim ùëä ‚àí dim(ùëà ‚à© ùëä) =dim ùëà + 2, where ùëà ‚à© ùëä = {0}because otherwise ùëà ‚à© ùëäwould be a one-dimensional subspace of ùëâ that is invariant under ùëá (impossible because ùëá has no eigenvectors). Because ùëà + ùëä is invariant under ùëá, the equation above shows that there exists a subspace of ùëâ invariant under ùëá of even dimension larger than dim ùëà. Thus the assumption that ùëà ‚â† ùëâ was incorrect. Hence ùëâ has even dimension. 150 Chapter 5 Eigenvalues and Eigenvectors The next result states that on odd-dimensional vector spaces, every operator has an eigenvalue. We already know this result for finite-dimensional complex vectors spaces (without the odd hypothesis). Thus in the proof below, we will assume that ùêÖ = ùêë. 5.34 operators on odd-dimensional vector spaces have eigenvalues Every operator on an odd-dimensional vector space has an eigenvalue. Proof Suppose ùêÖ = ùêë and ùëâ is finite-dimensional. Letùëõ = dim ùëâ, and suppose ùëõ is an odd number. Let ùëá ‚àà ‚Ñí(ùëâ). We will use induction on ùëõ in steps of size two to show that ùëá has an eigenvalue. To get started, note that the desired result holds if dim ùëâ = 1because then every nonzero vector in ùëâ is an eigenvector of ùëá. Now suppose that ùëõ ‚â• 3and the desired result holds for all operators on all odd-dimensional vector spaces of dimension less than ùëõ. Let ùëù denote the minimal polynomial of ùëá. If ùëù is a polynomial multiple of ùë• ‚àí ùúÜ for some ùúÜ ‚àà ùêë, then ùúÜ is an eigenvalue of ùëá [by 5.27(a)]and we are done. Thus we can assume that there exist ùëè, ùëê ‚àà ùêë such that ùëè2 < 4ùëêand ùëù is a polynomial multiple of ùë•2 + ùëèùë• + ùëê (see 4.16). There exists a monic polynomial ùëû ‚àà ùí´(ùêë) such that ùëù(ùë•) = ùëû(ùë•)(ùë•2 + ùëèùë• + ùëê) for all ùë• ‚àà ùêë. Now 0 = ùëù(ùëá) =(ùëû(ùëá))(ùëá2 + ùëèùëá + ùëêùêº), which means that ùëû(ùëá) equals 0on range(ùëá2 + ùëèùëá + ùëêùêº). Because deg ùëû < deg ùëù and ùëù is the minimal polynomial of ùëá, this implies that range(ùëá2 + ùëèùëá + ùëêùêº)‚â† ùëâ. The fundamental theorem of linear maps (3.21) tells us that dim ùëâ = dim null(ùëá2 + ùëèùëá + ùëêùêº)+ dim range(ùëá2 + ùëèùëá + ùëêùêº). Because dim ùëâ is odd (by hypothesis) and dim null(ùëá2 + ùëèùëá + ùëêùêº)is even (by 5.33), the equation above shows that dim range(ùëá2 + ùëèùëá + ùëêùêº)is odd. Hence range(ùëá2 + ùëèùëá + ùëêùêº)is a subspace of ùëâ that is invariant under ùëá (by 5.18) and that has odd dimension less than dim ùëâ. Our induction hypothesis now implies that ùëá restricted to range(ùëá2 + ùëèùëá + ùëêùêº)has an eigenvalue, which means that ùëá has an eigenvalue. See Exercise 23 in Section 8B and Exercise 10 in Section 9C for alternative proofs of the result above. Exercises 5B 1 Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that 9is an eigenvalue of ùëá2 if and only if 3or ‚àí3is an eigenvalue of ùëá. 2 Suppose ùëâ is a complex vector space and ùëá ‚àà ‚Ñí(ùëâ) has no eigenvalues. Prove that every subspace of ùëâ invariant under ùëá is either {0}or infinite- dimensional. Section 5B The Minimal Polynomial 151 3 Suppose ùëõ is a positive integer and ùëá ‚àà ‚Ñí(ùêÖùëõ)is defined by ùëá(ùë•1, ‚Ä¶, ùë•ùëõ) = (ùë•1 + ‚ãØ + ùë•ùëõ, ‚Ä¶, ùë•1 + ‚ãØ + ùë•ùëõ). (a) Find all eigenvalues and eigenvectors of ùëá. (b) Find the minimal polynomial of ùëá. The matrix of ùëá with respect to the standard basis of ùêÖùëõ consists of all 1‚Äôs. 4 Suppose ùêÖ = ùêÇ, ùëá ‚àà ‚Ñí(ùëâ), ùëù ‚àà ùí´(ùêÇ), and ùõº ‚àà ùêÇ. Prove that ùõº is an eigenvalue of ùëù(ùëá) if and only if ùõº = ùëù(ùúÜ) for some eigenvalue ùúÜ of ùëá. 5 Give an example of an operator on ùêë2 that shows the result in Exercise 4 does not hold if ùêÇ is replaced with ùêë. 6 Suppose ùëá ‚àà ‚Ñí(ùêÖ2)is defined byùëá(ùë§, ùëß) = (‚àíùëß, ùë§). Find the minimal polynomial of ùëá. 7 (a) Give an example of ùëÜ, ùëá ‚àà ‚Ñí(ùêÖ2)such that the minimal polynomial of ùëÜùëá does not equal the minimal polynomial of ùëáùëÜ. (b) Suppose ùëâ is finite-dimensional andùëÜ, ùëá ‚àà ‚Ñí(ùëâ). Prove that if at least one of ùëÜ, ùëá is invertible, then the minimal polynomial of ùëÜùëá equals the minimal polynomial of ùëáùëÜ. Hint: Show that if ùëÜ is invertible and ùëù ‚àà ùí´(ùêÖ), then ùëù(ùëáùëÜ) = ùëÜ‚àí1ùëù(ùëÜùëá)ùëÜ. 8 Suppose ùëá ‚àà ‚Ñí(ùêë2)is the operator of counterclockwise rotation by 1 ‚àò. Find the minimal polynomial of ùëá. Because dim ùêë2 = 2, the degree of the minimal polynomial of ùëá is at most 2. Thus the minimal polynomial of ùëá is not the tempting polynomial ùë•180 + 1, even though ùëá180 = ‚àíùêº. 9 Suppose ùëá ‚àà ‚Ñí(ùëâ) is such that with respect to some basis of ùëâ, all entries of the matrix of ùëá are rational numbers. Explain why all coefficients of the minimal polynomial of ùëá are rational numbers. 10 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùë£ ‚àà ùëâ. Prove that span(ùë£, ùëáùë£, ‚Ä¶, ùëáùëöùë£)= span(ùë£, ùëáùë£, ‚Ä¶, ùëádim ùëâ ‚àí 1ùë£) for all integers ùëö ‚â•dim ùëâ ‚àí 1. 11 Suppose ùëâ is a two-dimensional vector space, ùëá ‚àà ‚Ñí(ùëâ), and the matrix of ùëá with respect to some basis of ùëâ is ( ùëé ùëê ùëè ùëë ). (a) Show that ùëá2 ‚àí (ùëé + ùëë)ùëá + (ùëéùëë ‚àí ùëèùëê)ùêº = 0. (b) Show that the minimal polynomial of ùëá equals ‚éß{ ‚é®{‚é© ùëß ‚àí ùëé if ùëè = ùëê = 0and ùëé = ùëë, ùëß 2 ‚àí (ùëé + ùëë)ùëß + (ùëéùëë ‚àí ùëèùëê) otherwise. 152 Chapter 5 Eigenvalues and Eigenvectors 12 Defineùëá ‚àà ‚Ñí(ùêÖùëõ)by ùëá(ùë•1, ùë•2, ùë•3, ‚Ä¶, ùë•ùëõ) = (ùë•1, 2ùë•2, 3ùë•3, ‚Ä¶, ùëõùë•ùëõ). Find the minimal polynomial of ùëá. 13 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëù ‚àà ùí´(ùêÖ). Prove that there exists a unique ùëü ‚àà ùí´(ùêÖ) such that ùëù(ùëá) = ùëü(ùëá) and deg ùëü is less than the degree of the minimal polynomial of ùëá. 14 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ) has minimal polynomial 4+ 5ùëß ‚àí 6ùëß 2 ‚àí 7ùëß 3 + 2ùëß 4 + ùëß5. Find the minimal polynomial of ùëá‚àí1. 15 Suppose ùëâ is a finite-dimensional complex vector space withdim ùëâ > 0 and ùëá ‚àà ‚Ñí(ùëâ). Defineùëì‚à∂ ùêÇ ‚Üí ùêë by ùëì (ùúÜ) = dim range(ùëá ‚àí ùúÜùêº). Prove that ùëì is not a continuous function. 16 Suppose ùëé0, ‚Ä¶, ùëéùëõ ‚àí 1 ‚àà ùêÖ. Let ùëá be the operator on ùêÖùëõ whose matrix (with respect to the standard basis) is ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 0 ‚àíùëé0 1 0 ‚àíùëé1 1 ‚ã± ‚àíùëé2 ‚ã± ‚ãÆ 0 ‚àíùëéùëõ ‚àí 2 1 ‚àíùëéùëõ ‚àí 1 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . Here all entries of the matrix are 0except for all 1‚Äôs on the line under the diagonal and the entries in the last column (some of which might also be 0). Show that the minimal polynomial of ùëá is the polynomial ùëé0 + ùëé1ùëß + ‚ãØ + ùëéùëõ ‚àí 1ùëß ùëõ ‚àí 1 + ùëßùëõ. The matrix above is called the companion matrix of the polynomial above. This exercise shows that every monic polynomial is the minimal polynomial of some operator. Hence a formula or an algorithm that could produce exact eigenvalues for each operator on each ùêÖùëõ could then produce exact zeros for each polynomial [by 5.27(a)]. Thus there is no such formula or algorithm. However, efficient numeric methods exist for obtaining very good approximations for the eigenvalues of an operator. 17 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùëù is the minimal polynomial of ùëá. Suppose ùúÜ ‚àà ùêÖ. Show that the minimal polynomial of ùëá ‚àí ùúÜùêº is the polynomial ùëû defined byùëû(ùëß) = ùëù(ùëß + ùúÜ). 18 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùëù is the minimal polynomial of ùëá. Suppose ùúÜ ‚àà ùêÖ\\{0}. Show that the minimal polynomial of ùúÜùëá is the polynomial ùëû defined byùëû(ùëß) = ùúÜdeg ùëù ùëù( ùëß ùúÜ ). Section 5B The Minimal Polynomial 153 19 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Let ‚Ñ∞ be the subspace of ‚Ñí(ùëâ) defined by ‚Ñ∞ = {ùëû(ùëá) ‚à∂ ùëû ‚àà ùí´(ùêÖ)}. Prove that dim ‚Ñ∞ equals the degree of the minimal polynomial of ùëá. 20 Suppose ùëá ‚àà ‚Ñí(ùêÖ4)is such that the eigenvalues of ùëá are 3, 5, 8. Prove that (ùëá ‚àí 3ùêº) 2(ùëá ‚àí 5ùêº) 2(ùëá ‚àí 8ùêº) 2 = 0. 21 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Prove that the minimal polynomial of ùëá has degree at most 1+ dim range ùëá. If dim range ùëá < dim ùëâ ‚àí 1, then this exercise gives a better upper bound than 5.22 for the degree of the minimal polynomial of ùëá. 22 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is invertible if and only if ùêº ‚àà span(ùëá, ùëá2, ‚Ä¶, ùëádim ùëâ). 23 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Let ùëõ = dim ùëâ. Prove that if ùë£ ‚àà ùëâ, then span(ùë£, ùëáùë£, ‚Ä¶, ùëáùëõ ‚àí 1ùë£)is invariant under ùëá. 24 Suppose ùëâ is a finite-dimensional complex vector space. Supposeùëá ‚àà ‚Ñí(ùëâ) is such that 5and 6are eigenvalues of ùëá and that ùëá has no other eigenvalues. Prove that (ùëá ‚àí 5ùêº) dim ùëâ ‚àí 1(ùëá ‚àí 6ùêº) dim ùëâ ‚àí 1 = 0. 25 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùëà is a subspace of ùëâ that is invariant under ùëá. (a) Prove that the minimal polynomial of ùëá is a polynomial multiple of the minimal polynomial of the quotient operator ùëá/ùëà. (b) Prove that (minimal polynomial of ùëá|ùëà) √ó (minimal polynomial of ùëá/ùëà) is a polynomial multiple of the minimal polynomial of ùëá. The quotient operator ùëá/ùëà was defined in Exercise 38 in Section 5A. 26 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùëà is a subspace of ùëâ that is invariant under ùëá. Prove that the set of eigenvalues of ùëá equals the union of the set of eigenvalues of ùëá|ùëà and the set of eigenvalues of ùëá/ùëà. 27 Suppose ùêÖ = ùêë, ùëâ is finite-dimensional, andùëá ‚àà ‚Ñí(ùëâ). Prove that the minimal polynomial of ùëáùêÇ equals the minimal polynomial of ùëá. The complexification ùëáùêÇ was defined in Exercise 33 of Section 3B. 28 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Prove that the minimal polynomial of ùëá‚Ä≤ ‚àà ‚Ñí(ùëâ‚Ä≤)equals the minimal polynomial of ùëá. The dual map ùëá‚Ä≤ was defined in Section 3F. 29 Show that every operator on a finite-dimensional vector space of dimension at least two has an invariant subspace of dimension two. Exercise 6 in Section 5C will give an improvement of this result when ùêÖ = ùêÇ. 154 Chapter 5 Eigenvalues and Eigenvectors 5C Upper-Triangular Matrices In Chapter 3 we defined the matrix of a linear map from a finite-dimensional vector space to another finite-dimensional vector space. That matrix depends on a choice of basis of each of the two vector spaces. Now that we are studying operators, which map a vector space to itself, the emphasis is on using only one basis. 5.35 definition: matrix of an operator, ‚Ñ≥(ùëá) Suppose ùëá ‚àà ‚Ñí(ùëâ). The matrix of ùëá with respect to a basis ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ is the ùëõ-by-ùëõ matrix ‚Ñ≥(ùëá) = ‚éõ‚éú‚éú‚éú ‚éù ùê¥1, 1 ‚ãØ ùê¥1, ùëõ ‚ãÆ ‚ãÆ ùê¥ùëõ, 1 ‚ãØ ùê¥ùëõ, ùëõ ‚éû‚éü‚éü‚éü ‚é† whose entries ùê¥ùëó, ùëò are defined by ùëáùë£ùëò = ùê¥1, ùëòùë£1 + ‚ãØ + ùê¥ùëõ, ùëòùë£ùëõ. The notation ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ))is used if the basis is not clear from the context. Operators have square matrices (meaning that the number of rows equals the number of columns), rather than the more general rectangular matrices that we considered earlier for linear maps. The ùëòth column of the matrix ‚Ñ≥(ùëá) is formed from the coefficients used to write ùëáùë£ùëò as a linear combination of the basis ùë£1, ‚Ä¶, ùë£ùëõ. If ùëá is an operator on ùêÖùëõ and no ba- sis is specified, assume that the basis in question is the standard one (where the ùëòth basis vector is 1in the ùëòth slot and 0 in all other slots). You can then think of the ùëòth column of ‚Ñ≥(ùëá) as ùëá applied to the ùëòth basis vector, where we identify ùëõ-by-1column vectors with elements of ùêÖùëõ. 5.36 example:matrix of an operator with respect to standard basis Defineùëá ‚àà ‚Ñí(ùêÖ3)by ùëá(ùë•, ùë¶, ùëß) = (2ùë•+ ùë¶, 5ùë¶+ 3ùëß, 8ùëß). Then the matrix of ùëá with respect to the standard basis of ùêÖ3 is ‚Ñ≥(ùëá) = ‚éõ‚éú‚éú‚éú ‚éù 2 1 0 0 5 3 0 0 8 ‚éû‚éü‚éü‚éü ‚é† , as you should verify. A central goal of linear algebra is to show that given an operator ùëá on a finite- dimensional vector space ùëâ, there exists a basis of ùëâ with respect to which ùëá has a reasonably simple matrix. To make this vague formulation a bit more precise, we might try to choose a basis of ùëâ such that ‚Ñ≥(ùëá) has many 0‚Äôs. Section 5C Upper-Triangular Matrices 155 If ùëâ is a finite-dimensional complex vector space, then we already know enough to show that there is a basis of ùëâ with respect to which the matrix of ùëá has 0‚Äôs everywhere in the first column, except possibly the first entry. In other words, there is a basis of ùëâ with respect to which the matrix of ùëá looks like ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú ‚éù ùúÜ 0 ‚àó ‚ãÆ 0 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü ‚é† ; here ‚àó denotes the entries in all columns other than the first column. To prove this, let ùúÜ be an eigenvalue of ùëá (one exists by 5.19) and let ùë£ be a corresponding eigenvector. Extend ùë£ to a basis of ùëâ. Then the matrix of ùëá with respect to this basis has the form above. Soon we will see that we can choose a basis of ùëâ with respect to which the matrix of ùëá has even more 0‚Äôs. 5.37 definition:diagonal of a matrix The diagonal of a square matrix consists of the entries on the line from the upper left corner to the bottom right corner. For example, the diagonal of the matrix ‚Ñ≥(ùëá) = ‚éõ‚éú‚éú‚éú ‚éù 2 1 0 0 5 3 0 08 ‚éû‚éü‚éü‚éü ‚é† from Example 5.36 consists of the entries 2, 5, 8, which are shown in red in the matrix above. 5.38 definition: upper-triangular matrix A square matrix is called upper triangular if all entries below the diagonal are 0. For example, the 3-by-3matrix above is upper triangular. Typically we represent an upper-triangular matrix in the form ‚éõ‚éú‚éú‚éú ‚éù ùúÜ1 ‚àó ‚ã± 0 ùúÜùëõ ‚éû‚éü‚éü‚éü ‚é† ; We often use ‚àó to denote matrix entries that we do not know or that are irrele- vant to the questions being discussed. the 0in the matrix above indicates that all entries below the diagonal in this ùëõ-by-ùëõ matrix equal 0. Upper-triangular matrices can be considered reasonably simple‚Äîif ùëõ is large, then at least almost half the entries in an ùëõ-by-ùëõ upper- triangular matrix are 0. 156 Chapter 5 Eigenvalues and Eigenvectors The next result provides a useful connection between upper-triangular matrices and invariant subspaces. 5.39 conditions for upper-triangular matrix Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Then the following are equivalent. (a) The matrix of ùëá with respect to ùë£1, ‚Ä¶, ùë£ùëõ is upper triangular. (b) span(ùë£1, ‚Ä¶, ùë£ùëò) is invariant under ùëá for each ùëò = 1, ‚Ä¶, ùëõ. (c) ùëáùë£ùëò ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò) for each ùëò = 1, ‚Ä¶, ùëõ. Proof First suppose (a) holds. To prove that (b) holds, suppose ùëò ‚àà {1, ‚Ä¶, ùëõ}. If ùëó ‚àà {1, ‚Ä¶, ùëõ}, then ùëáùë£ùëó ‚àà span(ùë£1, ‚Ä¶, ùë£ùëó) because the matrix of ùëá with respect to ùë£1, ‚Ä¶, ùë£ùëõ is upper triangular. Because span(ùë£1, ‚Ä¶, ùë£ùëó) ‚äÜspan(ùë£1, ‚Ä¶, ùë£ùëò) if ùëó ‚â§ ùëò, we see that ùëáùë£ùëó ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò) for each ùëó ‚àà {1, ‚Ä¶, ùëò}. Thus span(ùë£1, ‚Ä¶, ùë£ùëò) is invariant under ùëá, completing the proof that (a) implies (b). Now suppose (b) holds, so span(ùë£1, ‚Ä¶, ùë£ùëò) is invariant under ùëá for each ùëò = 1, ‚Ä¶, ùëõ. In particular, ùëáùë£ùëò ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò) for each ùëò = 1, ‚Ä¶, ùëõ. Thus (b) implies (c). Now suppose (c) holds, so ùëáùë£ùëò ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò) for each ùëò = 1, ‚Ä¶, ùëõ. This means that when writing each ùëáùë£ùëò as a linear combination of the basis vectors ùë£1, ‚Ä¶, ùë£ùëõ, we need to use only the vectors ùë£1, ‚Ä¶, ùë£ùëò. Hence all entries under the diagonal of ‚Ñ≥(ùëá) are 0. Thus ‚Ñ≥(ùëá) is an upper-triangular matrix, completing the proof that (c) implies (a). We have shown that (a) ‚üπ (b) ‚üπ (c) ‚üπ (a), which shows that (a), (b), and (c) are equivalent. The next result tells us that if ùëá ‚àà ‚Ñí(ùëâ) and with respect to some basis of ùëâ we have ‚Ñ≥(ùëá) = ‚éõ‚éú‚éú‚éú ‚éù ùúÜ1 ‚àó ‚ã± 0 ùúÜùëõ ‚éû‚éü‚éü‚éü ‚é† , then ùëá satisfies a simple equation depending onùúÜ1, ‚Ä¶, ùúÜùëõ. 5.40 equation satisfied by operator with upper-triangular matrix Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëâ has a basis with respect to which ùëá has an upper- triangular matrix with diagonal entries ùúÜ1, ‚Ä¶, ùúÜùëõ. Then (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëõùêº) = 0. Section 5C Upper-Triangular Matrices 157 Proof Let ùë£1, ‚Ä¶, ùë£ùëõ denote a basis of ùëâ with respect to which ùëá has an upper- triangular matrix with diagonal entries ùúÜ1, ‚Ä¶, ùúÜùëõ. Then ùëáùë£1 = ùúÜ1ùë£1, which means that (ùëá ‚àí ùúÜ1ùêº)ùë£1 = 0, which implies that (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëöùêº)ùë£1 = 0for ùëö = 1, ‚Ä¶, ùëõ (using the commutativity of each ùëá ‚àí ùúÜùëóùêº with each ùëá ‚àí ùúÜùëòùêº). Note that (ùëá ‚àí ùúÜ2ùêº)ùë£2 ‚àà span(ùë£1). Thus (ùëá ‚àí ùúÜ1ùêº)(ùëá ‚àí ùúÜ2ùêº)ùë£2 = 0(by the previous paragraph), which implies that (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëöùêº)ùë£1 = 0for ùëö = 2, ‚Ä¶, ùëõ (using the commutativity of each ùëá ‚àí ùúÜùëóùêº with each ùëá ‚àí ùúÜùëòùêº). Note that (ùëá ‚àí ùúÜ3ùêº)ùë£3 ‚àà span(ùë£1, ùë£2). Thus by the previous paragraph, (ùëá‚àíùúÜ1ùêº)(ùëá‚àíùúÜ2ùêº)(ùëá‚àíùúÜ3ùêº)ùë£3 = 0, which implies that (ùëá‚àíùúÜ1ùêº)‚ãØ(ùëá‚àíùúÜùëöùêº)ùë£1 = 0 for ùëö = 3, ‚Ä¶, ùëõ (using the commutativity of each ùëá ‚àí ùúÜùëóùêº with each ùëá ‚àí ùúÜùëòùêº). Continuing this pattern, we see that (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëõùêº)ùë£ùëò = 0for each ùëò = 1, ‚Ä¶, ùëõ. Thus (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëõùêº) is the 0operator because it is 0on each vector in a basis of ùëâ. Unfortunately no method exists for exactly computing the eigenvalues of an operator from its matrix. However, if we are fortunate enough to find a basis with respect to which the matrix of the operator is upper triangular, then the problem of computing the eigenvalues becomes trivial, as the next result shows. 5.41 determination of eigenvalues from upper-triangular matrix Suppose ùëá ‚àà ‚Ñí(ùëâ) has an upper-triangular matrix with respect to some basis of ùëâ. Then the eigenvalues of ùëá are precisely the entries on the diagonal of that upper-triangular matrix. Proof Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ with respect to which ùëá has an upper- triangular matrix ‚Ñ≥(ùëá) = ‚éõ‚éú‚éú‚éú ‚éù ùúÜ1 ‚àó ‚ã± 0 ùúÜùëõ ‚éû‚éü‚éü‚éü ‚é† . Because ùëáùë£1 = ùúÜ1ùë£1, we see that ùúÜ1 is an eigenvalue of ùëá. Suppose ùëò ‚àà {2, ‚Ä¶, ùëõ}. Then (ùëá ‚àí ùúÜùëòùêº)ùë£ùëò ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1). Thus ùëá ‚àí ùúÜùëòùêº maps span(ùë£1, ‚Ä¶, ùë£ùëò) into span(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1). Because dim span(ùë£1, ‚Ä¶, ùë£ùëò) = ùëò and dim span(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1) = ùëò ‚àí 1, this implies that ùëá ‚àí ùúÜùëòùêº restricted to span(ùë£1, ‚Ä¶, ùë£ùëò) is not injective (by 3.22). Thus there exists ùë£ ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò) such that ùë£ ‚â† 0and (ùëá ‚àí ùúÜùëòùêº)ùë£ = 0. Thus ùúÜùëò is an eigenvalue of ùëá. Hence we have shown that every entry on the diagonal of ‚Ñ≥(ùëá) is an eigenvalue of ùëá. To prove ùëá has no other eigenvalues, let ùëû be the polynomial defined by ùëû(ùëß) = (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëõ). Then ùëû(ùëá) = 0(by 5.40). Hence ùëû is a polynomial multiple of the minimal polynomial of ùëá (by 5.29). Thus every zero of the minimal polynomial of ùëá is a zero of ùëû. Because the zeros of the minimal polynomial of ùëá are the eigenvalues of ùëá (by 5.27), this implies that every eigenvalue of ùëá is a zero of ùëû. Hence the eigenvalues of ùëá are all contained in the list ùúÜ1, ‚Ä¶, ùúÜùëõ. 158 Chapter 5 Eigenvalues and Eigenvectors 5.42 example: eigenvalues via an upper-triangular matrix Defineùëá ‚àà ‚Ñí(ùêÖ3)by ùëá(ùë•, ùë¶, ùëß) = (2ùë•+ ùë¶, 5ùë¶+ 3ùëß, 8ùëß). The matrix of ùëá with respect to the standard basis is ‚Ñ≥(ùëá) = ‚éõ‚éú‚éú‚éú ‚éù 2 1 0 0 5 3 0 0 8 ‚éû‚éü‚éü‚éü ‚é† . Now 5.41 implies that the eigenvalues of ùëá are 2, 5, and 8. The next example illustrates 5.44: an operator has an upper-triangular matrix with respect to some basis if and only if the minimal polynomial of the operator is the product of polynomials of degree 1. 5.43 example: whether ùëá has an upper-triangular matrix can depend on ùêÖ Defineùëá ‚àà ‚Ñí(ùêÖ4)by ùëá(ùëß1, ùëß2, ùëß3, ùëß4) = (‚àíùëß2, ùëß1, 2ùëß1 + 3ùëß3, ùëß3 + 3ùëß4). Thus with respect to the standard basis of ùêÖ4, the matrix of ùëá is ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 0 ‚àí1 0 0 1 0 0 0 2 0 3 0 0 0 1 3 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . You can ask a computer to verify that the minimal polynomial of ùëá is the polyno- mial ùëù defined by ùëù(ùëß) = 9 ‚àí 6ùëß+ 10ùëß 2 ‚àí 6ùëß 3 + ùëß4. First consider the case ùêÖ = ùêë. Then the polynomial ùëù factors as ùëù(ùëß) = (ùëß 2 + 1)(ùëß ‚àí 3)(ùëß ‚àí 3), with no further factorization of ùëß 2 + 1as the product of two polynomials of degree 1with real coefficients. Thus 5.44 states that there does not exist a basis of ùêë4 with respect to which ùëá has an upper-triangular matrix. Now consider the case ùêÖ = ùêÇ. Then the polynomial ùëù factors as ùëù(ùëß) = (ùëß ‚àí ùëñ)(ùëß + ùëñ)(ùëß ‚àí 3)(ùëß ‚àí 3), where all factors above have the form ùëß‚àí ùúÜùëò. Thus 5.44 states that there is a basis of ùêÇ 4 with respect to which ùëá has an upper-triangular matrix. Indeed, you can verify that with respect to the basis (4 ‚àí 3ùëñ, ‚àí3 ‚àí 4ùëñ, ‚àí3+ ùëñ, 1), (4+ 3ùëñ, ‚àí3+ 4ùëñ, ‚àí3 ‚àí ùëñ, 1), (0, 0, 0, 1), (0, 0, 1, 0)of ùêÇ4, the operator ùëá has the upper-triangular matrix ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú ‚éù ùëñ 0 0 0 0 ‚àíùëñ 0 0 0 0 3 1 0 0 0 3 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . Section 5C Upper-Triangular Matrices 159 5.44 necessary and sufficient condition to have an upper-triangular matrix Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Then ùëá has an upper- triangular matrix with respect to some basis of ùëâ if and only if the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö) for some ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÖ. Proof First suppose ùëá has an upper-triangular matrix with respect to some basis of ùëâ. Let ùõº1, ‚Ä¶, ùõºùëõ denote the diagonal entries of that matrix. Define a polynomial ùëû ‚àà ùí´(ùêÖ) by ùëû(ùëß) = (ùëß ‚àí ùõº1)‚ãØ(ùëß ‚àí ùõºùëõ). Then ùëû(ùëá) = 0, by 5.40. Hence ùëû is a polynomial multiple of the minimal polyno- mial of ùëá, by 5.29. Thus the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö) for some ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÖ with {ùúÜ1, ‚Ä¶, ùúÜùëö} ‚äÜ {ùõº1, ‚Ä¶, ùõºùëõ}. To prove the implication in the other direction, now suppose the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö) for some ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÖ. We will use induction on ùëö. To get started, if ùëö = 1then ùëß ‚àí ùúÜ1 is the minimal polynomial of ùëá, which implies that ùëá = ùúÜ1ùêº, which implies that the matrix of ùëá (with respect to any basis of ùëâ) is upper triangular. Now suppose ùëö > 1and the desired result holds for all smaller positive integers. Let ùëà = range(ùëá ‚àí ùúÜùëöùêº). Then ùëà is invariant under ùëá [this is a special case of 5.18 with ùëù(ùëß) = ùëß ‚àí ùúÜùëö]. Thus ùëá|ùëà is an operator on ùëà. If ùë¢ ‚àà ùëà, then ùë¢ = (ùëá ‚àí ùúÜùëöùêº)ùë£ for some ùë£ ‚àà ùëâ and (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëö ‚àí 1ùêº)ùë¢ = (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëöùêº)ùë£ = 0. Hence (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö ‚àí 1) is a polynomial multiple of the minimal polynomial of ùëá|ùëà, by 5.29. Thus the minimal polynomial of ùëá|ùëà is the product of at most ùëö ‚àí 1terms of the form ùëß ‚àí ùúÜùëò. By our induction hypothesis, there is a basis ùë¢1, ‚Ä¶, ùë¢ùëÄ of ùëà with respect to which ùëá|ùëà has an upper-triangular matrix. Thus for each ùëò ‚àà {1, ‚Ä¶, ùëÄ}, we have (using 5.39) 5.45 ùëáùë¢ùëò = (ùëá|ùëà)(ùë¢ùëò) ‚àà span(ùë¢1, ‚Ä¶, ùë¢ùëò). Extend ùë¢1, ‚Ä¶, ùë¢ùëÄ to a basis ùë¢1, ‚Ä¶, ùë¢ùëÄ, ùë£1, ‚Ä¶, ùë£ùëÅ of ùëâ. For each ùëò ‚àà {1, ‚Ä¶, ùëÅ}, we have ùëáùë£ùëò = (ùëá ‚àí ùúÜùëöùêº)ùë£ùëò + ùúÜùëöùë£ùëò. The definition ofùëà shows that (ùëá ‚àí ùúÜùëöùêº)ùë£ùëò ‚àà ùëà = span(ùë¢1, ‚Ä¶, ùë¢ùëÄ). Thus the equation above shows that 5.46 ùëáùë£ùëò ‚àà span(ùë¢1, ‚Ä¶, ùë¢ùëÄ, ùë£1, ‚Ä¶, ùë£ùëò). From 5.45 and 5.46, we conclude (using 5.39) that ùëá has an upper-triangular matrix with respect to the basis ùë¢1, ‚Ä¶, ùë¢ùëÄ, ùë£1, ‚Ä¶, ùë£ùëÅ of ùëâ, as desired. 160 Chapter 5 Eigenvalues and Eigenvectors The set of numbers {ùúÜ1, ‚Ä¶, ùúÜùëö} from the previous result equals the set of eigenvalues of ùëá (because the set of zeros of the minimal polynomial of ùëá equals the set of eigenvalues of ùëá, by 5.27), although the list ùúÜ1, ‚Ä¶, ùúÜùëö in the previous result may contain repetitions. In Chapter 8 we will improve even the wonderful result below; see 8.37 and 8.46. 5.47 if ùêÖ = ùêÇ, then every operator on ùëâ has an upper-triangular matrix Suppose ùëâ is a finite-dimensional complex vector space andùëá ‚àà ‚Ñí(ùëâ). Then ùëá has an upper-triangular matrix with respect to some basis of ùëâ. Proof The desired result follows immediately from 5.44 and the second version of the fundamental theorem of algebra (see 4.13). For an extension of the result above to two operators ùëÜ and ùëá such that ùëÜùëá = ùëáùëÜ, see 5.80. Also, for an extension to more than two operators, see Exercise 9(b) in Section 5E. Caution: If an operator ùëá ‚àà ‚Ñí(ùëâ) has a upper-triangular matrix with respect to some basis ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ, then the eigenvalues of ùëá are exactly the entries on the diagonal of ‚Ñ≥(ùëá), as shown by 5.41, and furthermore ùë£1 is an eigenvector of ùëá. However, ùë£2, ‚Ä¶, ùë£ùëõ need not be eigenvectors of ùëá. Indeed, a basis vector ùë£ùëò is an eigenvector of ùëá if and only if all entries in the ùëòth column of the matrix of ùëá are 0, except possibly the ùëòth entry. The row echelon form of the matrix of an operator does not give us a list of the eigenvalues of the operator. In contrast, an upper-triangular matrix with respect to some basis gives us a list of all the eigenvalues of the op- erator. However, there is no method for computing exactly such an upper- triangular matrix, even though 5.47 guarantees its existence if ùêÖ = ùêÇ. You may recall from a previous course that every matrix of numbers can be changed to a matrix in what is called row echelon form. If one begins with a square matrix, the matrix in row echelon form will be an upper-triangular matrix. Do not confuse this upper-triangular ma- trix with the upper-triangular matrix of an operator with respect to some basis whose existence is proclaimed by 5.47 (if ùêÖ = ùêÇ)‚Äîthere is no connection between these upper-triangular matrices. Exercises 5C 1 Prove or give a counterexample: If ùëá ‚àà ‚Ñí(ùëâ) and ùëá2 has an upper-triangular matrix with respect to some basis of ùëâ, then ùëá has an upper-triangular matrix with respect to some basis of ùëâ. Section 5C Upper-Triangular Matrices 161 2 Suppose ùê¥ and ùêµ are upper-triangular matrices of the same size, with ùõº1, ‚Ä¶, ùõºùëõ on the diagonal of ùê¥ and ùõΩ1, ‚Ä¶, ùõΩùëõ on the diagonal of ùêµ. (a) Show that ùê¥ + ùêµ is an upper-triangular matrix with ùõº1 + ùõΩ1, ‚Ä¶, ùõºùëõ + ùõΩùëõ on the diagonal. (b) Show that ùê¥ùêµ is an upper-triangular matrix with ùõº1ùõΩ1, ‚Ä¶, ùõºùëõùõΩùëõ on the diagonal. The results in this exercise are used in the proof of 5.81. 3 Suppose ùëá ‚àà ‚Ñí(ùëâ) is invertible and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ with respect to which the matrix of ùëá is upper triangular, with ùúÜ1, ‚Ä¶, ùúÜùëõ on the diagonal. Show that the matrix of ùëá‚àí1 is also upper triangular with respect to the basis ùë£1, ‚Ä¶, ùë£ùëõ, with 1 ùúÜ1 , ‚Ä¶, 1 ùúÜùëõ on the diagonal. 4 Give an example of an operator whose matrix with respect to some basis contains only 0‚Äôs on the diagonal, but the operator is invertible. This exercise and the exercise below show that 5.41 fails without the hypoth- esis that an upper-triangular matrix is under consideration. 5 Give an example of an operator whose matrix with respect to some basis contains only nonzero numbers on the diagonal, but the operator is not invertible. 6 Suppose ùêÖ = ùêÇ, ùëâ is finite-dimensional, andùëá ‚àà ‚Ñí(ùëâ). Prove that if ùëò ‚àà {1, ‚Ä¶, dim ùëâ}, then ùëâ has a ùëò-dimensional subspace invariant under ùëá. 7 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùë£ ‚àà ùëâ. (a) Prove that there exists a unique monic polynomial ùëùùë£ of smallest degree such that ùëùùë£(ùëá)ùë£ = 0. (b) Prove that the minimal polynomial of ùëá is a polynomial multiple of ùëùùë£. 8 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and there exists a nonzero vector ùë£ ‚àà ùëâ such that ùëá2ùë£ + 2ùëáùë£ = ‚àí2ùë£. (a) Prove that if ùêÖ = ùêë, then there does not exist a basis of ùëâ with respect to which ùëá has an upper-triangular matrix. (b) Prove that if ùêÖ = ùêÇ and ùê¥ is an upper-triangular matrix that equals the matrix of ùëá with respect to some basis of ùëâ, then ‚àí1+ ùëñ or ‚àí1 ‚àí ùëñ appears on the diagonal of ùê¥. 9 Suppose ùêµ is a square matrix with complex entries. Prove that there exists an invertible square matrix ùê¥ with complex entries such that ùê¥ ‚àí1ùêµùê¥ is an upper-triangular matrix. 162 Chapter 5 Eigenvalues and Eigenvectors 10 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Show that the following are equivalent. (a) The matrix of ùëá with respect to ùë£1, ‚Ä¶, ùë£ùëõ is lower triangular. (b) span(ùë£ùëò, ‚Ä¶, ùë£ùëõ) is invariant under ùëá for each ùëò = 1, ‚Ä¶, ùëõ. (c) ùëáùë£ùëò ‚àà span(ùë£ùëò, ‚Ä¶, ùë£ùëõ) for each ùëò = 1, ‚Ä¶, ùëõ. A square matrix is called lower triangular if all entries above the diagonal are 0. 11 Suppose ùêÖ = ùêÇ and ùëâ is finite-dimensional. Prove that ifùëá ‚àà ‚Ñí(ùëâ), then there exists a basis of ùëâ with respect to which ùëá has a lower-triangular matrix. 12 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ) has an upper-triangular matrix with respect to some basis of ùëâ, and ùëà is a subspace of ùëâ that is invariant under ùëá. (a) Prove that ùëá|ùëà has an upper-triangular matrix with respect to some basis of ùëà. (b) Prove that the quotient operator ùëá/ùëà has an upper-triangular matrix with respect to some basis of ùëâ/ùëà. The quotient operator ùëá/ùëà was defined in Exercise 38 in Section 5A. 13 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Suppose there exists a subspace ùëà of ùëâ that is invariant under ùëá such that ùëá|ùëà has an upper- triangular matrix with respect to some basis of ùëà and also ùëá/ùëà has an upper-triangular matrix with respect to some basis of ùëâ/ùëà. Prove that ùëá has an upper-triangular matrix with respect to some basis of ùëâ. 14 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá has an upper- triangular matrix with respect to some basis of ùëâ if and only if the dual operator ùëá‚Ä≤ has an upper-triangular matrix with respect to some basis of the dual space ùëâ‚Ä≤. Open Access This chapter is licensed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (https://creativecommons.org/licenses/by-nc/4.0), which permits any noncommercial use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to original author and source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this chapter are included in the chapter‚Äôs Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter‚Äôs Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. Section 5D Diagonalizable Operators 163 5D Diagonalizable Operators Diagonal Matrices 5.48 definition: diagonal matrix A diagonal matrix is a square matrix that is 0everywhere except possibly on the diagonal. 5.49 example: diagonal matrix ‚éõ‚éú‚éú‚éú ‚éù 8 0 0 0 5 0 0 0 5 ‚éû‚éü‚éü‚éü ‚é† is a diagonal matrix. Every diagonal matrix is upper tri- angular. Diagonal matrices typically have many more 0‚Äôs than most upper- triangular matrices of the same size. If an operator has a diagonal matrix with respect to some basis, then the en- tries on the diagonal are precisely the eigenvalues of the operator; this follows from 5.41 (or find an easier direct proof for diagonal matrices). 5.50 definition: diagonalizable An operator on ùëâ is called diagonalizable if the operator has a diagonal matrix with respect to some basis of ùëâ. 5.51 example: diagonalization may require a different basis Defineùëá ‚àà ‚Ñí(ùêë2)by ùëá(ùë•, ùë¶) = (41ùë•+ 7ùë¶, ‚àí20ùë•+ 74ùë¶). The matrix of ùëá with respect to the standard basis of ùêë2 is ( 41 7 ‚àí20 74 ), which is not a diagonal matrix. However, ùëá is diagonalizable. Specifically, the matrix of ùëá with respect to the basis (1, 4), (7, 5)is ( 69 0 0 46 ) because ùëá(1, 4) = (69, 276) = 69(1, 4)and ùëá(7, 5) = (322, 230) = 46(7, 5). 164 Chapter 5 Eigenvalues and Eigenvectors For ùúÜ ‚àà ùêÖ, we will find it convenient to have a name and a notation for the set of vectors that an operator ùëá maps to ùúÜ times the vector. 5.52 definition: eigenspace, ùê∏(ùúÜ, ùëá) Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ ‚àà ùêÖ. The eigenspace of ùëá corresponding to ùúÜ is the subspace ùê∏(ùúÜ, ùëá) of ùëâ defined by ùê∏(ùúÜ, ùëá) = null(ùëá ‚àí ùúÜùêº) = {ùë£ ‚àà ùëâ ‚à∂ ùëáùë£ = ùúÜùë£}. Hence ùê∏(ùúÜ, ùëá) is the set of all eigenvectors of ùëá corresponding to ùúÜ, along with the 0vector. For ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ ‚àà ùêÖ, the set ùê∏(ùúÜ, ùëá) is a subspace of ùëâ because the null space of each linear map on ùëâ is a subspace of ùëâ. The definitions imply thatùúÜ is an eigenvalue of ùëá if and only if ùê∏(ùúÜ, ùëá) ‚â† {0}. 5.53 example: eigenspaces of an operator Suppose the matrix of an operator ùëá ‚àà ‚Ñí(ùëâ) with respect to a basis ùë£1, ùë£2, ùë£3 of ùëâ is the matrix in Example 5.49. Then ùê∏(8, ùëá) = span(ùë£1), ùê∏(5, ùëá) = span(ùë£2, ùë£3). If ùúÜ is an eigenvalue of an operator ùëá ‚àà ‚Ñí(ùëâ), then ùëá restricted to ùê∏(ùúÜ, ùëá) is just the operator of multiplication by ùúÜ. 5.54 sum of eigenspaces is a direct sum Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ1, ‚Ä¶, ùúÜùëö are distinct eigenvalues of ùëá. Then ùê∏(ùúÜ1, ùëá) + ‚ãØ + ùê∏(ùúÜùëö, ùëá) is a direct sum. Furthermore, if ùëâ is finite-dimensional, then dim ùê∏(ùúÜ1, ùëá) + ‚ãØ + dim ùê∏(ùúÜùëö, ùëá) ‚â§dim ùëâ. Proof To show that ùê∏(ùúÜ1, ùëá) + ‚ãØ + ùê∏(ùúÜùëö, ùëá) is a direct sum, suppose ùë£1 + ‚ãØ + ùë£ùëö = 0, where each ùë£ùëò is in ùê∏(ùúÜùëò, ùëá). Because eigenvectors corresponding to distinct eigenvalues are linearly independent (by 5.11), this implies that each ùë£ùëò equals 0. Thus ùê∏(ùúÜ1, ùëá) + ‚ãØ + ùê∏(ùúÜùëö, ùëá) is a direct sum (by 1.45), as desired. Now suppose ùëâ is finite-dimensional. Then dim ùê∏(ùúÜ1, ùëá) + ‚ãØ + dim ùê∏(ùúÜùëö, ùëá) = dim(ùê∏(ùúÜ1, ùëá) ‚äï ‚ãØ ‚äï ùê∏(ùúÜùëö, ùëá)) ‚â§dim ùëâ, where the first line follows from3.94 and the second line follows from 2.37. Section 5D Diagonalizable Operators 165 Conditions for Diagonalizability The following characterizations of diagonalizable operators will be useful. 5.55 conditions equivalent to diagonalizability Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Let ùúÜ1, ‚Ä¶, ùúÜùëö denote the distinct eigenvalues of ùëá. Then the following are equivalent. (a) ùëá is diagonalizable. (b) ùëâ has a basis consisting of eigenvectors of ùëá. (c) ùëâ = ùê∏(ùúÜ1, ùëá) ‚äï ‚ãØ ‚äï ùê∏(ùúÜùëö, ùëá). (d) dim ùëâ = dim ùê∏(ùúÜ1, ùëá) + ‚ãØ + dim ùê∏(ùúÜùëö, ùëá). Proof An operator ùëá ‚àà ‚Ñí(ùëâ) has a diagonal matrix ‚éõ‚éú‚éú‚éú ‚éù ùúÜ1 0 ‚ã± 0 ùúÜùëõ ‚éû‚éü‚éü‚éü ‚é† with respect to a basis ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ if and only if ùëáùë£ùëò = ùúÜùëòùë£ùëò for each ùëò. Thus (a) and (b) are equivalent. Suppose (b) holds; thus ùëâ has a basis consisting of eigenvectors of ùëá. Hence every vector in ùëâ is a linear combination of eigenvectors of ùëá, which implies that ùëâ = ùê∏(ùúÜ1, ùëá) + ‚ãØ + ùê∏(ùúÜùëö, ùëá). Now 5.54 shows that (c) holds, proving that (b) implies (c). That (c) implies (d) follows immediately from 3.94. Finally, suppose (d) holds; thus 5.56 dim ùëâ = dim ùê∏(ùúÜ1, ùëá) + ‚ãØ + dim ùê∏(ùúÜùëö, ùëá). Choose a basis of each ùê∏(ùúÜùëò, ùëá); put all these bases together to form a list ùë£1, ‚Ä¶, ùë£ùëõ of eigenvectors of ùëá, where ùëõ = dim ùëâ (by 5.56). To show that this list is linearly independent, suppose ùëé1ùë£1 + ‚ãØ + ùëéùëõùë£ùëõ = 0, where ùëé1, ‚Ä¶, ùëéùëõ ‚àà ùêÖ. For each ùëò = 1, ‚Ä¶, ùëö, let ùë¢ùëò denote the sum of all the terms ùëéùëóùë£ùëó such that ùë£ùëó ‚àà ùê∏(ùúÜùëò, ùëá). Thus each ùë¢ùëò is in ùê∏(ùúÜùëò, ùëá), and ùë¢1 + ‚ãØ + ùë¢ùëö = 0. Because eigenvectors corresponding to distinct eigenvalues are linearly indepen- dent (see 5.11), this implies that each ùë¢ùëò equals 0. Because each ùë¢ùëò is a sum of terms ùëéùëóùë£ùëó, where the ùë£ùëó‚Äôs were chosen to be a basis of ùê∏(ùúÜùëò, ùëá), this implies that all ùëéùëó‚Äôs equal 0. Thus ùë£1, ‚Ä¶, ùë£ùëõ is linearly independent and hence is a basis of ùëâ (by 2.38). Thus (d) implies (b), completing the proof. For additional conditions equivalent to diagonalizability, see 5.62, Exercises 5 and 15 in this section, Exercise 24 in Section 7B, and Exercise 15 in Section 8A. 166 Chapter 5 Eigenvalues and Eigenvectors As we know, every operator on a finite-dimensional complex vector space has an eigenvalue. However, not every operator on a finite-dimensional complex vector space has enough eigenvectors to be diagonalizable, as shown by the next example. 5.57 example:an operator that is not diagonalizable Define an operatorùëá ‚àà ‚Ñí(ùêÖ3)by ùëá(ùëé, ùëè, ùëê) = (ùëè, ùëê, 0). The matrix of ùëá with respect to the standard basis of ùêÖ3 is ‚éõ‚éú‚éú‚éú ‚éù 0 1 0 0 0 1 0 0 0 ‚éû‚éü‚éü‚éü ‚é† , which is an upper-triangular matrix but is not a diagonal matrix. As you should verify, 0is the only eigenvalue of ùëá and furthermore ùê∏(0, ùëá) = {(ùëé, 0, 0) ‚àà ùêÖ 3 ‚à∂ ùëé ‚àà ùêÖ}. Hence conditions (b), (c), and (d) of 5.55 fail (of course, because these conditions are equivalent, it is sufficient to check that only one of them fails). Thus condition (a) of 5.55 also fails. Hence ùëá is not diagonalizable, regardless of whether ùêÖ = ùêë or ùêÖ = ùêÇ. The next result shows that if an operator has as many distinct eigenvalues as the dimension of its domain, then the operator is diagonalizable. 5.58 enough eigenvalues implies diagonalizability Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ) has dim ùëâ distinct eigenvalues. Then ùëá is diagonalizable. Proof Suppose ùëá has distinct eigenvalues ùúÜ1, ‚Ä¶, ùúÜdim ùëâ. For each ùëò, let ùë£ùëò ‚àà ùëâ be an eigenvector corresponding to the eigenvalue ùúÜùëò. Because eigenvectors corre- sponding to distinct eigenvalues are linearly independent (see 5.11), ùë£1, ‚Ä¶, ùë£dim ùëâ is linearly independent. A linearly independent list of dim ùëâ vectors in ùëâ is a basis of ùëâ (see 2.38); thus ùë£1, ‚Ä¶, ùë£dim ùëâ is a basis of ùëâ. With respect to this basis consisting of eigenvectors, ùëá has a diagonal matrix. In later chapters we will find additional conditions that imply that certain operators are diagonalizable. For example, see the real spectral theorem (7.29) and the complex spectral theorem (7.31). The result above gives a sufficient condition for an operator to be diagonal- izable. However, this condition is not necessary. For example, the operator ùëá on ùêÖ3 defined byùëá(ùë•, ùë¶, ùëß) = (6ùë•, 6ùë¶, 7ùëß)has only two eigenvalues (6and 7) and dim ùêÖ3 = 3, but ùëá is diagonalizable (by the standard basis of ùêÖ3). Section 5D Diagonalizable Operators 167 For a spectacular application of these techniques, see Exercise 21, which shows how to use diagonalization to find an exact formula for the ùëõth term of the Fibonacci sequence. The next example illustrates the im- portance of diagonalization, which can be used to compute high powers of an operator, taking advantage of the equa- tion ùëáùëòùë£ = ùúÜùëòùë£ if ùë£ is an eigenvector of ùëá with eigenvalue ùúÜ. 5.59 example: using diagonalization to compute ùëá100 Defineùëá ‚àà ‚Ñí(ùêÖ3)by ùëá(ùë•, ùë¶, ùëß) = (2ùë•+ ùë¶, 5ùë¶+ 3ùëß, 8ùëß). With respect to the standard basis, the matrix of ùëá is ‚éõ‚éú‚éú‚éú ‚éù 2 1 0 0 5 3 0 0 8 ‚éû‚éü‚éü‚éü ‚é† . The matrix above is an upper-triangular matrix but it is not a diagonal matrix. By 5.41, the eigenvalues of ùëá are 2, 5, and 8. Because ùëá is an operator on a vector space of dimension three and ùëá has three distinct eigenvalues, 5.58 assures us that there exists a basis of ùêÖ3 with respect to which ùëá has a diagonal matrix. To find this basis, we only have to find an eigenvector for each eigenvalue. In other words, we have to find a nonzero solution to the equation ùëá(ùë•, ùë¶, ùëß) = ùúÜ(ùë•, ùë¶, ùëß) for ùúÜ = 2, then for ùúÜ = 5, and then for ùúÜ = 8. Solving these simple equations shows that for ùúÜ = 2we have an eigenvector (1, 0, 0), for ùúÜ = 5we have an eigenvector (1, 3, 0), and for ùúÜ = 8we have an eigenvector (1, 6, 6). Thus (1, 0, 0), (1, 3, 0), (1, 6, 6)is a basis of ùêÖ3 consisting of eigenvectors of ùëá, and with respect to this basis the matrix of ùëá is the diagonal matrix ‚éõ‚éú‚éú‚éú ‚éù 2 0 0 0 5 0 0 0 8 ‚éû‚éü‚éü‚éü ‚é† . To compute ùëá100(0, 0, 1), for example, write (0, 0, 1)as a linear combination of our basis of eigenvectors: (0, 0, 1) = 1 6 (1, 0, 0) ‚àí 1 3 (1, 3, 0)+ 1 6 (1, 6, 6). Now apply ùëá100 to both sides of the equation above, getting ùëá100(0, 0, 1) = 1 6 (ùëá100(1, 0, 0))‚àí 1 3 (ùëá100(1, 3, 0))+ 1 6 (ùëá100(1, 6, 6)) = 1 6 (2 100(1, 0, 0) ‚àí 2 ‚ãÖ 5 100(1, 3, 0)+ 8 100(1, 6, 6)) = 1 6 (2 100 ‚àí 2 ‚ãÖ 5 100 + 8 100, 6 ‚ãÖ 8 100 ‚àí 6 ‚ãÖ 5 100, 6 ‚ãÖ 8 100). 168 Chapter 5 Eigenvalues and Eigenvectors We saw earlier that an operator ùëá on a finite-dimensional vector spaceùëâ has an upper-triangular matrix with respect to some basis of ùëâ if and only if the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö) for some ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÖ (see 5.44). As we previously noted (see 5.47), this condition is always satisfied ifùêÖ = ùêÇ. Our next result 5.62 states that an operator ùëá ‚àà ‚Ñí(ùëâ) has a diagonal matrix with respect to some basis of ùëâ if and only if the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö) for some distinct ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÖ. Before formally stating this result, we give two examples of using it. 5.60 example:diagonalizable, but with no known exact eigenvalues Defineùëá ‚àà ‚Ñí(ùêÇ 5)by ùëá(ùëß1, ùëß2, ùëß3, ùëß4, ùëß5) = (‚àí3ùëß5, ùëß1 + 6ùëß5, ùëß2, ùëß3, ùëß4). The matrix of ùëá is shown in Example 5.26, where we showed that the minimal polynomial of ùëá is 3 ‚àí 6ùëß+ ùëß 5. As mentioned in Example 5.28, no exact expression is known for any of the zeros of this polynomial, but numeric techniques show that the zeros of this polynomial are approximately ‚àí1.67, 0.51, 1.40, ‚àí0.12+ 1.59ùëñ, ‚àí0.12 ‚àí 1.59ùëñ. The software that produces these approximations is accurate to more than three digits. Thus these approximations are good enough to show that the five numbers above are distinct. The minimal polynomial of ùëá equals the fifth degree monic polynomial with these zeros. Now 5.62 shows that ùëá is diagonalizable. 5.61 example:showing that an operator is not diagonalizable Defineùëá ‚àà ‚Ñí(ùêÖ3)by ùëá(ùëß1, ùëß2, ùëß3) = (6ùëß1 + 3ùëß2 + 4ùëß3, 6ùëß2 + 2ùëß3, 7ùëß3). The matrix of ùëá with respect to the standard basis of ùêÖ3 is ‚éõ‚éú‚éú‚éú ‚éù 6 3 4 0 6 2 0 0 7 ‚éû‚éü‚éü‚éü ‚é† . The matrix above is an upper-triangular matrix but is not a diagonal matrix. Might ùëá have a diagonal matrix with respect to some other basis of ùêÖ3? To answer this question, we will find the minimal polynomial ofùëá. First note that the eigenvalues of ùëá are the diagonal entries of the matrix above (by 5.41). Thus the zeros of the minimal polynomial of ùëá are 6, 7[by 5.27(a)]. The diagonal of the matrix above tells us that (ùëá ‚àí 6ùêº) 2(ùëá ‚àí 7ùêº) = 0(by 5.40). The minimal polynomial of ùëá has degree at most 3(by 5.22). Putting all this together, we see that the minimal polynomial of ùëá is either (ùëß ‚àí 6)(ùëß ‚àí 7)or (ùëß ‚àí 6) 2(ùëß ‚àí 7). A simple computation shows that (ùëá ‚àí 6ùêº)(ùëá ‚àí 7ùêº) ‚â† 0. Thus the minimal polynomial of ùëá is (ùëß ‚àí 6) 2(ùëß ‚àí 7). Now 5.62 shows that ùëá is not diagonalizable. Section 5D Diagonalizable Operators 169 5.62 necessary and sufficient condition for diagonalizability Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Then ùëá is diagonalizable if and only if the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö) for some list of distinct numbers ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÖ. Proof First suppose ùëá is diagonalizable. Thus there is a basis ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ consisting of eigenvectors of ùëá. Let ùúÜ1, ‚Ä¶, ùúÜùëö be the distinct eigenvalues of ùëá. Then for each ùë£ùëó, there exists ùúÜùëò with (ùëá ‚àí ùúÜùëòùêº)ùë£ùëó = 0. Thus (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëöùêº)ùë£ùëó = 0, which implies that the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö). To prove the implication in the other direction, now suppose the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö) for some list of distinct numbers ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÖ. Thus 5.63 (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëöùêº) = 0. We will prove that ùëá is diagonalizable by induction on ùëö. To get started, suppose ùëö = 1. Then ùëá ‚àí ùúÜ1ùêº = 0, which means that ùëá is a scalar multiple of the identity operator, which implies that ùëá is diagonalizable. Now suppose that ùëö > 1and the desired result holds for all smaller values of ùëö. The subspace range(ùëá ‚àí ùúÜùëöùêº) is invariant under ùëá [this is a special case of 5.18 with ùëù(ùëß) = ùëß ‚àí ùúÜùëö]. Thus ùëá restricted to range(ùëá ‚àí ùúÜùëöùêº) is an operator on range(ùëá ‚àí ùúÜùëöùêº). If ùë¢ ‚àà range(ùëá ‚àí ùúÜùëöùêº), then ùë¢ = (ùëá ‚àí ùúÜùëöùêº)ùë£ for some ùë£ ‚àà ùëâ, and 5.63 implies 5.64 (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëö ‚àí 1ùêº)ùë¢ = (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëöùêº)ùë£ = 0. Hence (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö ‚àí 1) is a polynomial multiple of the minimal polynomial of ùëá restricted to range(ùëá ‚àí ùúÜùëöùêº) [by5.29]. Thus by our induction hypothesis, there is a basis of range(ùëá ‚àí ùúÜùëöùêº) consisting of eigenvectors of ùëá. Suppose that ùë¢ ‚àà range(ùëá ‚àí ùúÜùëöùêº) ‚à©null(ùëá ‚àí ùúÜùëöùêº). Then ùëáùë¢ = ùúÜùëöùë¢. Now 5.64 implies that 0 = (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëö ‚àí 1ùêº)ùë¢ = (ùúÜùëö ‚àí ùúÜ1)‚ãØ(ùúÜùëö ‚àí ùúÜùëö ‚àí 1)ùë¢. Because ùúÜ1, ‚Ä¶, ùúÜùëö are distinct, the equation above implies that ùë¢ = 0. Hence range(ùëá ‚àí ùúÜùëöùêº) ‚à©null(ùëá ‚àí ùúÜùëöùêº) = {0}. Thus range(ùëá‚àí ùúÜùëöùêº)+null(ùëá‚àí ùúÜùëöùêº) is a direct sum (by 1.46) whose dimension is dim ùëâ (by 3.94 and 3.21). Hence range(ùëá ‚àí ùúÜùëöùêº) ‚äï null(ùëá ‚àí ùúÜùëöùêº) = ùëâ. Every vector in null(ùëá ‚àí ùúÜùëöùêº) is an eigenvector of ùëá with eigenvalue ùúÜùëö. Earlier in this proof we saw that there is a basis of range(ùëá ‚àí ùúÜùëöùêº) consisting of eigenvectors of ùëá. Adjoining to that basis a basis of null(ùëá ‚àí ùúÜùëöùêº) gives a basis of ùëâ consisting of eigenvectors of ùëá. The matrix of ùëá with respect to this basis is a diagonal matrix, as desired. 170 Chapter 5 Eigenvalues and Eigenvectors No formula exists for the zeros of polynomials of degree 5or greater. However, the previous result can be used to determine whether an operator on a complex vector space is diagonalizable without even finding approximations of the zeros of the minimal polynomial‚Äîsee Exercise 15. The next result will be a key tool when we prove a result about the simul- taneous diagonalization of two operators; see 5.76. Note how the use of the characterization of diagonalizable operators in terms of the minimal polynomial (see 5.62) leads to a short proof of the next result. 5.65 restriction of diagonalizable operator to invariant subspace Suppose ùëá ‚àà ‚Ñí(ùëâ) is diagonalizable and ùëà is a subspace of ùëâ that is invariant under ùëá. Then ùëá|ùëà is a diagonalizable operator on ùëà. Proof Because the operator ùëá is diagonalizable, the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö) for some list of distinct numbers ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÖ (by 5.62). The minimal polynomial of ùëá is a polynomial multiple of the minimal polynomial of ùëá|ùëà (by 5.31). Hence the minimal polynomial of ùëá|ùëà has the form required by 5.62, which shows that ùëá|ùëà is diagonalizable. Gershgorin Disk Theorem 5.66 definition:Gershgorin disks Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Let ùê¥ denote the matrix of ùëá with respect to this basis. A Gershgorin disk of ùëá with respect to the basis ùë£1, ‚Ä¶, ùë£ùëõ is a set of the form {ùëß ‚àà ùêÖ ‚à∂ |ùëß ‚àí ùê¥ùëó, ùëó| ‚â§ ùëõ ‚àë ùëò = 1 ùëò ‚â† ùëó |ùê¥ùëó, ùëò|}, where ùëó ‚àà {1, ‚Ä¶, ùëõ}. Because there are ùëõ choices for ùëó in the definition above,ùëá has ùëõ Gershgorin disks. If ùêÖ = ùêÇ, then for each ùëó ‚àà {1, ‚Ä¶, ùëõ}, the corresponding Gershgorin disk is a closed disk in ùêÇ centered at ùê¥ùëó, ùëó, which is the ùëóth entry on the diagonal of ùê¥. The radius of this closed disk is the sum of the absolute values of the entries in row ùëó of ùê¥, excluding the diagonal entry. If ùêÖ = ùêë, then the Gershgorin disks are closed intervals in ùêë. In the special case that the square matrix ùê¥ above is a diagonal matrix, each Gershgorin disk consists of a single point that is a diagonal entry of ùê¥ (and each eigenvalue of ùëá is one of those points, as required by the next result). One consequence of our next result is that if the nondiagonal entries of ùê¥ are small, then each eigenvalue of ùëá is near a diagonal entry of ùê¥. Section 5D Diagonalizable Operators 171 5.67 Gershgorin disk theorem Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Then each eigenvalue of ùëá is contained in some Gershgorin disk of ùëá with respect to the basis ùë£1, ‚Ä¶, ùë£ùëõ. Proof Suppose ùúÜ ‚àà ùêÖ is an eigenvalue of ùëá. Let ùë§ ‚àà ùëâ be a corresponding eigenvector. There exist ùëê1, ‚Ä¶, ùëêùëõ ‚àà ùêÖ such that 5.68 ùë§ = ùëê1ùë£1 + ‚ãØ + ùëêùëõùë£ùëõ. Let ùê¥ denote the matrix of ùëá with respect to the basis ùë£1, ‚Ä¶, ùë£ùëõ. Applying ùëá to both sides of the equation above gives ùúÜùë§ = ùëõ ‚àë ùëò = 1 ùëêùëòùëáùë£ùëò5.69 = ùëõ ‚àë ùëò = 1 ùëêùëò ùëõ ‚àë ùëó = 1 ùê¥ùëó, ùëòùë£ùëó = ùëõ ‚àë ùëó = 1( ùëõ ‚àë ùëò = 1 ùê¥ùëó, ùëòùëêùëò)ùë£ùëó.5.70 Let ùëó ‚àà {1, ‚Ä¶, ùëõ} be such that |ùëêùëó| = max{|ùëê1|, ‚Ä¶, |ùëêùëõ|}. Using 5.68, we see that the coefficient of ùë£ùëó on the left side of 5.69 equals ùúÜùëêùëó, which must equal the coefficient of ùë£ùëó on the right side of 5.70. In other words, ùúÜùëêùëó = ùëõ ‚àë ùëò = 1 ùê¥ùëó, ùëò ùëêùëò. Subtract ùê¥ùëó, ùëó ùëêùëó from each side of the equation above and then divide both sides by ùëêùëó to get |ùúÜ ‚àí ùê¥ùëó, ùëó| = ‚à£ ùëõ ‚àë ùëò = 1 ùëò ‚â† ùëó ùê¥ùëó, ùëò ùëêùëò ùëêùëó ‚à£ ‚â§ ùëõ ‚àë ùëò = 1 ùëò ‚â† ùëó |ùê¥ùëó, ùëò|. Thus ùúÜ is in the ùëóth Gershgorin disk with respect to the basis ùë£1, ‚Ä¶, ùë£ùëõ. The Gershgorin disk theorem is named for Semyon Aronovich Gershgorin, who published this result in 1931. Exercise 22 gives a nice application of the Gershgorin disk theorem. Exercise 23 states that the radius of each Gershgorin disk could be changed to the sum of the absolute values of corresponding column entries (instead of row entries), excluding the diagonal entry, and the theorem above would still hold. 172 Chapter 5 Eigenvalues and Eigenvectors Exercises 5D 1 Suppose ùëâ is a finite-dimensional complex vector space andùëá ‚àà ‚Ñí(ùëâ). (a) Prove that if ùëá4 = ùêº, then ùëá is diagonalizable. (b) Prove that if ùëá4 = ùëá, then ùëá is diagonalizable. (c) Give an example of an operator ùëá ‚àà ‚Ñí(ùêÇ 2)such that ùëá4 = ùëá2 and ùëá is not diagonalizable. 2 Suppose ùëá ‚àà ‚Ñí(ùëâ) has a diagonal matrix ùê¥ with respect to some basis of ùëâ. Prove that if ùúÜ ‚àà ùêÖ, then ùúÜ appears on the diagonal of ùê¥ precisely dim ùê∏(ùúÜ, ùëá) times. 3 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Prove that if the operator ùëá is diagonalizable, then ùëâ = null ùëá ‚äï range ùëá. 4 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Prove that the following are equivalent. (a) ùëâ = null ùëá ‚äï range ùëá. (b) ùëâ = null ùëá + range ùëá. (c) null ùëá ‚à©range ùëá = {0}. 5 Suppose ùëâ is a finite-dimensional complex vector space andùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is diagonalizable if and only if ùëâ = null(ùëá ‚àí ùúÜùêº) ‚äï range(ùëá ‚àí ùúÜùêº) for every ùúÜ ‚àà ùêÇ. 6 Suppose ùëá ‚àà ‚Ñí(ùêÖ5)and dim ùê∏(8, ùëá) = 4. Prove that ùëá ‚àí 2ùêºor ùëá ‚àí 6ùêºis invertible. 7 Suppose ùëá ‚àà ‚Ñí(ùëâ) is invertible. Prove that ùê∏(ùúÜ, ùëá) = ùê∏( 1 ùúÜ , ùëá‚àí1) for every ùúÜ ‚àà ùêÖ with ùúÜ ‚â† 0. 8 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Let ùúÜ1, ‚Ä¶, ùúÜùëö denote the distinct nonzero eigenvalues of ùëá. Prove that dim ùê∏(ùúÜ1, ùëá) + ‚ãØ + dim ùê∏(ùúÜùëö, ùëá) ‚â§dim range ùëá. 9 Suppose ùëÖ, ùëá ‚àà ‚Ñí(ùêÖ3)each have 2, 6, 7as eigenvalues. Prove that there exists an invertible operator ùëÜ ‚àà ‚Ñí(ùêÖ3)such that ùëÖ = ùëÜ‚àí1ùëáùëÜ. 10 Find ùëÖ, ùëá ‚àà ‚Ñí(ùêÖ4)such that ùëÖ and ùëá each have 2, 6, 7as eigenvalues, ùëÖ and ùëá have no other eigenvalues, and there does not exist an invertible operator ùëÜ ‚àà ‚Ñí(ùêÖ4)such that ùëÖ = ùëÜ‚àí1ùëáùëÜ. Section 5D Diagonalizable Operators 173 11 Find ùëá ‚àà ‚Ñí(ùêÇ 3)such that 6and 7are eigenvalues of ùëá and such that ùëá does not have a diagonal matrix with respect to any basis of ùêÇ 3. 12 Suppose ùëá ‚àà ‚Ñí(ùêÇ 3)is such that 6and 7are eigenvalues of ùëá. Furthermore, suppose ùëá does not have a diagonal matrix with respect to any basis of ùêÇ 3. Prove that there exists (ùëß1, ùëß2, ùëß3) ‚àà ùêÇ3 such that ùëá(ùëß1, ùëß2, ùëß3) = (6+ 8ùëß1, 7+ 8ùëß2, 13+ 8ùëß3). 13 Suppose ùê¥ is a diagonal matrix with distinct entries on the diagonal and ùêµ is a matrix of the same size as ùê¥. Show that ùê¥ùêµ = ùêµùê¥ if and only if ùêµ is a diagonal matrix. 14 (a) Give an example of a finite-dimensional complex vector space and an operator ùëá on that vector space such that ùëá2 is diagonalizable but ùëá is not diagonalizable. (b) Suppose ùêÖ = ùêÇ, ùëò is a positive integer, and ùëá ‚àà ‚Ñí(ùëâ) is invertible. Prove that ùëá is diagonalizable if and only if ùëáùëò is diagonalizable. 15 Suppose ùëâ is a finite-dimensional complex vector space,ùëá ‚àà ‚Ñí(ùëâ), and ùëù is the minimal polynomial of ùëá. Prove that the following are equivalent. (a) ùëá is diagonalizable. (b) There does not exist ùúÜ ‚àà ùêÇ such that ùëù is a polynomial multiple of (ùëß ‚àí ùúÜ)2. (c) ùëù and its derivative ùëù ‚Ä≤ have no zeros in common. (d) The greatest common divisor of ùëù and ùëù ‚Ä≤ is the constant polynomial 1. The greatest common divisor of ùëù and ùëù ‚Ä≤ is the monic polynomial ùëû of largest degree such that ùëù and ùëù ‚Ä≤ are both polynomial multiples of ùëû. The Euclidean algorithm for polynomials (look it up) can quickly determine the greatest common divisor of two polynomials, without requiring any information about the zeros of the polynomials. Thus the equivalence of (a) and (d) above shows that we can determine whether ùëá is diagonalizable without knowing anything about the zeros of ùëù. 16 Suppose that ùëá ‚àà ‚Ñí(ùëâ) is diagonalizable. Let ùúÜ1, ‚Ä¶, ùúÜùëö denote the distinct eigenvalues of ùëá. Prove that a subspace ùëà of ùëâ is invariant under ùëá if and only if there exist subspaces ùëà1, ‚Ä¶, ùëàùëö of ùëâ such that ùëàùëò ‚äÜ ùê∏(ùúÜùëò, ùëá) for each ùëò and ùëà = ùëà1 ‚äï ‚ãØ ‚äï ùëàùëö. 17 Suppose ùëâ is finite-dimensional. Prove that‚Ñí(ùëâ) has a basis consisting of diagonalizable operators. 18 Suppose that ùëá ‚àà ‚Ñí(ùëâ) is diagonalizable and ùëà is a subspace of ùëâ that is invariant under ùëá. Prove that the quotient operator ùëá/ùëà is a diagonalizable operator on ùëâ/ùëà. The quotient operator ùëá/ùëà was defined in Exercise 38 in Section 5A. 174 Chapter 5 Eigenvalues and Eigenvectors 19 Prove or give a counterexample: If ùëá ‚àà ‚Ñí(ùëâ) and there exists a subspace ùëà of ùëâ that is invariant under ùëá such that ùëá|ùëà and ùëá/ùëà are both diagonalizable, then ùëá is diagonalizable. See Exercise 13 in Section 5C for an analogous statement about upper- triangular matrices. 20 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is diagonaliz- able if and only if the dual operator ùëá‚Ä≤ is diagonalizable. 21 The Fibonacci sequence ùêπ0, ùêπ1, ùêπ2, ‚Ä¶ is defined by ùêπ0 = 0, ùêπ1 = 1, and ùêπùëõ = ùêπùëõ ‚àí 2 + ùêπùëõ ‚àí 1 for ùëõ ‚â• 2. Defineùëá ‚àà ‚Ñí(ùêë2)by ùëá(ùë•, ùë¶) = (ùë¶, ùë• + ùë¶). (a) Show that ùëáùëõ(0, 1) = (ùêπùëõ, ùêπùëõ + 1) for each nonnegative integer ùëõ. (b) Find the eigenvalues of ùëá. (c) Find a basis of ùêë2 consisting of eigenvectors of ùëá. (d) Use the solution to (c) to compute ùëáùëõ(0, 1). Conclude that ùêπùëõ = 1 ‚àö5 [( 1+ ‚àö5 2 ) ùëõ ‚àí ( 1 ‚àí‚àö5 2 ) ùëõ] for each nonnegative integer ùëõ. (e) Use (d) to conclude that if ùëõ is a nonnegative integer, then the Fibonacci number ùêπùëõ is the integer that is closest to 1 ‚àö5 ( 1+ ‚àö5 2 ) ùëõ. Each ùêπùëõ is a nonnegative integer, even though the right side of the formula in (d) does not look like an integer. The number 1+ ‚àö5 2 is called the golden ratio. 22 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùê¥ is an ùëõ-by-ùëõ matrix that is the matrix of ùëá with respect to some basis of ùëâ. Prove that if |ùê¥ùëó, ùëó| > ùëõ ‚àë ùëò = 1 ùëò ‚â† ùëó |ùê¥ùëó, ùëò| for each ùëó ‚àà {1, ‚Ä¶, ùëõ}, then ùëá is invertible. This exercise states that if the diagonal entries of the matrix of ùëá are large compared to the nondiagonal entries, then ùëá is invertible. 23 Suppose the definition of the Gershgorin disks is changed so that the radius of the ùëòth disk is the sum of the absolute values of the entries in column (instead of row) ùëò of ùê¥, excluding the diagonal entry. Show that the Gershgorin disk theorem (5.67) still holds with this changed definition. Section 5E Commuting Operators 175 5E Commuting Operators 5.71 definition:commute ‚Ä¢ Two operators ùëÜ and ùëá on the same vector space commute if ùëÜùëá = ùëáùëÜ. ‚Ä¢ Two square matrices ùê¥ and ùêµ of the same size commute if ùê¥ùêµ = ùêµùê¥. For example, if ùëá is an operator and ùëù, ùëû ‚àà ùí´(ùêÖ), then ùëù(ùëá) and ùëû(ùëá) commute [see 5.17(b)]. As another example, if ùêº is the identity operator on ùëâ, then ùêº commutes with every operator on ùëâ. 5.72 example:partial differentiation operators commute Suppose ùëö is a nonnegative integer. Let ùí´ùëö(ùêë2)denote the real vector space of polynomials (with real coefficients) in two real variables and of degree at most ùëö, with the usual operations of addition and scalar multiplication of real-valued functions. Thus the elements of ùí´ùëö(ùêë2)are functions ùëù on ùêë2 of the form 5.73 ùëù = ‚àë ùëó + ùëò ‚â§ ùëö ùëéùëó, ùëòùë•ùëóùë¶ùëò, where the indices ùëó and ùëò take on all nonnegative integer values such that ùëó + ùëò ‚â§ ùëö, each ùëéùëó, ùëò is in ùêë, and ùë•ùëóùë¶ùëò denotes the function on ùêë2 defined by(ùë•, ùë¶) ‚Ü¶ ùë•ùëóùë¶ùëò. Define operatorsùê∑ùë•, ùê∑ùë¶ ‚àà ‚Ñí(ùí´ùëö(ùêë2))by ùê∑ùë•ùëù = ùúïùëù ùúïùë• = ‚àë ùëó + ùëò ‚â§ ùëö ùëóùëéùëó, ùëòùë•ùëó ‚àí 1ùë¶ùëò and ùê∑ùë¶ùëù = ùúïùëù ùúïùë¶ = ‚àë ùëó + ùëò ‚â§ ùëö ùëòùëéùëó, ùëòùë•ùëóùë¶ùëò ‚àí 1, where ùëù is as in 5.73. The operators ùê∑ùë• and ùê∑ùë¶ are called partial differentiation operators because each of these operators differentiates with respect to one of the variables while pretending that the other variable is a constant. The operators ùê∑ùë• and ùê∑ùë¶ commute because if ùëù is as in 5.73, then (ùê∑ùë•ùê∑ùë¶)ùëù = ‚àë ùëó + ùëò ‚â§ ùëö ùëóùëòùëéùëó, ùëòùë•ùëó ‚àí 1ùë¶ùëò ‚àí 1 = (ùê∑ùë¶ùê∑ùë•)ùëù. The equation ùê∑ùë•ùê∑ùë¶ = ùê∑ùë¶ùê∑ùë• on ùí´ùëö(ùêë2)illustrates a more general result that the order of partial differentiation does not matter for nice functions. All 214,358,881 (which equals 11 8) pairs of the 2-by-2matrices under con- sideration were checked by a computer to discover that only 674,609 of these pairs of matrices commute. Commuting matrices are unusual. For example, there are 214,358,881 pairs of 2-by-2matrices all of whose entries are integers in the interval [‚àí5, 5]. Only about 0.3% of these pairs of matrices commute. 176 Chapter 5 Eigenvalues and Eigenvectors The next result shows that two operators commute if and only if their matrices (with respect to the same basis) commute. 5.74 commuting operators correspond to commuting matrices Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Then ùëÜ and ùëá commute if and only if ‚Ñ≥(ùëÜ, (ùë£1, ‚Ä¶, ùë£ùëõ))and ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ))commute. Proof We have ùëÜ and ùëá commute ‚ü∫ ùëÜùëá = ùëáùëÜ ‚ü∫ ‚Ñ≥(ùëÜùëá) = ‚Ñ≥(ùëáùëÜ) ‚ü∫ ‚Ñ≥(ùëÜ)‚Ñ≥(ùëá) = ‚Ñ≥(ùëá)‚Ñ≥(ùëÜ) ‚ü∫ ‚Ñ≥(ùëÜ) and ‚Ñ≥(ùëá) commute, as desired. The next result shows that if two operators commute, then every eigenspace for one operator is invariant under the other operator. This result, which we will use several times, is one of the main reasons why a pair of commuting operators behaves better than a pair of operators that does not commute. 5.75 eigenspace is invariant under commuting operator Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) commute and ùúÜ ‚àà ùêÖ. Then ùê∏(ùúÜ, ùëÜ) is invariant under ùëá. Proof Suppose ùë£ ‚àà ùê∏(ùúÜ, ùëÜ). Then ùëÜ(ùëáùë£) = (ùëÜùëá)ùë£ = (ùëáùëÜ)ùë£ = ùëá(ùëÜùë£) = ùëá(ùúÜùë£) = ùúÜùëáùë£. The equation above shows that ùëáùë£ ‚àà ùê∏(ùúÜ, ùëÜ). Thus ùê∏(ùúÜ, ùëÜ) is invariant under ùëá. Suppose we have two operators, each of which is diagonalizable. If we want to do computations involving both operators (for example, involving their sum), then we want the two operators to be diagonalizable by the same basis, which according to the next result is possible when the two operators commute. 5.76 simultaneous diagonalizablity ‚ü∫ commutativity Two diagonalizable operators on the same vector space have diagonal matrices with respect to the same basis if and only if the two operators commute. Proof First suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) have diagonal matrices with respect to the same basis. The product of two diagonal matrices of the same size is the diagonal matrix obtained by multiplying the corresponding elements of the two diagonals. Thus any two diagonal matrices of the same size commute. Thus ùëÜ and ùëá commute, by 5.74. Section 5E Commuting Operators 177 To prove the implication in the other direction, now suppose that ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) are diagonalizable operators that commute. Let ùúÜ1, ‚Ä¶, ùúÜùëö denote the distinct eigenvalues of ùëÜ. Because ùëÜ is diagonalizable, 5.55(c) shows that 5.77 ùëâ = ùê∏(ùúÜ1, ùëÜ) ‚äï ‚ãØ ‚äï ùê∏(ùúÜùëö, ùëÜ). For each ùëò = 1, ‚Ä¶, ùëö, the subspace ùê∏(ùúÜùëò, ùëÜ) is invariant under ùëá (by 5.75). Because ùëá is diagonalizable, 5.65 implies that ùëá|ùê∏( ùúÜùëò, ùëÜ)is diagonalizable for each ùëò. Hence for each ùëò = 1, ‚Ä¶, ùëö, there is a basis of ùê∏(ùúÜùëò, ùëÜ) consisting of eigenvectors of ùëá. Putting these bases together gives a basis of ùëâ (because of 5.77), with each vector in this basis being an eigenvector of both ùëÜ and ùëá. Thus ùëÜ and ùëá both have diagonal matrices with respect to this basis, as desired. See Exercise 2 for an extension of the result above to more than two operators. Suppose ùëâ is a finite-dimensional nonzero complex vector space. Then every operator on ùëâ has an eigenvector (see 5.19). The next result shows that if two operators on ùëâ commute, then there is a vector in ùëâ that is an eigenvector for both operators (but the two commuting operators might not have a common eigenvalue). For an extension of the next result to more than two operators, see Exercise 9(a). 5.78 common eigenvector for commuting operators Every pair of commuting operators on a finite-dimensional nonzero complex vector space has a common eigenvector. Proof Suppose ùëâ is a finite-dimensional nonzero complex vector space and ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) commute. Let ùúÜ be an eigenvalue of ùëÜ (5.19 tells us that ùëÜ does indeed have an eigenvalue). Thus ùê∏(ùúÜ, ùëÜ) ‚â† {0}. Also, ùê∏(ùúÜ, ùëÜ) is invariant under ùëá (by 5.75). Thus ùëá|ùê∏( ùúÜ, ùëÜ)has an eigenvector (again using 5.19), which is an eigenvector for both ùëÜ and ùëá, completing the proof. 5.79 example:common eigenvector for partial differentiation operators Let ùí´ùëö(ùêë2)be as in Example 5.72 and let ùê∑ùë•, ùê∑ùë¶ ‚àà ‚Ñí(ùí´ùëö(ùêë2))be the commuting partial differentiation operators in that example. As you can verify, 0 is the only eigenvalue of each of these operators. Also ùê∏(0, ùê∑ùë•) = {ùëö ‚àë ùëò = 0 ùëéùëòùë¶ùëò ‚à∂ ùëé0, ‚Ä¶, ùëéùëö ‚àà ùêë}, ùê∏(0, ùê∑ùë¶) = { ùëö ‚àë ùëó = 0 ùëêùëóùë•ùëó ‚à∂ ùëê0, ‚Ä¶, ùëêùëö ‚àà ùêë}. The intersection of these two eigenspaces is the set of common eigenvectors of the two operators. Because ùê∏(0, ùê∑ùë•) ‚à© ùê∏(0, ùê∑ùë¶) is the set of constant functions, we see that ùê∑ùë• and ùê∑ùë¶ indeed have a common eigenvector, as promised by 5.78. 178 Chapter 5 Eigenvalues and Eigenvectors The next result extends 5.47 (the existence of a basis that gives an upper- triangular matrix) to two commuting operators. 5.80 commuting operators are simultaneously upper triangularizable Suppose ùëâ is a finite-dimensional complex vector space andùëÜ, ùëá are commuting operators on ùëâ. Then there is a basis of ùëâ with respect to which both ùëÜ and ùëá have upper-triangular matrices. Proof Let ùëõ = dim ùëâ. We will use induction on ùëõ. The desired result holds if ùëõ = 1because all 1-by-1matrices are upper triangular. Now suppose ùëõ > 1and the desired result holds for all complex vector spaces whose dimension is ùëõ ‚àí 1. Let ùë£1 be any common eigenvector of ùëÜ and ùëá (using 5.78). Hence ùëÜùë£1 ‚àà span(ùë£1) and ùëáùë£1 ‚àà span(ùë£1). Let ùëä be a subspace of ùëâ such that ùëâ = span(ùë£1) ‚äï ùëä; see 2.33 for the existence of ùëä. Define a linear mapùëÉ‚à∂ ùëâ ‚Üí ùëä by ùëÉ(ùëéùë£1 + ùë§) = ùë§ for each ùëé ‚àà ùêÇ and each ùë§ ‚àà ùëä. Define ÃÇùëÜ, ÃÇùëá ‚àà ‚Ñí(ùëä) by ÃÇùëÜùë§ = ùëÉ(ùëÜùë§) and ÃÇùëáùë§ = ùëÉ(ùëáùë§) for each ùë§ ‚àà ùëä. To apply our induction hypothesis to ÃÇùëÜ and ÃÇùëá, we must first show that these two operators on ùëä commute. To do this, suppose ùë§ ‚àà ùëä. Then there exists ùëé ‚àà ùêÇ such that (ÃÇùëÜ ÃÇùëá)ùë§ = ÃÇùëÜ(ùëÉ(ùëáùë§))= ÃÇùëÜ(ùëáùë§ ‚àí ùëéùë£1) = ùëÉ(ùëÜ(ùëáùë§ ‚àí ùëéùë£1))= ùëÉ((ùëÜùëá)ùë§), where the last equality holds because ùë£1 is an eigenvector of ùëÜ and ùëÉùë£1 = 0. Similarly, (ÃÇùëá ÃÇùëÜ)ùë§ = ùëÉ((ùëáùëÜ)ùë§). Because the operators ùëÜ and ùëá commute, the last two displayed equations show that (ÃÇùëÜ ÃÇùëá)ùë§ = (ÃÇùëá ÃÇùëÜ)ùë§. Hence ÃÇùëÜ and ÃÇùëá commute. Thus we can use our induction hypothesis to state that there exists a basis ùë£2, ‚Ä¶, ùë£ùëõ of ùëä such that ÃÇùëÜ and ÃÇùëá both have upper-triangular matrices with respect to this basis. The list ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. If ùëò ‚àà {2, ‚Ä¶, ùëõ}, then there exist ùëéùëò, ùëèùëò ‚àà ùêÇ such that ùëÜùë£ùëò = ùëéùëòùë£1 + ÃÇùëÜùë£ùëò and ùëáùë£ùëò = ùëèùëòùë£1 + ÃÇùëáùë£ùëò. Because ÃÇùëÜ and ÃÇùëá have upper-triangular matrices with respect to ùë£2, ‚Ä¶, ùë£ùëõ, we know that ÃÇùëÜùë£ùëò ‚àà span(ùë£2, ‚Ä¶, ùë£ùëò) and ÃÇùëáùë£ùëò ‚àà span(ùë£2, ‚Ä¶, ùë£ùëò). Hence the equations above imply that ùëÜùë£ùëò ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò) and ùëáùë£ùëò ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò). Thus ùëÜ and ùëá have upper-triangular matrices with respect to ùë£1, ‚Ä¶, ùë£ùëõ, as desired. Exercise 9(b) extends the result above to more than two operators. Section 5E Commuting Operators 179 In general, it is not possible to determine the eigenvalues of the sum or product of two operators from the eigenvalues of the two operators. However, the next result shows that something nice happens when the two operators commute. 5.81 eigenvalues of sum and product of commuting operators Suppose ùëâ is a finite-dimensional complex vector space andùëÜ, ùëá are commut- ing operators on ùëâ. Then ‚Ä¢ every eigenvalue of ùëÜ + ùëá is an eigenvalue of ùëÜ plus an eigenvalue of ùëá, ‚Ä¢ every eigenvalue of ùëÜùëá is an eigenvalue of ùëÜ times an eigenvalue of ùëá. Proof There is a basis of ùëâ with respect to which both ùëÜ and ùëá have upper- triangular matrices (by 5.80). With respect to that basis, ‚Ñ≥(ùëÜ + ùëá) = ‚Ñ≥(ùëÜ) + ‚Ñ≥(ùëá) and ‚Ñ≥(ùëÜùëá) = ‚Ñ≥(ùëÜ)‚Ñ≥(ùëá), as stated in 3.35 and 3.43. The definition of matrix addition shows that each entry on the diagonal of ‚Ñ≥(ùëÜ + ùëá) equals the sum of the corresponding entries on the diagonals of ‚Ñ≥(ùëÜ) and ‚Ñ≥(ùëá). Similarly, because ‚Ñ≥(ùëÜ) and ‚Ñ≥(ùëá) are upper-triangular matrices, the definition of matrix multiplication shows that each entry on the diagonal of ‚Ñ≥(ùëÜùëá) equals the product of the corresponding entries on the diagonals of ‚Ñ≥(ùëÜ) and ‚Ñ≥(ùëá). Furthermore, ‚Ñ≥(ùëÜ + ùëá) and ‚Ñ≥(ùëÜùëá) are upper-triangular matrices (see Exercise 2 in Section 5B). Every entry on the diagonal of ‚Ñ≥(ùëÜ) is an eigenvalue of ùëÜ, and every entry on the diagonal of ‚Ñ≥(ùëá) is an eigenvalue of ùëá (by 5.41). Every eigenvalue of ùëÜ + ùëá is on the diagonal of ‚Ñ≥(ùëÜ + ùëá), and every eigenvalue of ùëÜùëá is on the diagonal of ‚Ñ≥(ùëÜùëá) (these assertions follow from 5.41). Putting all this together, we conclude that every eigenvalue of ùëÜ + ùëá is an eigenvalue of ùëÜ plus an eigenvalue of ùëá, and every eigenvalue of ùëÜùëá is an eigenvalue of ùëÜ times an eigenvalue of ùëá. Exercises 5E 1 Give an example of two commuting operators ùëÜ, ùëá on ùêÖ4 such that there is a subspace of ùêÖ4 that is invariant under ùëÜ but not under ùëá and there is a subspace of ùêÖ4 that is invariant under ùëá but not under ùëÜ. 2 Suppose ‚Ñ∞ is a subset of ‚Ñí(ùëâ) and every element of ‚Ñ∞ is diagonalizable. Prove that there exists a basis of ùëâ with respect to which every element of ‚Ñ∞ has a diagonal matrix if and only if every pair of elements of ‚Ñ∞ commutes. This exercise extends 5.76, which considers the case in which ‚Ñ∞ contains only two elements. For this exercise, ‚Ñ∞ may contain any number of elements, and ‚Ñ∞ may even be an infinite set. 180 Chapter 5 Eigenvalues and Eigenvectors 3 Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) are such that ùëÜùëá = ùëáùëÜ. Suppose ùëù ‚àà ùí´(ùêÖ). (a) Prove that null ùëù(ùëÜ) is invariant under ùëá. (b) Prove that range ùëù(ùëÜ) is invariant under ùëá. See 5.18 for the special case ùëÜ = ùëá. 4 Prove or give a counterexample: If ùê¥ is a diagonal matrix and ùêµ is an upper-triangular matrix of the same size as ùê¥, then ùê¥ and ùêµ commute. 5 Prove that a pair of operators on a finite-dimensional vector space commute if and only if their dual operators commute. See 3.118 for the definition of the dual of an operator. 6 Suppose ùëâ is a finite-dimensional complex vector space andùëÜ, ùëá ‚àà ‚Ñí(ùëâ) commute. Prove that there exist ùõº, ùúÜ ‚àà ùêÇ such that range(ùëÜ ‚àí ùõºùêº) + range(ùëá ‚àí ùúÜùêº) ‚â† ùëâ. 7 Suppose ùëâ is a complex vector space, ùëÜ ‚àà ‚Ñí(ùëâ) is diagonalizable, and ùëá ‚àà ‚Ñí(ùëâ) commutes with ùëÜ. Prove that there is a basis of ùëâ such that ùëÜ has a diagonal matrix with respect to this basis and ùëá has an upper-triangular matrix with respect to this basis. 8 Suppose ùëö = 3in Example 5.72 and ùê∑ùë•, ùê∑ùë¶ are the commuting partial differentiation operators on ùí´3(ùêë2)from that example. Find a basis of ùí´3(ùêë2)with respect to which ùê∑ùë• and ùê∑ùë¶ each have an upper-triangular matrix. 9 Suppose ùëâ is a finite-dimensional nonzero complex vector space. Suppose that ‚Ñ∞ ‚äÜ‚Ñí(ùëâ) is such that ùëÜ and ùëá commute for all ùëÜ, ùëá ‚àà ‚Ñ∞. (a) Prove that there is a vector in ùëâ that is an eigenvector for every element of ‚Ñ∞. (b) Prove that there is a basis of ùëâ with respect to which every element of ‚Ñ∞ has an upper-triangular matrix. This exercise extends 5.78 and 5.80, which consider the case in which ‚Ñ∞ contains only two elements. For this exercise, ‚Ñ∞ may contain any number of elements, and ‚Ñ∞ may even be an infinite set. 10 Give an example of two commuting operators ùëÜ, ùëá on a finite-dimensional real vector space such that ùëÜ + ùëá has a eigenvalue that does not equal an eigenvalue of ùëÜ plus an eigenvalue of ùëá and ùëÜùëá has a eigenvalue that does not equal an eigenvalue of ùëÜ times an eigenvalue of ùëá. This exercise shows that 5.81 does not hold on real vector spaces. Chapter 6 Inner Product Spaces In making the definition of a vector space, we generalized the linear structure (addition and scalar multiplication) of ùêë2 and ùêë3. We ignored geometric features such as the notions of length and angle. These ideas are embedded in the concept of inner products, which we will investigate in this chapter. Every inner product induces a norm, which you can think of as a length. This norm satisfies key properties such as the Pythagorean theorem, the triangle inequality, the parallelogram equality, and the Cauchy‚ÄìSchwarz inequality. The notion of perpendicular vectors in Euclidean geometry gets renamed to orthogonal vectors in the context of an inner product space. We will see that orthonormal bases are tremendously useful in inner product spaces. The Gram‚Äì Schmidt procedure constructs such bases. This chapter will conclude by putting together these tools to solve minimization problems. standing assumptions for this chapter ‚Ä¢ ùêÖ denotes ùêë or ùêÇ. ‚Ä¢ ùëâ and ùëä denote vector spaces over ùêÖ.MatthewPetroffCCBY-SA The George Peabody Library, now part of Johns Hopkins University, opened while James Sylvester (1814‚Äì1897) was the university‚Äôs first mathematics professor. Sylvester‚Äôs publications include the first use of the word matrix in mathematics. 181 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0_6 ¬© Sheldon Axler 2024 182 Chapter 6 Inner Product Spaces 6A Inner Products and Norms Inner Products This vector ùë£ has norm ‚àöùëé2 + ùëè2. To motivate the concept of inner product, think of vectors in ùêë2 and ùêë3 as arrows with initial point at the origin. The length of a vector ùë£ in ùêë2 or ùêë3 is called the norm of ùë£ and is denoted by ‚Äñùë£‚Äñ. Thus for ùë£ = (ùëé, ùëè) ‚àà ùêë2, we have ‚Äñùë£‚Äñ = ‚àöùëé2 + ùëè2. Similarly, if ùë£ = (ùëé, ùëè, ùëê) ‚àà ùêë3, then ‚Äñùë£‚Äñ = ‚àöùëé2 + ùëè2 + ùëê2. Even though we cannot draw pictures in higher dimensions, the generalization to ùêëùëõ is easy: we define the norm ofùë• = (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêëùëõ by ‚Äñùë•‚Äñ = ‚àöùë•1 2 + ‚ãØ + ùë•ùëõ 2. The norm is not linear on ùêëùëõ. To inject linearity into the discussion, we introduce the dot product. 6.1 definition:dot product For ùë•, ùë¶ ‚àà ùêëùëõ, the dot product of ùë• and ùë¶, denoted by ùë• ‚ãÖ ùë¶, is defined by ùë• ‚ãÖ ùë¶ = ùë•1ùë¶1 + ‚ãØ + ùë•ùëõùë¶ùëõ, where ùë• = (ùë•1, ‚Ä¶, ùë•ùëõ) and ùë¶ = (ùë¶1, ‚Ä¶, ùë¶ùëõ). If we think of a vector as a point instead of as an arrow, then ‚Äñùë•‚Äñ should be interpreted to mean the distance from the origin to the point ùë•. The dot product of two vectors in ùêëùëõ is a number, not a vector. Notice that ùë• ‚ãÖ ùë• = ‚Äñùë•‚Äñ 2 for all ùë• ‚àà ùêëùëõ. Furthermore, the dot product on ùêëùëõ has the following properties. ‚Ä¢ ùë• ‚ãÖ ùë• ‚â• 0for all ùë• ‚àà ùêëùëõ. ‚Ä¢ ùë• ‚ãÖ ùë• = 0if and only if ùë• = 0. ‚Ä¢ For ùë¶ ‚àà ùêëùëõ fixed, the map fromùêëùëõ to ùêë that sends ùë• ‚àà ùêëùëõ to ùë• ‚ãÖ ùë¶ is linear. ‚Ä¢ ùë• ‚ãÖ ùë¶ = ùë¶ ‚ãÖ ùë• for all ùë•, ùë¶ ‚àà ùêëùëõ. An inner product is a generalization of the dot product. At this point you may be tempted to guess that an inner product is defined by abstracting the properties of the dot product discussed in the last paragraph. For real vector spaces, that guess is correct. However, so that we can make a definition that will be useful for both real and complex vector spaces, we need to examine the complex case before making the definition. Section 6A Inner Products and Norms 183 Recall that if ùúÜ = ùëé + ùëèùëñ, where ùëé, ùëè ‚àà ùêë, then ‚Ä¢ the absolute value of ùúÜ, denoted by |ùúÜ|, is defined by|ùúÜ| = ‚àöùëé2 + ùëè2; ‚Ä¢ the complex conjugate of ùúÜ, denoted by ùúÜ, is defined byùúÜ = ùëé ‚àí ùëèùëñ; ‚Ä¢ |ùúÜ|2 = ùúÜùúÜ. See Chapter 4 for the definitions and the basic properties of the absolute value and complex conjugate. For ùëß = (ùëß1, ‚Ä¶, ùëßùëõ) ‚àà ùêÇùëõ, we define the norm ofùëß by ‚Äñùëß‚Äñ = ‚àö|ùëß1|2 + ‚ãØ + |ùëßùëõ|2. The absolute values are needed because we want ‚Äñùëß‚Äñ to be a nonnegative number. Note that ‚Äñùëß‚Äñ 2 = ùëß1ùëß1 + ‚ãØ + ùëßùëõùëßùëõ. We want to think of ‚Äñùëß‚Äñ 2 as the inner product of ùëß with itself, as we did in ùêëùëõ. The equation above thus suggests that the inner product of the vector ùë§ = (ùë§1, ‚Ä¶, ùë§ùëõ) ‚àà ùêÇùëõ with ùëß should equal ùë§1ùëß1 + ‚ãØ + ùë§ùëõùëßùëõ. If the roles of the ùë§ and ùëß were interchanged, the expression above would be replaced with its complex conjugate. Thus we should expect that the inner product of ùë§ with ùëß equals the complex conjugate of the inner product of ùëß with ùë§. With that motivation, we are now ready to define an inner product onùëâ, which may be a real or a complex vector space. One comment about the notation used in the next definition: ‚Ä¢ For ùúÜ ‚àà ùêÇ, the notation ùúÜ ‚â• 0means ùúÜ is real and nonnegative. 6.2 definition:inner product An inner product on ùëâ is a function that takes each ordered pair (ùë¢, ùë£) of elements of ùëâ to a number ‚ü®ùë¢, ùë£‚ü© ‚àà ùêÖand has the following properties. positivity ‚ü®ùë£, ùë£‚ü© ‚â• 0for all ùë£ ‚àà ùëâ. definiteness ‚ü®ùë£, ùë£‚ü© = 0if and only if ùë£ = 0. additivity in first slot ‚ü®ùë¢+ ùë£, ùë§‚ü© = ‚ü®ùë¢, ùë§‚ü©+ ‚ü®ùë£, ùë§‚ü©for all ùë¢, ùë£, ùë§ ‚àà ùëâ. homogeneity in first slot ‚ü®ùúÜùë¢, ùë£‚ü© = ùúÜ‚ü®ùë¢, ùë£‚ü©for all ùúÜ ‚àà ùêÖ and all ùë¢, ùë£ ‚àà ùëâ. conjugate symmetry ‚ü®ùë¢, ùë£‚ü© = ‚ü®ùë£, ùë¢‚ü©for all ùë¢, ùë£ ‚àà ùëâ. 184 Chapter 6 Inner Product Spaces Most mathematicians define inner products as above, but many physicists use a definition that requires homo- geneity in the second slot instead of the first slot. Every real number equals its complex conjugate. Thus if we are dealing with a real vector space, then in the last con- dition above we can dispense with the complex conjugate and simply state that ‚ü®ùë¢, ùë£‚ü© = ‚ü®ùë£, ùë¢‚ü©for all ùë¢, ùë£ ‚àà ùëâ. 6.3 example:inner products (a) The Euclidean inner product on ùêÖùëõ is defined by ‚ü®(ùë§1, ‚Ä¶, ùë§ùëõ), (ùëß1, ‚Ä¶, ùëßùëõ)‚ü©= ùë§1ùëß1 + ‚ãØ + ùë§ùëõùëßùëõ for all (ùë§1, ‚Ä¶, ùë§ùëõ), (ùëß1, ‚Ä¶, ùëßùëõ) ‚àà ùêÖùëõ. (b) If ùëê1, ‚Ä¶, ùëêùëõ are positive numbers, then an inner product can be defined onùêÖùëõ by ‚ü®(ùë§1, ‚Ä¶, ùë§ùëõ), (ùëß1, ‚Ä¶, ùëßùëõ)‚ü©= ùëê1ùë§1ùëß1 + ‚ãØ + ùëêùëõùë§ùëõùëßùëõ for all (ùë§1, ‚Ä¶, ùë§ùëõ), (ùëß1, ‚Ä¶, ùëßùëõ) ‚àà ùêÖùëõ. (c) An inner product can be defined on the vector space of continuous real-valued functions on the interval [‚àí1, 1]by ‚ü® ùëì, ùëî‚ü© =‚à´1 ‚àí1 ùëì ùëî for all ùëì, ùëî continuous real-valued functions on [‚àí1, 1]. (d) An inner product can be defined onùí´(ùêë) by ‚ü®ùëù, ùëû‚ü© = ùëù(0)ùëû(0)+ ‚à´1 ‚àí1 ùëù ‚Ä≤ùëû ‚Ä≤ for all ùëù, ùëû ‚àà ùí´(ùêë). (e) An inner product can be defined onùí´(ùêë) by ‚ü®ùëù, ùëû‚ü© =‚à´ ‚àû 0 ùëù(ùë•)ùëû(ùë•)ùëí‚àíùë• ùëëùë• for all ùëù, ùëû ‚àà ùí´(ùêë). 6.4 definition:inner product space An inner product space is a vector space ùëâ along with an inner product on ùëâ. The most important example of an inner product space is ùêÖùëõ with the Euclidean inner product given by (a) in the example above. When ùêÖùëõ is referred to as an inner product space, you should assume that the inner product is the Euclidean inner product unless explicitly told otherwise. Section 6A Inner Products and Norms 185 So that we do not have to keep repeating the hypothesis that ùëâ and ùëä are inner product spaces, we make the following assumption. 6.5 notation:ùëâ, ùëä For the rest of this chapter and the next chapter, ùëâ and ùëä denote inner product spaces over ùêÖ. Note the slight abuse of language here. An inner product space is a vector space along with an inner product on that vector space. When we say that a vector space ùëâ is an inner product space, we are also thinking that an inner product on ùëâ is lurking nearby or is clear from the context (or is the Euclidean inner product if the vector space is ùêÖùëõ). 6.6 basic properties of an inner product (a) For each fixedùë£ ‚àà ùëâ, the function that takes ùë¢ ‚àà ùëâ to ‚ü®ùë¢, ùë£‚ü©is a linear map from ùëâ to ùêÖ. (b) ‚ü®0, ùë£‚ü© = 0for every ùë£ ‚àà ùëâ. (c) ‚ü®ùë£, 0‚ü© = 0for every ùë£ ‚àà ùëâ. (d) ‚ü®ùë¢, ùë£ + ùë§‚ü© = ‚ü®ùë¢, ùë£‚ü©+ ‚ü®ùë¢, ùë§‚ü©for all ùë¢, ùë£, ùë§ ‚àà ùëâ. (e) ‚ü®ùë¢, ùúÜùë£‚ü© = ùúÜ‚ü®ùë¢, ùë£‚ü©for all ùúÜ ‚àà ùêÖ and all ùë¢, ùë£ ‚àà ùëâ. Proof (a) For ùë£ ‚àà ùëâ, the linearity of ùë¢ ‚Ü¶ ‚ü®ùë¢, ùë£‚ü©follows from the conditions of additivity and homogeneity in the first slot in the definition of an inner product. (b) Every linear map takes 0to 0. Thus (b) follows from (a). (c) If ùë£ ‚àà ùëâ, then the conjugate symmetry property in the definition of an inner product and (b) show that ‚ü®ùë£, 0‚ü© = ‚ü®0, ùë£‚ü©= 0= 0. (d) Suppose ùë¢, ùë£, ùë§ ‚àà ùëâ. Then ‚ü®ùë¢, ùë£ + ùë§‚ü© = ‚ü®ùë£+ ùë§, ùë¢‚ü© = ‚ü®ùë£, ùë¢‚ü©+ ‚ü®ùë§, ùë¢‚ü© = ‚ü®ùë£, ùë¢‚ü©+ ‚ü®ùë§, ùë¢‚ü© = ‚ü®ùë¢, ùë£‚ü©+ ‚ü®ùë¢, ùë§‚ü©. (e) Suppose ùúÜ ‚àà ùêÖ and ùë¢, ùë£ ‚àà ùëâ. Then ‚ü®ùë¢, ùúÜùë£‚ü© = ‚ü®ùúÜùë£, ùë¢‚ü© = ùúÜ‚ü®ùë£, ùë¢‚ü© = ùúÜ ‚ü®ùë£, ùë¢‚ü© = ùúÜ‚ü®ùë¢, ùë£‚ü©. 186 Chapter 6 Inner Product Spaces Norms Our motivation for defining inner products came initially from the norms of vectors on ùêë2 and ùêë3. Now we see that each inner product determines a norm. 6.7 definition:norm, ‚Äñùë£‚Äñ For ùë£ ‚àà ùëâ, the norm of ùë£, denoted by ‚Äñùë£‚Äñ, is defined by ‚Äñùë£‚Äñ = ‚àö‚ü®ùë£, ùë£‚ü©. 6.8 example:norms (a) If (ùëß1, ‚Ä¶, ùëßùëõ) ‚àà ùêÖùëõ (with the Euclidean inner product), then ‚Äñ(ùëß1, ‚Ä¶, ùëßùëõ)‚Äñ = ‚àö|ùëß1|2 + ‚ãØ + |ùëßùëõ|2. (b) For ùëì in the vector space of continuous real-valued functions on [‚àí1, 1]and with inner product given as in 6.3(c), we have ‚Äñ ùëì ‚Äñ = ‚àö‚à´1 ‚àí1 ùëì 2. 6.9 basic properties of the norm Suppose ùë£ ‚àà ùëâ. (a) ‚Äñùë£‚Äñ = 0if and only if ùë£ = 0. (b) ‚ÄñùúÜùë£‚Äñ = |ùúÜ| ‚Äñùë£‚Äñ for all ùúÜ ‚àà ùêÖ. Proof (a) The desired result holds because ‚ü®ùë£, ùë£‚ü© = 0if and only if ùë£ = 0. (b) Suppose ùúÜ ‚àà ùêÖ. Then ‚ÄñùúÜùë£‚Äñ2 = ‚ü®ùúÜùë£, ùúÜùë£‚ü© = ùúÜ‚ü®ùë£, ùúÜùë£‚ü© = ùúÜùúÜ‚ü®ùë£, ùë£‚ü© = |ùúÜ|2 ‚Äñùë£‚Äñ 2. Taking square roots now gives the desired equality. The proof of (b) in the result above illustrates a general principle: working with norms squared is usually easier than working directly with norms. Section 6A Inner Products and Norms 187 Now we come to a crucial definition. 6.10 definition:orthogonal Two vectors ùë¢, ùë£ ‚àà ùëâ are called orthogonal if ‚ü®ùë¢, ùë£‚ü© = 0. The word orthogonal comes from the Greek word orthogonios, which means right-angled. In the definition above, the order of the two vectors does not matter, because ‚ü®ùë¢, ùë£‚ü© = 0if and only if ‚ü®ùë£, ùë¢‚ü© = 0. In- stead of saying ùë¢ and ùë£ are orthogonal, sometimes we say ùë¢ is orthogonal to ùë£. Exercise 15 asks you to prove that if ùë¢, ùë£ are nonzero vectors in ùêë2, then ‚ü®ùë¢, ùë£‚ü© = ‚Äñùë¢‚Äñ ‚Äñùë£‚Äñcos ùúÉ, where ùúÉ is the angle between ùë¢ and ùë£ (thinking of ùë¢ and ùë£ as arrows with initial point at the origin). Thus two nonzero vectors in ùêë2 are orthogonal (with respect to the Euclidean inner product) if and only if the cosine of the angle between them is 0, which happens if and only if the vectors are perpendicular in the usual sense of plane geometry. Thus you can think of the word orthogonal as a fancy word meaning perpendicular. We begin our study of orthogonality with an easy result. 6.11 orthogonality and 0 (a) 0is orthogonal to every vector in ùëâ. (b) 0is the only vector in ùëâ that is orthogonal to itself. Proof (a) Recall that 6.6(b) states that ‚ü®0, ùë£‚ü© = 0for every ùë£ ‚àà ùëâ. (b) If ùë£ ‚àà ùëâ and ‚ü®ùë£, ùë£‚ü© = 0, then ùë£ = 0(by definition of inner product). For the special case ùëâ = ùêë2, the next theorem was known over 3,500 years ago in Babylonia and then rediscovered and proved over 2,500 years ago in Greece. Of course, the proof below is not the original proof. 6.12 Pythagorean theorem Suppose ùë¢, ùë£ ‚àà ùëâ. If ùë¢ and ùë£ are orthogonal, then ‚Äñùë¢ + ùë£‚Äñ 2 = ‚Äñùë¢‚Äñ2 + ‚Äñùë£‚Äñ 2. Proof Suppose ‚ü®ùë¢, ùë£‚ü© = 0. Then ‚Äñùë¢ + ùë£‚Äñ 2 = ‚ü®ùë¢+ ùë£, ùë¢ + ùë£‚ü© = ‚ü®ùë¢, ùë¢‚ü©+ ‚ü®ùë¢, ùë£‚ü©+ ‚ü®ùë£, ùë¢‚ü©+ ‚ü®ùë£, ùë£‚ü© = ‚Äñùë¢‚Äñ2 + ‚Äñùë£‚Äñ 2. 188 Chapter 6 Inner Product Spaces Suppose ùë¢, ùë£ ‚àà ùëâ, with ùë£ ‚â† 0. We would like to write ùë¢ as a scalar multiple of ùë£ plus a vector ùë§ orthogonal to ùë£, as suggested in the picture here. An orthogonal decomposition: ùë¢ expressed as a scalar multiple of ùë£ plus a vector orthogonal to ùë£. To discover how to write ùë¢ as a scalar multiple of ùë£ plus a vector orthogonal to ùë£, let ùëê ‚àà ùêÖ denote a scalar. Then ùë¢ = ùëêùë£ + (ùë¢ ‚àí ùëêùë£). Thus we need to choose ùëê so that ùë£ is orthogonal to (ùë¢ ‚àí ùëêùë£). Hence we want 0 = ‚ü®ùë¢ ‚àí ùëêùë£, ùë£‚ü© = ‚ü®ùë¢, ùë£‚ü© ‚àí ùëê‚Äñùë£‚Äñ 2. The equation above shows that we should choose ùëê to be ‚ü®ùë¢, ùë£‚ü©/‚Äñùë£‚Äñ 2. Making this choice of ùëê, we can write ùë¢ = ‚ü®ùë¢, ùë£‚ü© ‚Äñùë£‚Äñ2 ùë£ + (ùë¢ ‚àí ‚ü®ùë¢, ùë£‚ü© ‚Äñùë£‚Äñ2 ùë£). As you should verify, the equation displayed above explicitly writes ùë¢ as a scalar multiple of ùë£ plus a vector orthogonal to ùë£. Thus we have proved the following key result. 6.13 an orthogonal decomposition Suppose ùë¢, ùë£ ‚àà ùëâ, with ùë£ ‚â† 0. Set ùëê = ‚ü®ùë¢, ùë£‚ü© ‚Äñùë£‚Äñ2 and ùë§ = ùë¢ ‚àí ‚ü®ùë¢, ùë£‚ü© ‚Äñùë£‚Äñ2 ùë£. Then ùë¢ = ùëêùë£ + ùë§ and ‚ü®ùë§, ùë£‚ü© = 0. The orthogonal decomposition 6.13 will be used in the proof of the Cauchy‚Äì Schwarz inequality, which is our next result and is one of the most important inequalities in mathematics. Section 6A Inner Products and Norms 189 6.14 Cauchy‚ÄìSchwarz inequality Suppose ùë¢, ùë£ ‚àà ùëâ. Then |‚ü®ùë¢, ùë£‚ü©| ‚â§ ‚Äñùë¢‚Äñ ‚Äñùë£‚Äñ. This inequality is an equality if and only if one of ùë¢, ùë£ is a scalar multiple of the other. Proof If ùë£ = 0, then both sides of the desired inequality equal 0. Thus we can assume that ùë£ ‚â† 0. Consider the orthogonal decomposition ùë¢ = ‚ü®ùë¢, ùë£‚ü© ‚Äñùë£‚Äñ2 ùë£ + ùë§ given by 6.13, where ùë§ is orthogonal to ùë£. By the Pythagorean theorem, ‚Äñùë¢‚Äñ2 = ‚à• ‚ü®ùë¢, ùë£‚ü© ‚Äñùë£‚Äñ2 ùë£‚à• 2 + ‚Äñùë§‚Äñ 2 = ‚à£‚ü®ùë¢, ùë£‚ü©‚à£2 ‚Äñùë£‚Äñ2 + ‚Äñùë§‚Äñ 2 ‚â• ‚à£‚ü®ùë¢, ùë£‚ü©‚à£2 ‚Äñùë£‚Äñ2 .6.15 Multiplying both sides of this inequality by ‚Äñùë£‚Äñ 2 and then taking square roots gives the desired inequality. Augustin-Louis Cauchy (1789‚Äì1857) proved 6.16(a) in 1821. In 1859, Cauchy‚Äôs student Viktor Bunyakovsky (1804‚Äì1889) proved integral inequal- ities like the one in 6.16(b). A few decades later, similar discoveries by Hermann Schwarz (1843‚Äì1921) at- tracted more attention and led to the name of this inequality. The proof in the paragraph above shows that the Cauchy‚ÄìSchwarz inequal- ity is an equality if and only if 6.15 is an equality. This happens if and only if ùë§ = 0. But ùë§ = 0if and only if ùë¢ is a multiple of ùë£ (see 6.13). Thus the Cauchy‚ÄìSchwarz inequality is an equal- ity if and only if ùë¢ is a scalar multiple of ùë£ or ùë£ is a scalar multiple of ùë¢ (or both; the phrasing has been chosen to cover cases in which either ùë¢ or ùë£ equals 0). 6.16 example:Cauchy‚ÄìSchwarz inequality (a) If ùë•1, ‚Ä¶, ùë•ùëõ, ùë¶1, ‚Ä¶, ùë¶ùëõ ‚àà ùêë, then (ùë•1ùë¶1 + ‚ãØ + ùë•ùëõùë¶ùëõ)2 ‚â§(ùë•1 2 + ‚ãØ + ùë•ùëõ 2)(ùë¶1 2 + ‚ãØ + ùë¶ùëõ 2), as follows from applying the Cauchy‚ÄìSchwarz inequality to the vectors (ùë•1, ‚Ä¶, ùë•ùëõ), (ùë¶1, ‚Ä¶, ùë¶ùëõ) ‚àà ùêëùëõ, using the usual Euclidean inner product. 190 Chapter 6 Inner Product Spaces (b) If ùëì, ùëî are continuous real-valued functions on [‚àí1, 1], then ‚à£‚à´1 ‚àí1 ùëì ùëî ‚à£ 2 ‚â§(‚à´1 ‚àí1 ùëì 2)(‚à´ 1 ‚àí1 ùëî2), as follows from applying the Cauchy‚ÄìSchwarz inequality to Example 6.3(c). In this triangle, the length of ùë¢ + ùë£ is less than the length of ùë¢ plus the length of ùë£. The next result, called the triangle inequality, has the geometric interpretation that the length of each side of a triangle is less than the sum of the lengths of the other two sides. Note that the triangle inequality implies that the shortest polygonal path between two points is a single line segment (a polygonal path consists of line segments). 6.17 triangle inequality Suppose ùë¢, ùë£ ‚àà ùëâ. Then ‚Äñùë¢ + ùë£‚Äñ ‚â§ ‚Äñùë¢‚Äñ+ ‚Äñùë£‚Äñ. This inequality is an equality if and only if one of ùë¢, ùë£ is a nonnegative real multiple of the other. Proof We have ‚Äñùë¢ + ùë£‚Äñ 2 = ‚ü®ùë¢+ ùë£, ùë¢ + ùë£‚ü© = ‚ü®ùë¢, ùë¢‚ü©+ ‚ü®ùë£, ùë£‚ü©+ ‚ü®ùë¢, ùë£‚ü©+ ‚ü®ùë£, ùë¢‚ü© = ‚ü®ùë¢, ùë¢‚ü©+ ‚ü®ùë£, ùë£‚ü©+ ‚ü®ùë¢, ùë£‚ü©+ ‚ü®ùë¢, ùë£‚ü© = ‚Äñùë¢‚Äñ2 + ‚Äñùë£‚Äñ 2 + 2Re‚ü®ùë¢, ùë£‚ü© ‚â§ ‚Äñùë¢‚Äñ 2 + ‚Äñùë£‚Äñ 2 + 2‚à£‚ü®ùë¢, ùë£‚ü©‚à£6.18 ‚â§ ‚Äñùë¢‚Äñ 2 + ‚Äñùë£‚Äñ 2 + 2‚Äñùë¢‚Äñ ‚Äñùë£‚Äñ6.19 = (‚Äñùë¢‚Äñ + ‚Äñùë£‚Äñ) 2, where 6.19 follows from the Cauchy‚ÄìSchwarz inequality (6.14). Taking square roots of both sides of the inequality above gives the desired inequality. The proof above shows that the triangle inequality is an equality if and only if we have equality in 6.18 and 6.19. Thus we have equality in the triangle inequality if and only if 6.20 ‚ü®ùë¢, ùë£‚ü© = ‚Äñùë¢‚Äñ ‚Äñùë£‚Äñ. If one of ùë¢, ùë£ is a nonnegative real multiple of the other, then 6.20 holds. Con- versely, suppose 6.20 holds. Then the condition for equality in the Cauchy‚Äì Schwarz inequality (6.14) implies that one of ùë¢, ùë£ is a scalar multiple of the other. This scalar must be a nonnegative real number, by 6.20, completing the proof. For the reverse triangle inequality, see Exercise 20. Section 6A Inner Products and Norms191 The diagonals of this parallelogram are ùë¢ + ùë£ and ùë¢ ‚àí ùë£. The next result is called the parallel- ogram equality because of its geometric interpretation: in every parallelogram, the sum of the squares of the lengths of the diagonals equals the sum of the squares of the lengths of the four sides. Note that the proof here is more straightforward than the usual proof in Euclidean geometry. 6.21 parallelogram equality Suppose ùë¢, ùë£ ‚àà ùëâ. Then ‚Äñùë¢ + ùë£‚Äñ 2 + ‚Äñùë¢ ‚àí ùë£‚Äñ2 = 2(‚Äñùë¢‚Äñ 2 + ‚Äñùë£‚Äñ2). Proof We have ‚Äñùë¢ + ùë£‚Äñ2 + ‚Äñùë¢ ‚àí ùë£‚Äñ2 = ‚ü®ùë¢+ ùë£, ùë¢ + ùë£‚ü©+ ‚ü®ùë¢ ‚àí ùë£, ùë¢ ‚àí ùë£‚ü© = ‚Äñùë¢‚Äñ2 + ‚Äñùë£‚Äñ2 + ‚ü®ùë¢, ùë£‚ü©+ ‚ü®ùë£, ùë¢‚ü© + ‚Äñùë¢‚Äñ2 + ‚Äñùë£‚Äñ 2 ‚àí ‚ü®ùë¢, ùë£‚ü© ‚àí ‚ü®ùë£, ùë¢‚ü© = 2(‚Äñùë¢‚Äñ 2 + ‚Äñùë£‚Äñ2), as desired. Exercises 6A 1 Prove or give a counterexample: If ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ, then ùëö ‚àë ùëó = 1 ùëö ‚àë ùëò = 1‚ü®ùë£ùëó, ùë£ùëò‚ü© ‚â• 0. 2 Suppose ùëÜ ‚àà ‚Ñí(ùëâ). Define ‚ü®‚ãÖ, ‚ãÖ‚ü©1 by ‚ü®ùë¢, ùë£‚ü©1 = ‚ü®ùëÜùë¢, ùëÜùë£‚ü© for all ùë¢, ùë£ ‚àà ùëâ. Show that ‚ü®‚ãÖ, ‚ãÖ‚ü©1 is an inner product on ùëâ if and only if ùëÜ is injective. 3 (a) Show that the function taking an ordered pair ((ùë•1, ùë•2), (ùë¶1, ùë¶2))of elements of ùêë2 to |ùë•1ùë¶1| + |ùë•2ùë¶2| is not an inner product on ùêë2. (b) Show that the function taking an ordered pair ((ùë•1, ùë•2, ùë•3), (ùë¶1, ùë¶2, ùë¶3)) of elements of ùêë3 to ùë•1ùë¶1 + ùë•3ùë¶3 is not an inner product on ùêë3. 4 Suppose ùëá ‚àà ‚Ñí(ùëâ)is such that ‚Äñùëáùë£‚Äñ ‚â§ ‚Äñùë£‚Äñfor every ùë£ ‚àà ùëâ. Prove that ùëá ‚àí ‚àö2 ùêºis injective. 192 Chapter 6 Inner Product Spaces 5 Suppose ùëâ is a real inner product space. (a) Show that ‚ü®ùë¢+ ùë£, ùë¢ ‚àí ùë£‚ü© = ‚Äñùë¢‚Äñ 2 ‚àí ‚Äñùë£‚Äñ2 for every ùë¢, ùë£ ‚àà ùëâ. (b) Show that if ùë¢, ùë£ ‚àà ùëâ have the same norm, then ùë¢ + ùë£ is orthogonal to ùë¢ ‚àí ùë£. (c) Use (b) to show that the diagonals of a rhombus are perpendicular to each other. 6 Suppose ùë¢, ùë£ ‚àà ùëâ. Prove that ‚ü®ùë¢, ùë£‚ü© = 0 ‚ü∫ ‚Äñùë¢‚Äñ ‚â§ ‚Äñùë¢+ ùëéùë£‚Äñ for all ùëé ‚àà ùêÖ. 7 Suppose ùë¢, ùë£ ‚àà ùëâ. Prove that ‚Äñùëéùë¢ + ùëèùë£‚Äñ = ‚Äñùëèùë¢ + ùëéùë£‚Äñ for all ùëé, ùëè ‚àà ùêë if and only if ‚Äñùë¢‚Äñ = ‚Äñùë£‚Äñ. 8 Suppose ùëé, ùëè, ùëê, ùë•, ùë¶ ‚àà ùêë and ùëé2 + ùëè 2 + ùëê2 + ùë•2 + ùë¶2 ‚â§ 1. Prove that ùëé + ùëè + ùëê + 4ùë•+ 9ùë¶ ‚â§ 10. 9 Suppose ùë¢, ùë£ ‚àà ùëâ and ‚Äñùë¢‚Äñ = ‚Äñùë£‚Äñ = 1and ‚ü®ùë¢, ùë£‚ü© = 1. Prove that ùë¢ = ùë£. 10 Suppose ùë¢, ùë£ ‚àà ùëâ and ‚Äñùë¢‚Äñ ‚â§ 1and ‚Äñùë£‚Äñ ‚â§ 1. Prove that ‚àö1 ‚àí ‚Äñùë¢‚Äñ2‚àö1 ‚àí ‚Äñùë£‚Äñ2 ‚â§ 1 ‚àí‚à£‚ü®ùë¢, ùë£‚ü©‚à£. 11 Find vectors ùë¢, ùë£ ‚àà ùêë2 such that ùë¢ is a scalar multiple of (1, 3), ùë£ is orthog- onal to (1, 3), and (1, 2) = ùë¢+ ùë£. 12 Suppose ùëé, ùëè, ùëê, ùëë are positive numbers. (a) Prove that (ùëé + ùëè + ùëê + ùëë)( 1 ùëé + 1 ùëè + 1 ùëê + 1 ùëë )‚â• 16. (b) For which positive numbers ùëé, ùëè, ùëê, ùëë is the inequality above an equality? 13 Show that the square of an average is less than or equal to the average of the squares. More precisely, show that if ùëé1, ‚Ä¶, ùëéùëõ ‚àà ùêë, then the square of the average of ùëé1, ‚Ä¶, ùëéùëõ is less than or equal to the average of ùëé1 2, ‚Ä¶, ùëéùëõ 2. 14 Suppose ùë£ ‚àà ùëâ and ùë£ ‚â† 0. Prove that ùë£/‚Äñùë£‚Äñ is the unique closest element on the unit sphere of ùëâ to ùë£. More precisely, prove that if ùë¢ ‚àà ùëâ and ‚Äñùë¢‚Äñ = 1, then ‚à•ùë£ ‚àí ùë£ ‚Äñùë£‚Äñ ‚à• ‚â§ ‚Äñùë£ ‚àí ùë¢‚Äñ, with equality only if ùë¢ = ùë£/‚Äñùë£‚Äñ. 15 Suppose ùë¢, ùë£ are nonzero vectors in ùêë2. Prove that ‚ü®ùë¢, ùë£‚ü© = ‚Äñùë¢‚Äñ ‚Äñùë£‚Äñcos ùúÉ, where ùúÉ is the angle between ùë¢ and ùë£ (thinking of ùë¢ and ùë£ as arrows with initial point at the origin). Hint: Use the law of cosines on the triangle formed by ùë¢, ùë£, and ùë¢ ‚àí ùë£. Section 6A Inner Products and Norms 193 16 The angle between two vectors (thought of as arrows with initial point at the origin) in ùêë2 or ùêë3 can be defined geometrically. However, geometry is not as clear in ùêëùëõ for ùëõ > 3. Thus the angle between two nonzero vectors ùë•, ùë¶ ‚àà ùêëùëõ is defined to be arccos ‚ü®ùë•, ùë¶‚ü© ‚Äñùë•‚Äñ ‚Äñùë¶‚Äñ , where the motivation for this definition comes from Exercise15. Explain why the Cauchy‚ÄìSchwarz inequality is needed to show that this definition makes sense. 17 Prove that ( ùëõ ‚àë ùëò = 1 ùëéùëòùëèùëò) 2 ‚â§( ùëõ ‚àë ùëò = 1 ùëòùëéùëò 2)( ùëõ ‚àë ùëò = 1 ùëèùëò 2 ùëò ) for all real numbers ùëé1, ‚Ä¶, ùëéùëõ and ùëè1, ‚Ä¶, ùëèùëõ. 18 (a) Suppose ùëì‚à∂ [1, ‚àû) ‚Üí [0, ‚àû) is continuous. Show that (‚à´‚àû 1 ùëì ) 2 ‚â§‚à´ ‚àû 1 ùë•2(ùëì (ùë•)) 2 ùëëùë•. (b) For which continuous functions ùëì‚à∂ [1, ‚àû) ‚Üí [0, ‚àû) is the inequality in (a) an equality with both sides finite? 19 Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ and ùëá ‚àà ‚Ñí(ùëâ). Prove that if ùúÜ is an eigenvalue of ùëá, then |ùúÜ|2 ‚â§ ùëõ ‚àë ùëó = 1 ùëõ ‚àë ùëò = 1|‚Ñ≥(ùëá)ùëó, ùëò| 2, where ‚Ñ≥(ùëá)ùëó, ùëò denotes the entry in row ùëó, column ùëò of the matrix of ùëá with respect to the basis ùë£1, ‚Ä¶, ùë£ùëõ. 20 Prove that if ùë¢, ùë£ ‚àà ùëâ, then ‚à£ ‚Äñùë¢‚Äñ ‚àí ‚Äñùë£‚Äñ ‚à£ ‚â§ ‚Äñùë¢ ‚àí ùë£‚Äñ. The inequality above is called the reverse triangle inequality. For the reverse triangle inequality when ùëâ = ùêÇ, see Exercise 2 in Chapter 4. 21 Suppose ùë¢, ùë£ ‚àà ùëâ are such that ‚Äñùë¢‚Äñ = 3, ‚Äñùë¢ + ùë£‚Äñ = 4, ‚Äñùë¢ ‚àí ùë£‚Äñ = 6. What number does ‚Äñùë£‚Äñ equal? 22 Show that if ùë¢, ùë£ ‚àà ùëâ, then ‚Äñùë¢ + ùë£‚Äñ ‚Äñùë¢ ‚àí ùë£‚Äñ ‚â§ ‚Äñùë¢‚Äñ 2 + ‚Äñùë£‚Äñ 2. 23 Suppose ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ are such that ‚Äñùë£ùëò‚Äñ ‚â§ 1for each ùëò = 1, ‚Ä¶, ùëö. Show that there exist ùëé1, ‚Ä¶, ùëéùëö ‚àà {1, ‚àí1}such that ‚Äñùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö‚Äñ ‚â§‚àö ùëö. 194 Chapter 6 Inner Product Spaces 24 Prove or give a counterexample: If ‚Äñ ‚ãÖ ‚Äñ is the norm associated with an inner product on ùêë2, then there exists (ùë•, ùë¶) ‚àà ùêë2 such that ‚Äñ(ùë•, ùë¶)‚Äñ ‚â† max{|ùë•|, |ùë¶|}. 25 Suppose ùëù > 0. Prove that there is an inner product on ùêë2 such that the associated norm is given by ‚Äñ(ùë•, ùë¶)‚Äñ = (|ùë•|ùëù + |ùë¶| ùëù) 1/ùëù for all (ùë•, ùë¶) ‚àà ùêë2 if and only if ùëù = 2. 26 Suppose ùëâ is a real inner product space. Prove that ‚ü®ùë¢, ùë£‚ü© = ‚Äñùë¢ + ùë£‚Äñ 2 ‚àí ‚Äñùë¢ ‚àí ùë£‚Äñ2 4 for all ùë¢, ùë£ ‚àà ùëâ. 27 Suppose ùëâ is a complex inner product space. Prove that ‚ü®ùë¢, ùë£‚ü© = ‚Äñùë¢ + ùë£‚Äñ 2 ‚àí ‚Äñùë¢ ‚àí ùë£‚Äñ2 + ‚Äñùë¢ + ùëñùë£‚Äñ 2ùëñ ‚àí ‚Äñùë¢ ‚àí ùëñùë£‚Äñ2ùëñ 4 for all ùë¢, ùë£ ‚àà ùëâ. 28 A norm on a vector space ùëà is a function ‚Äñ ‚ãÖ ‚Äñ‚à∂ ùëà ‚Üí [0, ‚àû) such that ‚Äñùë¢‚Äñ = 0if and only if ùë¢ = 0, ‚Äñùõºùë¢‚Äñ = |ùõº|‚Äñùë¢‚Äñ for all ùõº ‚àà ùêÖ and all ùë¢ ‚àà ùëà, and ‚Äñùë¢ + ùë£‚Äñ ‚â§ ‚Äñùë¢‚Äñ+ ‚Äñùë£‚Äñ for all ùë¢, ùë£ ‚àà ùëà. Prove that a norm satisfying the parallelogram equality comes from an inner product (in other words, show that if ‚Äñ ‚ãÖ ‚Äñ is a norm on ùëà satisfying the parallelogram equality, then there is an inner product ‚ü®‚ãÖ, ‚ãÖ‚ü©on ùëà such that ‚Äñùë¢‚Äñ = ‚ü®ùë¢, ùë¢‚ü© 1/2 for all ùë¢ ‚àà ùëà). 29 Suppose ùëâ1, ‚Ä¶, ùëâùëö are inner product spaces. Show that the equation ‚ü®(ùë¢1, ‚Ä¶, ùë¢ùëö), (ùë£1, ‚Ä¶, ùë£ùëö)‚ü©= ‚ü®ùë¢1, ùë£1‚ü©+ ‚ãØ + ‚ü®ùë¢ùëö, ùë£ùëö‚ü© defines an inner product onùëâ1 √ó ‚ãØ √ó ùëâùëö. In the expression above on the right, for each ùëò = 1, ‚Ä¶, ùëö, the inner product ‚ü®ùë¢ùëò, ùë£ùëò‚ü©denotes the inner product on ùëâùëò. Each of the spaces ùëâ1, ‚Ä¶, ùëâùëö may have a different inner product, even though the same notation is used here. 30 Suppose ùëâ is a real inner product space. For ùë¢, ùë£, ùë§, ùë• ‚àà ùëâ, define ‚ü®ùë¢+ ùëñùë£, ùë§ + ùëñùë•‚ü©ùêÇ = ‚ü®ùë¢, ùë§‚ü©+ ‚ü®ùë£, ùë•‚ü©+ (‚ü®ùë£, ùë§‚ü© ‚àí ‚ü®ùë¢, ùë•‚ü©)ùëñ. (a) Show that ‚ü®‚ãÖ, ‚ãÖ‚ü©ùêÇ makes ùëâùêÇ into a complex inner product space. (b) Show that if ùë¢, ùë£ ‚àà ùëâ, then ‚ü®ùë¢, ùë£‚ü©ùêÇ = ‚ü®ùë¢, ùë£‚ü© and ‚Äñùë¢ + ùëñùë£‚ÄñùêÇ 2 = ‚Äñùë¢‚Äñ2 + ‚Äñùë£‚Äñ 2. See Exercise 8 in Section 1B for the definition of the complexification ùëâùêÇ. Section 6A Inner Products and Norms 195 31 Suppose ùë¢, ùë£, ùë§ ‚àà ùëâ. Prove that ‚à•ùë§ ‚àí 1 2 (ùë¢ + ùë£)‚à• 2 = ‚Äñùë§ ‚àí ùë¢‚Äñ2 + ‚Äñùë§ ‚àí ùë£‚Äñ2 2 ‚àí ‚Äñùë¢ ‚àí ùë£‚Äñ2 4 . 32 Suppose that ùê∏ is a subset of ùëâ with the property that ùë¢, ùë£ ‚àà ùê∏ implies 1 2 (ùë¢ + ùë£) ‚àà ùê∏. Let ùë§ ‚àà ùëâ. Show that there is at most one point in ùê∏ that is closest to ùë§. In other words, show that there is at most one ùë¢ ‚àà ùê∏ such that ‚Äñùë§ ‚àí ùë¢‚Äñ ‚â§ ‚Äñùë§ ‚àí ùë•‚Äñ for all ùë• ‚àà ùê∏. 33 Suppose ùëì, ùëî are differentiable functions from ùêë to ùêëùëõ. (a) Show that ‚ü®ùëì (ùë°), ùëî(ùë°)‚ü© ‚Ä≤ = ‚ü®ùëì ‚Ä≤(ùë°), ùëî(ùë°)‚ü©+ ‚ü®ùëì (ùë°), ùëî‚Ä≤(ùë°)‚ü©. (b) Suppose ùëê is a positive number and ‚à• ùëì (ùë°)‚à• = ùëê for every ùë° ‚àà ùêë. Show that ‚ü®ùëì ‚Ä≤(ùë°), ùëì (ùë°)‚ü©= 0for every ùë° ‚àà ùêë. (c) Interpret the result in (b) geometrically in terms of the tangent vector to a curve lying on a sphere in ùêëùëõ centered at the origin. A function ùëì‚à∂ ùêë ‚Üí ùêëùëõ is called differentiable if there exist differentiable functions ùëì1, ‚Ä¶, ùëìùëõ from ùêë to ùêë such that ùëì (ùë°) = (ùëì1(ùë°), ‚Ä¶, ùëìùëõ(ùë°))for each ùë° ‚àà ùêë. Furthermore, for each ùë° ‚àà ùêë, the derivative ùëì ‚Ä≤(ùë°) ‚àà ùêëùëõ is defined by ùëì ‚Ä≤(ùë°) = (ùëì1‚Ä≤(ùë°), ‚Ä¶, ùëìùëõ‚Ä≤(ùë°)). 34 Use inner products to prove Apollonius‚Äôs identity: In a triangle with sides of length ùëé, ùëè, and ùëê, let ùëë be the length of the line segment from the midpoint of the side of length ùëê to the opposite vertex. Then ùëé 2 + ùëè2 = 1 2 ùëê2 + 2ùëë 2. 196 Chapter 6 Inner Product Spaces 35 Fix a positive integer ùëõ. The Laplacian Œîùëù of a twice differentiable real- valued function ùëù on ùêëùëõ is the function on ùêëùëõ defined by Œîùëù = ùúï2ùëù ùúïùë•1 2 + ‚ãØ + ùúï2ùëù ùúïùë•ùëõ 2 . The function ùëù is called harmonic if Œîùëù = 0. A polynomial on ùêëùëõ is a linear combination (with coefficients in ùêë) of functions of the form ùë•1 ùëö1‚ãØùë•ùëõ ùëöùëõ, where ùëö1, ‚Ä¶, ùëöùëõ are nonnegative integers. Suppose ùëû is a polynomial on ùêëùëõ. Prove that there exists a harmonic polynomial ùëù on ùêëùëõ such that ùëù(ùë•) = ùëû(ùë•) for every ùë• ‚àà ùêëùëõ with ‚Äñùë•‚Äñ = 1. The only fact about harmonic functions that you need for this exercise is that if ùëù is a harmonic function on ùêëùëõ and ùëù(ùë•) = 0for all ùë• ‚àà ùêëùëõ with ‚Äñùë•‚Äñ = 1, then ùëù = 0. Hint: A reasonable guess is that the desired harmonic polynomial ùëù is of the form ùëû + (1 ‚àí ‚Äñùë•‚Äñ 2)ùëü for some polynomial ùëü. Prove that there is a polynomial ùëü on ùêëùëõ such that ùëû + (1 ‚àí ‚Äñùë•‚Äñ 2)ùëü is harmonic by defining an operator ùëá on a suitable vector space by ùëáùëü = Œî((1 ‚àí ‚Äñùë•‚Äñ 2)ùëü) and then showing that ùëá is injective and hence surjective. In realms of numbers, where the secrets lie, A noble truth emerges from the deep, Cauchy and Schwarz, their wisdom they apply, An inequality for all to keep. Two vectors, by this bond, are intertwined, As inner products weave a gilded thread, Their magnitude, by providence, confined, A bound to which their destiny is wed. Though shadows fall, and twilight dims the day, This inequality will stand the test, To guide us in our quest, to light the way, And in its truth, our understanding rest. So sing, ye muses, of this noble feat, Cauchy‚ÄìSchwarz, the bound that none can beat. ‚Äîwritten by ChatGPT with input Shakespearean sonnet on Cauchy‚ÄìSchwarz inequality Section 6B Orthonormal Bases 197 6B Orthonormal Bases Orthonormal Lists and the Gram‚ÄìSchmidt Procedure 6.22 definition:orthonormal ‚Ä¢ A list of vectors is called orthonormal if each vector in the list has norm 1 and is orthogonal to all the other vectors in the list. ‚Ä¢ In other words, a list ùëí1, ‚Ä¶, ùëíùëö of vectors in ùëâ is orthonormal if ‚ü®ùëíùëó, ùëíùëò‚ü© = ‚éß{ ‚é®{‚é© 1 if ùëó = ùëò, 0 if ùëó ‚â† ùëò for all ùëó, ùëò ‚àà {1, ‚Ä¶, ùëö}. 6.23 example:orthonormal lists (a) The standard basis of ùêÖùëõ is an orthonormal list. (b) ( 1 ‚àö3 , 1 ‚àö3 , 1 ‚àö3 ), (‚àí 1 ‚àö2 , 1 ‚àö2 , 0)is an orthonormal list in ùêÖ3. (c) ( 1 ‚àö3 , 1 ‚àö3 , 1 ‚àö3 ), (‚àí 1 ‚àö2 , 1 ‚àö2 , 0), ( 1 ‚àö6 , 1 ‚àö6 , ‚àí 2 ‚àö6 )is an orthonormal list in ùêÖ3. (d) Suppose ùëõ is a positive integer. Then, as Exercise 4 asks you to verify, 1 ‚àö2ùúã , cos ùë• ‚àö ùúã , cos 2ùë• ‚àö ùúã , ‚Ä¶, cos ùëõùë• ‚àö ùúã , sin ùë• ‚àö ùúã , sin 2ùë• ‚àö ùúã , ‚Ä¶, sin ùëõùë• ‚àö ùúã is an orthonormal list of vectors in ùê∂[‚àíùúã, ùúã], the vector space of continuous real-valued functions on [‚àíùúã, ùúã] with inner product ‚ü® ùëì, ùëî‚ü© =‚à´ùúã ‚àíùúã ùëì ùëî. The orthonormal list above is often used for modeling periodic phenomena, such as tides. (e) Suppose we make ùí´2(ùêë) into an inner product space using the inner product given by ‚ü®ùëù, ùëû‚ü© =‚à´ 1 ‚àí1 ùëùùëû for all ùëù, ùëû ‚àà ùí´2(ùêë). The standard basis 1, ùë•, ùë•2 of ùí´2(ùêë) is not an orthonor- mal list because the vectors in that list do not have norm 1. Dividing each vector by its norm gives the list 1/‚àö2, ‚àö3/2ùë•, ‚àö5/2ùë• 2, in which each vector has norm 1, and the second vector is orthogonal to the first and third vectors. However, the first and third vectors are not orthogonal. Thus this is not an orthonormal list. Soon we will see how to construct an orthonormal list from the standard basis 1, ùë•, ùë•2 (see Example 6.34). 198 Chapter 6 Inner Product Spaces Orthonormal lists are particularly easy to work with, as illustrated by the next result. 6.24 norm of an orthonormal linear combination Suppose ùëí1, ‚Ä¶, ùëíùëö is an orthonormal list of vectors in ùëâ. Then ‚Äñùëé1ùëí1 + ‚ãØ + ùëéùëöùëíùëö‚Äñ2 = |ùëé1| 2 + ‚ãØ + |ùëéùëö|2 for all ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ. Proof Because each ùëíùëò has norm 1, this follows from repeated applications of the Pythagorean theorem (6.12). The result above has the following important corollary. 6.25 orthonormal lists are linearly independent Every orthonormal list of vectors is linearly independent. Proof Suppose ùëí1, ‚Ä¶, ùëíùëö is an orthonormal list of vectors in ùëâ and ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ are such that ùëé1ùëí1 + ‚ãØ + ùëéùëöùëíùëö = 0. Then |ùëé1| 2 + ‚ãØ + |ùëéùëö| 2 = 0(by 6.24), which means that all the ùëéùëò‚Äôs are 0. Thus ùëí1, ‚Ä¶, ùëíùëö is linearly independent. Now we come to an important inequality. 6.26 Bessel‚Äôs inequality Suppose ùëí1, ‚Ä¶, ùëíùëö is an orthonormal list of vectors in ùëâ. If ùë£ ‚àà ùëâ then ‚à£‚ü®ùë£, ùëí1‚ü©‚à£2 + ‚ãØ + ‚à£‚ü®ùë£, ùëíùëö‚ü©‚à£2 ‚â§ ‚Äñùë£‚Äñ 2. Proof Suppose ùë£ ‚àà ùëâ. Then ùë£ = ‚ü®ùë£, ùëí1‚ü©ùëí1 + ‚ãØ + ‚ü®ùë£, ùëíùëö‚ü©ùëíùëö‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü ùë¢ + ùë£ ‚àí ‚ü®ùë£, ùëí1‚ü©ùëí1 ‚àí ‚ãØ ‚àí ‚ü®ùë£, ùëíùëö‚ü©ùëíùëö‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü ùë§ . Let ùë¢ and ùë§ be defined as in the equation above. Ifùëò ‚àà {1, ‚Ä¶, ùëö}, then ‚ü®ùë§, ùëíùëò‚ü© = ‚ü®ùë£, ùëíùëò‚ü© ‚àí ‚ü®ùë£, ùëíùëò‚ü©‚ü®ùëíùëò, ùëíùëò‚ü© = 0. This implies that ‚ü®ùë§, ùë¢‚ü© = 0. The Pythagorean theorem now implies that ‚Äñùë£‚Äñ 2 = ‚Äñùë¢‚Äñ2 + ‚Äñùë§‚Äñ 2 ‚â• ‚Äñùë¢‚Äñ 2 = ‚à£‚ü®ùë£, ùëí1‚ü©‚à£2 + ‚ãØ + ‚à£‚ü®ùë£, ùëíùëö‚ü©‚à£2, where the last line comes from 6.24. Section 6B Orthonormal Bases 199 The next definition introduces one of the most useful concepts in the study of inner product spaces. 6.27 definition:orthonormal basis An orthonormal basis of ùëâ is an orthonormal list of vectors in ùëâ that is also a basis of ùëâ. For example, the standard basis is an orthonormal basis of ùêÖùëõ. 6.28 orthonormal lists of the right length are orthonormal bases Suppose ùëâ is finite-dimensional. Then every orthonormal list of vectors inùëâ of length dim ùëâ is an orthonormal basis of ùëâ. Proof By 6.25, every orthonormal list of vectors in ùëâ is linearly independent. Thus every such list of the right length is a basis‚Äîsee 2.38. 6.29 example:an orthonormal basis of ùêÖ4 As mentioned above, the standard basis is an orthonormal basis of ùêÖ4. We now show that ( 1 2 , 1 2 , 1 2 , 1 2 ), ( 1 2 , 1 2 , ‚àí 1 2 , ‚àí 1 2 ), ( 1 2 , ‚àí 1 2 , ‚àí 1 2 , 1 2 ), (‚àí 1 2 , 1 2 , ‚àí 1 2 , 1 2 ) is also an orthonormal basis of ùêÖ4. We have ‚à•( 1 2 , 1 2 , 1 2 , 1 2 )‚à•= ‚àö 1 22 + 1 22 + 1 22 + 1 22 = 1. Similarly, the other three vectors in the list above also have norm 1. Note that ‚ü®( 1 2 , 1 2 , 1 2 , 1 2 ), ( 1 2 , 1 2 , ‚àí 1 2 , ‚àí 1 2 )‚ü©= 1 2 ‚ãÖ 1 2 + 1 2 ‚ãÖ 1 2 + 1 2 ‚ãÖ (‚àí 1 2 )+ 1 2 ‚ãÖ (‚àí 1 2 )= 0. Similarly, the inner product of any two distinct vectors in the list above also equals 0. Thus the list above is orthonormal. Because we have an orthonormal list of length four in the four-dimensional vector space ùêÖ4, this list is an orthonormal basis of ùêÖ4 (by 6.28). In general, given a basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ and a vector ùë£ ‚àà ùëâ, we know that there is some choice of scalars ùëé1, ‚Ä¶, ùëéùëõ ‚àà ùêÖ such that ùë£ = ùëé1ùëí1 + ‚ãØ + ùëéùëõùëíùëõ. Computing the numbers ùëé1, ‚Ä¶, ùëéùëõ that satisfy the equation above can be a long computation for an arbitrary basis of ùëâ. The next result shows, however, that this is easy for an orthonormal basis‚Äîjust take ùëéùëò = ‚ü®ùë£, ùëíùëò‚ü©. 200 Chapter 6 Inner Product Spaces The formula below for ‚Äñùë£‚Äñ is called Parseval‚Äôs identity. It was published in 1799 in the context of Fourier series. Notice how the next result makes each inner product space of dimension ùëõ behave like ùêÖùëõ, with the role of the coordinates of a vector in ùêÖùëõ played by ‚ü®ùë£, ùëí1‚ü©, ‚Ä¶, ‚ü®ùë£, ùëíùëõ‚ü©. 6.30 writing a vector as a linear combination of an orthonormal basis Suppose ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ and ùë¢, ùë£ ‚àà ùëâ. Then (a) ùë£ = ‚ü®ùë£, ùëí1‚ü©ùëí1 + ‚ãØ + ‚ü®ùë£, ùëíùëõ‚ü©ùëíùëõ, (b) ‚Äñùë£‚Äñ 2 = ‚à£‚ü®ùë£, ùëí1‚ü©‚à£2 + ‚ãØ + ‚à£‚ü®ùë£, ùëíùëõ‚ü©‚à£2, (c) ‚ü®ùë¢, ùë£‚ü© = ‚ü®ùë¢, ùëí1‚ü©‚ü®ùë£, ùëí1‚ü©+ ‚ãØ + ‚ü®ùë¢, ùëíùëõ‚ü©‚ü®ùë£, ùëíùëõ‚ü©. Proof Because ùëí1, ‚Ä¶, ùëíùëõ is a basis of ùëâ, there exist scalars ùëé1, ‚Ä¶, ùëéùëõ such that ùë£ = ùëé1ùëí1 + ‚ãØ + ùëéùëõùëíùëõ. Because ùëí1, ‚Ä¶, ùëíùëõ is orthonormal, taking the inner product of both sides of this equation with ùëíùëò gives ‚ü®ùë£, ùëíùëò‚ü© = ùëéùëò. Thus (a) holds. Now (b) follows immediately from (a) and 6.24. Taking the inner product of ùë¢ with each side of (a) and then using the conjugate symmetry of the inner product gives (c). 6.31 example:finding coefficients for a linear combination Suppose we want to write the vector (1, 2, 4, 7) ‚àà ùêÖ 4 as a linear combination of the orthonormal basis ( 1 2 , 1 2 , 1 2 , 1 2 ), ( 1 2 , 1 2 , ‚àí 1 2 , ‚àí 1 2 ), ( 1 2 , ‚àí 1 2 , ‚àí 1 2 , 1 2 ), (‚àí 1 2 , 1 2 , ‚àí 1 2 , 1 2 ) of ùêÖ4 from Example 6.29. Instead of solving a system of four linear equations in four unknowns, as typically would be required if we were working with a nonorthonormal basis, we simply evaluate four inner products and use 6.30(a), getting that (1, 2, 4, 7)equals 7( 1 2 , 1 2 , 1 2 , 1 2 )‚àí 4( 1 2 , 1 2 , ‚àí 1 2 , ‚àí 1 2 )+ ( 1 2 , ‚àí 1 2 , ‚àí 1 2 , 1 2 )+ 2(‚àí 1 2 , 1 2 , ‚àí 1 2 , 1 2 ). Now that we understand the usefulness of orthonormal bases, how do we go about finding them? For example, doesùí´ùëö(ùêë) with inner product as in 6.3(c) have an orthonormal basis? The next result will lead to answers to these questions. J√∏rgen Gram (1850‚Äì1916) and Erhard Schmidt (1876‚Äì1959) popularized this algorithm that constructs orthonormal lists. The algorithm used in the next proof is called the Gram‚ÄìSchmidt procedure. It gives a method for turning a linearly independent list into an orthonormal list with the same span as the original list. Section 6B Orthonormal Bases 201 6.32 Gram‚ÄìSchmidt procedure Suppose ùë£1, ‚Ä¶, ùë£ùëö is a linearly independent list of vectors in ùëâ. Let ùëì1 = ùë£1. For ùëò = 2, ‚Ä¶, ùëö, defineùëìùëò inductively by ùëìùëò = ùë£ùëò ‚àí ‚ü®ùë£ùëò, ùëì1‚ü© ‚Äñ ùëì1‚Äñ2 ùëì1 ‚àí ‚ãØ ‚àí ‚ü®ùë£ùëò, ùëìùëò ‚àí 1‚ü© ‚Äñ ùëìùëò ‚àí 1‚Äñ2 ùëìùëò ‚àí 1. For each ùëò = 1, ‚Ä¶, ùëö, let ùëíùëò = ùëìùëò ‚Äñ ùëìùëò‚Äñ . Then ùëí1, ‚Ä¶, ùëíùëö is an orthonormal list of vectors in ùëâ such that span(ùë£1, ‚Ä¶, ùë£ùëò) = span(ùëí1, ‚Ä¶, ùëíùëò) for each ùëò = 1, ‚Ä¶, ùëö. Proof We will show by induction on ùëò that the desired conclusion holds. To get started with ùëò = 1, note that because ùëí1 = ùëì1/‚Äñ ùëì1‚Äñ, we have ‚Äñùëí1‚Äñ = 1; also, span(ùë£1) = span(ùëí1) because ùëí1 is a nonzero multiple of ùë£1. Suppose 1 < ùëò ‚â§ ùëöand the list ùëí1, ‚Ä¶, ùëíùëò ‚àí 1 generated by 6.32 is an orthonormal list such that 6.33 span(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1) = span(ùëí1, ‚Ä¶, ùëíùëò ‚àí 1). Because ùë£1, ‚Ä¶, ùë£ùëö is linearly independent, we have ùë£ùëò ‚àâ span(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1). Thus ùë£ùëò ‚àâ span(ùëí1, ‚Ä¶, ùëíùëò ‚àí 1) = span( ùëì1, ‚Ä¶, ùëìùëò ‚àí 1), which implies that ùëìùëò ‚â† 0. Hence we are not dividing by 0in the definition ofùëíùëò given in 6.32. Dividing a vector by its norm produces a new vector with norm 1; thus ‚Äñùëíùëò‚Äñ = 1. Let ùëó ‚àà {1, ‚Ä¶, ùëò ‚àí 1}. Then ‚ü®ùëíùëò, ùëíùëó‚ü© = 1 ‚Äñ ùëìùëò‚Äñ ‚Äñ ùëìùëó‚Äñ ‚ü® ùëìùëò, ùëìùëó‚ü© = 1 ‚Äñ ùëìùëò‚Äñ ‚Äñ ùëìùëó‚Äñ ‚ü®ùë£ùëò ‚àí ‚ü®ùë£ùëò, ùëì1‚ü© ‚Äñ ùëì1‚Äñ2 ùëì1 ‚àí ‚ãØ ‚àí ‚ü®ùë£ùëò, ùëìùëò ‚àí 1‚ü© ‚Äñ ùëìùëò ‚àí 1‚Äñ2 ùëìùëò ‚àí 1, ùëìùëó‚ü© = 1 ‚Äñ ùëìùëò‚Äñ ‚Äñ ùëìùëó‚Äñ (‚ü®ùë£ùëò, ùëìùëó‚ü© ‚àí ‚ü®ùë£ùëò, ùëìùëó‚ü©) = 0. Thus ùëí1, ‚Ä¶, ùëíùëò is an orthonormal list. From the definition ofùëíùëò given in 6.32, we see that ùë£ùëò ‚àà span(ùëí1, ‚Ä¶, ùëíùëò). Combining this information with 6.33 shows that span(ùë£1, ‚Ä¶, ùë£ùëò) ‚äÜspan(ùëí1, ‚Ä¶, ùëíùëò). Both lists above are linearly independent (the ùë£‚Äôs by hypothesis, and the ùëí‚Äôs by orthonormality and 6.25). Thus both subspaces above have dimension ùëò, and hence they are equal, completing the induction step and thus completing the proof. 202 Chapter 6 Inner Product Spaces 6.34 example:an orthonormal basis of ùí´2(ùêë) Suppose we make ùí´2(ùêë) into an inner product space using the inner product given by ‚ü®ùëù, ùëû‚ü© =‚à´ 1 ‚àí1 ùëùùëû for all ùëù, ùëû ‚àà ùí´2(ùêë). We know that 1, ùë•, ùë•2 is a basis of ùí´2(ùêë), but it is not an orthonormal basis. We will find an orthonormal basis ofùí´2(ùêë) by applying the Gram‚ÄìSchmidt procedure with ùë£1 = 1, ùë£2 = ùë•, and ùë£3 = ùë•2. To get started, take ùëì1 = ùë£1 = 1. Thus ‚Äñ ùëì1‚Äñ2 = ‚à´ 1 ‚àí1 1 = 2. Hence the formula in 6.32 tells us that ùëì2 = ùë£2 ‚àí ‚ü®ùë£2, ùëì1‚ü© ‚Äñ ùëì1‚Äñ2 ùëì1 = ùë• ‚àí ‚ü®ùë•, 1‚ü© ‚Äñ ùëì1‚Äñ2 = ùë•, where the last equality holds because ‚ü®ùë•, 1‚ü© =‚à´ 1 ‚àí1 ùë° ùëëùë° = 0. The formula above for ùëì2 implies that ‚Äñ ùëì2‚Äñ 2 = ‚à´1 ‚àí1 ùë°2 ùëëùë° = 2 3 . Now the formula in 6.32 tells us that ùëì3 = ùë£3 ‚àí ‚ü®ùë£3, ùëì1‚ü© ‚Äñ ùëì1‚Äñ2 ùëì1 ‚àí ‚ü®ùë£3, ùëì2‚ü© ‚Äñ ùëì2‚Äñ2 ùëì2 = ùë•2 ‚àí 1 2 ‚ü®ùë•2, 1‚ü©‚àí 3 2 ‚ü®ùë•2, ùë•‚ü©ùë• = ùë•2 ‚àí 1 3 . The formula above for ùëì3 implies that ‚Äñ ùëì3‚Äñ2 = ‚à´ 1 ‚àí1(ùë°2 ‚àí 1 3 ) 2 ùëëùë° = ‚à´ 1 ‚àí1(ùë°4 ‚àí 2 3 ùë°2 + 1 9 )ùëëùë° = 8 45 . Now dividing each of ùëì1, ùëì2, ùëì3 by its norm gives us the orthonormal list ‚àö 1 2 , ‚àö 3 2 ùë•, ‚àö 45 8 (ùë•2 ‚àí 1 3 ). The orthonormal list above has length three, which is the dimension of ùí´2(ùêë). Hence this orthonormal list is an orthonormal basis of ùí´2(ùêë) [by6.28]. Now we can answer the question about the existence of orthonormal bases. 6.35 existence of orthonormal basis Every finite-dimensional inner product space has an orthonormal basis. Proof Suppose ùëâ is finite-dimensional. Choose a basis ofùëâ. Apply the Gram‚Äì Schmidt procedure (6.32) to it, producing an orthonormal list of length dim ùëâ. By 6.28, this orthonormal list is an orthonormal basis of ùëâ. Sometimes we need to know not only that an orthonormal basis exists, but also that every orthonormal list can be extended to an orthonormal basis. In the next corollary, the Gram‚ÄìSchmidt procedure shows that such an extension is always possible. Section 6B Orthonormal Bases 203 6.36 every orthonormal list extends to an orthonormal basis Suppose ùëâ is finite-dimensional. Then every orthonormal list of vectors inùëâ can be extended to an orthonormal basis of ùëâ. Proof Suppose ùëí1, ‚Ä¶, ùëíùëö is an orthonormal list of vectors in ùëâ. Then ùëí1, ‚Ä¶, ùëíùëö is linearly independent (by 6.25). Hence this list can be extended to a basis ùëí1, ‚Ä¶, ùëíùëö, ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ (see 2.32). Now apply the Gram‚ÄìSchmidt procedure (6.32) to ùëí1, ‚Ä¶, ùëíùëö, ùë£1, ‚Ä¶, ùë£ùëõ, producing an orthonormal list ùëí1, ‚Ä¶, ùëíùëö, ùëì1, ‚Ä¶, ùëìùëõ; here the formula given by the Gram‚ÄìSchmidt procedure leaves the firstùëö vectors unchanged because they are already orthonormal. The list above is an orthonormal basis of ùëâ by 6.28. Recall that a matrix is called upper triangular if it looks like this: ‚éõ‚éú‚éú‚éú ‚éù ‚àó ‚àó ‚ã± 0 ‚àó ‚éû‚éü‚éü‚éü ‚é† , where the 0in the matrix above indicates that all entries below the diagonal equal 0, and asterisks are used to denote entries on and above the diagonal. In the last chapter, we gave a necessary and sufficient condition for an operator to have an upper-triangular matrix with respect to some basis (see 5.44). Now that we are dealing with inner product spaces, we would like to know whether there exists an orthonormal basis with respect to which we have an upper-triangular matrix. The next result shows that the condition for an operator to have an upper- triangular matrix with respect to some orthonormal basis is the same as the condition to have an upper-triangular matrix with respect to an arbitrary basis. 6.37 upper-triangular matrix with respect to some orthonormal basis Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ). Then ùëá has an upper- triangular matrix with respect to some orthonormal basis of ùëâ if and only if the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö) for some ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÖ. Proof Suppose ùëá has an upper-triangular matrix with respect to some basis ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ. Thus span(ùë£1, ‚Ä¶, ùë£ùëò) is invariant under ùëá for each ùëò = 1, ‚Ä¶, ùëõ (see 5.39). Apply the Gram‚ÄìSchmidt procedure to ùë£1, ‚Ä¶, ùë£ùëõ, producing an orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ. Because span(ùëí1, ‚Ä¶, ùëíùëò) = span(ùë£1, ‚Ä¶, ùë£ùëò) for each ùëò (see 6.32), we conclude that span(ùëí1, ‚Ä¶, ùëíùëò) is invariant under ùëá for each ùëò = 1, ‚Ä¶, ùëõ. Thus, by 5.39, ùëá has an upper-triangular matrix with respect to the orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ. Now use 5.44 to complete the proof. 204 Chapter 6 Inner Product Spaces Issai Schur (1875‚Äì1941) published a proof of the next result in 1909. For complex vector spaces, the next result is an important application of the result above. See Exercise 20 for a ver- sion of Schur‚Äôs theorem that applies simultaneously to more than one operator. 6.38 Schur‚Äôs theorem Every operator on a finite-dimensional complex inner product space has an upper-triangular matrix with respect to some orthonormal basis. Proof The desired result follows from the second version of the fundamental theorem of algebra (4.13) and 6.37. Linear Functionals on Inner Product Spaces Because linear maps into the scalar fieldùêÖ play a special role, we defined a special name for them and their vector space in Section 3F. Those definitions are repeated below in case you skipped Section 3F. 6.39 definition:linear functional, dual space, ùëâ‚Ä≤ ‚Ä¢ A linear functional on ùëâ is a linear map from ùëâ to ùêÖ. ‚Ä¢ The dual space of ùëâ, denoted by ùëâ‚Ä≤, is the vector space of all linear functionals on ùëâ. In other words, ùëâ‚Ä≤ = ‚Ñí(ùëâ, ùêÖ). 6.40 example:linear functional on ùêÖ3 The function ùúë‚à∂ ùêÖ3 ‚Üí ùêÖ defined by ùúë(ùëß1, ùëß2, ùëß3) = 2ùëß1 ‚àí 5ùëß2 + ùëß3 is a linear functional on ùêÖ3. We could write this linear functional in the form ùúë(ùëß) = ‚ü®ùëß, ùë§‚ü© for every ùëß ‚àà ùêÖ3, where ùë§ = (2, ‚àí5, 1). 6.41 example:linear functional on ùí´5(ùêë) The function ùúë‚à∂ ùí´5(ùêë) ‚Üí ùêë defined by ùúë(ùëù) = ‚à´1 ‚àí1 ùëù(ùë°)(cos(ùúãùë°))ùëëùë° is a linear functional on ùí´5(ùêë). Section 6B Orthonormal Bases 205 The next result is named in honor of Frigyes Riesz (1880‚Äì1956), who proved several theorems early in the twentieth century that look very much like the result below. If ùë£ ‚àà ùëâ, then the map that sends ùë¢ to ‚ü®ùë¢, ùë£‚ü©is a linear functional on ùëâ. The next result states that every linear func- tional on ùëâ is of this form. For example, we can take ùë£ = (2, ‚àí5, 1)in Example 6.40. Suppose we make the vector space ùí´5(ùêë) into an inner product space by defining‚ü®ùëù, ùëû‚ü© =‚à´ 1 ‚àí1 ùëùùëû. Let ùúë be as in Example 6.41. It is not obvious that there exists ùëû ‚àà ùí´5(ùêë) such that ‚à´1 ‚àí1 ùëù(ùë°)(cos(ùúãùë°))ùëëùë° = ‚ü®ùëù, ùëû‚ü© for every ùëù ‚àà ùí´5(ùêë) [we cannot take ùëû(ùë°) = cos(ùúãùë°) because that choice of ùëû is not an element of ùí´5(ùêë)]. The next result tells us the somewhat surprising result that there indeed exists a polynomial ùëû ‚àà ùí´5(ùêë) such that the equation above holds for all ùëù ‚àà ùí´5(ùêë). 6.42 Riesz representation theorem Suppose ùëâ is finite-dimensional andùúë is a linear functional on ùëâ. Then there is a unique vector ùë£ ‚àà ùëâ such that ùúë(ùë¢) = ‚ü®ùë¢, ùë£‚ü© for every ùë¢ ‚àà ùëâ. Proof First we show that there exists a vector ùë£ ‚àà ùëâ such that ùúë(ùë¢) = ‚ü®ùë¢, ùë£‚ü©for every ùë¢ ‚àà ùëâ. Let ùëí1, ‚Ä¶, ùëíùëõ be an orthonormal basis of ùëâ. Then ùúë(ùë¢) = ùúë(‚ü®ùë¢, ùëí1‚ü©ùëí1 + ‚ãØ + ‚ü®ùë¢, ùëíùëõ‚ü©ùëíùëõ) = ‚ü®ùë¢, ùëí1‚ü©ùúë(ùëí1) + ‚ãØ + ‚ü®ùë¢, ùëíùëõ‚ü©ùúë(ùëíùëõ) = ‚ü®ùë¢, ùúë(ùëí1)ùëí1 + ‚ãØ + ùúë(ùëíùëõ)ùëíùëõ‚ü© for every ùë¢ ‚àà ùëâ, where the first equality comes from6.30(a). Thus setting 6.43 ùë£ = ùúë(ùëí1)ùëí1 + ‚ãØ + ùúë(ùëíùëõ)ùëíùëõ, we have ùúë(ùë¢) = ‚ü®ùë¢, ùë£‚ü©for every ùë¢ ‚àà ùëâ, as desired. Now we prove that only one vector ùë£ ‚àà ùëâ has the desired behavior. Suppose ùë£1, ùë£2 ‚àà ùëâ are such that ùúë(ùë¢) = ‚ü®ùë¢, ùë£1‚ü© = ‚ü®ùë¢, ùë£2‚ü© for every ùë¢ ‚àà ùëâ. Then 0 = ‚ü®ùë¢, ùë£1‚ü© ‚àí ‚ü®ùë¢, ùë£2‚ü© = ‚ü®ùë¢, ùë£1 ‚àí ùë£2‚ü© for every ùë¢ ‚àà ùëâ. Taking ùë¢ = ùë£1 ‚àí ùë£2 shows that ùë£1 ‚àí ùë£2 = 0. Thus ùë£1 = ùë£2, completing the proof of the uniqueness part of the result. 206 Chapter 6 Inner Product Spaces 6.44 example:computation illustrating Riesz representation theorem Suppose we want to find a polynomialùëû ‚àà ùí´2(ùêë) such that 6.45 ‚à´ 1 ‚àí1 ùëù(ùë°)(cos(ùúãùë°))ùëëùë° = ‚à´ 1 ‚àí1 ùëùùëû for every polynomial ùëù ‚àà ùí´2(ùêë). To do this, we make ùí´2(ùêë) into an inner product space by defining‚ü®ùëù, ùëû‚ü©to be the right side of the equation above for ùëù, ùëû ‚àà ùí´2(ùêë). Note that the left side of the equation above does not equal the inner product in ùí´2(ùêë) of ùëù and the function ùë° ‚Ü¶ cos(ùúãùë°) because this last function is not a polynomial. Define a linear functionalùúë on ùí´2(ùêë) by letting ùúë(ùëù) = ‚à´1 ‚àí1 ùëù(ùë°)(cos(ùúãùë°))ùëëùë° for each ùëù ‚àà ùí´2(ùêë). Now use the orthonormal basis from Example 6.34 and apply formula 6.43 from the proof of the Riesz representation theorem to see that if ùëù ‚àà ùí´2(ùêë), then ùúë(ùëù) = ‚ü®ùëù, ùëû‚ü©, where ùëû(ùë•) = (‚à´1 ‚àí1 ‚àö 1 2 cos(ùúãùë°) ùëëùë°)‚àö 1 2 + (‚à´1 ‚àí1 ‚àö 3 2 ùë° cos(ùúãùë°) ùëëùë°)‚àö 3 2 ùë• + (‚à´1 ‚àí1 ‚àö 45 8 (ùë°2 ‚àí 1 3 )cos(ùúãùë°) ùëëùë°)‚àö 45 8 (ùë•2 ‚àí 1 3 ). A bit of calculus applied to the equation above shows that ùëû(ùë•) = 15 2ùúã2 (1 ‚àí 3ùë• 2). The same procedure shows that if we want to findùëû ‚àà ùí´5(ùêë) such that 6.45 holds for all ùëù ‚àà ùí´5(ùêë), then we should take ùëû(ùë•) = 105 8ùúã4 ((27 ‚àí 2ùúã 2)+ (24ùúã 2 ‚àí 270)ùë•2 + (315 ‚àí 30ùúã 2)ùë•4). Suppose ùëâ is finite-dimensional andùúë a linear functional on ùëâ. Then 6.43 gives a formula for the vector ùë£ that satisfies ùúë(ùë¢) = ‚ü®ùë¢, ùë£‚ü© for all ùë¢ ‚àà ùëâ. Specifically, we have ùë£ = ùúë(ùëí1)ùëí1 + ‚ãØ + ùúë(ùëíùëõ)ùëíùëõ. The right side of the equation above seems to depend on the orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ as well as on ùúë. However, 6.42 tells us that ùë£ is uniquely determined by ùúë. Thus the right side of the equation above is the same regardless of which orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ is chosen. For two additional different proofs of the Riesz representation theorem, see 6.58 and also Exercise 13 in Section 6C. Section 6B Orthonormal Bases 207 Exercises 6B 1 Suppose ùëí1, ‚Ä¶, ùëíùëö is a list of vectors in ùëâ such that ‚Äñùëé1ùëí1 + ‚ãØ + ùëéùëöùëíùëö‚Äñ2 = |ùëé1| 2 + ‚ãØ + |ùëéùëö|2 for all ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ. Show that ùëí1, ‚Ä¶, ùëíùëö is an orthonormal list. This exercise provides a converse to 6.24. 2 (a) Suppose ùúÉ ‚àà ùêë. Show that both (cos ùúÉ, sin ùúÉ), (‚àí sin ùúÉ, cos ùúÉ) and (cos ùúÉ, sin ùúÉ), (sin ùúÉ, ‚àí cos ùúÉ) are orthonormal bases of ùêë2. (b) Show that each orthonormal basis of ùêë2 is of the form given by one of the two possibilities in (a). 3 Suppose ùëí1, ‚Ä¶, ùëíùëö is an orthonormal list in ùëâ and ùë£ ‚àà ùëâ. Prove that ‚Äñùë£‚Äñ 2 = ‚à£‚ü®ùë£, ùëí1‚ü©‚à£2 + ‚ãØ + ‚à£‚ü®ùë£, ùëíùëö‚ü©‚à£2 ‚ü∫ ùë£ ‚àà span(ùëí1, ‚Ä¶, ùëíùëö). 4 Suppose ùëõ is a positive integer. Prove that 1 ‚àö2ùúã , cos ùë• ‚àö ùúã , cos 2ùë• ‚àö ùúã , ‚Ä¶, cos ùëõùë• ‚àö ùúã , sin ùë• ‚àö ùúã , sin 2ùë• ‚àö ùúã , ‚Ä¶, sin ùëõùë• ‚àö ùúã is an orthonormal list of vectors in ùê∂[‚àíùúã, ùúã], the vector space of continuous real-valued functions on [‚àíùúã, ùúã] with inner product ‚ü® ùëì, ùëî‚ü© =‚à´ùúã ‚àíùúã ùëì ùëî. Hint: The following formulas should help. (sin ùë•)(cos ùë¶) = sin(ùë• ‚àí ùë¶) + sin(ùë• + ùë¶) 2 (sin ùë•)(sin ùë¶) = cos(ùë• ‚àí ùë¶) ‚àí cos(ùë• + ùë¶) 2 (cos ùë•)(cos ùë¶) = cos(ùë• ‚àí ùë¶) + cos(ùë• + ùë¶) 2 5 Suppose ùëì‚à∂ [‚àíùúã, ùúã] ‚Üí ùêë is continuous. For each nonnegative integer ùëò, define ùëéùëò = 1 ‚àöùúã ‚à´ùúã ‚àíùúã ùëì (ùë•) cos(ùëòùë•) ùëëùë• and ùëèùëò = 1 ‚àö ùúã ‚à´ùúã ‚àíùúã ùëì (ùë•) sin(ùëòùë•) ùëëùë•. Prove that ùëé0 2 2 + ‚àû ‚àë ùëò = 1(ùëéùëò 2 + ùëèùëò 2)‚â§‚à´ ùúã ‚àíùúã ùëì 2. The inequality above is actually an equality for all continuous functions ùëì‚à∂ [‚àíùúã, ùúã] ‚Üí ùêë. However, proving that this inequality is an equality involves Fourier series techniques beyond the scope of this book. 208 Chapter 6 Inner Product Spaces 6 Suppose ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ. (a) Prove that if ùë£1, ‚Ä¶, ùë£ùëõ are vectors in ùëâ such that ‚Äñùëíùëò ‚àí ùë£ùëò‚Äñ < 1 ‚àö ùëõ for each ùëò, then ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. (b) Show that there exist ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùëâ such that ‚Äñùëíùëò ‚àí ùë£ùëò‚Äñ ‚â§ 1 ‚àö ùëõ for each ùëò, but ùë£1, ‚Ä¶, ùë£ùëõ is not linearly independent. This exercise states in (a) that an appropriately small perturbation of an orthonormal basis is a basis. Then (b) shows that the number 1/ ‚àöùëõ on the right side of the inequality in (a) cannot be improved upon. 7 Suppose ùëá ‚àà ‚Ñí(ùêë3)has an upper-triangular matrix with respect to the basis (1, 0, 0), (1, 1, 1), (1, 1, 2). Find an orthonormal basis of ùêë3 with respect to which ùëá has an upper-triangular matrix. 8 Make ùí´2(ùêë) into an inner product space by defining‚ü®ùëù, ùëû‚ü© =‚à´ 1 0 ùëùùëû for all ùëù, ùëû ‚àà ùí´2(ùêë). (a) Apply the Gram‚ÄìSchmidt procedure to the basis 1, ùë•, ùë•2 to produce an orthonormal basis of ùí´2(ùêë). (b) The differentiation operator (the operator that takes ùëù to ùëù ‚Ä≤)on ùí´2(ùêë) has an upper-triangular matrix with respect to the basis 1, ùë•, ùë•2, which is not an orthonormal basis. Find the matrix of the differentiation operator on ùí´2(ùêë) with respect to the orthonormal basis produced in (a) and verify that this matrix is upper triangular, as expected from the proof of 6.37. 9 Suppose ùëí1, ‚Ä¶, ùëíùëö is the result of applying the Gram‚ÄìSchmidt procedure to a linearly independent list ùë£1, ‚Ä¶, ùë£ùëö in ùëâ. Prove that ‚ü®ùë£ùëò, ùëíùëò‚ü© > 0for each ùëò = 1, ‚Ä¶, ùëö. 10 Suppose ùë£1, ‚Ä¶, ùë£ùëö is a linearly independent list in ùëâ. Explain why the orthonormal list produced by the formulas of the Gram‚ÄìSchmidt procedure (6.32) is the only orthonormal list ùëí1, ‚Ä¶, ùëíùëö in ùëâ such that ‚ü®ùë£ùëò, ùëíùëò‚ü© > 0and span(ùë£1, ‚Ä¶, ùë£ùëò) = span(ùëí1, ‚Ä¶, ùëíùëò) for each ùëò = 1, ‚Ä¶, ùëö. The result in this exercise is used in the proof of 7.58. 11 Find a polynomial ùëû ‚àà ùí´2(ùêë) such that ùëù( 1 2 )= ‚à´1 0 ùëùùëû for every ùëù ‚àà ùí´2(ùêë). 12 Find a polynomial ùëû ‚àà ùí´2(ùêë) such that ‚à´ 1 0 ùëù(ùë•) cos(ùúãùë•) ùëëùë• = ‚à´ 1 0 ùëùùëû for every ùëù ‚àà ùí´2(ùêë). Section 6B Orthonormal Bases 209 13 Show that a list ùë£1, ‚Ä¶, ùë£ùëö of vectors in ùëâ is linearly dependent if and only if the Gram‚ÄìSchmidt formula in 6.32 produces ùëìùëò = 0for some ùëò ‚àà {1, ‚Ä¶, ùëö}. This exercise gives an alternative to Gaussian elimination techniques for determining whether a list of vectors in an inner product space is linearly dependent. 14 Suppose ùëâ is a real inner product space and ùë£1, ‚Ä¶, ùë£ùëö is a linearly indepen- dent list of vectors in ùëâ. Prove that there exist exactly 2 ùëö orthonormal lists ùëí1, ‚Ä¶, ùëíùëö of vectors in ùëâ such that span(ùë£1, ‚Ä¶, ùë£ùëò) = span(ùëí1, ‚Ä¶, ùëíùëò) for all ùëò ‚àà {1, ‚Ä¶, ùëö}. 15 Suppose ‚ü®‚ãÖ, ‚ãÖ‚ü©1 and ‚ü®‚ãÖ, ‚ãÖ‚ü©2 are inner products on ùëâ such that ‚ü®ùë¢, ùë£‚ü©1 = 0if and only if ‚ü®ùë¢, ùë£‚ü©2 = 0. Prove that there is a positive number ùëê such that ‚ü®ùë¢, ùë£‚ü©1 = ùëê‚ü®ùë¢, ùë£‚ü©2 for every ùë¢, ùë£ ‚àà ùëâ. This exercise shows that if two inner products have the same pairs of orthogonal vectors, then each of the inner products is a scalar multiple of the other inner product. 16 Suppose ùëâ is finite-dimensional. Suppose‚ü®‚ãÖ, ‚ãÖ‚ü©1, ‚ü®‚ãÖ, ‚ãÖ‚ü©2 are inner products on ùëâ with corresponding norms ‚Äñ ‚ãÖ ‚Äñ1 and ‚Äñ ‚ãÖ ‚Äñ2. Prove that there exists a positive number ùëê such that ‚Äñùë£‚Äñ1 ‚â§ ùëê‚Äñùë£‚Äñ2 for every ùë£ ‚àà ùëâ. 17 Suppose ùêÖ = ùêÇ and ùëâ is finite-dimensional. Prove that ifùëá is an operator on ùëâ such that 1is the only eigenvalue of ùëá and ‚Äñùëáùë£‚Äñ ‚â§ ‚Äñùë£‚Äñfor all ùë£ ‚àà ùëâ, then ùëá is the identity operator. 18 Suppose ùë¢1, ‚Ä¶, ùë¢ùëö is a linearly independent list in ùëâ. Show that there exists ùë£ ‚àà ùëâ such that ‚ü®ùë¢ùëò, ùë£‚ü© = 1for all ùëò ‚àà {1, ‚Ä¶, ùëö}. 19 Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Prove that there exists a basis ùë¢1, ‚Ä¶, ùë¢ùëõ of ùëâ such that ‚ü®ùë£ùëó, ùë¢ùëò‚ü© = ‚éß{ ‚é®{‚é© 0 if ùëó ‚â† ùëò, 1 if ùëó = ùëò. 20 Suppose ùêÖ = ùêÇ, ùëâ is finite-dimensional, and‚Ñ∞ ‚äÜ‚Ñí(ùëâ) is such that ùëÜùëá = ùëáùëÜ for all ùëÜ, ùëá ‚àà ‚Ñ∞. Prove that there is an orthonormal basis of ùëâ with respect to which every element of ‚Ñ∞ has an upper-triangular matrix. This exercise strengthens Exercise 9(b) in Section 5E (in the context of inner product spaces) by asserting that the basis in that exercise can be chosen to be orthonormal. 21 Suppose ùêÖ = ùêÇ, ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and all eigenvalues of ùëá have absolute value less than 1. Let ùúñ > 0. Prove that there exists a positive integer ùëö such that ‚à•ùëáùëöùë£‚à• ‚â§ ùúñ‚Äñùë£‚Äñfor every ùë£ ‚àà ùëâ. 210 Chapter 6 Inner Product Spaces 22 Suppose ùê∂[‚àí1, 1]is the vector space of continuous real-valued functions on the interval [‚àí1, 1]with inner product given by ‚ü® ùëì, ùëî‚ü© =‚à´1 ‚àí1 ùëì ùëî for all ùëì, ùëî ‚àà ùê∂[‚àí1, 1]. Let ùúë be the linear functional on ùê∂[‚àí1, 1]defined by ùúë( ùëì ) = ùëì (0). Show that there does not exist ùëî ‚àà ùê∂[‚àí1, 1]such that ùúë( ùëì ) = ‚ü® ùëì, ùëî‚ü© for every ùëì ‚àà ùê∂[‚àí1, 1]. This exercise shows that the Riesz representation theorem (6.42) does not hold on infinite-dimensional vector spaces without additional hypotheses on ùëâ and ùúë. 23 For all ùë¢, ùë£ ‚àà ùëâ, defineùëë(ùë¢, ùë£) = ‚Äñùë¢ ‚àí ùë£‚Äñ. (a) Show that ùëë is a metric on ùëâ. (b) Show that if ùëâ is finite-dimensional, thenùëë is a complete metric on ùëâ (meaning that every Cauchy sequence converges). (c) Show that every finite-dimensional subspace ofùëâ is a closed subset of ùëâ (with respect to the metric ùëë ). This exercise requires familiarity with metric spaces. orthogonality at the Supreme Court Law professor Richard Friedman presenting a case before the U.S. Supreme Court in 2010: Mr. Friedman: I think that issue is entirely orthogonal to the issue here because the Commonwealth is acknowledging‚Äî Chief Justice Roberts: I‚Äôm sorry. Entirely what? Mr. Friedman: Orthogonal. Right angle. Unrelated. Irrelevant. Chief Justice Roberts: Oh. Justice Scalia: What was that adjective? I liked that. Mr. Friedman: Orthogonal. Chief Justice Roberts: Orthogonal. Mr. Friedman: Right, right. Justice Scalia: Orthogonal, ooh. (Laughter.) Justice Kennedy: I knew this case presented us a problem. (Laughter.) Section 6C Orthogonal Complements and Minimization Problems 211 6C Orthogonal Complements and Minimization Problems Orthogonal Complements 6.46 definition:orthogonal complement, ùëà‚üÇ If ùëà is a subset of ùëâ, then the orthogonal complement of ùëà, denoted by ùëà‚üÇ, is the set of all vectors in ùëâ that are orthogonal to every vector in ùëà: ùëà‚üÇ = {ùë£ ‚àà ùëâ ‚à∂ ‚ü®ùë¢, ùë£‚ü© = 0for every ùë¢ ‚àà ùëà}. The orthogonal complement ùëà‚üÇ depends on ùëâ as well as on ùëà. However, the inner product space ùëâ should always be clear from the context and thus it can be omitted from the notation. 6.47 example:orthogonal complements ‚Ä¢ If ùëâ = ùêë3 and ùëà is the subset of ùëâ consisting of the single point (2, 3, 5), then ùëà‚üÇ is the plane {(ùë•, ùë¶, ùëß) ‚àà ùêë3 ‚à∂ 2ùë•+ 3ùë¶+ 5ùëß = 0}. ‚Ä¢ If ùëâ = ùêë3 and ùëà is the plane {(ùë•, ùë¶, ùëß) ‚àà ùêë3 ‚à∂ 2ùë•+ 3ùë¶+ 5ùëß = 0}, then ùëà‚üÇ is the line {(2ùë°, 3ùë°, 5ùë°)‚à∂ ùë° ‚àà ùêë}. ‚Ä¢ More generally, if ùëà is a plane in ùêë3 containing the origin, then ùëà‚üÇ is the line containing the origin that is perpendicular to ùëà. ‚Ä¢ If ùëà is a line in ùêë3 containing the origin, then ùëà‚üÇ is the plane containing the origin that is perpendicular to ùëà. ‚Ä¢ If ùëâ = ùêÖ5 and ùëà = {(ùëé, ùëè, 0, 0, 0) ‚àà ùêÖ 5 ‚à∂ ùëé, ùëè ‚àà ùêÖ}, then ùëà‚üÇ = {(0, 0, ùë•, ùë¶, ùëß) ‚àà ùêÖ5 ‚à∂ ùë•, ùë¶, ùëß ‚àà ùêÖ}. ‚Ä¢ If ùëí1, ‚Ä¶, ùëíùëö, ùëì1, ‚Ä¶, ùëìùëõ is an orthonormal basis of ùëâ, then (span(ùëí1, ‚Ä¶, ùëíùëö)) ‚üÇ = span( ùëì1, ‚Ä¶, ùëìùëõ). We begin with some straightforward consequences of the definition. 6.48 properties of orthogonal complement (a) If ùëà is a subset of ùëâ, then ùëà‚üÇ is a subspace of ùëâ. (b) {0} ‚üÇ = ùëâ. (c) ùëâ‚üÇ = {0}. (d) If ùëà is a subset of ùëâ, then ùëà ‚à© ùëà ‚üÇ ‚äÜ {0}. (e) If ùê∫ and ùêª are subsets of ùëâ and ùê∫ ‚äÜ ùêª, then ùêª‚üÇ ‚äÜ ùê∫ ‚üÇ. 212 Chapter 6 Inner Product Spaces Proof (a) Suppose ùëà is a subset of ùëâ. Then ‚ü®ùë¢, 0‚ü© = 0for every ùë¢ ‚àà ùëà; thus 0 ‚àà ùëà ‚üÇ. Suppose ùë£, ùë§ ‚àà ùëà‚üÇ. If ùë¢ ‚àà ùëà, then ‚ü®ùë¢, ùë£ + ùë§‚ü© = ‚ü®ùë¢, ùë£‚ü©+ ‚ü®ùë¢, ùë§‚ü© = 0+ 0 = 0. Thus ùë£ + ùë§ ‚àà ùëà‚üÇ, which shows that ùëà‚üÇ is closed under addition. Similarly, suppose ùúÜ ‚àà ùêÖ and ùë£ ‚àà ùëà‚üÇ. If ùë¢ ‚àà ùëà, then ‚ü®ùë¢, ùúÜùë£‚ü© = ùúÜ‚ü®ùë¢, ùë£‚ü© = ùúÜ‚ãÖ 0 = 0. Thus ùúÜùë£ ‚àà ùëà‚üÇ, which shows that ùëà‚üÇ is closed under scalar multiplication. Thus ùëà‚üÇ is a subspace of ùëâ. (b) Suppose that ùë£ ‚àà ùëâ. Then ‚ü®0, ùë£‚ü© = 0, which implies that ùë£ ‚àà {0} ‚üÇ. Thus {0} ‚üÇ = ùëâ. (c) Suppose that ùë£ ‚àà ùëâ‚üÇ. Then ‚ü®ùë£, ùë£‚ü© = 0, which implies that ùë£ = 0. Thus ùëâ‚üÇ = {0}. (d) Suppose ùëà is a subset of ùëâ and ùë¢ ‚àà ùëà ‚à© ùëà ‚üÇ. Then ‚ü®ùë¢, ùë¢‚ü© = 0, which implies that ùë¢ = 0. Thus ùëà ‚à© ùëà ‚üÇ ‚äÜ {0}. (e) Suppose ùê∫ and ùêª are subsets of ùëâ and ùê∫ ‚äÜ ùêª. Suppose ùë£ ‚àà ùêª‚üÇ. Then ‚ü®ùë¢, ùë£‚ü© = 0for every ùë¢ ‚àà ùêª, which implies that ‚ü®ùë¢, ùë£‚ü© = 0for every ùë¢ ‚àà ùê∫. Hence ùë£ ‚àà ùê∫‚üÇ. Thus ùêª‚üÇ ‚äÜ ùê∫ ‚üÇ. Recall that if ùëà and ùëä are subspaces of ùëâ, then ùëâ is the direct sum of ùëà and ùëä (written ùëâ = ùëà ‚äï ùëä) if each element of ùëâ can be written in exactly one way as a vector in ùëà plus a vector in ùëä (see 1.41). Furthermore, this happens if and only if ùëâ = ùëà + ùëä and ùëà ‚à© ùëä = {0}(see 1.46). The next result shows that every finite-dimensional subspace ofùëâ leads to a natural direct sum decomposition of ùëâ. See Exercise 16 for an example showing that the result below can fail without the hypothesis that the subspace ùëà is finite- dimensional. 6.49 direct sum of a subspace and its orthogonal complement Suppose ùëà is a finite-dimensional subspace ofùëâ. Then ùëâ = ùëà ‚äï ùëà‚üÇ. Proof First we will show that ùëâ = ùëà + ùëà‚üÇ. To do this, suppose that ùë£ ‚àà ùëâ. Let ùëí1, ‚Ä¶, ùëíùëö be an orthonormal basis of ùëà. We want to write ùë£ as the sum of a vector in ùëà and a vector orthogonal to ùëà. Section 6C Orthogonal Complements and Minimization Problems 213 We have 6.50 ùë£ = ‚ü®ùë£, ùëí1‚ü©ùëí1 + ‚ãØ + ‚ü®ùë£, ùëíùëö‚ü©ùëíùëö‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü ùë¢ + ùë£ ‚àí ‚ü®ùë£, ùëí1‚ü©ùëí1 ‚àí ‚ãØ ‚àí ‚ü®ùë£, ùëíùëö‚ü©ùëíùëö‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü‚èü ùë§ . Let ùë¢ and ùë§ be defined as in the equation above (as was done in the proof of6.26). Because each ùëíùëò ‚àà ùëà, we see that ùë¢ ‚àà ùëà. Because ùëí1, ‚Ä¶, ùëíùëö is an orthonormal list, for each ùëò = 1, ‚Ä¶, ùëö we have ‚ü®ùë§, ùëíùëò‚ü© = ‚ü®ùë£, ùëíùëò‚ü© ‚àí ‚ü®ùë£, ùëíùëò‚ü© = 0. Thus ùë§ is orthogonal to every vector in span(ùëí1, ‚Ä¶, ùëíùëö), which shows that ùë§ ‚àà ùëà‚üÇ. Hence we have written ùë£ = ùë¢ + ùë§, where ùë¢ ‚àà ùëà and ùë§ ‚àà ùëà‚üÇ, completing the proof that ùëâ = ùëà + ùëà‚üÇ. From 6.48(d), we know that ùëà ‚à© ùëà ‚üÇ = {0}. Now equation ùëâ = ùëà + ùëà‚üÇ implies that ùëâ = ùëà ‚äï ùëà‚üÇ (see 1.46). Now we can see how to compute dim ùëà‚üÇ from dim ùëà. 6.51 dimension of orthogonal complement Suppose ùëâ is finite-dimensional andùëà is a subspace of ùëâ. Then dim ùëà‚üÇ = dim ùëâ ‚àí dim ùëà. Proof The formula for dim ùëà‚üÇ follows immediately from 6.49 and 3.94. The next result is an important consequence of 6.49. 6.52 orthogonal complement of the orthogonal complement Suppose ùëà is a finite-dimensional subspace ofùëâ. Then ùëà = (ùëà‚üÇ) ‚üÇ . Proof First we will show that 6.53 ùëà ‚äÜ(ùëà‚üÇ) ‚üÇ . To do this, suppose ùë¢ ‚àà ùëà. Then ‚ü®ùë¢, ùë§‚ü© = 0for every ùë§ ‚àà ùëà‚üÇ (by the definition of ùëà‚üÇ). Because ùë¢ is orthogonal to every vector in ùëà‚üÇ, we have ùë¢ ‚àà (ùëà‚üÇ) ‚üÇ, completing the proof of 6.53. To prove the inclusion in the other direction, suppose ùë£ ‚àà (ùëà‚üÇ) ‚üÇ. By 6.49, we can write ùë£ = ùë¢ + ùë§, where ùë¢ ‚àà ùëà and ùë§ ‚àà ùëà‚üÇ. We have ùë£ ‚àí ùë¢ = ùë§ ‚àà ùëà‚üÇ. Because ùë£ ‚àà (ùëà‚üÇ) ‚üÇ and ùë¢ ‚àà (ùëà‚üÇ) ‚üÇ (from 6.53), we have ùë£ ‚àí ùë¢ ‚àà (ùëà‚üÇ) ‚üÇ. Thus ùë£ ‚àí ùë¢ ‚àà ùëà‚üÇ ‚à©(ùëà‚üÇ) ‚üÇ, which implies that ùë£ ‚àí ùë¢ = 0[by6.48(d)], which implies that ùë£ = ùë¢, which implies that ùë£ ‚àà ùëà. Thus (ùëà‚üÇ) ‚üÇ ‚äÜ ùëà, which along with 6.53 completes the proof. 214 Chapter 6 Inner Product Spaces Exercise 16(a) shows that the result below is not true without the hypothesis that ùëà is finite-dimensional. Suppose ùëà is a subspace of ùëâ and we want to show that ùëà = ùëâ. In some situations, the easiest way to do this is to show that the only vector orthogonal to ùëà is 0, and then use the result below. For example, the result below is useful for Exercise 4. 6.54 ùëà‚üÇ = {0} ‚ü∫ ùëà = ùëâ(for ùëà a finite-dimensional subspace of ùëâ) Suppose ùëà is a finite-dimensional subspace ofùëâ. Then ùëà‚üÇ = {0} ‚ü∫ ùëà = ùëâ. Proof First suppose ùëà‚üÇ = {0}. Then by 6.52, ùëà = (ùëà‚üÇ) ‚üÇ = {0} ‚üÇ = ùëâ, as desired. Conversely, if ùëà = ùëâ, then ùëà‚üÇ = ùëâ‚üÇ = {0}by 6.48(c). We now define an operatorùëÉùëà for each finite-dimensional subspaceùëà of ùëâ. 6.55 definition:orthogonal projection, ùëÉùëà Suppose ùëà is a finite-dimensional subspace ofùëâ. The orthogonal projection of ùëâ onto ùëà is the operator ùëÉùëà ‚àà ‚Ñí(ùëâ) defined as follows: For eachùë£ ‚àà ùëâ, write ùë£ = ùë¢ + ùë§, where ùë¢ ‚àà ùëà and ùë§ ‚àà ùëà‚üÇ. Then let ùëÉùëàùë£ = ùë¢. The direct sum decomposition ùëâ = ùëà ‚äï ùëà‚üÇ given by 6.49 shows that each ùë£ ‚àà ùëâ can be uniquely written in the form ùë£ = ùë¢ + ùë§ with ùë¢ ‚àà ùëà and ùë§ ‚àà ùëà‚üÇ. Thus ùëÉùëàùë£ is well defined. See the figure that accompanies the proof of6.61 for the picture describing ùëÉùëàùë£ that you should keep in mind. 6.56 example:orthogonal projection onto one-dimensional subspace Suppose ùë¢ ‚àà ùëâ with ùë¢ ‚â† 0and ùëà is the one-dimensional subspace of ùëâ defined byùëà = span(ùë¢). If ùë£ ‚àà ùëâ, then ùë£ = ‚ü®ùë£, ùë¢‚ü© ‚Äñùë¢‚Äñ2 ùë¢ + (ùë£ ‚àí ‚ü®ùë£, ùë¢‚ü© ‚Äñùë¢‚Äñ2 ùë¢), where the first term on the right is inspan(ùë¢) (and thus is in ùëà) and the second term on the right is orthogonal to ùë¢ (and thus is in ùëà‚üÇ). Thus ùëÉùëàùë£ equals the first term on the right. In other words, we have the formula ùëÉùëàùë£ = ‚ü®ùë£, ùë¢‚ü© ‚Äñùë¢‚Äñ2 ùë¢ for every ùë£ ‚àà ùëâ. Taking ùë£ = ùë¢, the formula above becomes ùëÉùëàùë¢ = ùë¢, as expected. Furthermore, taking ùë£ ‚àà {ùë¢}‚üÇ, the formula above becomes ùëÉùëàùë£ = 0, also as expected. Section 6C Orthogonal Complements and Minimization Problems 215 6.57 properties of orthogonal projection ùëÉùëà Suppose ùëà is a finite-dimensional subspace ofùëâ. Then (a) ùëÉùëà ‚àà ‚Ñí(ùëâ); (b) ùëÉùëàùë¢ = ùë¢ for every ùë¢ ‚àà ùëà; (c) ùëÉùëàùë§ = 0for every ùë§ ‚àà ùëà‚üÇ; (d) range ùëÉùëà = ùëà; (e) null ùëÉùëà = ùëà‚üÇ; (f) ùë£ ‚àí ùëÉùëàùë£ ‚àà ùëà‚üÇ for every ùë£ ‚àà ùëâ; (g) ùëÉùëà 2 = ùëÉùëà; (h) ‚ÄñùëÉùëàùë£‚Äñ ‚â§ ‚Äñùë£‚Äñfor every ùë£ ‚àà ùëâ; (i) if ùëí1, ‚Ä¶, ùëíùëö is an orthonormal basis of ùëà and ùë£ ‚àà ùëâ, then ùëÉùëàùë£ = ‚ü®ùë£, ùëí1‚ü©ùëí1 + ‚ãØ + ‚ü®ùë£, ùëíùëö‚ü©ùëíùëö. Proof (a) To show that ùëÉùëà is a linear map on ùëâ, suppose ùë£1, ùë£2 ‚àà ùëâ. Write ùë£1 = ùë¢1 + ùë§1 and ùë£2 = ùë¢2 + ùë§2 with ùë¢1, ùë¢2 ‚àà ùëà and ùë§1, ùë§2 ‚àà ùëà‚üÇ. Thus ùëÉùëàùë£1 = ùë¢1 and ùëÉùëàùë£2 = ùë¢2. Now ùë£1 + ùë£2 = (ùë¢1 + ùë¢2) + (ùë§1 + ùë§2), where ùë¢1 + ùë¢2 ‚àà ùëà and ùë§1 + ùë§2 ‚àà ùëà‚üÇ. Thus ùëÉùëà(ùë£1 + ùë£2) = ùë¢1 + ùë¢2 = ùëÉùëàùë£1 + ùëÉùëàùë£2. Similarly, suppose ùúÜ ‚àà ùêÖ and ùë£ ‚àà ùëâ. Write ùë£ = ùë¢ + ùë§, where ùë¢ ‚àà ùëà and ùë§ ‚àà ùëà‚üÇ. Then ùúÜùë£ = ùúÜùë¢ + ùúÜùë§ with ùúÜùë¢ ‚àà ùëà and ùúÜùë§ ‚àà ùëà‚üÇ. Thus ùëÉùëà(ùúÜùë£) = ùúÜùë¢ = ùúÜùëÉùëàùë£. Hence ùëÉùëà is a linear map from ùëâ to ùëâ. (b) Suppose ùë¢ ‚àà ùëà. We can write ùë¢ = ùë¢ + 0, where ùë¢ ‚àà ùëà and 0 ‚àà ùëà ‚üÇ. Thus ùëÉùëàùë¢ = ùë¢. (c) Suppose ùë§ ‚àà ùëà‚üÇ. We can write ùë§ = 0+ ùë§, where 0 ‚àà ùëàand ùë§ ‚àà ùëà‚üÇ. Thus ùëÉùëàùë§ = 0. (d) The definition ofùëÉùëà implies that range ùëÉùëà ‚äÜ ùëà. Furthermore, (b) implies that ùëà ‚äÜrange ùëÉùëà. Thus range ùëÉùëà = ùëà. (e) The inclusion ùëà‚üÇ ‚äÜnull ùëÉùëà follows from (c). To prove the inclusion in the other direction, note that if ùë£ ‚àà null ùëÉùëà then the decomposition given by 6.49 must be ùë£ = 0+ ùë£, where 0 ‚àà ùëàand ùë£ ‚àà ùëà‚üÇ. Thus null ùëÉùëà ‚äÜ ùëà ‚üÇ. 216 Chapter 6 Inner Product Spaces (f) If ùë£ ‚àà ùëâ and ùë£ = ùë¢ + ùë§ with ùë¢ ‚àà ùëà and ùë§ ‚àà ùëà‚üÇ, then ùë£ ‚àí ùëÉùëàùë£ = ùë£ ‚àí ùë¢ = ùë§ ‚àà ùëà‚üÇ. (g) If ùë£ ‚àà ùëâ and ùë£ = ùë¢ + ùë§ with ùë¢ ‚àà ùëà and ùë§ ‚àà ùëà‚üÇ, then (ùëÉùëà 2)ùë£ = ùëÉùëà(ùëÉùëàùë£) = ùëÉùëàùë¢ = ùë¢ = ùëÉùëàùë£. (h) If ùë£ ‚àà ùëâ and ùë£ = ùë¢ + ùë§ with ùë¢ ‚àà ùëà and ùë§ ‚àà ùëà‚üÇ, then ‚ÄñùëÉùëàùë£‚Äñ2 = ‚Äñùë¢‚Äñ2 ‚â§ ‚Äñùë¢‚Äñ 2 + ‚Äñùë§‚Äñ 2 = ‚Äñùë£‚Äñ2, where the last equality comes from the Pythagorean theorem. (i) The formula for ùëÉùëàùë£ follows from equation 6.50 in the proof of 6.49. In the previous section we proved the Riesz representation theorem (6.42), whose key part states that every linear functional on a finite-dimensional inner product space is given by taking the inner product with some fixed vector. Seeing a different proof often provides new insight. Thus we now give a new proof of the key part of the Riesz representation theorem using orthogonal complements instead of orthonormal bases as in our previous proof. The restatement below of the Riesz representation theorem provides an iden- tification ofùëâ with ùëâ‚Ä≤. We will prove only the ‚Äúonto‚Äù part of the result below because the more routine ‚Äúone-to-one‚Äù part of the result can be proved as in6.42. Intuition behind this new proof: If ùúë ‚àà ùëâ‚Ä≤, ùë£ ‚àà ùëâ, and ùúë(ùë¢) = ‚ü®ùë¢, ùë£‚ü©for all ùë¢ ‚àà ùëâ, then ùë£ ‚àà (null ùúë) ‚üÇ. However, (null ùúë) ‚üÇ is a one-dimensional subspace of ùëâ (except for the trivial case in which ùúë = 0), as follows from 6.51 and 3.21. Thus we can obtain ùë£ be choosing any nonzero element of (null ùúë) ‚üÇ and then multiplying by an appropriate scalar, as is done in the proof below. 6.58 Riesz representation theorem, revisited Suppose ùëâ is finite-dimensional. For eachùë£ ‚àà ùëâ, defineùúëùë£ ‚àà ùëâ‚Ä≤ by ùúëùë£(ùë¢) = ‚ü®ùë¢, ùë£‚ü© for each ùë¢ ‚àà ùëâ. Then ùë£ ‚Ü¶ ùúëùë£ is a one-to-one function from ùëâ onto ùëâ‚Ä≤. Caution: The function ùë£ ‚Ü¶ ùúëùë£ is a linear mapping from ùëâ to ùëâ‚Ä≤ if ùêÖ = ùêë. However, this function is not linear if ùêÖ = ùêÇ because ùúë ùúÜùë£ = ùúÜùúëùë£ if ùúÜ ‚àà ùêÇ. Proof To show that ùë£ ‚Ü¶ ùúëùë£ is surjective, suppose ùúë ‚àà ùëâ‚Ä≤. If ùúë = 0, then ùúë = ùúë0. Thus assume ùúë ‚â† 0. Hence null ùúë ‚â† ùëâ, which implies that (null ùúë) ‚üÇ ‚â† {0}(by 6.49 with ùëà = null ùúë). Let ùë§ ‚àà (null ùúë) ‚üÇ be such that ùë§ ‚â† 0. Let 6.59 ùë£ = ùúë(ùë§) ‚Äñùë§‚Äñ2 ùë§. Then ùë£ ‚àà (null ùúë) ‚üÇ. Also, ùë£ ‚â† 0(because ùë§ ‚àâ null ùúë). Section 6C Orthogonal Complements and Minimization Problems 217 Taking the norm of both sides of 6.59 gives 6.60 ‚Äñùë£‚Äñ = |ùúë(ùë§)| ‚Äñùë§‚Äñ . Applying ùúë to both sides of 6.59 and then using 6.60, we have ùúë(ùë£) = |ùúë(ùë§)| 2 ‚Äñùë§‚Äñ2 = ‚Äñùë£‚Äñ2. Now suppose ùë¢ ‚àà ùëâ. Using the equation above, we have ùë¢ = (ùë¢ ‚àí ùúë(ùë¢) ùúë(ùë£) ùë£)+ ùúë(ùë¢) ‚Äñùë£‚Äñ2 ùë£. The first term in parentheses above is innull ùúë and hence is orthogonal to ùë£. Thus taking the inner product of both sides of the equation above with ùë£ shows that ‚ü®ùë¢, ùë£‚ü© = ùúë(ùë¢) ‚Äñùë£‚Äñ2 ‚ü®ùë£, ùë£‚ü© = ùúë(ùë¢). Thus ùúë = ùúëùë£, showing that ùë£ ‚Ü¶ ùúëùë£ is surjective, as desired. See Exercise 13 for yet another proof of the Riesz representation theorem. Minimization Problems The remarkable simplicity of the solu- tion to this minimization problem has led to many important applications of inner product spaces outside of pure mathematics. The following problem often arises: Given a subspace ùëà of ùëâ and a point ùë£ ‚àà ùëâ, find a pointùë¢ ‚àà ùëà such that ‚Äñùë£ ‚àí ùë¢‚Äñ is as small as possible. The next result shows that ùë¢ = ùëÉùëàùë£ is the unique solution of this minimization problem. 6.61 minimizing distance to a subspace Suppose ùëà is a finite-dimensional subspace ofùëâ, ùë£ ‚àà ùëâ, and ùë¢ ‚àà ùëà. Then ‚Äñùë£ ‚àí ùëÉùëàùë£‚Äñ ‚â§ ‚Äñùë£ ‚àí ùë¢‚Äñ. Furthermore, the inequality above is an equality if and only if ùë¢ = ùëÉùëàùë£. Proof We have ‚Äñùë£ ‚àí ùëÉùëàùë£‚Äñ 2 ‚â§ ‚Äñùë£ ‚àí ùëÉùëàùë£‚Äñ 2 + ‚ÄñùëÉùëàùë£ ‚àí ùë¢‚Äñ26.62 = ‚à•(ùë£ ‚àí ùëÉùëàùë£) + (ùëÉùëàùë£ ‚àí ùë¢)‚à•2 = ‚Äñùë£ ‚àí ùë¢‚Äñ2, 218 Chapter 6 Inner Product Spaces ùëÉùëàùë£ is the closest point in ùëà to ùë£. where the first line above holds because0 ‚â§ ‚ÄñùëÉùëàùë£ ‚àí ùë¢‚Äñ2, the second line above comes from the Pythagorean the- orem [which applies because ùë£ ‚àí ùëÉùëàùë£ ‚àà ùëà‚üÇ by 6.57(f), and ùëÉùëàùë£ ‚àí ùë¢ ‚àà ùëà], and the third line above holds by simple algebra. Taking square roots gives the desired inequality. The inequality proved above is an equality if and only if 6.62 is an equality, which happens if and only if ‚ÄñùëÉùëàùë£ ‚àí ùë¢‚Äñ = 0, which happens if and only if ùë¢ = ùëÉùëàùë£. The last result is often combined with the formula 6.57(i) to compute explicit solutions to minimization problems, as in the following example. 6.63 example:using linear algebra to approximate the sine function Suppose we want to find a polynomialùë¢ with real coefficients and of degree at most 5that approximates the sine function as well as possible on the interval [‚àíùúã, ùúã], in the sense that ‚à´ ùúã ‚àíùúã‚à£sin ùë• ‚àí ùë¢(ùë•)‚à£2 ùëëùë• is as small as possible. Let ùê∂[‚àíùúã, ùúã] denote the real inner product space of continuous real-valued functions on [‚àíùúã, ùúã] with inner product 6.64 ‚ü® ùëì, ùëî‚ü© =‚à´ùúã ‚àíùúã ùëì ùëî. Let ùë£ ‚àà ùê∂[‚àíùúã, ùúã] be the function defined byùë£(ùë•) = sin ùë•. Let ùëà denote the subspace of ùê∂[‚àíùúã, ùúã] consisting of the polynomials with real coefficients and of degree at most 5. Our problem can now be reformulated as follows: Find ùë¢ ‚àà ùëà such that ‚Äñùë£ ‚àí ùë¢‚Äñ is as small as possible. A computer that can integrate is useful here. To compute the solution to our ap- proximation problem, first apply the Gram‚ÄìSchmidt procedure (using the in- ner product given by 6.64) to the basis 1, ùë•, ùë•2, ùë•3, ùë•4, ùë•5 of ùëà, producing an ortho- normal basis ùëí1, ùëí2, ùëí3, ùëí4, ùëí5, ùëí6 of ùëà. Then, again using the inner product given by 6.64, compute ùëÉùëàùë£ using 6.57(i) (with ùëö = 6). Doing this computation shows that ùëÉùëàùë£ is the function ùë¢ defined by 6.65 ùë¢(ùë•) = 0.987862ùë• ‚àí 0.155271ùë• 3 + 0.00564312ùë• 5, where the ùúã‚Äôs that appear in the exact answer have been replaced with a good decimal approximation. By 6.61, the polynomial ùë¢ above is the best approximation to the sine function on [‚àíùúã, ùúã] using polynomials of degree at most 5(here ‚Äúbest approximation‚Äù means in the sense of minimizing‚à´ùúã ‚àíùúã | sin ùë• ‚àí ùë¢(ùë•)|2 ùëëùë•). Section 6C Orthogonal Complements and Minimization Problems 219 To see how good this approximation is, the next figure shows the graphs of both the sine function and our approximation ùë¢ given by 6.65 over the interval [‚àíùúã, ùúã]. Graphs on [‚àíùúã, ùúã] of the sine function (red) and its best fifth degree polynomial approximation ùë¢ (blue) from 6.65. Our approximation 6.65 is so accurate that the two graphs are almost identical‚Äî our eyes may see only one graph! Here the red graph is placed almost exactly over the blue graph. If you are viewing this on an electronic device, enlarge the picture above by 400% near ùúã or ‚àíùúã to see a small gap between the two graphs. Another well-known approximation to the sine function by a polynomial of degree 5is given by the Taylor polynomial ùëù defined by 6.66 ùëù(ùë•) = ùë• ‚àí ùë•3 3! + ùë•5 5! . To see how good this approximation is, the next picture shows the graphs of both the sine function and the Taylor polynomial ùëù over the interval [‚àíùúã, ùúã]. Graphs on [‚àíùúã, ùúã] of the sine function (red) and the Taylor polynomial (blue) from 6.66. The Taylor polynomial is an excellent approximation to sin ùë• for ùë• near 0. But the picture above shows that for |ùë•| > 2, the Taylor polynomial is not so accurate, especially compared to 6.65. For example, taking ùë• = 3, our approximation 6.65 estimates sin 3with an error of approximately 0.001, but the Taylor series 6.66 estimates sin 3with an error of approximately 0.4. Thus at ùë• = 3, the error in the Taylor series is hundreds of times larger than the error given by 6.65. Linear algebra has helped us discover an approximation to the sine function that improves upon what we learned in calculus! 220 Chapter 6 Inner Product Spaces Pseudoinverse Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùëè ‚àà ùëä. Consider the problem of findingùë• ‚àà ùëâ such that ùëáùë• = ùëè. For example, if ùëâ = ùêÖùëõ and ùëä = ùêÖùëö, then the equation above could represent a system of ùëö linear equations in ùëõ unknowns. If ùëá is invertible, then the unique solution to the equation above is ùë• = ùëá‚àí1ùëè. However, if ùëá is not invertible, then for some ùëè ‚àà ùëä there may not exist any solutions of the equation above, and for some ùëè ‚àà ùëä there may exist infinitely many solutions of the equation above. If ùëá is not invertible, then we can still try to do as well as possible with the equation above. For example, if the equation above has no solutions, then instead of solving the equation ùëáùë• ‚àí ùëè = 0, we can try to findùë• ‚àà ùëâ such that ‚Äñùëáùë• ‚àí ùëè‚Äñ is as small as possible. As another example, if the equation above has infinitely many solutions ùë• ‚àà ùëâ, then among all those solutions we can try to find one such that ‚Äñùë•‚Äñ is as small as possible. The pseudoinverse will provide the tool to solve the equation above as well as possible, even when ùëá is not invertible. We need the next result to define the pseudoinverse. In the next two proofs, we will use without further comment the result that if ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä), then null ùëá, (null ùëá) ‚üÇ, and range ùëá are all finite-dimensional. 6.67restriction of a linear map to obtain a one-to-one and onto map Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Then ùëá|(null ùëá)‚üÇ is a one- to-one map of (null ùëá) ‚üÇ onto range ùëá. Proof Suppose that ùë£ ‚àà (null ùëá) ‚üÇ and ùëá|(null ùëá)‚üÇùë£ = 0. Hence ùëáùë£ = 0and thus ùë£ ‚àà (null ùëá) ‚à© (null ùëá) ‚üÇ, which implies that ùë£ = 0[by 6.48(d)]. Hence null ùëá|(null ùëá)‚üÇ = {0}, which implies that ùëá|(null ùëá)‚üÇ is injective, as desired. Clearly range ùëá|(null ùëá)‚üÇ ‚äÜrange ùëá. To prove the inclusion in the other direction, suppose ùë§ ‚àà range ùëá. Hence there exists ùë£ ‚àà ùëâ such that ùë§ = ùëáùë£. There exist ùë¢ ‚àà null ùëá and ùë• ‚àà (null ùëá) ‚üÇ such that ùë£ = ùë¢ + ùë• (by 6.49). Now ùëá|(null ùëá)‚üÇùë• = ùëáùë• = ùëáùë£ ‚àí ùëáùë¢ = ùë§ ‚àí 0 = ùë§, which shows that ùë§ ‚àà range ùëá|(null ùëá)‚üÇ. Hence range ùëá ‚äÜrange ùëá|(null ùëá)‚üÇ, complet- ing the proof that range ùëá|(null ùëá)‚üÇ = range ùëá. To produce the pseudoinverse notation ùëá‚Ä† in TEX, type T ÃÇ\\dagger. Now we can define the pseudoinverse ùëá‚Ä† (pronounced ‚Äúùëá dagger‚Äù) of a linear map ùëá. In the next definition (and from now on), think of ùëá|(null ùëá)‚üÇ as an invertible linear map from (null ùëá) ‚üÇ onto range ùëá, as is justified by the result above. Section 6C Orthogonal Complements and Minimization Problems 221 6.68 definition:pseudoinverse, ùëá‚Ä† Suppose that ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). The pseudoinverse ùëá‚Ä† ‚àà ‚Ñí(ùëä, ùëâ) of ùëá is the linear map from ùëä to ùëâ defined by ùëá‚Ä†ùë§ = (ùëá|(null ùëá)‚üÇ)‚àí1ùëÉrange ùëá ùë§ for each ùë§ ‚àà ùëä. Recall that ùëÉrange ùëá ùë§ = 0if ùë§ ‚àà (range ùëá) ‚üÇ and ùëÉrange ùëá ùë§ = ùë§ if ùë§ ‚àà range ùëá. Thus if ùë§ ‚àà (range ùëá) ‚üÇ, then ùëá‚Ä†ùë§ = 0, and if ùë§ ‚àà range ùëá, then ùëá‚Ä†ùë§ is the unique element of (null ùëá) ‚üÇ such that ùëá(ùëá‚Ä†ùë§)= ùë§. The pseudoinverse behaves much like an inverse, as we will see. 6.69 algebraic properties of the pseudoinverse Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). (a) If ùëá is invertible, then ùëá‚Ä† = ùëá‚àí1. (b) ùëáùëá‚Ä† = ùëÉrange ùëá = the orthogonal projection of ùëä onto range ùëá. (c) ùëá‚Ä†ùëá = ùëÉ(null ùëá)‚üÇ = the orthogonal projection of ùëâ onto (null ùëá)‚üÇ. Proof (a) Suppose ùëá is invertible. Then (null ùëá) ‚üÇ = ùëâ and range ùëá = ùëä. Thus ùëá|(null ùëá)‚üÇ = ùëá and ùëÉrange ùëá is the identity operator on ùëä. Hence ùëá‚Ä† = ùëá‚àí1. (b) Suppose ùë§ ‚àà range ùëá. Thus ùëáùëá‚Ä†ùë§ = ùëá(ùëá|(null ùëá)‚üÇ)‚àí1ùë§ = ùë§ = ùëÉrange ùëá ùë§. If ùë§ ‚àà (range ùëá) ‚üÇ, then ùëá‚Ä†ùë§ = 0. Hence ùëáùëá‚Ä†ùë§ = 0 = ùëÉrange ùëá ùë§. Thus ùëáùëá‚Ä† and ùëÉrange ùëá agree on range ùëá and on (range ùëá) ‚üÇ. Hence these two linear maps are equal (by 6.49). (c) Suppose ùë£ ‚àà (null ùëá) ‚üÇ. Because ùëáùë£ ‚àà range ùëá, the definition ofùëá‚Ä† shows that ùëá‚Ä†(ùëáùë£) = (ùëá|(null ùëá)‚üÇ)‚àí1(ùëáùë£) = ùë£ = ùëÉ(null ùëá)‚üÇùë£. If ùë£ ‚àà null ùëá, then ùëá‚Ä†ùëáùë£ = 0 = ùëÉ(null ùëá)‚üÇùë£. Thus ùëá‚Ä†ùëá and ùëÉ(null ùëá)‚üÇ agree on (null ùëá) ‚üÇ and on null ùëá. Hence these two linear maps are equal (by 6.49). The pseudoinverse is also called the Moore‚ÄìPenrose inverse. Suppose that ùëá ‚àà ‚Ñí(ùëâ, ùëä). If ùëá is surjective, then ùëáùëá‚Ä† is the identity opera- tor on ùëä, as follows from (b) in the result above. If ùëá is injective, then ùëá‚Ä†ùëá is the identity operator on ùëâ, as follows from (c) in the result above. For additional algebraic properties of the pseudoinverse, see Exercises 19‚Äì23. 222 Chapter 6 Inner Product Spaces Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä), ùëè ‚àà ùëä, and we want to findùë• ‚àà ùëâ that solves the equation ùëáùë• = ùëè. If ùëá is invertible, then ùë• = ùëá‚àí1ùëè is the unique solution. If ùëá is not invertible, then ùëá‚àí1 is not defined. However, the pseudoinverseùëá‚Ä† is defined. Takingùë• = ùëá‚Ä†ùëè makes ùëáùë• as close to ùëè as possible, as shown by (a) of the next result. Thus the pseudoinverse provides what is called a best fit to the equation above. Among all vectors ùë• ‚àà ùëâ that make ùëáùë• as close as possible to ùëè, the vector ùëá‚Ä†ùëè has the smallest norm, as shown by combining (b) in the next result with the condition for equality in (a). 6.70 pseudoinverse provides best approximate solution or best solution Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ, ùëä), and ùëè ‚àà ùëä. (a) If ùë• ‚àà ùëâ, then ‚à•ùëá(ùëá‚Ä†ùëè) ‚àí ùëè‚à• ‚â§ ‚Äñùëáùë• ‚àí ùëè‚Äñ, with equality if and only if ùë• ‚àà ùëá‚Ä†ùëè + null ùëá. (b) If ùë• ‚àà ùëá‚Ä†ùëè + null ùëá, then ‚à•ùëá‚Ä†ùëè‚à• ‚â§ ‚Äñùë•‚Äñ, with equality if and only if ùë• = ùëá‚Ä†ùëè. Proof (a) Suppose ùë• ‚àà ùëâ. Then ùëáùë• ‚àí ùëè = (ùëáùë• ‚àí ùëáùëá‚Ä†ùëè) + (ùëáùëá‚Ä†ùëè ‚àí ùëè). The first term in parentheses above is inrange ùëá. Because the operator ùëáùëá‚Ä† is the orthogonal projection of ùëä onto range ùëá [by 6.69(b)], the second term in parentheses above is in (range ùëá) ‚üÇ [see 6.57(f)]. Thus the Pythagorean theorem implies the desired inequality that the norm of the second term in parentheses above is less than or equal to ‚Äñùëáùë• ‚àí ùëè‚Äñ, with equality if and only if the first term in parentheses above equals0. Hence we have equality if and only if ùë• ‚àí ùëá‚Ä†ùëè ‚àà null ùëá, which is equivalent to the statement that ùë• ‚àà ùëá‚Ä†ùëè + null ùëá, completing the proof of (a). (b) Suppose ùë• ‚àà ùëá‚Ä†ùëè + null ùëá. Hence ùë• ‚àí ùëá‚Ä†ùëè ‚àà null ùëá. Now ùë• = (ùë• ‚àí ùëá‚Ä†ùëè) + ùëá‚Ä†ùëè. The definition ofùëá‚Ä† implies that ùëá‚Ä†ùëè ‚àà (null ùëá) ‚üÇ. Thus the Pythagorean theorem implies that ‚à•ùëá‚Ä†ùëè‚à• ‚â§ ‚Äñùë•‚Äñ, with equality if and only if ùë• = ùëá‚Ä†ùëè. A formula for ùëá‚Ä† will be given in the next chapter (see 7.78). Section 6C Orthogonal Complements and Minimization Problems 223 6.71 example:pseudoinverse of a linear map from ùêÖ4 to ùêÖ3 Suppose ùëá ‚àà ‚Ñí(ùêÖ4, ùêÖ3)is defined by ùëá(ùëé, ùëè, ùëê, ùëë) = (ùëé + ùëè + ùëê, 2ùëê+ ùëë, 0). This linear map is neither injective nor surjective, but we can compute its pseudo- inverse. To do this, first note thatrange ùëá = {(ùë•, ùë¶, 0)‚à∂ ùë•, ùë¶ ‚àà ùêÖ}. Thus ùëÉrange ùëá(ùë•, ùë¶, ùëß) = (ùë•, ùë¶, 0) for each (ùë•, ùë¶, ùëß) ‚àà ùêÖ3. Also, null ùëá = {(ùëé, ùëè, ùëê, ùëë) ‚àà ùêÖ4 ‚à∂ ùëé + ùëè + ùëê = 0and 2ùëê+ ùëë = 0}. The list (‚àí1, 1, 0, 0), (‚àí1, 0, 1, ‚àí2)of two vectors in null ùëá spans null ùëá because if (ùëé, ùëè, ùëê, ùëë) ‚àà null ùëá then (ùëé, ùëè, ùëê, ùëë) = ùëè(‚àí1, 1, 0, 0)+ ùëê(‚àí1, 0, 1, ‚àí2). Because the list (‚àí1, 1, 0, 0), (‚àí1, 0, 1, ‚àí2)is linearly independent, this list is a basis of null ùëá. Now suppose (ùë•, ùë¶, ùëß) ‚àà ùêÖ3. Then 6.72 ùëá‚Ä†(ùë•, ùë¶, ùëß) = (ùëá|(null ùëá)‚üÇ) ‚àí1ùëÉrange ùëá(ùë•, ùë¶, ùëß) = (ùëá|(null ùëá)‚üÇ)‚àí1(ùë•, ùë¶, 0). The right side of the equation above is the vector (ùëé, ùëè, ùëê, ùëë) ‚àà ùêÖ4 such that ùëá(ùëé, ùëè, ùëê, ùëë) = (ùë•, ùë¶, 0)and (ùëé, ùëè, ùëê, ùëë) ‚àà (null ùëá)‚üÇ. In other words, ùëé, ùëè, ùëê, ùëë must satisfy the following equations: ùëé + ùëè + ùëê = ùë• 2ùëê+ ùëë = ùë¶ ‚àíùëé + ùëè = 0 ‚àíùëé + ùëê ‚àí 2ùëë = 0, where the first two equations are equivalent to the equationùëá(ùëé, ùëè, ùëê, ùëë) = (ùë•, ùë¶, 0) and the last two equations come from the condition for (ùëé, ùëè, ùëê, ùëë) to be orthogo- nal to each of the basis vectors (‚àí1, 1, 0, 0), (‚àí1, 0, 1, ‚àí2)in this basis of null ùëá. Thinking of ùë• and ùë¶ as constants and ùëé, ùëè, ùëê, ùëë as unknowns, we can solve the system above of four equations in four unknowns, getting ùëé = 1 11 (5ùë• ‚àí 2ùë¶), ùëè = 1 11 (5ùë• ‚àí 2ùë¶), ùëê = 1 11 (ùë• + 4ùë¶), ùëë = 1 11 (‚àí2ùë•+ 3ùë¶). Hence 6.72 tells us that ùëá‚Ä†(ùë•, ùë¶, ùëß) = 1 11 (5ùë• ‚àí 2ùë¶, 5ùë• ‚àí 2ùë¶, ùë• + 4ùë¶, ‚àí2ùë•+ 3ùë¶). The formula above for ùëá‚Ä† shows that ùëáùëá‚Ä†(ùë•, ùë¶, ùëß) = (ùë•, ùë¶, 0)for all (ùë•, ùë¶, ùëß) ‚àà ùêÖ3, which illustrates the equation ùëáùëá‚Ä† = ùëÉrange ùëá from 6.69(b). 224 Chapter 6 Inner Product Spaces Exercises 6C 1 Suppose ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ. Prove that {ùë£1, ‚Ä¶, ùë£ùëö} ‚üÇ = (span(ùë£1, ‚Ä¶, ùë£ùëö)) ‚üÇ . 2 Suppose ùëà is a subspace of ùëâ with basis ùë¢1, ‚Ä¶, ùë¢ùëö and ùë¢1, ‚Ä¶, ùë¢ùëö, ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Prove that if the Gram‚ÄìSchmidt procedure is applied to the basis of ùëâ above, producing a list ùëí1, ‚Ä¶, ùëíùëö, ùëì1, ‚Ä¶, ùëìùëõ, then ùëí1, ‚Ä¶, ùëíùëö is an orthonormal basis of ùëà and ùëì1, ‚Ä¶, ùëìùëõ is an orthonormal basis of ùëà‚üÇ. 3 Suppose ùëà is the subspace of ùêë4 defined by ùëà = span((1, 2, 3, ‚àí4), (‚àí5, 4, 3, 2)). Find an orthonormal basis of ùëà and an orthonormal basis of ùëà‚üÇ. 4 Suppose ùëí1, ‚Ä¶, ùëíùëõ is a list of vectors in ùëâ with ‚Äñùëíùëò‚Äñ = 1for each ùëò = 1, ‚Ä¶, ùëõ and ‚Äñùë£‚Äñ 2 = ‚à£‚ü®ùë£, ùëí1‚ü©‚à£2 + ‚ãØ + ‚à£‚ü®ùë£, ùëíùëõ‚ü©‚à£2 for all ùë£ ‚àà ùëâ. Prove that ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ. This exercise provides a converse to 6.30(b). 5 Suppose that ùëâ is finite-dimensional andùëà is a subspace of ùëâ. Show that ùëÉùëà‚üÇ = ùêº ‚àí ùëÉùëà, where ùêº is the identity operator on ùëâ. 6 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Show that ùëá = ùëáùëÉ(null ùëá)‚üÇ = ùëÉrange ùëáùëá. 7 Suppose that ùëã and ùëå are finite-dimensional subspaces ofùëâ. Prove that ùëÉùëãùëÉùëå = 0if and only if ‚ü®ùë•, ùë¶‚ü© = 0for all ùë• ‚àà ùëã and all ùë¶ ‚àà ùëå. 8 Suppose ùëà is a finite-dimensional subspace ofùëâ and ùë£ ‚àà ùëâ. Define a linear functional ùúë‚à∂ ùëà ‚Üí ùêÖ by ùúë(ùë¢) = ‚ü®ùë¢, ùë£‚ü© for all ùë¢ ‚àà ùëà. By the Riesz representation theorem (6.42) as applied to the inner product space ùëà, there exists a unique vector ùë§ ‚àà ùëà such that ùúë(ùë¢) = ‚ü®ùë¢, ùë§‚ü© for all ùë¢ ‚àà ùëà. Show that ùë§ = ùëÉùëàùë£. 9 Suppose ùëâ is finite-dimensional. SupposeùëÉ ‚àà ‚Ñí(ùëâ) is such that ùëÉ2 = ùëÉ and every vector in null ùëÉ is orthogonal to every vector in range ùëÉ. Prove that there exists a subspace ùëà of ùëâ such that ùëÉ = ùëÉùëà. Section 6C Orthogonal Complements and Minimization Problems 225 10 Suppose ùëâ is finite-dimensional andùëÉ ‚àà ‚Ñí(ùëâ) is such that ùëÉ2 = ùëÉ and ‚ÄñùëÉùë£‚Äñ ‚â§ ‚Äñùë£‚Äñ for every ùë£ ‚àà ùëâ. Prove that there exists a subspace ùëà of ùëâ such that ùëÉ = ùëÉùëà. 11 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëà is a finite-dimensional subspace ofùëâ. Prove that ùëà is invariant under ùëá ‚ü∫ ùëÉùëàùëáùëÉùëà = ùëáùëÉùëà. 12 Suppose ùëâ is finite-dimensional,ùëá ‚àà ‚Ñí(ùëâ), and ùëà is a subspace of ùëâ. Prove that ùëà and ùëà‚üÇ are both invariant under ùëá ‚ü∫ ùëÉùëàùëá = ùëáùëÉùëà. 13 Suppose ùêÖ = ùêë and ùëâ is finite-dimensional. For eachùë£ ‚àà ùëâ, let ùúëùë£ denote the linear functional on ùëâ defined by ùúëùë£(ùë¢) = ‚ü®ùë¢, ùë£‚ü© for all ùë¢ ‚àà ùëâ. (a) Show that ùë£ ‚Ü¶ ùúëùë£ is an injective linear map from ùëâ to ùëâ‚Ä≤. (b) Use (a) and a dimension-counting argument to show that ùë£ ‚Ü¶ ùúëùë£ is an isomorphism from ùëâ onto ùëâ‚Ä≤. The purpose of this exercise is to give an alternative proof of the Riesz representation theorem (6.42 and 6.58) when ùêÖ = ùêë. Thus you should not use the Riesz representation theorem as a tool in your solution. 14 Suppose that ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ. Explain why the dual basis (see 3.112) of ùëí1, ‚Ä¶, ùëíùëõ is ùëí1, ‚Ä¶, ùëíùëõ under the identification ofùëâ‚Ä≤ with ùëâ provided by the Riesz representation theorem (6.58). 15 In ùêë4, let ùëà = span((1, 1, 0, 0), (1, 1, 1, 2)). Find ùë¢ ‚àà ùëà such that ‚Äñùë¢ ‚àí (1, 2, 3, 4)‚Äñis as small as possible. 16 Suppose ùê∂[‚àí1, 1]is the vector space of continuous real-valued functions on the interval [‚àí1, 1]with inner product given by ‚ü® ùëì, ùëî‚ü© =‚à´1 ‚àí1 ùëì ùëî for all ùëì, ùëî ‚àà ùê∂[‚àí1, 1]. Let ùëà be the subspace of ùê∂[‚àí1, 1]defined by ùëà = {ùëì ‚àà ùê∂[‚àí1, 1]‚à∂ ùëì (0) = 0}. (a) Show that ùëà‚üÇ = {0}. (b) Show that 6.49 and 6.52 do not hold without the finite-dimensional hypothesis. 226 Chapter 6 Inner Product Spaces 17 Find ùëù ‚àà ùí´3(ùêë) such that ùëù(0) = 0, ùëù ‚Ä≤(0) = 0, and ‚à´1 0 ‚à£2+ 3ùë• ‚àí ùëù(ùë•)‚à£ 2 ùëëùë• is as small as possible. 18 Find ùëù ‚àà ùí´5(ùêë) that makes ‚à´ùúã ‚àíùúã ‚à£sin ùë• ‚àí ùëù(ùë•)‚à£ 2 ùëëùë• as small as possible. The polynomial 6.65 is an excellent approximation to the answer to this exercise, but here you are asked to find the exact solution, which involves powers of ùúã. A computer that can perform symbolic integration should help. 19 Suppose ùëâ is finite-dimensional andùëÉ ‚àà ‚Ñí(ùëâ) is an orthogonal projection of ùëâ onto some subspace of ùëâ. Prove that ùëÉ‚Ä† = ùëÉ. 20 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Show that null ùëá‚Ä† = (range ùëá) ‚üÇ and range ùëá‚Ä† = (null ùëá)‚üÇ. 21 Suppose ùëá ‚àà ‚Ñí(ùêÖ3, ùêÖ2)is defined by ùëá(ùëé, ùëè, ùëê) = (ùëé + ùëè + ùëê, 2ùëè+ 3ùëê). (a) For (ùë•, ùë¶) ‚àà ùêÖ2, find a formula forùëá‚Ä†(ùë•, ùë¶). (b) Verify that the equation ùëáùëá‚Ä† = ùëÉrange ùëá from 6.69(b) holds with the formula for ùëá‚Ä† obtained in (a). (c) Verify that the equation ùëá‚Ä†ùëá = ùëÉ(null ùëá)‚üÇ from 6.69(c) holds with the formula for ùëá‚Ä† obtained in (a). 22 Suppose ùëâ is finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that ùëáùëá‚Ä†ùëá = ùëá and ùëá‚Ä†ùëáùëá‚Ä† = ùëá‚Ä†. Both formulas above clearly hold if ùëá is invertible because in that case we can replace ùëá‚Ä† with ùëá‚àí1. 23 Suppose ùëâ and ùëä are finite-dimensional andùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that (ùëá‚Ä†) ‚Ä† = ùëá. The equation above is analogous to the equation (ùëá‚àí1) ‚àí1 = ùëá that holds if ùëá is invertible. Open Access This chapter is licensed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (https://creativecommons.org/licenses/by-nc/4.0), which permits any noncommercial use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to original author and source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this chapter are included in the chapter‚Äôs Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter‚Äôs Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. Chapter 7 Operators on Inner Product Spaces The deepest results related to inner product spaces deal with the subject to which we now turn‚Äîlinear maps and operators on inner product spaces. As we will see, good theorems can be proved by exploiting properties of the adjoint. The hugely important spectral theorem will provide a complete description of self-adjoint operators on real inner product spaces and of normal operators on complex inner product spaces. We will then use the spectral theorem to help understand positive operators and unitary operators, which will lead to unitary matrices and matrix factorizations. The spectral theorem will also lead to the popular singular value decomposition, which will lead to the polar decomposition. The most important results in the rest of this book are valid only in finite dimensions. Thus from now on we assume that ùëâ and ùëä are finite-dimensional. standing assumptions for this chapter ‚Ä¢ ùêÖ denotes ùêë or ùêÇ. ‚Ä¢ ùëâ and ùëä are nonzero finite-dimensional inner product spaces overùêÖ.PetarMilo≈°eviƒáCCBY-SA Market square in Lviv, a city that has had several names and has been in several countries because of changing international borders. From 1772 until 1918, the city was in Austria and was called Lemberg. Between World War I and World War II, the city was in Poland and was called Lw√≥w. During this time, mathematicians in Lw√≥w, particularly Stefan Banach (1892‚Äì1945) and his colleagues, developed the basic results of modern functional analysis, using tools of analysis to study infinite-dimensional vector spaces. Since the end of World War II, Lviv has been in Ukraine, which was part of the Soviet Union until Ukraine became an independent country in 1991. 227 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0_7 ¬© Sheldon Axler 2024 228 Chapter 7 Operators on Inner Product Spaces 7A Self-Adjoint and Normal Operators Adjoints 7.1 definition:adjoint, ùëá‚àó Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). The adjoint of ùëá is the function ùëá‚àó ‚à∂ ùëä ‚Üí ùëâ such that ‚ü®ùëáùë£, ùë§‚ü© =‚ü®ùë£, ùëá‚àóùë§‚ü© for every ùë£ ‚àà ùëâ and every ùë§ ‚àà ùëä. The word adjoint has another meaning in linear algebra. In case you en- counter the second meaning elsewhere, be warned that the two meanings for adjoint are unrelated to each other. To see why the definition above makes sense, suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Fix ùë§ ‚àà ùëä. Consider the linear functional ùë£ ‚Ü¶ ‚ü®ùëáùë£, ùë§‚ü© on ùëâ that maps ùë£ ‚àà ùëâ to ‚ü®ùëáùë£, ùë§‚ü©; this linear functional depends on ùëá and ùë§. By the Riesz representation theorem (6.42), there exists a unique vector in ùëâ such that this linear functional is given by taking the inner product with it. We call this unique vector ùëá‚àóùë§. In other words, ùëá‚àóùë§ is the unique vector in ùëâ such that ‚ü®ùëáùë£, ùë§‚ü© =‚ü®ùë£, ùëá‚àóùë§‚ü© for every ùë£ ‚àà ùëâ. In the equation above, the inner product on the left takes place in ùëä and the inner product on the right takes place in ùëâ. However, we use the same notation ‚ü®‚ãÖ, ‚ãÖ‚ü©for both inner products. 7.2 example:adjoint of a linear map from ùêë3 to ùêë2 Defineùëá‚à∂ ùêë3 ‚Üí ùêë2 by ùëá(ùë•1, ùë•2, ùë•3) = (ùë•2 + 3ùë•3, 2ùë•1). To compute ùëá‚àó, suppose (ùë•1, ùë•2, ùë•3) ‚àà ùêë3 and (ùë¶1, ùë¶2) ‚àà ùêë2. Then ‚ü®ùëá(ùë•1, ùë•2, ùë•3), (ùë¶1, ùë¶2)‚ü©= ‚ü®(ùë•2 + 3ùë•3, 2ùë•1), (ùë¶1, ùë¶2)‚ü© = ùë•2ùë¶1 + 3ùë•3ùë¶1 + 2ùë•1ùë¶2 = ‚ü®(ùë•1, ùë•2, ùë•3), (2ùë¶2, ùë¶1, 3ùë¶1)‚ü©. The equation above and the definition of the adjoint imply that ùëá‚àó(ùë¶1, ùë¶2) = (2ùë¶2, ùë¶1, 3ùë¶1). Section 7A Self-Adjoint and Normal Operators 229 7.3 example:adjoint of a linear map with range of dimension at most 1 Fix ùë¢ ‚àà ùëâ and ùë• ‚àà ùëä. Defineùëá ‚àà ‚Ñí(ùëâ, ùëä) by ùëáùë£ = ‚ü®ùë£, ùë¢‚ü©ùë• for each ùë£ ‚àà ùëâ. To compute ùëá‚àó, suppose ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä. Then ‚ü®ùëáùë£, ùë§‚ü© =‚ü®‚ü®ùë£, ùë¢‚ü©ùë•, ùë§‚ü© = ‚ü®ùë£, ùë¢‚ü©‚ü®ùë•, ùë§‚ü© = ‚ü®ùë£, ‚ü®ùë§, ùë•‚ü©ùë¢‚ü©. Thus ùëá‚àóùë§ = ‚ü®ùë§, ùë•‚ü©ùë¢. The two examples above and the proof below use a common technique for computing ùëá‚àó: start with a formula for ‚ü®ùëáùë£, ùë§‚ü©then manipulate it to get just ùë£ in the first slot; the entry in the second slot will then be ùëá‚àóùë§. In the two examples above, ùëá‚àó turned out to be not just a function from ùëâ to ùëä but a linear map from ùëâ to ùëä. This behavior is true in general, as shown by the next result. 7.4 adjoint of a linear map is a linear map If ùëá ‚àà ‚Ñí(ùëâ, ùëä), then ùëá‚àó ‚àà ‚Ñí(ùëä, ùëâ). Proof Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). If ùë£ ‚àà ùëâ and ùë§1, ùë§2 ‚àà ùëä, then ‚ü®ùëáùë£, ùë§1 + ùë§2‚ü© = ‚ü®ùëáùë£, ùë§1‚ü©+ ‚ü®ùëáùë£, ùë§2‚ü© = ‚ü®ùë£, ùëá‚àóùë§1‚ü©+ ‚ü®ùë£, ùëá‚àóùë§2‚ü© = ‚ü®ùë£, ùëá‚àóùë§1 + ùëá‚àóùë§2‚ü©. The equation above shows that ùëá‚àó(ùë§1 + ùë§2) = ùëá‚àóùë§1 + ùëá‚àóùë§2. If ùë£ ‚àà ùëâ, ùúÜ ‚àà ùêÖ, and ùë§ ‚àà ùëä, then ‚ü®ùëáùë£, ùúÜùë§‚ü© = ùúÜ‚ü®ùëáùë£, ùë§‚ü© = ùúÜ‚ü®ùë£, ùëá‚àóùë§‚ü© = ‚ü®ùë£, ùúÜùëá‚àóùë§‚ü©. The equation above shows that ùëá‚àó(ùúÜùë§) = ùúÜùëá‚àóùë§. Thus ùëá‚àó is a linear map, as desired. 230 Chapter 7 Operators on Inner Product Spaces 7.5 properties of the adjoint Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then (a) (ùëÜ + ùëá)‚àó = ùëÜ‚àó + ùëá‚àó for all ùëÜ ‚àà ‚Ñí(ùëâ, ùëä); (b) (ùúÜùëá)‚àó = ùúÜùëá‚àó for all ùúÜ ‚àà ùêÖ; (c) (ùëá‚àó) ‚àó = ùëá; (d) (ùëÜùëá)‚àó = ùëá‚àóùëÜ‚àó for all ùëÜ ‚àà ‚Ñí(ùëä, ùëà) (here ùëà is a finite-dimensional inner product space over ùêÖ); (e) ùêº‚àó = ùêº, where ùêº is the identity operator on ùëâ; (f) if ùëá is invertible, then ùëá‚àó is invertible and (ùëá‚àó) ‚àí1 = (ùëá‚àí1) ‚àó. Proof Suppose ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä. (a) If ùëÜ ‚àà ‚Ñí(ùëâ, ùëä), then ‚ü®(ùëÜ + ùëá)ùë£, ùë§‚ü©= ‚ü®ùëÜùë£, ùë§‚ü©+ ‚ü®ùëáùë£, ùë§‚ü© = ‚ü®ùë£, ùëÜ‚àóùë§‚ü©+ ‚ü®ùë£, ùëá‚àóùë§‚ü© = ‚ü®ùë£, ùëÜ‚àóùë§ + ùëá‚àóùë§‚ü©. Thus (ùëÜ + ùëá)‚àóùë§ = ùëÜ‚àóùë§ + ùëá‚àóùë§, as desired. (b) If ùúÜ ‚àà ùêÖ, then ‚ü®(ùúÜùëá)ùë£, ùë§‚ü©= ùúÜ‚ü®ùëáùë£, ùë§‚ü© = ùúÜ‚ü®ùë£, ùëá‚àóùë§‚ü©= ‚ü®ùë£, ùúÜùëá‚àóùë§‚ü©. Thus (ùúÜùëá)‚àóùë§ = ùúÜùëá‚àóùë§, as desired. (c) We have ‚ü®ùëá‚àóùë§, ùë£‚ü©= ‚ü®ùë£, ùëá‚àóùë§‚ü©= ‚ü®ùëáùë£, ùë§‚ü©= ‚ü®ùë§, ùëáùë£‚ü©. Thus (ùëá‚àó) ‚àóùë£ = ùëáùë£, as desired. (d) Suppose ùëÜ ‚àà ‚Ñí(ùëä, ùëà) and ùë¢ ‚àà ùëà. Then ‚ü®(ùëÜùëá)ùë£, ùë¢‚ü©= ‚ü®ùëÜ(ùëáùë£), ùë¢‚ü©= ‚ü®ùëáùë£, ùëÜ‚àóùë¢‚ü©= ‚ü®ùë£, ùëá‚àó(ùëÜ‚àóùë¢)‚ü©. Thus (ùëÜùëá)‚àóùë¢ = ùëá‚àó(ùëÜ‚àóùë¢), as desired. (e) Suppose ùë¢ ‚àà ùëâ. Then ‚ü®ùêºùë¢, ùë£‚ü© = ‚ü®ùë¢, ùë£‚ü©. Thus ùêº‚àóùë£ = ùë£, as desired. (f) Suppose ùëá is invertible. Take adjoints of both sides of the equation ùëá‚àí1ùëá = ùêº, then use (d) and (e) to show that ùëá‚àó(ùëá‚àí1) ‚àó = ùêº. Similarly, the equation ùëáùëá‚àí1 = ùêº implies (ùëá‚àí1) ‚àóùëá‚àó = ùêº. Thus (ùëá‚àí1) ‚àó is the inverse of ùëá‚àó, as desired. If ùêÖ = ùêë, then the map ùëá ‚Ü¶ ùëá‚àó is a linear map from ‚Ñí(ùëâ, ùëä) to ‚Ñí(ùëä, ùëâ), as follows from (a) and (b) of the result above. However, if ùêÖ = ùêÇ, then this map is not linear because of the complex conjugate that appears in (b). Section 7A Self-Adjoint and Normal Operators 231 The next result shows the relationship between the null space and the range of a linear map and its adjoint. 7.6 null space and range of ùëá‚àó Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then (a) null ùëá‚àó = (range ùëá) ‚üÇ; (b) range ùëá‚àó = (null ùëá) ‚üÇ; (c) null ùëá = (range ùëá‚àó) ‚üÇ; (d) range ùëá = (null ùëá‚àó) ‚üÇ. Proof We begin by proving (a). Let ùë§ ‚àà ùëä. Then ùë§ ‚àà null ùëá‚àó ‚ü∫ ùëá‚àóùë§ = 0 ‚ü∫ ‚ü®ùë£, ùëá‚àóùë§‚ü©= 0for all ùë£ ‚àà ùëâ ‚ü∫ ‚ü®ùëáùë£, ùë§‚ü© = 0for all ùë£ ‚àà ùëâ ‚ü∫ ùë§ ‚àà (range ùëá)‚üÇ. Thus null ùëá‚àó = (range ùëá)‚üÇ, proving (a). If we take the orthogonal complement of both sides of (a), we get (d), where we have used 6.52. Replacing ùëá with ùëá‚àó in (a) gives (c), where we have used 7.5(c). Finally, replacing ùëá with ùëá‚àó in (d) gives (b). As we will soon see, the next definition is intimately connected to the matrix of the adjoint of a linear map. 7.7 definition:conjugate transpose, ùê¥‚àó The conjugate transpose of an ùëö-by-ùëõ matrix ùê¥ is the ùëõ-by-ùëö matrix ùê¥‚àó obtained by interchanging the rows and columns and then taking the complex conjugate of each entry. In other words, if ùëó ‚àà {1, ‚Ä¶, ùëõ} and ùëò ‚àà {1, ‚Ä¶, ùëö}, then (ùê¥‚àó)ùëó, ùëò = ùê¥ùëò, ùëó. 7.8 example:conjugate transpose of a 2-by-3matrix If a matrix ùê¥ has only real entries, then ùê¥‚àó = ùê¥t, where ùê¥ t denotes the transpose of ùê¥ (the matrix obtained by interchanging the rows and the columns). The conjugate transpose of the 2-by-3 matrix ( 2 3+ 4ùëñ 7 6 5 8ùëñ )is the 3-by-2 matrix ‚éõ‚éú‚éú‚éú ‚éù 2 6 3 ‚àí 4ùëñ 5 7 ‚àí8ùëñ ‚éû‚éü‚éü‚éü ‚é† . 232 Chapter 7 Operators on Inner Product Spaces The adjoint of a linear map does not depend on a choice of basis. Thus we frequently emphasize adjoints of linear maps instead of transposes or conjugate transposes of matrices. The next result shows how to compute the matrix of ùëá‚àó from the matrix of ùëá. Caution: With respect to nonorthonor- mal bases, the matrix of ùëá‚àó does not nec- essarily equal the conjugate transpose of the matrix of ùëá. 7.9 matrix of ùëá‚àó equals conjugate transpose of matrix of ùëá Let ùëá ‚àà ‚Ñí(ùëâ, ùëä). Suppose ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ and ùëì1, ‚Ä¶, ùëìùëö is an orthonormal basis of ùëä. Then ‚Ñ≥(ùëá‚àó, ( ùëì1, ‚Ä¶, ùëìùëö), (ùëí1, ‚Ä¶, ùëíùëõ)) is the conjugate transpose of ‚Ñ≥(ùëá, (ùëí1, ‚Ä¶, ùëíùëõ), ( ùëì1, ‚Ä¶, ùëìùëö)). In other words, ‚Ñ≥(ùëá‚àó)= (‚Ñ≥(ùëá)) ‚àó . Proof In this proof, we will write ‚Ñ≥(ùëá) and ‚Ñ≥(ùëá‚àó)instead of the longer expressions ‚Ñ≥(ùëá, (ùëí1, ‚Ä¶, ùëíùëõ), ( ùëì1, ‚Ä¶, ùëìùëö))and ‚Ñ≥(ùëá‚àó, ( ùëì1, ‚Ä¶, ùëìùëö), (ùëí1, ‚Ä¶, ùëíùëõ)). Recall that we obtain the ùëòth column of ‚Ñ≥(ùëá) by writing ùëáùëíùëò as a linear combination of the ùëìùëó‚Äôs; the scalars used in this linear combination then become the ùëòth column of ‚Ñ≥(ùëá). Because ùëì1, ‚Ä¶, ùëìùëö is an orthonormal basis of ùëä, we know how to write ùëáùëíùëò as a linear combination of the ùëìùëó‚Äôs [see 6.30(a)]: ùëáùëíùëò = ‚ü®ùëáùëíùëò, ùëì1‚ü© ùëì1 + ‚ãØ + ‚ü®ùëáùëíùëò, ùëìùëö‚ü© ùëìùëö. Thus the entry in row ùëó, column ùëò, of ‚Ñ≥(ùëá) is ‚ü®ùëáùëíùëò, ùëìùëó‚ü©. In the statement above, replace ùëá with ùëá‚àó and interchange ùëí1, ‚Ä¶, ùëíùëõ and ùëì1, ‚Ä¶, ùëìùëö. This shows that the entry in row ùëó, column ùëò, of ‚Ñ≥(ùëá‚àó)is ‚ü®ùëá‚àóùëìùëò, ùëíùëó‚ü©, which equals ‚ü® ùëìùëò, ùëáùëíùëó‚ü©, which equals ‚ü®ùëáùëíùëó, ùëìùëò‚ü©, which equals the complex conjugate of the entry in row ùëò, column ùëó, of ‚Ñ≥(ùëá). Thus ‚Ñ≥(ùëá‚àó)= (‚Ñ≥(ùëá)) ‚àó. The Riesz representation theorem as stated in 6.58 provides an identification of ùëâ with its dual space ùëâ‚Ä≤ defined in3.110. Under this identification, the orthogonal complement ùëà‚üÇ of a subset ùëà ‚äÜ ùëâcorresponds to the annihilator ùëà0 of ùëà. If ùëà is a subspace of ùëâ, then the formulas for the dimensions of ùëà‚üÇ and ùëà0 become identical under this identification‚Äîsee3.125 and 6.51. Because orthogonal complements and adjoints are easier to deal with than annihilators and dual maps, there is no need to work with annihilators and dual maps in the context of inner product spaces. Suppose ùëá‚à∂ ùëâ ‚Üí ùëä is a linear map. Under the identification ofùëâ with ùëâ‚Ä≤ and the identification ofùëä with ùëä‚Ä≤, the ad- joint map ùëá‚àó ‚à∂ ùëä ‚Üí ùëâ corresponds to the dual map ùëá‚Ä≤ ‚à∂ ùëä‚Ä≤ ‚Üí ùëâ‚Ä≤ defined in 3.118, as Exercise 32 asks you to verify. Under this identification, the formulas for null ùëá‚àó and range ùëá‚àó [7.6(a) and (b)]then become identical to the formulas for null ùëá‚Ä≤ and range ùëá‚Ä≤ [3.128(a) and 3.130(b)]. Furthermore, the theorem about the matrix of ùëá‚àó (7.9) is analogous to the theorem about the matrix of ùëá‚Ä≤ (3.132). Section 7A Self-Adjoint and Normal Operators 233 Self-Adjoint Operators Now we switch our attention to operators on inner product spaces. Instead of considering linear maps from ùëâ to ùëä, we will focus on linear maps from ùëâ to ùëâ; recall that such linear maps are called operators. 7.10 definition:self-adjoint An operator ùëá ‚àà ‚Ñí(ùëâ) is called self-adjoint if ùëá = ùëá‚àó. If ùëá ‚àà ‚Ñí(ùëâ) and ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ, then ùëá is self-adjoint if and only if ‚Ñ≥(ùëá, (ùëí1, ‚Ä¶, ùëíùëõ))= ‚Ñ≥(ùëá, (ùëí1, ‚Ä¶, ùëíùëõ)) ‚àó, as follows from 7.9. 7.11 example:determining whether ùëá is self-adjoint from its matrix Suppose ùëê ‚àà ùêÖ and ùëá is the operator on ùêÖ2 whose matrix (with respect to the standard basis) is ‚Ñ≥(ùëá) = ( 2 ùëê 3 7 ). The matrix of ùëá‚àó (with respect to the standard basis) is ‚Ñ≥(ùëá‚àó)= ( 2 3 ùëê 7). Thus ‚Ñ≥(ùëá) = ‚Ñ≥(ùëá‚àó)if and only if ùëê = 3. Hence the operator ùëá is self-adjoint if and only if ùëê = 3. A good analogy to keep in mind is that the adjoint on ‚Ñí(ùëâ) plays a role similar to that of the complex conjugate on ùêÇ. A complex number ùëß is real if and only if ùëß = ùëß; thus a self-adjoint operator (ùëá = ùëá‚àó) is analogous to a real number. An operator ùëá ‚àà ‚Ñí(ùëâ) is self-adjoint if and only if ‚ü®ùëáùë£, ùë§‚ü© = ‚ü®ùë£, ùëáùë§‚ü© for all ùë£, ùë§ ‚àà ùëâ. We will see that the analogy discussed above is reflected in some important prop- erties of self-adjoint operators, beginning with eigenvalues in the next result. If ùêÖ = ùêë, then by definition every eigenvalue is real, so the next result is interesting only when ùêÖ = ùêÇ. 7.12 eigenvalues of self-adjoint operators Every eigenvalue of a self-adjoint operator is real. Proof Suppose ùëá is a self-adjoint operator on ùëâ. Let ùúÜ be an eigenvalue of ùëá, and let ùë£ be a nonzero vector in ùëâ such that ùëáùë£ = ùúÜùë£. Then ùúÜ‚Äñùë£‚Äñ 2 = ‚ü®ùúÜùë£, ùë£‚ü© = ‚ü®ùëáùë£, ùë£‚ü© = ‚ü®ùë£, ùëáùë£‚ü© = ‚ü®ùë£, ùúÜùë£‚ü© = ùúÜ‚Äñùë£‚Äñ 2. Thus ùúÜ = ùúÜ, which means that ùúÜ is real, as desired. 234 Chapter 7 Operators on Inner Product Spaces The next result is false for real inner product spaces. As an example, consider the operator ùëá ‚àà ‚Ñí(ùêë2)that is a counterclockwise rotation of 90 ‚àò around the origin; thus ùëá(ùë•, ùë¶) = (‚àíùë¶, ùë•). Notice that ùëáùë£ is orthogonal to ùë£ for every ùë£ ‚àà ùêë2, even though ùëá ‚â† 0. 7.13 ùëáùë£ is orthogonal to ùë£ for all ùë£ ‚ü∫ ùëá = 0(assuming ùêÖ = ùêÇ) Suppose ùëâ is a complex inner product space and ùëá ‚àà ‚Ñí(ùëâ). Then ‚ü®ùëáùë£, ùë£‚ü© = 0for every ùë£ ‚àà ùëâ ‚ü∫ ùëá = 0. Proof If ùë¢, ùë§ ‚àà ùëâ, then ‚ü®ùëáùë¢, ùë§‚ü© = ‚ü®ùëá(ùë¢ + ùë§), ùë¢ + ùë§‚ü©‚àí ‚ü®ùëá(ùë¢ ‚àí ùë§), ùë¢ ‚àí ùë§‚ü© 4 + ‚ü®ùëá(ùë¢ + ùëñùë§), ùë¢ + ùëñùë§‚ü©‚àí ‚ü®ùëá(ùë¢ ‚àí ùëñùë§), ùë¢ ‚àí ùëñùë§‚ü© 4 ùëñ, as can be verified by computing the right side. Note that each term on the right side is of the form ‚ü®ùëáùë£, ùë£‚ü©for appropriate ùë£ ‚àà ùëâ. Now suppose ‚ü®ùëáùë£, ùë£‚ü© = 0for every ùë£ ‚àà ùëâ. Then the equation above implies that ‚ü®ùëáùë¢, ùë§‚ü© = 0for all ùë¢, ùë§ ‚àà ùëâ, which then implies that ùëáùë¢ = 0for every ùë¢ ‚àà ùëà (take ùë§ = ùëáùë¢). Hence ùëá = 0, as desired. The next result provides another good example of how self-adjoint operators behave like real numbers. The next result is false for real inner product spaces, as shown by considering any operator on a real inner product space that is not self-adjoint. 7.14 ‚ü®ùëáùë£, ùë£‚ü©is real for all ùë£ ‚ü∫ ùëá is self-adjoint (assuming ùêÖ = ùêÇ) Suppose ùëâ is a complex inner product space and ùëá ‚àà ‚Ñí(ùëâ). Then ùëá is self-adjoint ‚ü∫ ‚ü®ùëáùë£, ùë£‚ü© ‚àà ùêëfor every ùë£ ‚àà ùëâ. Proof If ùë£ ‚àà ùëâ, then 7.15 ‚ü®ùëá‚àóùë£, ùë£‚ü©= ‚ü®ùë£, ùëá‚àóùë£‚ü©= ‚ü®ùëáùë£, ùë£‚ü©. Now ùëá is self-adjoint ‚ü∫ ùëá ‚àí ùëá‚àó = 0 ‚ü∫ ‚ü®(ùëá ‚àí ùëá‚àó)ùë£, ùë£‚ü©= 0for every ùë£ ‚àà ùëâ ‚ü∫ ‚ü®ùëáùë£, ùë£‚ü© ‚àí ‚ü®ùëáùë£, ùë£‚ü©= 0for every ùë£ ‚àà ùëâ ‚ü∫ ‚ü®ùëáùë£, ùë£‚ü© ‚àà ùêëfor every ùë£ ‚àà ùëâ, where the second equivalence follows from 7.13 as applied to ùëá ‚àí ùëá‚àó and the third equivalence follows from 7.15. Section 7A Self-Adjoint and Normal Operators 235 On a real inner product space ùëâ, a nonzero operator ùëá might satisfy ‚ü®ùëáùë£, ùë£‚ü© = 0 for all ùë£ ‚àà ùëâ. However, the next result shows that this cannot happen for a self- adjoint operator. 7.16 ùëá self-adjoint and ‚ü®ùëáùë£, ùë£‚ü© = 0for all ùë£ ‚ü∫ ùëá = 0 Suppose ùëá is a self-adjoint operator on ùëâ. Then ‚ü®ùëáùë£, ùë£‚ü© = 0for every ùë£ ‚àà ùëâ ‚ü∫ ùëá = 0. Proof We have already proved this (without the hypothesis that ùëá is self-adjoint) when ùëâ is a complex inner product space (see 7.13). Thus we can assume that ùëâ is a real inner product space. If ùë¢, ùë§ ‚àà ùëâ, then 7.17 ‚ü®ùëáùë¢, ùë§‚ü© = ‚ü®ùëá(ùë¢ + ùë§), ùë¢ + ùë§‚ü©‚àí ‚ü®ùëá(ùë¢ ‚àí ùë§), ùë¢ ‚àí ùë§‚ü© 4 , as can be proved by computing the right side using the equation ‚ü®ùëáùë§, ùë¢‚ü© = ‚ü®ùë§, ùëáùë¢‚ü© = ‚ü®ùëáùë¢, ùë§‚ü©, where the first equality holds becauseùëá is self-adjoint and the second equality holds because we are working in a real inner product space. Now suppose ‚ü®ùëáùë£, ùë£‚ü© = 0for every ùë£ ‚àà ùëâ. Because each term on the right side of 7.17 is of the form ‚ü®ùëáùë£, ùë£‚ü©for appropriate ùë£, this implies that ‚ü®ùëáùë¢, ùë§‚ü© = 0 for all ùë¢, ùë§ ‚àà ùëâ. This implies that ùëáùë¢ = 0for every ùë¢ ‚àà ùëâ (take ùë§ = ùëáùë¢). Hence ùëá = 0, as desired. Normal Operators 7.18 definition:normal ‚Ä¢ An operator on an inner product space is called normal if it commutes with its adjoint. ‚Ä¢ In other words, ùëá ‚àà ‚Ñí(ùëâ) is normal if ùëáùëá‚àó = ùëá‚àóùëá. Every self-adjoint operator is normal, because if ùëá is self-adjoint then ùëá‚àó = ùëá and hence ùëá commutes with ùëá‚àó. 7.19 example:an operator that is normal but not self-adjoint Let ùëá be the operator on ùêÖ2 whose matrix (with respect to the standard basis) is ( 2 ‚àí3 3 2 ). Thus ùëá(ùë§, ùëß) = (2ùë§ ‚àí 3ùëß, 3ùë§+ 2ùëß). 236 Chapter 7 Operators on Inner Product Spaces This operator ùëá is not self-adjoint because the entry in row 2, column 1 (which equals 3) does not equal the complex conjugate of the entry in row 1, column 2 (which equals ‚àí3). The matrix of ùëáùëá‚àó equals ( 2 ‚àí3 3 2 )( 2 3 ‚àí3 2 ), which equals ( 13 0 0 13 ). Similarly, the matrix of ùëá‚àóùëá equals ( 2 3 ‚àí3 2 )( 2 ‚àí3 3 2 ), which equals ( 13 0 0 13 ). Because ùëáùëá‚àó and ùëá‚àóùëá have the same matrix, we see that ùëáùëá‚àó = ùëá‚àóùëá. Thus ùëá is normal. In the next section we will see why normal operators are worthy of special attention. The next result provides a useful characterization of normal operators. 7.20 ùëá is normal if and only if ùëáùë£ and ùëá‚àóùë£ have the same norm Suppose ùëá ‚àà ‚Ñí(ùëâ). Then ùëá is normal ‚ü∫ ‚Äñùëáùë£‚Äñ = ‚Äñùëá‚àóùë£‚Äñ for every ùë£ ‚àà ùëâ. Proof We have ùëá is normal ‚ü∫ ùëá‚àóùëá ‚àí ùëáùëá‚àó = 0 ‚ü∫ ‚ü®(ùëá‚àóùëá ‚àí ùëáùëá‚àó)ùë£, ùë£‚ü©= 0for every ùë£ ‚àà ùëâ ‚ü∫ ‚ü®ùëá‚àóùëáùë£, ùë£‚ü©= ‚ü®ùëáùëá‚àóùë£, ùë£‚ü©for every ùë£ ‚àà ùëâ ‚ü∫ ‚ü®ùëáùë£, ùëáùë£‚ü© =‚ü®ùëá‚àóùë£, ùëá‚àóùë£‚ü©for every ùë£ ‚àà ùëâ ‚ü∫ ‚Äñùëáùë£‚Äñ2 = ‚à•ùëá‚àóùë£‚à• 2 for every ùë£ ‚àà ùëâ ‚ü∫ ‚Äñùëáùë£‚Äñ = ‚à•ùëá‚àóùë£‚à• for every ùë£ ‚àà ùëâ, where we used 7.16 to establish the second equivalence (note that the operator ùëá‚àóùëá ‚àí ùëáùëá‚àó is self-adjoint). The next result presents several consequences of the result above. Compare (e) of the next result to Exercise 3. That exercise states that the eigenvalues of the adjoint of each operator are equal (as a set) to the complex conjugates of the eigenvalues of the operator. The exercise says nothing about eigenvectors, because an operator and its adjoint may have different eigenvectors. However, (e) of the next result implies that a normal operator and its adjoint have the same eigenvectors. Section 7A Self-Adjoint and Normal Operators 237 7.21 range, null space, and eigenvectors of a normal operator Suppose ùëá ‚àà ‚Ñí(ùëâ) is normal. Then (a) null ùëá = null ùëá‚àó; (b) range ùëá = range ùëá‚àó; (c) ùëâ = null ùëá ‚äï range ùëá; (d) ùëá ‚àí ùúÜùêº is normal for every ùúÜ ‚àà ùêÖ; (e) if ùë£ ‚àà ùëâ and ùúÜ ‚àà ùêÖ, then ùëáùë£ = ùúÜùë£ if and only if ùëá‚àóùë£ = ùúÜùë£. Proof (a) Suppose ùë£ ‚àà ùëâ. Then ùë£ ‚àà null ùëá ‚ü∫ ‚Äñùëáùë£‚Äñ = 0 ‚ü∫‚à•ùëá‚àóùë£‚à• = 0 ‚ü∫ ùë£ ‚àànull ùëá‚àó, where the middle equivalence above follows from 7.20. Thus null ùëá = null ùëá‚àó. (b) We have range ùëá = (null ùëá‚àó) ‚üÇ = (null ùëá) ‚üÇ = range ùëá‚àó, where the first equality comes from7.6(d), the second equality comes from (a) in this result, and the third equality comes from 7.6(b). (c) We have ùëâ = (null ùëá) ‚äï (null ùëá) ‚üÇ = null ùëá ‚äï range ùëá‚àó = null ùëá ‚äï range ùëá, where the first equality comes from6.49, the second equality comes from 7.6(b), and the third equality comes from (b) in this result. (d) Suppose ùúÜ ‚àà ùêÖ. Then (ùëá ‚àí ùúÜùêº)(ùëá ‚àí ùúÜùêº)‚àó = (ùëá ‚àí ùúÜùêº)(ùëá‚àó ‚àí ùúÜùêº) = ùëáùëá‚àó ‚àí ùúÜùëá ‚àí ùúÜùëá‚àó + |ùúÜ|2ùêº = ùëá‚àóùëá ‚àí ùúÜùëá ‚àí ùúÜùëá‚àó + |ùúÜ|2ùêº = (ùëá‚àó ‚àí ùúÜùêº)(ùëá ‚àí ùúÜùêº) = (ùëá ‚àí ùúÜùêº)‚àó(ùëá ‚àí ùúÜùêº). Thus ùëá ‚àí ùúÜùêº commutes with its adjoint. Hence ùëá ‚àí ùúÜùêº is normal. (e) Suppose ùë£ ‚àà ùëâ and ùúÜ ‚àà ùêÖ. Then (d) and 7.20 imply that ‚Äñ(ùëá ‚àí ùúÜùêº)ùë£‚Äñ = ‚à•(ùëá ‚àí ùúÜùêº)‚àóùë£‚à• = ‚à•(ùëá‚àó ‚àí ùúÜùêº)ùë£‚à•. Thus ‚Äñ(ùëá ‚àí ùúÜùêº)ùë£‚Äñ = 0if and only if ‚à•(ùëá‚àó ‚àí ùúÜùêº)ùë£‚à• = 0. Hence ùëáùë£ = ùúÜùë£ if and only if ùëá‚àóùë£ = ùúÜùë£. 238 Chapter 7 Operators on Inner Product Spaces Because every self-adjoint operator is normal, the next result applies in partic- ular to self-adjoint operators. 7.22 orthogonal eigenvectors for normal operators Suppose ùëá ‚àà ‚Ñí(ùëâ) is normal. Then eigenvectors of ùëá corresponding to distinct eigenvalues are orthogonal. Proof Suppose ùõº, ùõΩ are distinct eigenvalues of ùëá, with corresponding eigen- vectors ùë¢, ùë£. Thus ùëáùë¢ = ùõºùë¢ and ùëáùë£ = ùõΩùë£. From 7.21(e) we have ùëá‚àóùë£ = ùõΩùë£. Thus (ùõº ‚àí ùõΩ)‚ü®ùë¢, ùë£‚ü© = ‚ü®ùõºùë¢, ùë£‚ü© ‚àí‚ü®ùë¢, ùõΩùë£‚ü© = ‚ü®ùëáùë¢, ùë£‚ü© ‚àí‚ü®ùë¢, ùëá‚àóùë£‚ü© = 0. Because ùõº ‚â† ùõΩ, the equation above implies that ‚ü®ùë¢, ùë£‚ü© = 0. Thus ùë¢ and ùë£ are orthogonal, as desired. As stated here, the next result makes sense only when ùêÖ = ùêÇ. However, see Exercise 12 for a version that makes sense when ùêÖ = ùêÇ and when ùêÖ = ùêë. Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Under the analogy between ‚Ñí(ùëâ) and ùêÇ, with the adjoint on ‚Ñí(ùëâ) playing a similar role to that of the complex conjugate on ùêÇ, the operators ùê¥ and ùêµ as defined by7.24 correspond to the real and imaginary parts of ùëá. Thus the informal title of the result below should make sense. 7.23 ùëá is normal ‚ü∫ the real and imaginary parts of ùëá commute Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Then ùëá is normal if and only if there exist commuting self-adjoint operators ùê¥ and ùêµ such that ùëá = ùê¥ + ùëñùêµ. Proof First suppose ùëá is normal. Let 7.24 ùê¥ = ùëá + ùëá‚àó 2 and ùêµ = ùëá ‚àí ùëá‚àó 2ùëñ . Then ùê¥ and ùêµ are self-adjoint and ùëá = ùê¥ + ùëñùêµ. A quick computation shows that 7.25 ùê¥ùêµ ‚àí ùêµùê¥ = ùëá‚àóùëá ‚àí ùëáùëá‚àó 2ùëñ . Because ùëá is normal, the right side of the equation above equals 0. Thus the operators ùê¥ and ùêµ commute, as desired. To prove the implication in the other direction, now suppose there exist com- muting self-adjoint operators ùê¥ and ùêµ such that ùëá = ùê¥ + ùëñùêµ. Then ùëá‚àó = ùê¥ ‚àí ùëñùêµ. Adding the last two equations and then dividing by 2produces the equation for ùê¥ in 7.24. Subtracting the last two equations and then dividing by 2ùëñproduces the equation for ùêµ in 7.24. Now 7.24 implies 7.25. Because ùêµ and ùê¥ commute, 7.25 implies that ùëá is normal, as desired. Section 7A Self-Adjoint and Normal Operators 239 Exercises 7A 1 Suppose ùëõ is a positive integer. Defineùëá ‚àà ‚Ñí(ùêÖùëõ)by ùëá(ùëß1, ‚Ä¶, ùëßùëõ) = (0, ùëß1, ‚Ä¶, ùëßùëõ ‚àí 1). Find a formula for ùëá‚àó(ùëß1, ‚Ä¶, ùëßùëõ). 2 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that ùëá = 0 ‚ü∫ ùëá‚àó = 0 ‚ü∫ ùëá‚àóùëá = 0 ‚ü∫ ùëáùëá‚àó = 0. 3 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ ‚àà ùêÖ. Prove that ùúÜ is an eigenvalue of ùëá ‚ü∫ ùúÜ is an eigenvalue of ùëá‚àó. 4 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëà is a subspace of ùëâ. Prove that ùëà is invariant under ùëá ‚ü∫ ùëà‚üÇ is invariant under ùëá‚àó. 5 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Suppose ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ and ùëì1, ‚Ä¶, ùëìùëö is an orthonormal basis of ùëä. Prove that ‚Äñùëáùëí1‚Äñ2 + ‚ãØ + ‚Äñùëáùëíùëõ‚Äñ2 = ‚à•ùëá‚àóùëì1‚à•2 + ‚ãØ + ‚à•ùëá‚àóùëìùëö‚à• 2 . The numbers ‚Äñùëáùëí1‚Äñ 2, ‚Ä¶, ‚Äñùëáùëíùëõ‚Äñ2 in the equation above depend on the ortho- normal basis ùëí1, ‚Ä¶, ùëíùëõ, but the right side of the equation does not depend on ùëí1, ‚Ä¶, ùëíùëõ. Thus the equation above shows that the sum on the left side does not depend on which orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ is used. 6 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that (a) ùëá is injective ‚ü∫ ùëá‚àó is surjective; (b) ùëá is surjective ‚ü∫ ùëá‚àó is injective. 7 Prove that if ùëá ‚àà ‚Ñí(ùëâ, ùëä), then (a) dim null ùëá‚àó = dim null ùëá + dim ùëä ‚àí dim ùëâ; (b) dim range ùëá‚àó = dim range ùëá. 8 Suppose ùê¥ is an ùëö-by-ùëõ matrix with entries in ùêÖ. Use (b) in Exercise 7 to prove that the row rank of ùê¥ equals the column rank of ùê¥. This exercise asks for yet another alternative proof of a result that was previously proved in 3.57 and 3.133. 9 Prove that the product of two self-adjoint operators on ùëâ is self-adjoint if and only if the two operators commute. 10 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is self-adjoint if and only if ‚ü®ùëáùë£, ùë£‚ü© =‚ü®ùëá‚àóùë£, ùë£‚ü© for all ùë£ ‚àà ùëâ. 240 Chapter 7 Operators on Inner Product Spaces 11 Define an operatorùëÜ‚à∂ ùêÖ2 ‚Üí ùêÖ2 by ùëÜ(ùë§, ùëß) = (‚àíùëß, ùë§). (a) Find a formula for ùëÜ‚àó. (b) Show that ùëÜ is normal but not self-adjoint. (c) Find all eigenvalues of ùëÜ. If ùêÖ = ùêë, then ùëÜ is the operator on ùêë2 of counterclockwise rotation by 90 ‚àò. 12 An operator ùêµ ‚àà ‚Ñí(ùëâ) is called skew if ùêµ‚àó = ‚àíùêµ. Suppose that ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is normal if and only if there exist commuting operators ùê¥ and ùêµ such that ùê¥ is self-adjoint, ùêµ is a skew operator, and ùëá = ùê¥ + ùêµ. 13 Suppose ùêÖ = ùêë. Defineùíú ‚àà ‚Ñí(‚Ñí(ùëâ))by ùíúùëá = ùëá‚àó for all ùëá ‚àà ‚Ñí(ùëâ). (a) Find all eigenvalues of ùíú. (b) Find the minimal polynomial of ùíú. 14 Define an inner product onùí´2(ùêë) by ‚ü®ùëù, ùëû‚ü© =‚à´ 1 0 ùëùùëû. Define an operator ùëá ‚àà ‚Ñí(ùí´2(ùêë))by ùëá(ùëéùë•2 + ùëèùë• + ùëê)= ùëèùë•. (a) Show that with this inner product, the operator ùëá is not self-adjoint. (b) The matrix of ùëá with respect to the basis 1, ùë•, ùë•2 is ‚éõ‚éú‚éú‚éú ‚éù 0 0 0 0 1 0 0 0 0 ‚éû‚éü‚éü‚éü ‚é† . This matrix equals its conjugate transpose, even though ùëá is not self- adjoint. Explain why this is not a contradiction. 15 Suppose ùëá ‚àà ‚Ñí(ùëâ) is invertible. Prove that (a) ùëá is self-adjoint ‚ü∫ ùëá‚àí1 is self-adjoint; (b) ùëá is normal ‚ü∫ ùëá‚àí1 is normal. 16 Suppose ùêÖ = ùêë. (a) Show that the set of self-adjoint operators on ùëâ is a subspace of ‚Ñí(ùëâ). (b) What is the dimension of the subspace of ‚Ñí(ùëâ) in (a) [in terms of dim ùëâ]? 17 Suppose ùêÖ = ùêÇ. Show that the set of self-adjoint operators on ùëâ is not a subspace of ‚Ñí(ùëâ). 18 Suppose dim ùëâ ‚â• 2. Show that the set of normal operators on ùëâ is not a subspace of ‚Ñí(ùëâ). Section 7A Self-Adjoint and Normal Operators 241 19 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ‚à•ùëá‚àóùë£‚à• ‚â§ ‚Äñùëáùë£‚Äñfor every ùë£ ‚àà ùëâ. Prove that ùëá is normal. This exercise fails on infinite-dimensional inner product spaces, leading to what are called hyponormal operators, which have a well-developed theory. 20 Suppose ùëÉ ‚àà ‚Ñí(ùëâ) is such that ùëÉ2 = ùëÉ. Prove that the following are equivalent. (a) ùëÉ is self-adjoint. (b) ùëÉ is normal. (c) There is a subspace ùëà of ùëâ such that ùëÉ = ùëÉùëà. 21 Suppose ùê∑‚à∂ ùí´8(ùêë) ‚Üí ùí´8(ùêë) is the differentiation operator defined by ùê∑ùëù = ùëù‚Ä≤. Prove that there does not exist an inner product on ùí´8(ùêë) that makes ùê∑ a normal operator. 22 Give an example of an operator ùëá ‚àà ‚Ñí(ùêë3)such that ùëá is normal but not self-adjoint. 23 Suppose ùëá is a normal operator on ùëâ. Suppose also that ùë£, ùë§ ‚àà ùëâ satisfy the equations ‚Äñùë£‚Äñ = ‚Äñùë§‚Äñ = 2, ùëáùë£ = 3ùë£, ùëáùë§ = 4ùë§. Show that ‚Äñùëá(ùë£ + ùë§)‚Äñ = 10. 24 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëé0 + ùëé1ùëß + ùëé2ùëß2 + ‚ãØ + ùëéùëö ‚àí 1ùëß ùëö ‚àí 1 + ùëß ùëö is the minimal polynomial of ùëá. Prove that the minimal polynomial of ùëá‚àó is ùëé0 + ùëé1 ùëß + ùëé2 ùëß 2 + ‚ãØ + ùëéùëö ‚àí 1 ùëß ùëö ‚àí 1 + ùëß ùëö. This exercise shows that the minimal polynomial of ùëá‚àó equals the minimal polynomial of ùëá if ùêÖ = ùêë. 25 Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is diagonalizable if and only if ùëá‚àó is diagonalizable. 26 Fix ùë¢, ùë• ‚àà ùëâ. Defineùëá ‚àà ‚Ñí(ùëâ) by ùëáùë£ = ‚ü®ùë£, ùë¢‚ü©ùë•for every ùë£ ‚àà ùëâ. (a) Prove that if ùëâ is a real vector space, then ùëá is self-adjoint if and only if the list ùë¢, ùë• is linearly dependent. (b) Prove that ùëá is normal if and only if the list ùë¢, ùë• is linearly dependent. 27 Suppose ùëá ‚àà ‚Ñí(ùëâ) is normal. Prove that null ùëáùëò = null ùëá and range ùëáùëò = range ùëá for every positive integer ùëò. 28 Suppose ùëá ‚àà ‚Ñí(ùëâ) is normal. Prove that if ùúÜ ‚àà ùêÖ, then the minimal polynomial of ùëá is not a polynomial multiple of (ùë• ‚àí ùúÜ)2. 242 Chapter 7 Operators on Inner Product Spaces 29 Prove or give a counterexample: If ùëá ‚àà ‚Ñí(ùëâ) and there is an orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ such that ‚Äñùëáùëíùëò‚Äñ = ‚à•ùëá‚àóùëíùëò‚à• for each ùëò = 1, ‚Ä¶, ùëõ, then ùëá is normal. 30 Suppose that ùëá ‚àà ‚Ñí(ùêÖ3)is normal and ùëá(1, 1, 1) = (2, 2, 2). Suppose (ùëß1, ùëß2, ùëß3) ‚àà null ùëá. Prove that ùëß1 + ùëß2 + ùëß3 = 0. 31 Fix a positive integer ùëõ. In the inner product space of continuous real-valued functions on [‚àíùúã, ùúã] with inner product ‚ü® ùëì, ùëî‚ü© =‚à´ ùúã ‚àíùúã ùëì ùëî, let ùëâ = span(1, cos ùë•, cos 2ùë•, ‚Ä¶, cos ùëõùë•, sin ùë•, sin 2ùë•, ‚Ä¶, sin ùëõùë•). (a) Defineùê∑ ‚àà ‚Ñí(ùëâ) by ùê∑ ùëì = ùëì ‚Ä≤. Show that ùê∑‚àó = ‚àíùê∑. Conclude that ùê∑ is normal but not self-adjoint. (b) Defineùëá ‚àà ‚Ñí(ùëâ) by ùëá ùëì = ùëì ‚Ä≥. Show that ùëá is self-adjoint. 32 Suppose ùëá‚à∂ ùëâ ‚Üí ùëä is a linear map. Show that under the standard identifica- tion of ùëâ with ùëâ‚Ä≤ (see 6.58) and the corresponding identification ofùëä with ùëä‚Ä≤, the adjoint map ùëá‚àó ‚à∂ ùëä ‚Üí ùëâ corresponds to the dual map ùëá‚Ä≤ ‚à∂ ùëä‚Ä≤ ‚Üí ùëâ‚Ä≤. More precisely, show that ùëá‚Ä≤(ùúëùë§) = ùúëùëá‚àóùë§ for all ùë§ ‚àà ùëä, where ùúëùë§ and ùúëùëá‚àóùë§ are defined as in6.58. Open Access This chapter is licensed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (https://creativecommons.org/licenses/by-nc/4.0), which permits any noncommercial use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to original author and source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this chapter are included in the chapter‚Äôs Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter‚Äôs Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. Section 7B Spectral Theorem 243 7B Spectral Theorem Recall that a diagonal matrix is a square matrix that is 0everywhere except possibly on the diagonal. Recall that an operator on ùëâ is called diagonalizable if the operator has a diagonal matrix with respect to some basis of ùëâ. Recall also that this happens if and only if there is a basis of ùëâ consisting of eigenvectors of the operator (see 5.55). The nicest operators on ùëâ are those for which there is an orthonormal basis of ùëâ with respect to which the operator has a diagonal matrix. These are precisely the operators ùëá ‚àà ‚Ñí(ùëâ) such that there is an orthonormal basis of ùëâ consisting of eigenvectors of ùëá. Our goal in this section is to prove the spectral theorem, which characterizes these operators as the self-adjoint operators when ùêÖ = ùêë and as the normal operators when ùêÖ = ùêÇ. The spectral theorem is probably the most useful tool in the study of operators on inner product spaces. Its extension to certain infinite-dimensional inner product spaces (see, for example, Section 10D of the author‚Äôs book Measure, Integration & Real Analysis) plays a key role in functional analysis. Because the conclusion of the spectral theorem depends on ùêÖ, we will break the spectral theorem into two pieces, called the real spectral theorem and the complex spectral theorem. Real Spectral Theorem To prove the real spectral theorem, we will need two preliminary results. These preliminary results hold on both real and complex inner product spaces, but they are not needed for the proof of the complex spectral theorem. This completing-the-square technique can be used to derive the quadratic formula. You could guess that the next result is true and even discover its proof by think- ing about quadratic polynomials with real coefficients. Specifically, suppose ùëè, ùëê ‚àà ùêë and ùëè 2 < 4ùëê. Let ùë• be a real number. Then ùë•2 + ùëèùë• + ùëê = (ùë• + ùëè 2 ) 2 + (ùëê ‚àí ùëè2 4 )> 0. In particular, ùë•2 + ùëèùë• + ùëê is an invertible real number (a convoluted way of saying that it is not 0). Replacing the real number ùë• with a self-adjoint operator (recall the analogy between real numbers and self-adjoint operators) leads to the next result. 7.26 invertible quadratic expressions Suppose ùëá ‚àà ‚Ñí(ùëâ) is self-adjoint and ùëè, ùëê ‚àà ùêë are such that ùëè 2 < 4ùëê. Then ùëá2 + ùëèùëá + ùëêùêº is an invertible operator. 244 Chapter 7 Operators on Inner Product Spaces Proof Let ùë£ be a nonzero vector in ùëâ. Then ‚ü®(ùëá2 + ùëèùëá + ùëêùêº)ùë£, ùë£‚ü©= ‚ü®ùëá2ùë£, ùë£‚ü©+ ùëè‚ü®ùëáùë£, ùë£‚ü©+ ùëê‚ü®ùë£, ùë£‚ü© = ‚ü®ùëáùë£, ùëáùë£‚ü©+ ùëè‚ü®ùëáùë£, ùë£‚ü©+ ùëê‚Äñùë£‚Äñ 2 ‚â• ‚Äñùëáùë£‚Äñ 2 ‚àí |ùëè| ‚Äñùëáùë£‚Äñ ‚Äñùë£‚Äñ + ùëê‚Äñùë£‚Äñ 2 = (‚Äñùëáùë£‚Äñ ‚àí |ùëè| ‚Äñùë£‚Äñ 2 ) 2 + (ùëê ‚àí ùëè 2 4 )‚Äñùë£‚Äñ 2 > 0, where the third line above holds by the Cauchy‚ÄìSchwarz inequality (6.14). The last inequality implies that (ùëá2 + ùëèùëá + ùëêùêº)ùë£ ‚â† 0. Thus ùëá2 + ùëèùëá + ùëêùêº is injective, which implies that it is invertible (see 3.65). The next result will be a key tool in our proof of the real spectral theorem. 7.27 minimal polynomial of self-adjoint operator Suppose ùëá ‚àà ‚Ñí(ùëâ) is self-adjoint. Then the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö) for some ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêë. Proof First suppose ùêÖ = ùêÇ. The zeros of the minimal polynomial of ùëá are the eigenvalues of ùëá [by 5.27(a)]. All eigenvalues of ùëá are real (by 7.12). Thus the second version of the fundamental theorem of algebra (see 6.69) tells us that the minimal polynomial of ùëá has the desired form. Now suppose ùêÖ = ùêë. By the factorization of a polynomial over ùêë (see 4.16) there exist ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêë and ùëè1, ‚Ä¶, ùëèùëÅ, ùëê1, ‚Ä¶, ùëêùëÅ ‚àà ùêë with ùëèùëò 2 < 4ùëêùëò for each ùëò such that the minimal polynomial of ùëá equals 7.28 (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö)(ùëß 2 + ùëè1ùëß + ùëê1)‚ãØ(ùëß 2 + ùëèùëÅùëß + ùëêùëÅ); here either ùëö or ùëÅ might equal 0, meaning that there are no terms of the corre- sponding form. Now (ùëá ‚àí ùúÜ1ùêº)‚ãØ(ùëá ‚àí ùúÜùëöùêº)(ùëá2 + ùëè1ùëá + ùëê1ùêº)‚ãØ(ùëá2 + ùëèùëÅùëá + ùëêùëÅùêº)= 0. If ùëÅ > 0, then we could multiply both sides of the equation above on the right by the inverse of ùëá2 + ùëèùëÅùëá + ùëêùëÅùêº (which is an invertible operator by 7.26) to obtain a polynomial expression of ùëá that equals 0. The corresponding polynomial would have degree two less than the degree of 7.28, violating the minimality of the degree of the polynomial with this property. Thus we must have ùëÅ = 0, which means that the minimal polynomial in 7.28 has the form (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö), as desired. The result above along with 5.27(a) implies that every self-adjoint operator has an eigenvalue. In fact, as we will see in the next result, self-adjoint operators have enough eigenvectors to form a basis. Section 7B Spectral Theorem 245 The next result, which gives a complete description of the self-adjoint operators on a real inner product space, is one of the major theorems in linear algebra. 7.29 real spectral theorem Suppose ùêÖ = ùêë and ùëá ‚àà ‚Ñí(ùëâ). Then the following are equivalent. (a) ùëá is self-adjoint. (b) ùëá has a diagonal matrix with respect to some orthonormal basis of ùëâ. (c) ùëâ has an orthonormal basis consisting of eigenvectors of ùëá. Proof First suppose (a) holds, so ùëá is self-adjoint. Our results on minimal poly- nomials, specifically6.37 and 7.27, imply that ùëá has an upper-triangular matrix with respect to some orthonormal basis of ùëâ. With respect to this orthonormal basis, the matrix of ùëá‚àó is the transpose of the matrix of ùëá. However, ùëá‚àó = ùëá. Thus the transpose of the matrix of ùëá equals the matrix of ùëá. Because the matrix of ùëá is upper-triangular, this means that all entries of the matrix above and below the diagonal are 0. Hence the matrix of ùëá is a diagonal matrix with respect to the orthonormal basis. Thus (a) implies (b). Conversely, now suppose (b) holds, so ùëá has a diagonal matrix with respect to some orthonormal basis of ùëâ. That diagonal matrix equals its transpose. Thus with respect to that basis, the matrix of ùëá‚àó equals the matrix of ùëá. Hence ùëá‚àó = ùëá, proving that (b) implies (a). The equivalence of (b) and (c) follows from the definitions[or see the proof that (a) and (b) are equivalent in 5.55]. 7.30 example:an orthonormal basis of eigenvectors for an operator Consider the operator ùëá on ùêë3 whose matrix (with respect to the standard basis) is ‚éõ‚éú‚éú‚éú ‚éù 14 ‚àí13 8 ‚àí13 14 8 8 8 ‚àí7 ‚éû‚éü‚éü‚éü ‚é† . This matrix with real entries equals its transpose; thus ùëá is self-adjoint. As you can verify, (1, ‚àí1, 0) ‚àö2 , (1, 1, 1) ‚àö3 , (1, 1, ‚àí2) ‚àö6 is an orthonormal basis of ùêë3 consisting of eigenvectors of ùëá. With respect to this basis, the matrix of ùëá is the diagonal matrix ‚éõ‚éú‚éú‚éú ‚éù 27 0 0 0 9 0 0 0 ‚àí15 ‚éû‚éü‚éü‚éü ‚é† . See Exercise 17 for a version of the real spectral theorem that applies simulta- neously to more than one operator. 246 Chapter 7 Operators on Inner Product Spaces Complex Spectral Theorem The next result gives a complete description of the normal operators on a complex inner product space. 7.31 complex spectral theorem Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Then the following are equivalent. (a) ùëá is normal. (b) ùëá has a diagonal matrix with respect to some orthonormal basis of ùëâ. (c) ùëâ has an orthonormal basis consisting of eigenvectors of ùëá. Proof First suppose (a) holds, so ùëá is normal. By Schur‚Äôs theorem (6.38), there is an orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ with respect to which ùëá has an upper-triangular matrix. Thus we can write 7.32 ‚Ñ≥(ùëá, (ùëí1, ‚Ä¶, ùëíùëõ))= ‚éõ‚éú‚éú‚éú ‚éù ùëé1, 1 ‚ãØ ùëé1, ùëõ ‚ã± ‚ãÆ 0 ùëéùëõ, ùëõ ‚éû‚éü‚éü‚éü ‚é† . We will show that this matrix is actually a diagonal matrix. We see from the matrix above that ‚Äñùëáùëí1‚Äñ2 = |ùëé1, 1| 2, ‚à•ùëá‚àóùëí1‚à• 2 = |ùëé1, 1| 2 + |ùëé1, 2| 2 + ‚ãØ + |ùëé1, ùëõ| 2. Because ùëá is normal, ‚Äñùëáùëí1‚Äñ = ‚à•ùëá‚àóùëí1‚à• (see 7.20). Thus the two equations above imply that all entries in the first row of the matrix in7.32, except possibly the first entry ùëé1, 1, equal 0. Now 7.32 implies ‚Äñùëáùëí2‚Äñ 2 = |ùëé2, 2| 2 (because ùëé1, 2 = 0, as we showed in the paragraph above) and ‚à•ùëá‚àóùëí2‚à• 2 = |ùëé2, 2| 2 + |ùëé2, 3| 2 + ‚ãØ + |ùëé2, ùëõ| 2. Because ùëá is normal, ‚Äñùëáùëí2‚Äñ = ‚à•ùëá‚àóùëí2‚à•. Thus the two equations above imply that all entries in the second row of the matrix in 7.32, except possibly the diagonal entry ùëé2, 2, equal 0. Continuing in this fashion, we see that all nondiagonal entries in the matrix 7.32 equal 0. Thus (b) holds, completing the proof that (a) implies (b). Now suppose (b) holds, so ùëá has a diagonal matrix with respect to some orthonormal basis of ùëâ. The matrix of ùëá‚àó (with respect to the same basis) is obtained by taking the conjugate transpose of the matrix of ùëá; hence ùëá‚àó also has a diagonal matrix. Any two diagonal matrices commute; thus ùëá commutes with ùëá‚àó, which means that ùëá is normal. In other words, (a) holds, completing the proof that (b) implies (a). The equivalence of (b) and (c) follows from the definitions (also see5.55). Section 7B Spectral Theorem 247 See Exercises 13 and 20 for alternative proofs that (a) implies (b) in the previous result. Exercises 14 and 15 interpret the real spectral theorem and the complex spectral theorem by expressing the domain space as an orthogonal direct sum of eigenspaces. See Exercise 16 for a version of the complex spectral theorem that applies simultaneously to more than one operator. The main conclusion of the complex spectral theorem is that every normal operator on a complex finite-dimensional inner product space is diagonalizable by an orthonormal basis, as illustrated by the next example. 7.33 example:an orthonormal basis of eigenvectors for an operator Consider the operator ùëá ‚àà ‚Ñí(ùêÇ 2)defined byùëá(ùë§, ùëß) = (2ùë§ ‚àí 3ùëß, 3ùë§+ 2ùëß). The matrix of ùëá (with respect to the standard basis) is ( 2 ‚àí3 3 2 ). As we saw in Example 7.19, ùëá is a normal operator. As you can verify, 1 ‚àö2 (ùëñ, 1), 1 ‚àö2 (‚àíùëñ, 1) is an orthonormal basis of ùêÇ 2 consisting of eigenvectors of ùëá, and with respect to this basis the matrix of ùëá is the diagonal matrix ( 2+ 3ùëñ 0 0 2 ‚àí 3ùëñ ). Exercises 7B 1 Prove that a normal operator on a complex inner product space is self-adjoint if and only if all its eigenvalues are real. This exercise strengthens the analogy (for normal operators) between self- adjoint operators and real numbers. 2 Suppose ùêÖ = ùêÇ. Suppose ùëá ‚àà ‚Ñí(ùëâ) is normal and has only one eigenvalue. Prove that ùëá is a scalar multiple of the identity operator. 3 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ) is normal. Prove that the set of eigenvalues of ùëá is contained in {0, 1}if and only if there is a subspace ùëà of ùëâ such that ùëá = ùëÉùëà. 4 Prove that a normal operator on a complex inner product space is skew (meaning it equals the negative of its adjoint) if and only if all its eigenvalues are purely imaginary (meaning that they have real part equal to 0). 248 Chapter 7 Operators on Inner Product Spaces 5 Prove or give a counterexample: If ùëá ‚àà ‚Ñí(ùêÇ 3)is a diagonalizable operator, then ùëá is normal (with respect to the usual inner product). 6 Suppose ùëâ is a complex inner product space and ùëá ‚àà ‚Ñí(ùëâ) is a normal operator such that ùëá9 = ùëá8. Prove that ùëá is self-adjoint and ùëá2 = ùëá. 7 Give an example of an operator ùëá on a complex vector space such that ùëá9 = ùëá8 but ùëá2 ‚â† ùëá. 8 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is normal if and only if every eigenvector of ùëá is also an eigenvector of ùëá‚àó. 9 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is normal if and only if there exists a polynomial ùëù ‚àà ùí´(ùêÇ) such that ùëá‚àó = ùëù(ùëá). 10 Suppose ùëâ is a complex inner product space. Prove that every normal operator on ùëâ has a square root. An operator ùëÜ ‚àà ‚Ñí(ùëâ) is called a square root of ùëá ‚àà ‚Ñí(ùëâ) if ùëÜ2 = ùëá. We will discuss more about square roots of operators in Sections 7C and 8C. 11 Prove that every self-adjoint operator on ùëâ has a cube root. An operator ùëÜ ‚àà ‚Ñí(ùëâ) is called a cube root of ùëá ‚àà ‚Ñí(ùëâ) if ùëÜ3 = ùëá. 12 Suppose ùëâ is a complex vector space and ùëá ‚àà ‚Ñí(ùëâ) is normal. Prove that if ùëÜ is an operator on ùëâ that commutes with ùëá, then ùëÜ commutes with ùëá‚àó. The result in this exercise is called Fuglede‚Äôs theorem. 13 Without using the complex spectral theorem, use the version of Schur‚Äôs theorem that applies to two commuting operators (take ‚Ñ∞ = {ùëá, ùëá‚àó}in Exercise 20 in Section 6B)to give a different proof that if ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ) is normal, then ùëá has a diagonal matrix with respect to some orthonormal basis of ùëâ. 14 Suppose ùêÖ = ùêë and ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is self-adjoint if and only if all pairs of eigenvectors corresponding to distinct eigenvalues of ùëá are orthogonal and ùëâ = ùê∏(ùúÜ1, ùëá) ‚äï ‚ãØ ‚äï ùê∏(ùúÜùëö, ùëá), where ùúÜ1, ‚Ä¶, ùúÜùëö denote the distinct eigenvalues of ùëá. 15 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is normal if and only if all pairs of eigenvectors corresponding to distinct eigenvalues of ùëá are orthogonal and ùëâ = ùê∏(ùúÜ1, ùëá) ‚äï ‚ãØ ‚äï ùê∏(ùúÜùëö, ùëá), where ùúÜ1, ‚Ä¶, ùúÜùëö denote the distinct eigenvalues of ùëá. 16 Suppose ùêÖ = ùêÇ and ‚Ñ∞ ‚äÜ ‚Ñí(ùëâ). Prove that there is an orthonormal basis of ùëâ with respect to which every element of ‚Ñ∞ has a diagonal matrix if and only if ùëÜ and ùëá are commuting normal operators for all ùëÜ, ùëá ‚àà ‚Ñ∞. This exercise extends the complex spectral theorem to the context of a collection of commuting normal operators. Section 7B Spectral Theorem 249 17 Suppose ùêÖ = ùêë and ‚Ñ∞ ‚äÜ ‚Ñí(ùëâ). Prove that there is an orthonormal basis of ùëâ with respect to which every element of ‚Ñ∞ has a diagonal matrix if and only if ùëÜ and ùëá are commuting self-adjoint operators for all ùëÜ, ùëá ‚àà ‚Ñ∞. This exercise extends the real spectral theorem to the context of a collection of commuting self-adjoint operators. 18 Give an example of a real inner product space ùëâ, an operator ùëá ‚àà ‚Ñí(ùëâ), and real numbers ùëè, ùëê with ùëè 2 < 4ùëêsuch that ùëá2 + ùëèùëá + ùëêùêº is not invertible. This exercise shows that the hypothesis that ùëá is self-adjoint cannot be deleted in 7.26, even for real vector spaces. 19 Suppose ùëá ‚àà ‚Ñí(ùëâ) is self-adjoint and ùëà is a subspace of ùëâ that is invariant under ùëá. (a) Prove that ùëà‚üÇ is invariant under ùëá. (b) Prove that ùëá|ùëà ‚àà ‚Ñí(ùëà) is self-adjoint. (c) Prove that ùëá|ùëà‚üÇ ‚àà ‚Ñí(ùëà‚üÇ)is self-adjoint. 20 Suppose ùëá ‚àà ‚Ñí(ùëâ) is normal and ùëà is a subspace of ùëâ that is invariant under ùëá. (a) Prove that ùëà‚üÇ is invariant under ùëá. (b) Prove that ùëà is invariant under ùëá‚àó. (c) Prove that (ùëá|ùëà)‚àó = (ùëá‚àó)|ùëà. (d) Prove that ùëá|ùëà ‚àà ‚Ñí(ùëà) and ùëá|ùëà‚üÇ ‚àà ‚Ñí(ùëà‚üÇ)are normal operators. This exercise can be used to give yet another proof of the complex spectral theorem (use induction on dim ùëâ and the result that ùëá has an eigenvector). 21 Suppose that ùëá is a self-adjoint operator on a finite-dimensional inner product space and that 2and 3are the only eigenvalues of ùëá. Prove that ùëá2 ‚àí 5ùëá+ 6ùêº = 0. 22 Give an example of an operator ùëá ‚àà ‚Ñí(ùêÇ 3)such that 2and 3are the only eigenvalues of ùëá and ùëá2 ‚àí 5ùëá+ 6ùêº ‚â† 0. 23 Suppose ùëá ‚àà ‚Ñí(ùëâ) is self-adjoint, ùúÜ ‚àà ùêÖ, and ùúñ > 0. Suppose there exists ùë£ ‚àà ùëâ such that ‚Äñùë£‚Äñ = 1and ‚Äñùëáùë£ ‚àí ùúÜùë£‚Äñ < ùúñ. Prove that ùëá has an eigenvalue ùúÜ‚Ä≤ such that ‚à£ùúÜ ‚àí ùúÜ‚Ä≤‚à£ < ùúñ. This exercise shows that for a self-adjoint operator, a number that is close to satisfying an equation that would make it an eigenvalue is close to an eigenvalue. 250 Chapter 7 Operators on Inner Product Spaces 24 Suppose ùëà is a finite-dimensional vector space andùëá ‚àà ‚Ñí(ùëà). (a) Suppose ùêÖ = ùêë. Prove that ùëá is diagonalizable if and only if there is a basis of ùëà such that the matrix of ùëá with respect to this basis equals its transpose. (b) Suppose ùêÖ = ùêÇ. Prove that ùëá is diagonalizable if and only if there is a basis of ùëà such that the matrix of ùëá with respect to this basis commutes with its conjugate transpose. This exercise adds another equivalence to the list of conditions equivalent to diagonalizability in 5.55. 25 Suppose that ùëá ‚àà ‚Ñí(ùëâ) and there is an orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ consisting of eigenvectors of ùëá, with corresponding eigenvalues ùúÜ1, ‚Ä¶, ùúÜùëõ. Show that if ùëò ‚àà {1, ‚Ä¶, ùëõ}, then the pseudoinverse ùëá‚Ä† satisfies the equation ùëá‚Ä†ùëíùëò = ‚éß { ‚é® { ‚é© 1 ùúÜùëò ùëíùëò if ùúÜùëò ‚â† 0, 0 if ùúÜùëò = 0. Section 7C Positive Operators 251 7C Positive Operators 7.34 definition:positive operator An operator ùëá ‚àà ‚Ñí(ùëâ) is called positive if ùëá is self-adjoint and ‚ü®ùëáùë£, ùë£‚ü© ‚â• 0 for all ùë£ ‚àà ùëâ. If ùëâ is a complex vector space, then the requirement that ùëá be self-adjoint can be dropped from the definition above (by7.14). 7.35 example:positive operators (a) Let ùëá ‚àà ‚Ñí(ùêÖ2)be the operator whose matrix (using the standard basis) is (2 ‚àí1 ‚àí1 1 ). Then ùëá is self-adjoint and ‚ü®ùëá(ùë§, ùëß), (ùë§, ùëß)‚ü©= 2|ùë§| 2‚àí2Re(ùë§ùëß)+|ùëß| 2 = |ùë§ ‚àí ùëß|2 + |ùë§| 2 ‚â• 0for all (ùë§, ùëß) ‚àà ùêÖ2. Thus ùëá is a positive operator. (b) If ùëà is a subspace of ùëâ, then the orthogonal projection ùëÉùëà is a positive operator, as you should verify. (c) If ùëá ‚àà ‚Ñí(ùëâ) is self-adjoint and ùëè, ùëê ‚àà ùêë are such that ùëè 2 < 4ùëê, then ùëá2+ùëèùëá+ùëêùêº is a positive operator, as shown by the proof of 7.26. 7.36 definition:square root An operator ùëÖ is called a square root of an operator ùëá if ùëÖ 2 = ùëá. 7.37 example:square root of an operator If ùëá ‚àà ‚Ñí(ùêÖ3)is defined byùëá(ùëß1, ùëß2, ùëß3) = (ùëß3, 0, 0), then the operator ùëÖ ‚àà ‚Ñí(ùêÖ3)defined byùëÖ(ùëß1, ùëß2, ùëß3) = (ùëß2, ùëß3, 0)is a square root of ùëá because ùëÖ 2 = ùëá, as you can verify. Because positive operators correspond to nonnegative numbers, better termi- nology would use the term nonnegative operators. However, operator theorists consistently call these positive opera- tors, so we follow that custom. Some mathematicians use the term positive semidefinite operator, which means the same as positive operator. The characterizations of the positive operators in the next result correspond to characterizations of the nonnegative numbers among ùêÇ. Specifically, a num- ber ùëß ‚àà ùêÇ is nonnegative if and only if it has a nonnegative square root, cor- responding to condition (d). Also, ùëß is nonnegative if and only if it has a real square root, corresponding to condition (e). Finally, ùëß is nonnegative if and only if there exists ùë§ ‚àà ùêÇ such that ùëß = ùë§ùë§, corresponding to condition (f). See Exercise 20 for another condition that is equivalent to being a positive operator. 252 Chapter 7 Operators on Inner Product Spaces 7.38 characterization of positive operators Let ùëá ‚àà ‚Ñí(ùëâ). Then the following are equivalent. (a) ùëá is a positive operator. (b) ùëá is self-adjoint and all eigenvalues of ùëá are nonnegative. (c) With respect to some orthonormal basis of ùëâ, the matrix of ùëá is a diagonal matrix with only nonnegative numbers on the diagonal. (d) ùëá has a positive square root. (e) ùëá has a self-adjoint square root. (f) ùëá = ùëÖ‚àóùëÖ for some ùëÖ ‚àà ‚Ñí(ùëâ). Proof We will prove that (a) ‚áí (b) ‚áí (c) ‚áí (d) ‚áí (e) ‚áí (f) ‚áí (a). First suppose (a) holds, so that ùëá is positive, which implies that ùëá is self-adjoint (by definition of positive operator). To prove the other condition in (b), suppose ùúÜ is an eigenvalue of ùëá. Let ùë£ be an eigenvector of ùëá corresponding to ùúÜ. Then 0 ‚â§ ‚ü®ùëáùë£, ùë£‚ü© = ‚ü®ùúÜùë£, ùë£‚ü© = ùúÜ‚ü®ùë£, ùë£‚ü©. Thus ùúÜ is a nonnegative number. Hence (b) holds, showing that (a) implies (b). Now suppose (b) holds, so that ùëá is self-adjoint and all eigenvalues of ùëá are nonnegative. By the spectral theorem (7.29 and 7.31), there is an orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ consisting of eigenvectors of ùëá. Let ùúÜ1, ‚Ä¶, ùúÜùëõ be the eigenval- ues of ùëá corresponding to ùëí1, ‚Ä¶, ùëíùëõ; thus each ùúÜùëò is a nonnegative number. The matrix of ùëá with respect to ùëí1, ‚Ä¶, ùëíùëõ is the diagonal matrix with ùúÜ1, ‚Ä¶, ùúÜùëõ on the diagonal, which shows that (b) implies (c). Now suppose (c) holds. Suppose ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ such that the matrix of ùëá with respect to this basis is a diagonal matrix with nonnegative numbers ùúÜ1, ‚Ä¶, ùúÜùëõ on the diagonal. The linear map lemma (3.4) implies that there exists ùëÖ ‚àà ‚Ñí(ùëâ) such that ùëÖùëíùëò = ‚àöùúÜùëòùëíùëò for each ùëò = 1, ‚Ä¶, ùëõ. As you should verify, ùëÖ is a positive operator. Furthermore, ùëÖ 2ùëíùëò = ùúÜùëòùëíùëò = ùëáùëíùëò for each ùëò, which implies that ùëÖ2 = ùëá. Thus ùëÖ is a positive square root of ùëá. Hence (d) holds, which shows that (c) implies (d). Every positive operator is self-adjoint (by definition of positive operator). Thus (d) implies (e). Now suppose (e) holds, meaning that there exists a self-adjoint operator ùëÖ on ùëâ such that ùëá = ùëÖ2. Then ùëá = ùëÖ‚àóùëÖ (because ùëÖ‚àó = ùëÖ). Hence (e) implies (f). Finally, suppose (f) holds. Let ùëÖ ‚àà ‚Ñí(ùëâ) be such that ùëá = ùëÖ‚àóùëÖ. Then ùëá‚àó = (ùëÖ‚àóùëÖ) ‚àó = ùëÖ‚àó(ùëÖ‚àó) ‚àó = ùëÖ‚àóùëÖ = ùëá. Hence ùëá is self-adjoint. To complete the proof that (a) holds, note that ‚ü®ùëáùë£, ùë£‚ü© =‚ü®ùëÖ‚àóùëÖùë£, ùë£‚ü©= ‚ü®ùëÖùë£, ùëÖùë£‚ü© ‚â• 0 for every ùë£ ‚àà ùëâ. Thus ùëá is positive, showing that (f) implies (a). Section 7C Positive Operators 253 Every nonnegative number has a unique nonnegative square root. The next result shows that positive operators enjoy a similar property. 7.39 each positive operator has only one positive square root Every positive operator on ùëâ has a unique positive square root. A positive operator can have infinitely many square roots (although only one of them can be positive). For example, the identity operator on ùëâ has infinitely many square roots if dim ùëâ > 1. Proof Suppose ùëá ‚àà ‚Ñí(ùëâ) is positive. Suppose ùë£ ‚àà ùëâ is an eigenvector of ùëá. Hence there exists a real number ùúÜ ‚â• 0 such that ùëáùë£ = ùúÜùë£. Let ùëÖ be a positive square root of ùëá. We will prove that ùëÖùë£ = ‚àöùúÜùë£. This will imply that the behavior of ùëÖ on the eigenvectors of ùëá is uniquely determined. Because there is a basis of ùëâ consisting of eigenvectors of ùëá (by the spectral theorem), this will imply that ùëÖ is uniquely determined. To prove that ùëÖùë£ = ‚àöùúÜùë£, note that the spectral theorem asserts that there is an orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ consisting of eigenvectors of ùëÖ. Because ùëÖ is a positive operator, all its eigenvalues are nonnegative. Thus there exist nonnegative numbers ùúÜ1, ‚Ä¶, ùúÜùëõ such that ùëÖùëíùëò = ‚àöùúÜùëòùëíùëò for each ùëò = 1, ‚Ä¶, ùëõ. Because ùëí1, ‚Ä¶, ùëíùëõ is a basis of ùëâ, we can write ùë£ = ùëé1ùëí1 + ‚ãØ + ùëéùëõùëíùëõ for some numbers ùëé1, ‚Ä¶, ùëéùëõ ‚àà ùêÖ. Thus ùëÖùë£ = ùëé1‚àöùúÜ1ùëí1 + ‚ãØ + ùëéùëõ‚àöùúÜùëõùëíùëõ. Hence ùúÜùë£ = ùëáùë£ = ùëÖ2ùë£ = ùëé1 ùúÜ1ùëí1 + ‚ãØ + ùëéùëõ ùúÜùëõùëíùëõ. The equation above implies that ùëé1 ùúÜùëí1 + ‚ãØ + ùëéùëõ ùúÜùëíùëõ = ùëé1 ùúÜ1ùëí1 + ‚ãØ + ùëéùëõ ùúÜùëõùëíùëõ. Thus ùëéùëò(ùúÜ ‚àí ùúÜùëò) = 0for each ùëò = 1, ‚Ä¶, ùëõ. Hence ùë£ = ‚àë {ùëò ‚à∂ ùúÜùëò = ùúÜ} ùëéùëòùëíùëò. Thus ùëÖùë£ = ‚àë {ùëò ‚à∂ ùúÜùëò = ùúÜ} ùëéùëò‚àöùúÜùëíùëò = ‚àöùúÜùë£, as desired. The notation defined below makes sense thanks to the result above. 7.40 notation:‚àöùëá For ùëá a positive operator, ‚àöùëá denotes the unique positive square root of ùëá. 254 Chapter 7 Operators on Inner Product Spaces 7.41 example:square root of positive operators Define operatorsùëÜ, ùëá on ùêë2 (with the usual Euclidean inner product) by ùëÜ(ùë•, ùë¶) = (ùë•, 2ùë¶) and ùëá(ùë•, ùë¶) = (ùë• + ùë¶, ùë• + ùë¶). Then with respect to the standard basis of ùêë2 we have 7.42 ‚Ñ≥(ùëÜ) = ( 1 0 0 2 ) and ‚Ñ≥(ùëá) = ( 1 1 1 1 ). Each of these matrices equals its transpose; thus ùëÜ and ùëá are self-adjoint. If (ùë•, ùë¶) ‚àà ùêë2, then ‚ü®ùëÜ(ùë•, ùë¶), (ùë•, ùë¶)‚ü©= ùë•2 + 2ùë¶ 2 ‚â• 0 and ‚ü®ùëá(ùë•, ùë¶), (ùë•, ùë¶)‚ü©= ùë•2 + 2ùë•ùë¶+ ùë¶2 = (ùë• + ùë¶)2 ‚â• 0. Thus ùëÜ and ùëá are positive operators. The standard basis of ùêë2 is an orthonormal basis consisting of eigenvectors of ùëÜ. Note that ( 1 ‚àö2 , 1 ‚àö2 ), ( 1 ‚àö2 , ‚àí 1 ‚àö2 ) is an orthonormal basis of eigenvectors of ùëá, with eigenvalue 2for the first eigenvector and eigenvalue 0for the second eigenvector. Thus ‚àöùëá has the same eigenvectors, with eigenvalues ‚àö2and 0. You can verify that ‚Ñ≥(‚àöùëÜ )= ‚éõ‚éú ‚éù 1 0 0 ‚àö2‚éû‚éü ‚é† and ‚Ñ≥(‚àöùëá )= ‚éõ‚éú‚éú‚éú‚éú ‚éù 1 ‚àö2 1 ‚àö2 1 ‚àö2 1 ‚àö2 ‚éû‚éü‚éü‚éü‚éü ‚é† with respect to the standard basis by showing that the squares of the matrices above are the matrices in 7.42 and that each matrix above is the matrix of a positive operator. The statement of the next result does not involve a square root, but the clean proof makes nice use of the square root of a positive operator. 7.43 ùëá positive and ‚ü®ùëáùë£, ùë£‚ü© = 0 ‚üπ ùëáùë£ = 0 Suppose ùëá is a positive operator on ùëâ and ùë£ ‚àà ùëâ is such that ‚ü®ùëáùë£, ùë£‚ü© = 0. Then ùëáùë£ = 0. Proof We have 0 = ‚ü®ùëáùë£, ùë£‚ü© =‚ü®‚àöùëá‚àöùëáùë£, ùë£‚ü©= ‚ü®‚àöùëáùë£, ‚àöùëáùë£‚ü©= ‚à•‚àöùëáùë£‚à•2 . Hence ‚àöùëáùë£ = 0. Thus ùëáùë£ = ‚àöùëá(‚àöùëáùë£)= 0, as desired. Section 7C Positive Operators 255 Exercises 7C 1 Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that if both ùëá and ‚àíùëá are positive operators, then ùëá = 0. 2 Suppose ùëá ‚àà ‚Ñí(ùêÖ4)is the operator whose matrix (with respect to the standard basis) is ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 2 ‚àí1 0 0 ‚àí1 2 ‚àí1 0 0 ‚àí1 2 ‚àí1 0 0 ‚àí1 2 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . Show that ùëá is an invertible positive operator. 3 Suppose ùëõ is a positive integer and ùëá ‚àà ‚Ñí(ùêÖùëõ)is the operator whose matrix (with respect to the standard basis) consists of all 1‚Äôs. Show that ùëá is a positive operator. 4 Suppose ùëõ is an integer with ùëõ > 1. Show that there exists an ùëõ-by-ùëõ matrix ùê¥ such that all of the entries of ùê¥ are positive numbers and ùê¥ = ùê¥‚àó, but the operator on ùêÖùëõ whose matrix (with respect to the standard basis) equals ùê¥ is not a positive operator. 5 Suppose ùëá ‚àà ‚Ñí(ùëâ) is self-adjoint. Prove that ùëá is a positive operator if and only if for every orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ, all entries on the diagonal of ‚Ñ≥(ùëá, (ùëí1, ‚Ä¶, ùëíùëõ))are nonnegative numbers. 6 Prove that the sum of two positive operators on ùëâ is a positive operator. 7 Suppose ùëÜ ‚àà ‚Ñí(ùëâ) is an invertible positive operator and ùëá ‚àà ‚Ñí(ùëâ) is a positive operator. Prove that ùëÜ + ùëá is invertible. 8 Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is a positive operator if and only if the pseudoinverse ùëá‚Ä† is a positive operator. 9 Suppose ùëá ‚àà ‚Ñí(ùëâ) is a positive operator and ùëÜ ‚àà ‚Ñí(ùëä, ùëâ). Prove that ùëÜ‚àóùëáùëÜ is a positive operator on ùëä. 10 Suppose ùëá is a positive operator on ùëâ. Suppose ùë£, ùë§ ‚àà ùëâ are such that ùëáùë£ = ùë§ and ùëáùë§ = ùë£. Prove that ùë£ = ùë§. 11 Suppose ùëá is a positive operator on ùëâ and ùëà is a subspace of ùëâ invariant under ùëá. Prove that ùëá|ùëà ‚àà ‚Ñí(ùëà) is a positive operator on ùëà. 12 Suppose ùëá ‚àà ‚Ñí(ùëâ) is a positive operator. Prove that ùëáùëò is a positive operator for every positive integer ùëò. 256 Chapter 7 Operators on Inner Product Spaces 13 Suppose ùëá ‚àà ‚Ñí(ùëâ) is self-adjoint and ùõº ‚àà ùêë. (a) Prove that ùëá ‚àí ùõºùêº is a positive operator if and only if ùõº is less than or equal to every eigenvalue of ùëá. (b) Prove that ùõºùêº ‚àí ùëá is a positive operator if and only if ùõº is greater than or equal to every eigenvalue of ùëá. 14 Suppose ùëá is a positive operator on ùëâ and ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ. Prove that ùëö ‚àë ùëó = 1 ùëö ‚àë ùëò = 1‚ü®ùëáùë£ùëò, ùë£ùëó‚ü© ‚â• 0. 15 Suppose ùëá ‚àà ‚Ñí(ùëâ) is self-adjoint. Prove that there exist positive operators ùê¥, ùêµ ‚àà ‚Ñí(ùëâ) such that ùëá = ùê¥ ‚àí ùêµ and ‚àöùëá‚àóùëá = ùê¥ + ùêµ and ùê¥ùêµ = ùêµùê¥ = 0. 16 Suppose ùëá is a positive operator on ùëâ. Prove that null ‚àöùëá = null ùëá and range ‚àöùëá = range ùëá. 17 Suppose that ùëá ‚àà ‚Ñí(ùëâ) is a positive operator. Prove that there exists a polynomial ùëù with real coefficients such that ‚àöùëá = ùëù(ùëá). 18 Suppose ùëÜ and ùëá are positive operators on ùëâ. Prove that ùëÜùëá is a positive operator if and only if ùëÜ and ùëá commute. 19 Show that the identity operator on ùêÖ2 has infinitely many self-adjoint square roots. 20 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ. Prove that ùëá is a positive operator if and only if there exist ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùëâ such that ‚ü®ùëáùëíùëò, ùëíùëó‚ü© = ‚ü®ùë£ùëò, ùë£ùëó‚ü© for all ùëó, ùëò = 1, ‚Ä¶, ùëõ. The numbers {‚ü®ùëáùëíùëò, ùëíùëó‚ü©} ùëó, ùëò = 1, ‚Ä¶, ùëõ are the entries in the matrix of ùëá with respect to the orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ. 21 Suppose ùëõ is a positive integer. The ùëõ-by-ùëõ Hilbert matrix is the ùëõ-by-ùëõ matrix whose entry in row ùëó, column ùëò is 1 ùëó + ùëò ‚àí 1 . Suppose ùëá ‚àà ‚Ñí(ùëâ) is an operator whose matrix with respect to some orthonormal basis of ùëâ is the ùëõ-by-ùëõ Hilbert matrix. Prove that ùëá is a positive invertible operator. Example: The 4-by-4Hilbert matrix is ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 1 1 2 1 3 1 4 1 2 1 3 1 4 1 5 1 3 1 4 1 5 1 6 1 4 1 5 1 6 1 7 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . Section 7C Positive Operators 257 22 Suppose ùëá ‚àà ‚Ñí(ùëâ) is a positive operator and ùë¢ ‚àà ùëâ is such that ‚Äñùë¢‚Äñ = 1 and ‚Äñùëáùë¢‚Äñ ‚â• ‚Äñùëáùë£‚Äñfor all ùë£ ‚àà ùëâ with ‚Äñùë£‚Äñ = 1. Show that ùë¢ is an eigenvector of ùëá corresponding to the largest eigenvalue of ùëá. 23 For ùëá ‚àà ‚Ñí(ùëâ) and ùë¢, ùë£ ‚àà ùëâ, define‚ü®ùë¢, ùë£‚ü©ùëá by ‚ü®ùë¢, ùë£‚ü©ùëá = ‚ü®ùëáùë¢, ùë£‚ü©. (a) Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that ‚ü®‚ãÖ, ‚ãÖ‚ü©ùëá is an inner product on ùëâ if and only if ùëá is an invertible positive operator (with respect to the original inner product ‚ü®‚ãÖ, ‚ãÖ‚ü©). (b) Prove that every inner product on ùëâ is of the form ‚ü®‚ãÖ, ‚ãÖ‚ü©ùëá for some positive invertible operator ùëá ‚àà ‚Ñí(ùëâ). 24 Suppose ùëÜ and ùëá are positive operators on ùëâ. Prove that null(ùëÜ + ùëá) = null ùëÜ ‚à©null ùëá. 25 Let ùëá be the second derivative operator in Exercise 31(b) in Section 7A. Show that ‚àíùëá is a positive operator. 258 Chapter 7 Operators on Inner Product Spaces 7D Isometries, Unitary Operators, and Matrix Factorization Isometries Linear maps that preserve norms are sufficiently important to deserve a name. 7.44 definition:isometry A linear map ùëÜ ‚àà ‚Ñí(ùëâ, ùëä) is called an isometry if ‚ÄñùëÜùë£‚Äñ = ‚Äñùë£‚Äñ for every ùë£ ‚àà ùëâ. In other words, a linear map is an isometry if it preserves norms. The Greek word isos means equal; the Greek word metron means measure. Thus isometry literally means equal measure. If ùëÜ ‚àà ‚Ñí(ùëâ, ùëä) is an isometry and ùë£ ‚àà ùëâ is such that ùëÜùë£ = 0, then ‚Äñùë£‚Äñ = ‚ÄñùëÜùë£‚Äñ = ‚Äñ0‚Äñ = 0, which implies that ùë£ = 0. Thus every isometry is injective. 7.45 example:orthonormal basis maps to orthonormal list ‚üπ isometry Suppose ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ and ùëî1, ‚Ä¶, ùëîùëõ is an orthonormal list in ùëä. Let ùëÜ ‚àà ‚Ñí(ùëâ, ùëä) be the linear map such that ùëÜùëíùëò = ùëîùëò for each ùëò = 1, ‚Ä¶, ùëõ. To show that ùëÜ is an isometry, suppose ùë£ ‚àà ùëâ. Then 7.46 ùë£ = ‚ü®ùë£, ùëí1‚ü©ùëí1 + ‚ãØ + ‚ü®ùë£, ùëíùëõ‚ü©ùëíùëõ and 7.47 ‚Äñùë£‚Äñ 2 = ‚à£‚ü®ùë£, ùëí1‚ü©‚à£2 + ‚ãØ + ‚à£‚ü®ùë£, ùëíùëõ‚ü©‚à£2, where we have used 6.30(b). Applying ùëÜ to both sides of 7.46 gives ùëÜùë£ = ‚ü®ùë£, ùëí1‚ü©ùëÜùëí1 + ‚ãØ + ‚ü®ùë£, ùëíùëõ‚ü©ùëÜùëíùëõ = ‚ü®ùë£, ùëí1‚ü©ùëî1 + ‚ãØ + ‚ü®ùë£, ùëíùëõ‚ü©ùëîùëõ. Thus 7.48 ‚ÄñùëÜùë£‚Äñ 2 = ‚à£‚ü®ùë£, ùëí1‚ü©‚à£2 + ‚ãØ + |‚ü®ùë£, ùëíùëõ‚ü©| 2. Comparing 7.47 and 7.48 shows that ‚Äñùë£‚Äñ = ‚ÄñùëÜùë£‚Äñ. Thus ùëÜ is an isometry. The next result gives conditions equivalent to being an isometry. The equiv- alence of (a) and (c) shows that a linear map is an isometry if and only if it preserves inner products. The equivalence of (a) and (d) shows that a linear map is an isometry if and only if it maps some orthonormal basis to an orthonormal list. Thus the isometries given by Example 7.45 include all isometries. Furthermore, a linear map is an isometry if and only if it maps every orthonormal basis to an orthonormal list [because whether or not (a) holds does not depend on the basis ùëí1, ‚Ä¶, ùëíùëõ]. Section 7D Isometries, Unitary Operators, and Matrix Factorization 259 The equivalence of (a) and (e) in the next result shows that a linear map is an isometry if and only if the columns of its matrix (with respect to any orthonormal bases) form an orthonormal list. Here we are identifying the columns of an ùëö-by-ùëõ matrix with elements of ùêÖùëö and then using the Euclidean inner product on ùêÖùëö. 7.49 characterization of isometries Suppose ùëÜ ‚àà ‚Ñí(ùëâ, ùëä). Suppose ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ and ùëì1, ‚Ä¶, ùëìùëö is an orthonormal basis of ùëä. Then the following are equivalent. (a) ùëÜ is an isometry. (b) ùëÜ‚àóùëÜ = ùêº. (c) ‚ü®ùëÜùë¢, ùëÜùë£‚ü© = ‚ü®ùë¢, ùë£‚ü©for all ùë¢, ùë£ ‚àà ùëâ. (d) ùëÜùëí1, ‚Ä¶, ùëÜùëíùëõ is an orthonormal list in ùëä. (e) The columns of ‚Ñ≥(ùëÜ, (ùëí1, ‚Ä¶, ùëíùëõ), ( ùëì1, ‚Ä¶, ùëìùëö))form an orthonormal list in ùêÖùëö with respect to the Euclidean inner product. Proof First suppose (a) holds, so ùëÜ is an isometry. If ùë£ ‚àà ùëâ then ‚ü®(ùêº ‚àí ùëÜ‚àóùëÜ)ùë£, ùë£‚ü©= ‚ü®ùë£, ùë£‚ü© ‚àí‚ü®ùëÜ‚àóùëÜùë£, ùë£‚ü©= ‚Äñùë£‚Äñ2 ‚àí ‚ü®ùëÜùë£, ùëÜùë£‚ü© = ‚Äñùë£‚Äñ 2 ‚àí ‚ÄñùëÜùë£‚Äñ2 = 0. Hence the self-adjoint operator ùêº ‚àí ùëÜ‚àóùëÜ equals 0(by 7.16). Thus ùëÜ‚àóùëÜ = ùêº, proving that (a) implies (b). Now suppose (b) holds, so ùëÜ‚àóùëÜ = ùêº. If ùë¢, ùë£ ‚àà ùëâ then ‚ü®ùëÜùë¢, ùëÜùë£‚ü© =‚ü®ùëÜ‚àóùëÜùë¢, ùë£‚ü©= ‚ü®ùêºùë¢, ùë£‚ü© = ‚ü®ùë¢, ùë£‚ü©, proving that (b) implies (c). Now suppose that (c) holds, so ‚ü®ùëÜùë¢, ùëÜùë£‚ü© = ‚ü®ùë¢, ùë£‚ü©for all ùë¢, ùë£ ‚àà ùëâ. Thus if ùëó, ùëò ‚àà {1, ‚Ä¶, ùëõ}, then ‚ü®ùëÜùëíùëó, ùëÜùëíùëò‚ü© = ‚ü®ùëíùëó, ùëíùëò‚ü©. Hence ùëÜùëí1, ‚Ä¶, ùëÜùëíùëõ is an orthonormal list in ùëä, proving that (c) implies (d). Now suppose that (d) holds, so ùëÜùëí1, ‚Ä¶, ùëÜùëíùëõ is an orthonormal list in ùëä. Let ùê¥ = ‚Ñ≥(ùëÜ, (ùëí1, ‚Ä¶, ùëíùëõ), ( ùëì1, ‚Ä¶, ùëìùëö)). If ùëò, ùëü ‚àà {1, ‚Ä¶, ùëõ}, then 7.50 ùëö ‚àë ùëó = 1 ùê¥ùëó, ùëòùê¥ùëó, ùëü = ‚ü® ùëö ‚àë ùëó = 1 ùê¥ùëó, ùëò ùëìùëó, ùëö ‚àë ùëó = 1 ùê¥ùëó, ùëü ùëìùëó‚ü©= ‚ü®ùëÜùëíùëò, ùëÜùëíùëü‚ü© = ‚éß{ ‚é®{‚é© 1 if ùëò = ùëü, 0 if ùëò ‚â† ùëü. The left side of 7.50 is the inner product in ùêÖùëö of columns ùëò and ùëü of ùê¥. Thus the columns of ùê¥ form an orthonormal list in ùêÖùëö, proving that (d) implies (e). Now suppose (e) holds, so the columns of the matrix ùê¥ defined in the paragraph above form an orthonormal list in ùêÖùëõ. Then 7.50 shows that ùëÜùëí1, ‚Ä¶, ùëÜùëíùëõ is an orthonormal list in ùëä. Thus Example 7.45, with ùëÜùëí1, ‚Ä¶, ùëÜùëíùëõ playing the role of ùëî1, ‚Ä¶, ùëîùëõ, shows that ùëÜ is an isometry, proving that (e) implies (a). See Exercises 1 and 11 for additional conditions that are equivalent to being an isometry. 260 Chapter 7 Operators on Inner Product Spaces Unitary Operators In this subsection, we confine our attention to linear maps from a vector space to itself. In other words, we will be working with operators. 7.51 definition:unitary operator An operator ùëÜ ‚àà ‚Ñí(ùëâ) is called unitary if ùëÜ is an invertible isometry. Although the words ‚Äúunitary‚Äù and ‚Äúisometry‚Äù mean the same thing for operators on finite-dimensional inner product spaces, remember that a uni- tary operator maps a vector space to itself, while an isometry maps a vector space to another (possibly different) vector space. As previously noted, every isometry is injective. Every injective operator on a finite-dimensional vector space is in- vertible (see 3.65). A standing assump- tion for this chapter is that ùëâ is a finite- dimensional inner product space. Thus we could delete the word ‚Äúinvertible‚Äù from the definition above without chang- ing the meaning. The unnecessary word ‚Äúinvertible‚Äù has been retained in the definition above for consistency with the definition readers may encounter when learning about inner product spaces that are not necessarily finite-dimensional. 7.52 example:rotation of ùêë2 Suppose ùúÉ ‚àà ùêë and ùëÜ is the operator on ùêÖ2 whose matrix with respect to the standard basis of ùêÖ2 is ( cos ùúÉ ‚àí sin ùúÉ sin ùúÉ cos ùúÉ ). The two columns of this matrix form an orthonormal list in ùêÖ2; hence ùëÜ is an isometry [by the equivalence of (a) and (e) in 7.49]. Thus ùëÜ is a unitary operator. If ùêÖ = ùêë, then ùëÜ is the operator of counterclockwise rotation by ùúÉ radians around the origin of ùêë2. This observation gives us another way to think about why ùëÜ is an isometry, because each rotation around the origin of ùêë2 preserves norms. The next result (7.53) lists several conditions that are equivalent to being a unitary operator. All the conditions equivalent to being an isometry in 7.49 should be added to this list. The extra conditions in 7.53 arise because of limiting the context to linear maps from a vector space to itself. For example, 7.49 shows that a linear map ùëÜ ‚àà ‚Ñí(ùëâ, ùëä) is an isometry if and only if ùëÜ‚àóùëÜ = ùêº, while 7.53 shows that an operator ùëÜ ‚àà ‚Ñí(ùëâ) is a unitary operator if and only if ùëÜ‚àóùëÜ = ùëÜùëÜ‚àó = ùêº. Another difference is that 7.49(d) mentions an orthonormal list, while 7.53(d) mentions an orthonormal basis. Also, 7.49(e) mentions the columns of ‚Ñ≥(ùëá), while 7.53(e) mentions the rows of ‚Ñ≥(ùëá). Furthermore, ‚Ñ≥(ùëá) in 7.49(e) is with respect to an orthonormal basis of ùëâ and an orthonormal basis of ùëä, while ‚Ñ≥(ùëá) in 7.53(e) is with respect to a single basis of ùëâ doing double duty. Section 7D Isometries, Unitary Operators, and Matrix Factorization 261 7.53 characterization of unitary operators Suppose ùëÜ ‚àà ‚Ñí(ùëâ). Suppose ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ. Then the following are equivalent. (a) ùëÜ is a unitary operator. (b) ùëÜ‚àóùëÜ = ùëÜùëÜ‚àó = ùêº. (c) ùëÜ is invertible and ùëÜ ‚àí1 = ùëÜ‚àó. (d) ùëÜùëí1, ‚Ä¶, ùëÜùëíùëõ is an orthonormal basis of ùëâ. (e) The rows of ‚Ñ≥(ùëÜ, (ùëí1, ‚Ä¶, ùëíùëõ))form an orthonormal basis of ùêÖùëõ with respect to the Euclidean inner product. (f) ùëÜ‚àó is a unitary operator. Proof First suppose (a) holds, so ùëÜ is a unitary operator. Hence ùëÜ‚àóùëÜ = ùêº by the equivalence of (a) and (b) in 7.49. Multiply both sides of this equation by ùëÜ ‚àí1 on the right, getting ùëÜ‚àó = ùëÜ‚àí1. Thus ùëÜùëÜ‚àó = ùëÜùëÜ‚àí1 = ùêº, as desired, proving that (a) implies (b). The definitions of invertible and inverse show that (b) implies (c). Now suppose (c) holds, so ùëÜ is invertible and ùëÜ‚àí1 = ùëÜ‚àó. Thus ùëÜ‚àóùëÜ = ùêº. Hence ùëÜùëí1, ‚Ä¶, ùëÜùëíùëõ is an orthonormal list in ùëâ, by the equivalence of (b) and (d) in 7.49. The length of this list equals dim ùëâ. Thus ùëÜùëí1, ‚Ä¶, ùëÜùëíùëõ is an orthonormal basis of ùëâ, proving that (c) implies (d). Now suppose (d) holds, so ùëÜùëí1, ‚Ä¶, ùëÜùëíùëõ is an orthonormal basis of ùëâ. The equivalence of (a) and (d) in 7.49 shows that ùëÜ is a unitary operator. Thus (ùëÜ‚àó) ‚àóùëÜ‚àó = ùëÜùëÜ‚àó = ùêº, where the last equation holds because we have already shown that (a) implies (b) in this result. The equation above and the equivalence of (a) and (b) in 7.49 show that ùëÜ‚àó is an isometry. Thus the columns of ‚Ñ≥(ùëÜ‚àó, (ùëí1, ‚Ä¶, ùëíùëõ))form an orthonormal ba- sis of ùêÖùëõ [by the equivalence of (a) and (e) of 7.49]. The rows of ‚Ñ≥(ùëÜ, (ùëí1, ‚Ä¶, ùëíùëõ)) are the complex conjugates of the columns of ‚Ñ≥(ùëÜ‚àó, (ùëí1, ‚Ä¶, ùëíùëõ)). Thus the rows of ‚Ñ≥(ùëÜ, (ùëí1, ‚Ä¶, ùëíùëõ))form an orthonormal basis of ùêÖùëõ, proving that (d) implies (e). Now suppose (e) holds. Thus the columns of ‚Ñ≥(ùëÜ‚àó, (ùëí1, ‚Ä¶, ùëíùëõ))form an orthonormal basis of ùêÖùëõ. The equivalence of (a) and (e) in 7.49 shows that ùëÜ‚àó is an isometry, proving that (e) implies (f). Now suppose (f) holds, so ùëÜ‚àó is a unitary operator. The chain of implications we have already proved in this result shows that (a) implies (f). Applying this result to ùëÜ‚àó shows that (ùëÜ‚àó) ‚àó is a unitary operator, proving that (f) implies (a). We have shown that (a) ‚áí (b) ‚áí (c) ‚áí (d) ‚áí (e) ‚áí (f) ‚áí (a), completing the proof. 262 Chapter 7 Operators on Inner Product Spaces Recall our analogy between ùêÇ and ‚Ñí(ùëâ). Under this analogy, a complex number ùëß corresponds to an operator ùëÜ ‚àà ‚Ñí(ùëâ), and ùëß corresponds to ùëÜ‚àó. The real numbers (ùëß = ùëß)correspond to the self-adjoint operators (ùëÜ = ùëÜ‚àó), and the nonnegative numbers correspond to the (badly named) positive operators. Another distinguished subset of ùêÇ is the unit circle, which consists of the complex numbers ùëß such that |ùëß| = 1. The condition |ùëß| = 1is equivalent to the condition ùëßùëß = 1. Under our analogy, this corresponds to the condition ùëÜ‚àóùëÜ = ùêº, which is equivalent to ùëÜ being a unitary operator. Hence the analogy shows that the unit circle in ùêÇ corresponds to the set of unitary operators. In the next two results, this analogy appears in the eigenvalues of unitary operators. Also see Exercise 15 for another example of this analogy. 7.54 eigenvalues of unitary operators have absolute value 1 Suppose ùúÜ is an eigenvalue of a unitary operator. Then |ùúÜ| = 1. Proof Suppose ùëÜ ‚àà ‚Ñí(ùëâ) is a unitary operator and ùúÜ is an eigenvalue of ùëÜ. Let ùë£ ‚àà ùëâ be such that ùë£ ‚â† 0and ùëÜùë£ = ùúÜùë£. Then |ùúÜ| ‚Äñùë£‚Äñ = ‚ÄñùúÜùë£‚Äñ = ‚ÄñùëÜùë£‚Äñ = ‚Äñùë£‚Äñ. Thus |ùúÜ| = 1, as desired. The next result characterizes unitary operators on finite-dimensional complex inner product spaces, using the complex spectral theorem as the main tool. 7.55 description of unitary operators on complex inner product spaces Suppose ùêÖ = ùêÇ and ùëÜ ‚àà ‚Ñí(ùëâ). Then the following are equivalent. (a) ùëÜ is a unitary operator. (b) There is an orthonormal basis of ùëâ consisting of eigenvectors of ùëÜ whose corresponding eigenvalues all have absolute value 1. Proof Suppose (a) holds, so ùëÜ is a unitary operator. The equivalence of (a) and (b) in 7.53 shows that ùëÜ is normal. Thus the complex spectral theorem (7.31) shows that there is an orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ consisting of eigenvectors of ùëÜ. Every eigenvalue of ùëÜ has absolute value 1(by 7.54), completing the proof that (a) implies (b). Now suppose (b) holds. Let ùëí1, ‚Ä¶, ùëíùëõ be an orthonormal basis of ùëâ consisting of eigenvectors of ùëÜ whose corresponding eigenvalues ùúÜ1, ‚Ä¶, ùúÜùëõ all have absolute value 1. Then ùëÜùëí1, ‚Ä¶, ùëÜùëíùëõ is also an orthonormal basis of ùëâ because ‚ü®ùëÜùëíùëó, ùëÜùëíùëò‚ü© = ‚ü®ùúÜùëóùëíùëó, ùúÜùëòùëíùëò‚ü© = ùúÜùëó ùúÜùëò‚ü®ùëíùëó, ùëíùëò‚ü© = ‚éß{ ‚é®{‚é© 0 if ùëó ‚â† ùëò, 1 if ùëó = ùëò for all ùëó, ùëò = 1, ‚Ä¶, ùëõ. Thus the equivalence of (a) and (d) in 7.53 shows that ùëÜ is unitary, proving that (b) implies (a). Section 7D Isometries, Unitary Operators, and Matrix Factorization 263 QR Factorization In this subsection, we shift our attention from operators to matrices. This switch should give you good practice in identifying an operator with a square matrix (after picking a basis of the vector space on which the operator is defined). You should also become more comfortable with translating concepts and results back and forth between the context of operators and the context of square matrices. When starting with ùëõ-by-ùëõ matrices instead of operators, unless otherwise specified assume that the associated operators live onùêÖùëõ (with the Euclidean inner product) and that their matrices are computed with respect to the standard basis of ùêÖùëõ. We begin by making the following definition, transferring the notion of a unitary operator to a unitary matrix. 7.56 definition:unitary matrix An ùëõ-by-ùëõ matrix is called unitary if its columns form an orthonormal list in ùêÖùëõ. In the definition above, we could have replaced ‚Äúorthonormal list inùêÖùëõ‚Äù with ‚Äúorthonormal basis ofùêÖùëõ‚Äù because every orthonormal list of lengthùëõ in an ùëõ- dimensional inner product space is an orthonormal basis. If ùëÜ ‚àà ‚Ñí(ùëâ) and ùëí1, ‚Ä¶, ùëíùëõ and ùëì1, ‚Ä¶, ùëìùëõ are orthonormal bases of ùëâ, then ùëÜ is a unitary operator if and only if ‚Ñ≥(ùëÜ, (ùëí1, ‚Ä¶, ùëíùëõ), ( ùëì1, ‚Ä¶, ùëìùëõ))is a unitary matrix, as shown by the equivalence of (a) and (e) in 7.49. Also note that we could also have replaced ‚Äúcolumns‚Äù in the definition above with ‚Äúrows‚Äù by using the equivalence between conditions (a) and (e) in 7.53. The next result, whose proof will be left as an exercise for the reader, gives some equivalent conditions for a square matrix to be unitary. In (c), ùëÑùë£ denotes the matrix product of ùëÑ and ùë£, identifying elements of ùêÖùëõ with ùëõ-by-1matrices (sometimes called column vectors). The norm in (c) below is the usual Euclidean norm on ùêÖùëõ that comes from the Euclidean inner product. In (d), ùëÑ‚àó denotes the conjugate transpose of the matrix ùëÑ, which corresponds to the adjoint of the associated operator. 7.57 characterizations of unitary matrices Suppose ùëÑ is an ùëõ-by-ùëõ matrix. Then the following are equivalent. (a) ùëÑ is a unitary matrix. (b) The rows of ùëÑ form an orthonormal list in ùêÖùëõ. (c) ‚ÄñùëÑùë£‚Äñ = ‚Äñùë£‚Äñ for every ùë£ ‚àà ùêÖùëõ. (d) ùëÑ‚àóùëÑ = ùëÑùëÑ‚àó = ùêº, the ùëõ-by-ùëõ matrix with 1‚Äôs on the diagonal and 0‚Äôs elsewhere. 264 Chapter 7 Operators on Inner Product Spaces The QR factorization stated and proved below is the main tool in the widely used QR algorithm (not discussed here) for finding good approximations to eigenvalues and eigenvectors of square matrices. In the result below, if the matrix ùê¥ is in ùêÖùëõ, ùëõ, then the matrices ùëÑ and ùëÖ are also in ùêÖùëõ, ùëõ. 7.58 QR factorization Suppose ùê¥ is a square matrix with linearly independent columns. Then there exist unique matrices ùëÑ and ùëÖ such that ùëÑ is unitary, ùëÖ is upper triangular with only positive numbers on its diagonal, and ùê¥ = ùëÑùëÖ. Proof Let ùë£1, ‚Ä¶, ùë£ùëõ denote the columns of ùê¥, thought of as elements of ùêÖùëõ. Apply the Gram‚ÄìSchmidt procedure (6.32) to the list ùë£1, ‚Ä¶, ùë£ùëõ, getting an orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùêÖùëõ such that 7.59 span(ùë£1, ‚Ä¶, ùë£ùëò) = span(ùëí1, ‚Ä¶, ùëíùëò) for each ùëò = 1, ‚Ä¶, ùëõ. Let ùëÖ be the ùëõ-by-ùëõ matrix defined by ùëÖùëó, ùëò = ‚ü®ùë£ùëò, ùëíùëó‚ü©, where ùëÖùëó, ùëò denotes the entry in row ùëó, column ùëò of ùëÖ. If ùëó > ùëò, then ùëíùëó is orthogonal to span(ùëí1, ‚Ä¶, ùëíùëò) and hence ùëíùëó is orthogonal to ùë£ùëò (by 7.59). In other words, if ùëó > ùëò then ‚ü®ùë£ùëò, ùëíùëó‚ü© = 0. Thus ùëÖ is an upper-triangular matrix. Let ùëÑ be the unitary matrix whose columns are ùëí1, ‚Ä¶, ùëíùëõ. If ùëò ‚àà {1, ‚Ä¶, ùëõ}, then the ùëòth column of ùëÑùëÖ equals a linear combination of the columns of ùëÑ, with the coefficients for the linear combination coming from the ùëòth column of ùëÖ‚Äîsee 3.51(a). Hence the ùëòth column of ùëÑùëÖ equals ‚ü®ùë£ùëò, ùëí1‚ü©ùëí1 + ‚ãØ + ‚ü®ùë£ùëò, ùëíùëò‚ü©ùëíùëò, which equals ùë£ùëò [by 6.30(a)], the ùëòth column of ùê¥. Thus ùê¥ = ùëÑùëÖ, as desired. The equations defining the Gram‚ÄìSchmidt procedure (see6.32) show that each ùë£ùëò equals a positive multiple of ùëíùëò plus a linear combination of ùëí1, ‚Ä¶, ùëíùëò ‚àí 1. Thus each ‚ü®ùë£ùëò, ùëíùëò‚ü©is a positive number. Hence all entries on the diagonal of ùëÖ are positive numbers, as desired. Finally, to show that ùëÑ and ùëÖ are unique, suppose we also have ùê¥ = ÃÇùëÑ ÃÇùëÖ, where ÃÇùëÑ is unitary and ÃÇùëÖ is upper triangular with only positive numbers on its diagonal. Let ùëû1, ‚Ä¶, ùëûùëõ denote the columns of ÃÇùëÑ. Thinking of matrix multiplication as above, we see that each ùë£ùëò is a linear combination of ùëû1, ‚Ä¶, ùëûùëò, with the coefficients coming from the ùëòth column of ÃÇùëÖ. This implies that span(ùë£1, ‚Ä¶, ùë£ùëò) = span(ùëû1, ‚Ä¶, ùëûùëò) and ‚ü®ùë£ùëò, ùëûùëò‚ü© > 0. The uniqueness of the orthonormal lists satisfying these conditions (see Exercise 10 in Section 6B) now shows that ùëûùëò = ùëíùëò for each ùëò = 1, ‚Ä¶, ùëõ. Hence ÃÇùëÑ = ùëÑ, which then implies that ÃÇùëÖ = ùëÖ, completing the proof of uniqueness. Section 7D Isometries, Unitary Operators, and Matrix Factorization 265 The proof of the QR factorization shows that the columns of the unitary matrix can be computed by applying the Gram‚ÄìSchmidt procedure to the columns of the matrix to be factored. The next example illustrates the computation of the QR factorization based on the proof that we just completed. 7.60 example:QR factorization of a 3-by-3matrix To find the QR factorization of the matrix ùê¥ = ‚éõ‚éú‚éú‚éú ‚éù 1 2 1 0 1 ‚àí4 0 3 2 ‚éû‚éü‚éü‚éü ‚é† , follow the proof of 7.58. Thus set ùë£1, ùë£2, ùë£3 equal to the columns of ùê¥: ùë£1 = (1, 0, 0), ùë£2 = (2, 1, 3), ùë£3 = (1, ‚àí4, 2). Apply the Gram‚ÄìSchmidt procedure to ùë£1, ùë£2, ùë£3, producing the orthonormal list ùëí1 = (1, 0, 0), ùëí2 = (0, 1 ‚àö10 , 3 ‚àö10 ), ùëí3 = (0, ‚àí 3 ‚àö10 , 1 ‚àö10 ). Still following the proof of 7.58, let ùëÑ be the unitary matrix whose columns are ùëí1, ùëí2, ùëí3: ùëÑ = ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 1 0 0 0 1 ‚àö10 ‚àí 3 ‚àö10 0 3 ‚àö10 1 ‚àö10 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . As in the proof of 7.58, let ùëÖ be the 3-by-3matrix whose entry in row ùëó, column ùëò is ‚ü®ùë£ùëò, ùëíùëó‚ü©, which gives ùëÖ = ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 1 2 1 0 ‚àö10 ‚àö10 5 0 0 7‚àö10 5 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . Note that ùëÖ is indeed an upper-triangular matrix with only positive numbers on the diagonal, as required by the QR factorization. Now matrix multiplication can verify that ùê¥ = ùëÑùëÖ is the desired factorization of ùê¥: ùëÑùëÖ = ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 1 0 0 0 1 ‚àö10 ‚àí 3 ‚àö10 0 3 ‚àö10 1 ‚àö10 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü ‚é† ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 1 2 1 0 ‚àö10 ‚àö10 5 0 0 7‚àö10 5 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü ‚é† = ‚éõ‚éú‚éú‚éú ‚éù 1 2 1 0 1 ‚àí4 0 3 2 ‚éû‚éü‚éü‚éü ‚é† = ùê¥. Thus ùê¥ = ùëÑùëÖ, as expected. The QR factorization will be the major tool used in the proof of the Cholesky factorization (7.63) in the next subsection. For another nice application of the QR factorization, see the proof of Hadamard‚Äôs inequality (9.66). 266 Chapter 7 Operators on Inner Product Spaces If a QR factorization is available, then it can be used to solve a corresponding system of linear equations without using Gaussian elimination. Specifically, suppose ùê¥ is an ùëõ-by-ùëõ square matrix with linearly independent columns. Suppose that ùëè ‚àà ùêÖùëõ and we want to solve the equation ùê¥ùë• = ùëè for ùë• = (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêÖùëõ (as usual, we are identifying elements of ùêÖùëõ with ùëõ-by-1column vectors). Suppose ùê¥ = ùëÑùëÖ, where ùëÑ is unitary and ùëÖ is upper triangular with only positive numbers on its diagonal (ùëÑ and ùëÖ are computable from ùê¥ using just the Gram‚ÄìSchmidt procedure, as shown in the proof of 7.58). The equation ùê¥ùë• = ùëè is equivalent to the equation ùëÑùëÖùë• = ùëè. Multiplying both sides of this last equation by ùëÑ‚àó on the left and using 7.57(d) gives the equation ùëÖùë• = ùëÑ‚àóùëè. The matrix ùëÑ‚àó is the conjugate transpose of the matrix ùëÑ. Thus computing ùëÑ‚àóùëè is straightforward. Because ùëÖ is an upper-triangular matrix with positive numbers on its diagonal, the system of linear equations represented by the equation above can quickly be solved by first solving forùë•ùëõ, then for ùë•ùëõ ‚àí 1, and so on. Cholesky Factorization We begin this subsection with a characterization of positive invertible operators in terms of inner products. 7.61 positive invertible operator A self-adjoint operator ùëá ‚àà ‚Ñí(ùëâ) is a positive invertible operator if and only if ‚ü®ùëáùë£, ùë£‚ü© > 0for every nonzero ùë£ ‚àà ùëâ. Proof First suppose ùëá is a positive invertible operator. If ùë£ ‚àà ùëâ and ùë£ ‚â† 0, then because ùëá is invertible we have ùëáùë£ ‚â† 0. This implies that ‚ü®ùëáùë£, ùë£‚ü© ‚â† 0(by 7.43). Hence ‚ü®ùëáùë£, ùë£‚ü© > 0. To prove the implication in the other direction, suppose now that ‚ü®ùëáùë£, ùë£‚ü© > 0 for every nonzero ùë£ ‚àà ùëâ. Thus ùëáùë£ ‚â† 0for every nonzero ùë£ ‚àà ùëâ. Hence ùëá is injective. Thus ùëá is invertible, as desired. The next definition transfers the result above to the language of matrices. Here we are using the usual Euclidean inner product on ùêÖùëõ and identifying elements of ùêÖùëõ with ùëõ-by-1column vectors. 7.62 definition:positive definite A matrix ùêµ ‚àà ùêÖùëõ, ùëõ is called positive definite if ùêµ‚àó = ùêµ and ‚ü®ùêµùë•, ùë•‚ü© > 0 for every nonzero ùë• ‚àà ùêÖùëõ. Section 7D Isometries, Unitary Operators, and Matrix Factorization 267 A matrix is upper triangular if and only if its conjugate transpose is lower triangular (meaning that all entries above the diagonal are 0). The factorization below, which has important consequences in computational linear algebra, writes a positive definite matrix as the product of a lower triangular matrix and its conjugate transpose. Our next result is solely about matrices, although the proof makes use of the identification of results about operators with results about square matrices. In the result below, if the matrix ùêµ is in ùêÖùëõ, ùëõ, then the matrix ùëÖ is also in ùêÖùëõ, ùëõ. 7.63 Cholesky factorization Suppose ùêµ is a positive definite matrix. Then there exists a unique upper- triangular matrix ùëÖ with only positive numbers on its diagonal such that ùêµ = ùëÖ‚àóùëÖ. Proof Because ùêµ is positive definite, there exists an invertible square matrixùê¥ of the same size as ùêµ such that ùêµ = ùê¥‚àóùê¥ [by the equivalence of (a) and (f) in 7.38]. Let ùê¥ = ùëÑùëÖ be the QR factorization of ùê¥ (see 7.58), where ùëÑ is unitary and ùëÖ is upper triangular with only positive numbers on its diagonal. Then ùê¥‚àó = ùëÖ‚àóùëÑ‚àó. Andr√©-Louis Cholesky (1875‚Äì1918) discovered this factorization, which was published posthumously in 1924. Thus ùêµ = ùê¥‚àóùê¥ = ùëÖ‚àóùëÑ‚àóùëÑùëÖ = ùëÖ‚àóùëÖ, as desired. To prove the uniqueness part of this result, suppose ùëÜ is an upper-triangular matrix with only positive numbers on its diagonal and ùêµ = ùëÜ‚àóùëÜ. The matrix ùëÜ is invertible because ùêµ is invertible (see Exercise 11 in Section 3D). Multiplying both sides of the equation ùêµ = ùëÜ‚àóùëÜ by ùëÜ ‚àí1 on the left gives the equation ùêµùëÜ ‚àí1 = ùëÜ‚àó. Let ùê¥ be the matrix from the first paragraph of this proof. Then (ùê¥ùëÜ ‚àí1) ‚àó(ùê¥ùëÜ ‚àí1)= (ùëÜ‚àó) ‚àí1ùê¥‚àóùê¥ùëÜ ‚àí1 = (ùëÜ‚àó) ‚àí1ùêµùëÜ ‚àí1 = (ùëÜ‚àó) ‚àí1ùëÜ‚àó = ùêº. Thus ùê¥ùëÜ‚àí1 is unitary. Hence ùê¥ = (ùê¥ùëÜ‚àí1)ùëÜ is a factorization of ùê¥ as the product of a unitary matrix and an upper-triangular matrix with only positive numbers on its diagonal. The uniqueness of the QR factorization, as stated in 7.58, now implies that ùëÜ = ùëÖ. In the first paragraph of the proof above, we could have chosenùê¥ to be the unique positive definite matrix that is a square root ofùêµ (see 7.39). However, the proof was presented with the more general choice of ùê¥ because for specific positive definite matricesùêµ, it may be easier to find a different choice ofùê¥. 268 Chapter 7 Operators on Inner Product Spaces Exercises 7D 1 Suppose dim ùëâ ‚â• 2and ùëÜ ‚àà ‚Ñí(ùëâ, ùëä). Prove that ùëÜ is an isometry if and only if ùëÜùëí1, ùëÜùëí2 is an orthonormal list in ùëä for every orthonormal list ùëí1, ùëí2 of length two in ùëâ. 2 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that ùëá is a scalar multiple of an isometry if and only if ùëá preserves orthogonality. The phrase ‚Äúùëá preserves orthogonality‚Äù means that‚ü®ùëáùë¢, ùëáùë£‚ü© = 0for all ùë¢, ùë£ ‚àà ùëâ such that ‚ü®ùë¢, ùë£‚ü© = 0. 3 (a) Show that the product of two unitary operators on ùëâ is a unitary operator. (b) Show that the inverse of a unitary operator on ùëâ is a unitary operator. This exercise shows that the set of unitary operators on ùëâ is a group, where the group operation is the usual product of two operators. 4 Suppose ùêÖ = ùêÇ and ùê¥, ùêµ ‚àà ‚Ñí(ùëâ) are self-adjoint. Show that ùê¥ + ùëñùêµ is unitary if and only if ùê¥ùêµ = ùêµùê¥ and ùê¥ 2 + ùêµ 2 = ùêº. 5 Suppose ùëÜ ‚àà ‚Ñí(ùëâ). Prove that the following are equivalent. (a) ùëÜ is a self-adjoint unitary operator. (b) ùëÜ = 2ùëÉ ‚àí ùêºfor some orthogonal projection ùëÉ on ùëâ. (c) There exists a subspace ùëà of ùëâ such that ùëÜùë¢ = ùë¢ for every ùë¢ ‚àà ùëà and ùëÜùë§ = ‚àíùë§ for every ùë§ ‚àà ùëà‚üÇ. 6 Suppose ùëá1, ùëá2 are both normal operators on ùêÖ3 with 2, 5, 7as eigenvalues. Prove that there exists a unitary operator ùëÜ ‚àà ‚Ñí(ùêÖ3)such that ùëá1 = ùëÜ‚àóùëá2ùëÜ. 7 Give an example of two self-adjoint operators ùëá1, ùëá2 ‚àà ‚Ñí(ùêÖ4)such that the eigenvalues of both operators are 2, 5, 7but there does not exist a unitary operator ùëÜ ‚àà ‚Ñí(ùêÖ4)such that ùëá1 = ùëÜ‚àóùëá2ùëÜ. Be sure to explain why there is no unitary operator with the required property. 8 Prove or give a counterexample: If ùëÜ ‚àà ‚Ñí(ùëâ) and there exists an orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ such that ‚ÄñùëÜùëíùëò‚Äñ = 1for each ùëíùëò, then ùëÜ is a unitary operator. 9 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Suppose every eigenvalue of ùëá has absolute value 1 and ‚Äñùëáùë£‚Äñ ‚â§ ‚Äñùë£‚Äñfor every ùë£ ‚àà ùëâ. Prove that ùëá is a unitary operator. 10 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ) is a self-adjoint operator such that ‚Äñùëáùë£‚Äñ ‚â§ ‚Äñùë£‚Äñ for all ùë£ ‚àà ùëâ. (a) Show that ùêº ‚àí ùëá2 is a positive operator. (b) Show that ùëá + ùëñ‚àöùêº ‚àí ùëá2 is a unitary operator. 11 Suppose ùëÜ ‚àà ‚Ñí(ùëâ). Prove that ùëÜ is a unitary operator if and only if {ùëÜùë£ ‚à∂ ùë£ ‚àà ùëâ and ‚Äñùë£‚Äñ ‚â§ 1}= {ùë£ ‚àà ùëâ ‚à∂ ‚Äñùë£‚Äñ ‚â§ 1}. 12 Prove or give a counterexample: If ùëÜ ‚àà ‚Ñí(ùëâ) is invertible and ‚à•ùëÜ ‚àí1ùë£‚à• = ‚ÄñùëÜùë£‚Äñ for every ùë£ ‚àà ùëâ, then ùëÜ is unitary. Section 7D Isometries, Unitary Operators, and Matrix Factorization 269 13 Explain why the columns of a square matrix of complex numbers form an orthonormal list in ùêÇ ùëõ if and only if the rows of the matrix form an orthonormal list in ùêÇ ùëõ. 14 Suppose ùë£ ‚àà ùëâ with ‚Äñùë£‚Äñ = 1and ùëè ‚àà ùêÖ. Also suppose dim ùëâ ‚â• 2. Prove that there exists a unitary operator ùëÜ ‚àà ‚Ñí(ùëâ) such that ‚ü®ùëÜùë£, ùë£‚ü© = ùëèif and only if |ùëè| ‚â§ 1. 15 Suppose ùëá is a unitary operator on ùëâ such that ùëá ‚àí ùêº is invertible. (a) Prove that (ùëá + ùêº)(ùëá ‚àí ùêº)‚àí1 is a skew operator (meaning that it equals the negative of its adjoint). (b) Prove that if ùêÖ = ùêÇ, then ùëñ(ùëá + ùêº)(ùëá ‚àí ùêº)‚àí1 is a self-adjoint operator. The function ùëß ‚Ü¶ ùëñ(ùëß + 1)(ùëß ‚àí 1) ‚àí1 maps the unit circle in ùêÇ (except for the point 1) to ùêë. Thus (b) illustrates the analogy between the unitary operators and the unit circle in ùêÇ, along with the analogy between the self-adjoint operators and ùêë. 16 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ) is self-adjoint. Prove that (ùëá + ùëñùêº)(ùëá ‚àí ùëñùêº)‚àí1 is a unitary operator and 1is not an eigenvalue of this operator. 17 Explain why the characterization of unitary matrices given by 7.57 holds. 18 A square matrix ùê¥ is called symmetric if it equals its transpose. Prove that if ùê¥ is a symmetric matrix with real entries, then there exists a unitary matrix ùëÑ with real entries such that ùëÑ‚àóùê¥ùëÑ is a diagonal matrix. 19 Suppose ùëõ is a positive integer. For this exercise, we adopt the notation that a typical element ùëß of ùêÇ ùëõ is denoted by ùëß = (ùëß0, ùëß1, ‚Ä¶, ùëßùëõ ‚àí 1). Define linear functionals ùúî0, ùúî1, ‚Ä¶, ùúîùëõ ‚àí 1 on ùêÇ ùëõ by ùúîùëó(ùëß0, ùëß1, ‚Ä¶, ùëßùëõ ‚àí 1) = 1 ‚àö ùëõ ùëõ ‚àí 1 ‚àë ùëö = 0 ùëßùëö ùëí‚àí2ùúãùëñùëóùëö/ùëõ. The discrete Fourier transform is the operator ‚Ñ±‚à∂ ùêÇ ùëõ ‚Üí ùêÇùëõ defined by ‚Ñ±ùëß = (ùúî0(ùëß), ùúî1(ùëß), ‚Ä¶, ùúîùëõ ‚àí 1(ùëß)). (a) Show that ‚Ñ± is a unitary operator on ùêÇ ùëõ. (b) Show that if (ùëß0, ‚Ä¶, ùëßùëõ ‚àí 1) ‚àà ùêÇùëõ and ùëßùëõ is defined to equalùëß0, then ‚Ñ±‚àí1(ùëß0, ùëß1, ‚Ä¶, ùëßùëõ ‚àí 1) = ‚Ñ±(ùëßùëõ, ùëßùëõ ‚àí 1, ‚Ä¶, ùëß1). (c) Show that ‚Ñ±4 = ùêº. The discrete Fourier transform has many important applications in data analysis. The usual Fourier transform involves expressions of the form ‚à´ ‚àû ‚àí‚àû ùëì (ùë•)ùëí‚àí2ùúãùëñùë°ùë•ùëëùë• for complex-valued integrable functions ùëì defined on ùêë. 20 Suppose ùê¥ is a square matrix with linearly independent columns. Prove that there exist unique matrices ùëÖ and ùëÑ such that ùëÖ is lower triangular with only positive numbers on its diagonal, ùëÑ is unitary, and ùê¥ = ùëÖùëÑ. 270 Chapter 7 Operators on Inner Product Spaces 7E Singular Value Decomposition Singular Values We will need the following result in this section. 7.64 properties of ùëá‚àóùëá Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then (a) ùëá‚àóùëá is a positive operator on ùëâ; (b) null ùëá‚àóùëá = null ùëá; (c) range ùëá‚àóùëá = range ùëá‚àó; (d) dim range ùëá = dim range ùëá‚àó = dim range ùëá‚àóùëá. Proof (a) We have (ùëá‚àóùëá) ‚àó = ùëá‚àó(ùëá‚àó) ‚àó = ùëá‚àóùëá. Thus ùëá‚àóùëá is self-adjoint. If ùë£ ‚àà ùëâ, then ‚ü®(ùëá‚àóùëá)ùë£, ùë£‚ü©= ‚ü®ùëá‚àó(ùëáùë£), ùë£‚ü©= ‚ü®ùëáùë£, ùëáùë£‚ü© = ‚Äñùëáùë£‚Äñ 2 ‚â• 0. Thus ùëá‚àóùëá is a positive operator. (b) First suppose ùë£ ‚àà null ùëá‚àóùëá. Then ‚Äñùëáùë£‚Äñ 2 = ‚ü®ùëáùë£, ùëáùë£‚ü© =‚ü®ùëá‚àóùëáùë£, ùë£‚ü©= ‚ü®0, ùë£‚ü© = 0. Thus ùëáùë£ = 0, proving that null ùëá‚àóùëá ‚äÜnull ùëá. The inclusion in the other direction is clear, because if ùë£ ‚àà ùëâ and ùëáùë£ = 0, then ùëá‚àóùëáùë£ = 0. Thus null ùëá‚àóùëá = null ùëá, completing the proof of (b). (c) We already know from (a) that ùëá‚àóùëá is self-adjoint. Thus range ùëá‚àóùëá = (null ùëá‚àóùëá) ‚üÇ = (null ùëá) ‚üÇ = range ùëá‚àó, where the first and last equalities come from7.6 and the second equality comes from (b). (d) To verify the first equation in (d), note that dim range ùëá = dim(null ùëá‚àó) ‚üÇ = dim ùëä ‚àí dim null ùëá‚àó = dim range ùëá‚àó, where the first equality comes from7.6(d), the second equality comes from 6.51, and the last equality comes from the fundamental theorem of linear maps (3.21). The equality dim range ùëá‚àó = dim range ùëá‚àóùëá follows from (c). Section 7E Singular Value Decomposition 271 The eigenvalues of an operator tell us something about the behavior of the operator. Another collection of numbers, called the singular values, is also useful. Eigenspaces and the notation ùê∏ (used in the examples) were defined in5.52. 7.65 definition:singular values Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). The singular values of ùëá are the nonnegative square roots of the eigenvalues of ùëá‚àóùëá, listed in decreasing order, each included as many times as the dimension of the corresponding eigenspace of ùëá‚àóùëá. 7.66 example:singular values of an operator on ùêÖ4 Defineùëá ‚àà ‚Ñí(ùêÖ4)by ùëá(ùëß1, ùëß2, ùëß3, ùëß4) = (0, 3ùëß1, 2ùëß2, ‚àí3ùëß4). A calculation shows that ùëá‚àóùëá(ùëß1, ùëß2, ùëß3, ùëß4) = (9ùëß1, 4ùëß2, 0, 9ùëß4), as you should verify. Thus the standard basis of ùêÖ4 diagonalizes ùëá‚àóùëá, and we see that the eigenvalues of ùëá‚àóùëá are 9, 4, and 0. Also, the dimensions of the eigenspaces corresponding to the eigenvalues are dim ùê∏(9, ùëá‚àóùëá)= 2 and dim ùê∏(4, ùëá‚àóùëá)= 1 and dim ùê∏(0, ùëá‚àóùëá)= 1. Taking nonnegative square roots of these eigenvalues of ùëá‚àóùëá and using dimension information from above, we conclude that the singular values of ùëá are 3, 3, 2, 0. The only eigenvalues of ùëá are ‚àí3and 0. Thus in this case, the collection of eigenvalues did not pick up the number 2that appears in the definition (and hence the behavior) of ùëá, but the list of singular values does include 2. 7.67 example:singular values of a linear map from ùêÖ4 to ùêÖ3 Suppose ùëá ‚àà ‚Ñí(ùêÖ4, ùêÖ3)has matrix (with respect to the standard bases) ‚éõ‚éú‚éú‚éú ‚éù 0 0 0 ‚àí5 0 0 0 0 1 1 0 0 ‚éû‚éü‚éü‚éü ‚é† . You can verify that the matrix of ùëá‚àóùëá is ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 25 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü ‚é† and that the eigenvalues of the operator ùëá‚àóùëá are 25, 2, 0, with dim ùê∏(25, ùëá‚àóùëá)= 1, dim ùê∏(2, ùëá‚àóùëá)= 1, and dim ùê∏(0, ùëá‚àóùëá)= 2. Thus the singular values of ùëá are 5, ‚àö2, 0, 0. See Exercise 2 for a characterization of the positive singular values. ‚âà 100 ùëí Chapter 7 Operators on Inner Product Spaces 7.68 role of positive singular values Suppose that ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then (a) ùëá is injective ‚ü∫ 0is not a singular value of ùëá; (b) the number of positive singular values of ùëá equals dim range ùëá; (c) ùëá is surjective ‚ü∫ number of positive singular values of ùëá equals dim ùëä. Proof The linear map ùëá is injective if and only if null ùëá = {0}, which happens if and only if null ùëá‚àóùëá = {0}[by 7.64(b)], which happens if and only if 0is not an eigenvalue of ùëá‚àóùëá, which happens if and only if 0is not a singular value of ùëá, completing the proof of (a). The spectral theorem applied to ùëá‚àóùëá shows that dim range ùëá‚àóùëá equals the num- ber of positive eigenvalues of ùëá‚àóùëá (counting repetitions). Thus 7.64(c) implies that dim range ùëá equals the number of positive singular values of ùëá, proving (b). Use (b) and 2.39 to show that (c) holds. The table below compares eigenvalues with singular values. list of eigenvalues list of singular values context: vector spaces context: inner product spaces defined only for linear maps from a vector space to itself defined for linear maps from an inner product space to a possibly different inner product space can be arbitrary real numbers (if ùêÖ = ùêë) or complex numbers (if ùêÖ = ùêÇ) are nonnegative numbers can be the empty list if ùêÖ = ùêë length of list equals dimension of domain includes 0 ‚ü∫operator is not invertible includes 0 ‚ü∫linear map is not injective no standard order, especially if ùêÖ = ùêÇ always listed in decreasing order The next result nicely characterizes isometries in terms of singular values. 7.69 isometries characterized by having all singular values equal 1 Suppose that ùëÜ ‚àà ‚Ñí(ùëâ, ùëä). Then ùëÜ is an isometry ‚ü∫ all singular values of ùëÜ equal 1. Proof We have ùëÜ is an isometry ‚ü∫ ùëÜ‚àóùëÜ = ùêº ‚ü∫ all eigenvalues of ùëÜ‚àóùëÜ equal 1 ‚ü∫ all singular values of ùëÜ equal 1, where the first equivalence comes from7.49 and the second equivalence comes from the spectral theorem (7.29 or 7.31) applied to the self-adjoint operator ùëÜ‚àóùëÜ. Section 7E Singular Value Decomposition 273 SVD for Linear Maps and for Matrices The singular value decomposition is useful in computational linear alge- bra because good techniques exist for approximating eigenvalues and eigen- vectors of positive operators such as ùëá‚àóùëá, whose eigenvalues and eigenvec- tors lead to the singular value decom- position. The next result shows that every linear map from ùëâ to ùëä has a remarkably clean description in terms of its singular val- ues and orthonormal lists in ùëâ and ùëä. In the next section we will see several important applications of the singular value decomposition (often called the SVD). 7.70 singular value decomposition Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and the positive singular values of ùëá are ùë†1, ‚Ä¶, ùë†ùëö. Then there exist orthonormal lists ùëí1, ‚Ä¶, ùëíùëö in ùëâ and ùëì1, ‚Ä¶, ùëìùëö in ùëä such that 7.71 ùëáùë£ = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü© ùëìùëö for every ùë£ ‚àà ùëâ. Proof Let ùë†1, ‚Ä¶, ùë†ùëõ denote the singular values of ùëá (thus ùëõ = dim ùëâ). Because ùëá‚àóùëá is a positive operator [see 7.64(a)], the spectral theorem implies that there exists an orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ with 7.72 ùëá‚àóùëáùëíùëò = ùë†ùëò 2ùëíùëò for each ùëò = 1, ‚Ä¶, ùëõ. For each ùëò = 1, ‚Ä¶, ùëö, let 7.73 ùëìùëò = ùëáùëíùëò ùë†ùëò . If ùëó, ùëò ‚àà {1, ‚Ä¶, ùëö}, then ‚ü® ùëìùëó, ùëìùëò‚ü© = 1 ùë†ùëóùë†ùëò ‚ü®ùëáùëíùëó, ùëáùëíùëò‚ü© = 1 ùë†ùëóùë†ùëò ‚ü®ùëíùëó, ùëá‚àóùëáùëíùëò‚ü©= ùë†ùëò ùë†ùëó ‚ü®ùëíùëó, ùëíùëò‚ü© = ‚éß{ ‚é®{‚é© 0 if ùëó ‚â† ùëò, 1 if ùëó = ùëò. Thus ùëì1, ‚Ä¶, ùëìùëö is an orthonormal list in ùëä. If ùëò ‚àà {1, ‚Ä¶, ùëõ} and ùëò > ùëö, then ùë†ùëò = 0and hence ùëá‚àóùëáùëíùëò = 0(by 7.72), which implies that ùëáùëíùëò = 0[by 7.64(b)]. Suppose ùë£ ‚àà ùëâ. Then ùëáùë£ = ùëá(‚ü®ùë£, ùëí1‚ü©ùëí1 + ‚ãØ + ‚ü®ùë£, ùëíùëõ‚ü©ùëíùëõ) = ‚ü®ùë£, ùëí1‚ü©ùëáùëí1 + ‚ãØ + ‚ü®ùë£, ùëíùëö‚ü©ùëáùëíùëö = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü© ùëìùëö, where the last index in the first line switched fromùëõ to ùëö in the second line because ùëáùëíùëò = 0if ùëò > ùëö (as noted in the paragraph above) and the third line follows from 7.73. The equation above is our desired result. 274 Chapter 7 Operators on Inner Product Spaces Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä), the positive singular values of ùëá are ùë†1, ‚Ä¶, ùë†ùëö, and ùëí1, ‚Ä¶, ùëíùëö and ùëì1, ‚Ä¶, ùëìùëö are as in the singular value decomposition 7.70. The orthonormal list ùëí1, ‚Ä¶, ùëíùëö can be extended to an orthonormal basis ùëí1, ‚Ä¶, ùëídim ùëâ of ùëâ and the orthonormal list ùëì1, ‚Ä¶, ùëìùëö can be extended to an orthonormal basis ùëì1, ‚Ä¶, ùëìdim ùëä of ùëä. The formula 7.71 shows that ùëáùëíùëò = ‚éß{ ‚é®{‚é© ùë†ùëò ùëìùëò if 1 ‚â§ ùëò ‚â§ ùëö, 0 if ùëö < ùëò ‚â§dim ùëâ. Thus the matrix of ùëá with respect to the orthonormal bases (ùëí1, ‚Ä¶, ùëídim ùëâ) and ( ùëì1, ‚Ä¶, ùëìdim ùëä) has the simple form ‚Ñ≥(ùëá, (ùëí1, ‚Ä¶, ùëídim ùëâ), ( ùëì1, ‚Ä¶, ùëìdim ùëä)) ùëó, ùëò = ‚éß{ ‚é®{‚é© ùë†ùëò if 1 ‚â§ ùëó = ùëò ‚â§ ùëö, 0 otherwise. If dim ùëâ = dim ùëä (as happens, for example, if ùëä = ùëâ), then the matrix described in the paragraph above is a diagonal matrix. If we extend the definition of diagonal matrix as follows to apply to matrices that are not necessarily square, then we have proved the wonderful result that every linear map from ùëâ to ùëä has a diagonal matrix with respect to appropriate orthonormal bases. 7.74 definition:diagonal matrix An ùëÄ-by-ùëÅ matrix ùê¥ is called a diagonal matrix if all entries of the matrix are 0except possibly ùê¥ùëò, ùëò for ùëò = 1, ‚Ä¶, min{ùëÄ, ùëÅ}. The table below compares the spectral theorem (7.29 and 7.31) with the singular value decomposition (7.70). spectral theorem singular value decomposition describes only self-adjoint operators (when ùêÖ = ùêë) or normal operators (when ùêÖ = ùêÇ) describes arbitrary linear maps from an inner product space to a possibly different inner product space produces a single orthonormal basis produces two orthonormal lists, one for domain space and one for range space, that are not necessarily the same even when range space equals domain space different proofs depending on whether ùêÖ = ùêë or ùêÖ = ùêÇ same proof works regardless of whether ùêÖ = ùêë or ùêÖ = ùêÇ The singular value decomposition gives us a new way to understand the adjoint and the inverse of a linear map. Specifically, the next result shows that given a singular value decomposition of a linear map ùëá ‚àà ‚Ñí(ùëâ, ùëä), we can obtain the adjoint of ùëá simply by interchanging the roles of the ùëí‚Äôs and the ùëì ‚Äôs (see 7.77). Similarly, we can obtain the pseudoinverse ùëá‚Ä† (see 6.68) of ùëá by interchanging the roles of the ùëí‚Äôs and the ùëì ‚Äôs and replacing each positive singular value ùë†ùëò of ùëá with 1/ùë†ùëò (see 7.78). Section 7E Singular Value Decomposition 275 Recall that the pseudoinverse ùëá‚Ä† in 7.78 below equals the inverse ùëá‚àí1 if ùëá is invertible [see 6.69(a)]. 7.75 singular value decomposition of adjoint and pseudoinverse Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and the positive singular values of ùëá are ùë†1, ‚Ä¶, ùë†ùëö. Suppose ùëí1, ‚Ä¶, ùëíùëö and ùëì1, ‚Ä¶, ùëìùëö are orthonormal lists in ùëâ and ùëä such that 7.76 ùëáùë£ = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü© ùëìùëö for every ùë£ ‚àà ùëâ. Then 7.77 ùëá‚àóùë§ = ùë†1‚ü®ùë§, ùëì1‚ü©ùëí1 + ‚ãØ + ùë†ùëö‚ü®ùë§, ùëìùëö‚ü©ùëíùëö and 7.78 ùëá‚Ä†ùë§ = ‚ü®ùë§, ùëì1‚ü© ùë†1 ùëí1 + ‚ãØ + ‚ü®ùë§, ùëìùëö‚ü© ùë†ùëö ùëíùëö for every ùë§ ‚àà ùëä. Proof If ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä then ‚ü®ùëáùë£, ùë§‚ü© =‚ü®ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü© ùëìùëö, ùë§‚ü© = ùë†1‚ü®ùë£, ùëí1‚ü©‚ü® ùëì1, ùë§‚ü©+ ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü©‚ü® ùëìùëö, ùë§‚ü© = ‚ü®ùë£, ùë†1‚ü®ùë§, ùëì1‚ü©ùëí1 + ‚ãØ + ùë†ùëö‚ü®ùë§, ùëìùëö‚ü©ùëíùëö‚ü©. This implies that ùëá‚àóùë§ = ùë†1‚ü®ùë§, ùëì1‚ü©ùëí1 + ‚ãØ + ùë†ùëö‚ü®ùë§, ùëìùëö‚ü©ùëíùëö, proving 7.77. To prove 7.78, suppose ùë§ ‚àà ùëä. Let ùë£ = ‚ü®ùë§, ùëì1‚ü© ùë†1 ùëí1 + ‚ãØ + ‚ü®ùë§, ùëìùëö‚ü© ùë†ùëö ùëíùëö. Apply ùëá to both sides of the equation above, getting ùëáùë£ = ‚ü®ùë§, ùëì1‚ü© ùë†1 ùëáùëí1 + ‚ãØ + ‚ü®ùë§, ùëìùëö‚ü© ùë†ùëö ùëáùëíùëö = ‚ü®ùë§, ùëì1‚ü© ùëì1 + ‚ãØ + ‚ü®ùë§, ùëìùëö‚ü© ùëìùëö = ùëÉrange ùëá ùë§, where the second line holds because 7.76 implies that ùëáùëíùëò = ùë†ùëò ùëìùëò if ùëò = 1, ‚Ä¶, ùëö, and the last line above holds because 7.76 implies that ùëì1, ‚Ä¶, ùëìùëö spans range ùëá and thus is an orthonormal basis of range ùëá [and hence 6.57(i) applies]. The equation above, the observation that ùë£ ‚àà (null ùëá) ‚üÇ [see Exercise 8(b)], and the definition of ùëá‚Ä†ùë§ (see 6.68) show that ùë£ = ùëá‚Ä†ùë§, proving 7.78. 276 Chapter 7 Operators on Inner Product Spaces 7.79 example:finding a singular value decomposition Defineùëá ‚àà ‚Ñí(ùêÖ4, ùêÖ3)by ùëá(ùë•1, ùë•2, ùë•3, ùë•4) = (‚àí5ùë•4, 0, ùë•1 + ùë•2). We want to find a singular value decomposition ofùëá. The matrix of ùëá (with respect to the standard bases) is ‚éõ‚éú‚éú‚éú ‚éù 0 0 0 ‚àí5 0 0 0 0 1 1 0 0 ‚éû‚éü‚éü‚éü ‚é† . Thus, as discussed in Example 7.67, the matrix of ùëá‚àóùëá is ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 25 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü ‚é† , and the positive eigenvalues of ùëá‚àóùëá are 25, 2, with dim ùê∏(25, ùëá‚àóùëá)= 1and dim ùê∏(2, ùëá‚àóùëá)= 1. Hence the positive singular values of ùëá are 5, ‚àö2. Thus to find a singular value decomposition ofùëá, we must find an orthonormal list ùëí1, ùëí2 in ùêÖ4 and an orthonormal list ùëì1, ùëì2 in ùêÖ3 such that ùëáùë£ = 5‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚àö2‚ü®ùë£, ùëí2‚ü© ùëì2 for all ùë£ ‚àà ùêÖ4. An orthonormal basis of ùê∏(25, ùëá‚àóùëá)is the vector (0, 0, 0, 1); an orthonormal basis of ùê∏(2, ùëá‚àóùëá)is the vector ( 1 ‚àö2 , 1 ‚àö2 , 0, 0). Thus, following the proof of 7.70, we take ùëí1 = (0, 0, 0, 1) and ùëí2 = ( 1 ‚àö2 , 1 ‚àö2 , 0, 0) and ùëì1 = ùëáùëí1 5 = (‚àí1, 0, 0) and ùëì2 = ùëáùëí2 ‚àö2 = (0, 0, 1). Then, as expected, we see that ùëí1, ùëí2 is an orthonormal list in ùêÖ4 and ùëì1, ùëì2 is an orthonormal list in ùêÖ3 and ùëáùë£ = 5‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚àö2‚ü®ùë£, ùëí2‚ü© ùëì2 for all ùë£ ‚àà ùêÖ4. Thus we have found a singular value decomposition of ùëá. The next result translates the singular value decomposition from the context of linear maps to the context of matrices. Specifically, the following result gives a factorization of an arbitrary matrix as the product of three nice matrices. The proof gives an explicit construction of these three matrices in terms of the singular value decomposition. In the next result, the phrase ‚Äúorthogonal columns‚Äù should be interpreted to mean that the columns are orthogonal with respect to the standard Euclidean inner product. Section 7E Singular Value Decomposition 277 7.80 matrix version of SVD Suppose ùê¥ is an ùëÄ-by-ùëõ matrix of rank ùëö ‚â• 1. Then there exist an ùëÄ-by-ùëö matrix ùêµ with orthonormal columns, an ùëö-by-ùëö diagonal matrix ùê∑ with positive numbers on the diagonal, and an ùëõ-by-ùëö matrix ùê∂ with orthonormal columns such that ùê¥ = ùêµùê∑ùê∂‚àó. Proof Let ùëá‚à∂ ùêÖùëõ ‚Üí ùêÖùëÄ be the linear map whose matrix with respect to the standard bases equals ùê¥. Then dim range ùëá = ùëö (by 3.78). Let 7.81 ùëáùë£ = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü© ùëìùëö be a singular value decomposition of ùëá. Let ùêµ = the ùëÄ-by-ùëö matrix whose columns are ùëì1, ‚Ä¶, ùëìùëö, ùê∑ = the ùëö-by-ùëö diagonal matrix whose diagonal entries are ùë†1, ‚Ä¶, ùë†ùëö, ùê∂ = the ùëõ-by-ùëö matrix whose columns are ùëí1, ‚Ä¶, ùëíùëö. Let ùë¢1, ‚Ä¶, ùë¢ùëö denote the standard basis of ùêÖùëö. If ùëò ‚àà {1, ‚Ä¶, ùëö} then (ùê¥ùê∂ ‚àí ùêµùê∑)ùë¢ùëò = ùê¥ùëíùëò ‚àí ùêµ(ùë†ùëòùë¢ùëò) = ùë†ùëò ùëìùëò ‚àí ùë†ùëò ùëìùëò = 0. Thus ùê¥ùê∂ = ùêµùê∑. Multiply both sides of this last equation by ùê∂‚àó (the conjugate transpose of ùê∂) on the right to get ùê¥ùê∂ùê∂‚àó = ùêµùê∑ùê∂‚àó. Note that the rows of ùê∂‚àó are the complex conjugates of ùëí1, ‚Ä¶, ùëíùëö. Thus if ùëò ‚àà {1, ‚Ä¶, ùëö}, then the definition of matrix multiplication shows thatùê∂‚àóùëíùëò = ùë¢ùëò; hence ùê∂ùê∂‚àóùëíùëò = ùëíùëò. Thus ùê¥ùê∂ùê∂‚àóùë£ = ùê¥ùë£ for all ùë£ ‚àà span(ùëí1, ‚Ä¶, ùëíùëö). If ùë£ ‚àà (span(ùëí1, ‚Ä¶, ùëíùëö)) ‚üÇ, then ùê¥ùë£ = 0(as follows from 7.81) and ùê∂‚àóùë£ = 0 (as follows from the definition of matrix multiplication). Henceùê¥ùê∂ùê∂‚àóùë£ = ùê¥ùë£ for all ùë£ ‚àà (span(ùëí1, ‚Ä¶, ùëíùëö)) ‚üÇ. Because ùê¥ùê∂ùê∂‚àó and ùê¥ agree on span(ùëí1, ‚Ä¶, ùëíùëö) and on (span(ùëí1, ‚Ä¶, ùëíùëö)) ‚üÇ, we conclude that ùê¥ùê∂ùê∂‚àó = ùê¥. Thus the displayed equation above becomes ùê¥ = ùêµùê∑ùê∂‚àó, as desired. Note that the matrix ùê¥ in the result above has ùëÄùëõ entries. In comparison, the matrices ùêµ, ùê∑, and ùê∂ above have a total of ùëö(ùëÄ + ùëö + ùëõ) entries. Thus if ùëÄ and ùëõ are large numbers and the rank ùëö is considerably less than ùëÄ and ùëõ, then the number of entries that must be stored on a computer to represent ùê¥ is considerably less than ùëÄùëõ. 278 Chapter 7 Operators on Inner Product Spaces Exercises 7E 1 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Show that ùëá = 0if and only if all singular values of ùëá are 0. 2 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùë† > 0. Prove that ùë† is a singular value of ùëá if and only if there exist nonzero vectors ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä such that ùëáùë£ = ùë†ùë§ and ùëá‚àóùë§ = ùë†ùë£. The vectors ùë£, ùë§ satisfying both equations above are called a Schmidt pair. Erhard Schmidt introduced the concept of singular values in 1907. 3 Give an example of ùëá ‚àà ‚Ñí(ùêÇ 2)such that 0is the only eigenvalue of ùëá and the singular values of ùëá are 5, 0. 4 Suppose that ùëá ‚àà ‚Ñí(ùëâ, ùëä), ùë†1 is the largest singular value of ùëá, and ùë†ùëõ is the smallest singular value of ùëá. Prove that {‚Äñùëáùë£‚Äñ ‚à∂ ùë£ ‚àà ùëâ and ‚Äñùë£‚Äñ = 1}= [ùë†ùëõ, ùë†1]. 5 Suppose ùëá ‚àà ‚Ñí(ùêÇ 2)is defined byùëá(ùë•, ùë¶) = (‚àí4ùë¶, ùë•). Find the singular values of ùëá. 6 Find the singular values of the differentiation operator ùê∑ ‚àà ‚Ñí(ùí´2(ùêë)) defined byùê∑ùëù = ùëù‚Ä≤, where the inner product on ùí´2(ùêë) is as in Example 6.34. 7 Suppose that ùëá ‚àà ‚Ñí(ùëâ) is self-adjoint or that ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ) is normal. Let ùúÜ1, ‚Ä¶, ùúÜùëõ be the eigenvalues of ùëá, each included in this list as many times as the dimension of the corresponding eigenspace. Show that the singular values of ùëá are |ùúÜ1|, ‚Ä¶, |ùúÜùëõ|, after these numbers have been sorted into decreasing order. 8 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Suppose ùë†1 ‚â• ùë†2 ‚â• ‚ãØ ‚â• ùë†ùëö > 0and ùëí1, ‚Ä¶, ùëíùëö is an orthonormal list in ùëâ and ùëì1, ‚Ä¶, ùëìùëö is an orthonormal list in ùëä such that ùëáùë£ = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü© ùëìùëö for every ùë£ ‚àà ùëâ. (a) Prove that ùëì1, ‚Ä¶, ùëìùëö is an orthonormal basis of range ùëá. (b) Prove that ùëí1, ‚Ä¶, ùëíùëö is an orthonormal basis of (null ùëá) ‚üÇ. (c) Prove that ùë†1, ‚Ä¶, ùë†ùëö are the positive singular values of ùëá. (d) Prove that if ùëò ‚àà {1, ‚Ä¶, ùëö}, then ùëíùëò is an eigenvector of ùëá‚àóùëá with corre- sponding eigenvalue ùë†ùëò 2. (e) Prove that ùëáùëá‚àóùë§ = ùë†1 2‚ü®ùë§, ùëì1‚ü© ùëì1 + ‚ãØ + ùë†ùëö 2‚ü®ùë§, ùëìùëö‚ü© ùëìùëö for all ùë§ ‚àà ùëä. Section 7E Singular Value Decomposition 279 9 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Show that ùëá and ùëá‚àó have the same positive singular values. 10 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) has singular values ùë†1, ‚Ä¶, ùë†ùëõ. Prove that if ùëá is an invertible linear map, then ùëá‚àí1 has singular values 1 ùë†ùëõ , ‚Ä¶, 1 ùë†1 . 11 Suppose that ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùë£1, ‚Ä¶, ùë£ùëõ is an orthonormal basis of ùëâ. Let ùë†1, ‚Ä¶, ùë†ùëõ denote the singular values of ùëá. (a) Prove that ‚Äñùëáùë£1‚Äñ2 + ‚ãØ + ‚Äñùëáùë£ùëõ‚Äñ 2 = ùë†1 2 + ‚ãØ + ùë†ùëõ 2. (b) Prove that if ùëä = ùëâ and ùëá is a positive operator, then ‚ü®ùëáùë£1, ùë£1‚ü©+ ‚ãØ + ‚ü®ùëáùë£ùëõ, ùë£ùëõ‚ü© = ùë†1 + ‚ãØ + ùë†ùëõ. See the comment after Exercise 5 in Section 7A. 12 (a) Give an example of a finite-dimensional vector space and an operatorùëá on it such that the singular values of ùëá2 do not equal the squares of the singular values of ùëá. (b) Suppose ùëá ‚àà ‚Ñí(ùëâ) is normal. Prove that the singular values of ùëá2 equal the squares of the singular values of ùëá. 13 Suppose ùëá1, ùëá2 ‚àà ‚Ñí(ùëâ). Prove that ùëá1 and ùëá2 have the same singular values if and only if there exist unitary operators ùëÜ1, ùëÜ2 ‚àà ‚Ñí(ùëâ) such that ùëá1 = ùëÜ1ùëá2ùëÜ2. 14 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Let ùë†ùëõ denote the smallest singular value of ùëá. Prove that ùë†ùëõ‚Äñùë£‚Äñ ‚â§ ‚Äñùëáùë£‚Äñfor every ùë£ ‚àà ùëâ. 15 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùë†1 ‚â• ‚ãØ ‚â• ùë†ùëõ are the singular values of ùëá. Prove that if ùúÜ is an eigenvalue of ùëá, then ùë†1 ‚â• |ùúÜ| ‚â• ùë†ùëõ. 16 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that (ùëá‚àó) ‚Ä† = (ùëá‚Ä†) ‚àó. Compare the result in this exercise to the analogous result for invertible linear maps [see 7.5( f )]. 17 Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is self-adjoint if and only if ùëá‚Ä† is self- adjoint. Matrices unfold Singular values gleam like stars Order in chaos shines ‚Äîwritten by ChatGPT with input haiku about SVD 280 Chapter 7 Operators on Inner Product Spaces 7F Consequences of Singular Value Decomposition Norms of Linear Maps The singular value decomposition leads to the following upper bound for ‚Äñùëáùë£‚Äñ. 7.82 upper bound for ‚Äñùëáùë£‚Äñ Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Let ùë†1 be the largest singular value of ùëá. Then ‚Äñùëáùë£‚Äñ ‚â§ ùë†1‚Äñùë£‚Äñ for all ùë£ ‚àà ùëâ. For a lower bound on ‚Äñùëáùë£‚Äñ, look at Exercise 14 in Section 7E. Proof Let ùë†1, ‚Ä¶, ùë†ùëö denote the positive singular values of ùëá, and let ùëí1, ‚Ä¶, ùëíùëö be an orthonormal list in ùëâ and ùëì1, ‚Ä¶, ùëìùëö be an orthonormal list in ùëä that provide a singular value decomposition of ùëá. Thus 7.83 ùëáùë£ = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü© ùëìùëö for all ùë£ ‚àà ùëâ. Hence if ùë£ ‚àà ùëâ then ‚Äñùëáùë£‚Äñ 2 = ùë†1 2 ‚à£‚ü®ùë£, ùëí1‚ü©‚à£2 + ‚ãØ + ùë†ùëö 2 ‚à£‚ü®ùë£, ùëíùëö‚ü©‚à£2 ‚â§ ùë†1 2(‚à£‚ü®ùë£, ùëí1‚ü©‚à£2 + ‚ãØ + ‚à£‚ü®ùë£, ùëíùëö‚ü©‚à£2) ‚â§ ùë†1 2 ‚Äñùë£‚Äñ 2, where the last inequality follows from Bessel‚Äôs inequality (6.26). Taking square roots of both sides of the inequality above shows that ‚Äñùëáùë£‚Äñ ‚â§ ùë†1‚Äñùë£‚Äñ, as desired. Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùë†1 is the largest singular value of ùëá. The result above shows that 7.84 ‚Äñùëáùë£‚Äñ ‚â§ ùë†1 for all ùë£ ‚àà ùëâ with ‚Äñùë£‚Äñ ‚â§ 1. Taking ùë£ = ùëí1 in 7.83 shows that ùëáùëí1 = ùë†1 ùëì1. Because ‚Äñ ùëì1‚Äñ = 1, this implies that ‚Äñùëáùëí1‚Äñ = ùë†1. Thus because ‚Äñùëí1‚Äñ = 1, the inequality in 7.84 leads to the equation 7.85 max{‚Äñùëáùë£‚Äñ ‚à∂ ùë£ ‚àà ùëâ and ‚Äñùë£‚Äñ ‚â§ 1}= ùë†1. The equation above is the motivation for the following definition, which defines the norm of ùëá to be the left side of the equation above without needing to refer to singular values or the singular value decomposition. 7.86 definition:norm of a linear map, ‚Äñ ‚ãÖ ‚Äñ Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then the norm of ùëá, denoted by ‚Äñùëá‚Äñ, is defined by ‚Äñùëá‚Äñ = max{‚Äñùëáùë£‚Äñ ‚à∂ ùë£ ‚àà ùëâ and ‚Äñùë£‚Äñ ‚â§ 1}. Section 7F Consequences of Singular Value Decomposition 281 In general, the maximum of an infinite set of nonnegative numbers need not exist. However, the discussion before 7.86 shows that the maximum in the definition of the norm of a linear mapùëá from ùëâ to ùëä does indeed exist (and equals the largest singular value of ùëá). We now have two different uses of the word norm and the notation ‚Äñ ‚ãÖ ‚Äñ. Our first use of this notation was in connection with an inner product onùëâ, when we defined‚Äñùë£‚Äñ = ‚àö‚ü®ùë£, ùë£‚ü©for each ùë£ ‚àà ùëâ. Our second use of the norm notation and terminology is with the definition we just made of‚Äñùëá‚Äñ for ùëá ‚àà ‚Ñí(ùëâ, ùëä). The norm ‚Äñùëá‚Äñ for ùëá ‚àà ‚Ñí(ùëâ, ùëä) does not usually come from taking an inner product of ùëá with itself (see Exercise 21). You should be able to tell from the context and from the symbols used which meaning of the norm is intended. The properties of the norm on ‚Ñí(ùëâ, ùëä) listed below look identical to properties of the norm on an inner product space (see 6.9 and 6.17). The inequality in (d) is called the triangle inequality, thus using the same terminology that we used for the norm on ùëâ. For the reverse triangle inequality, see Exercise 1. 7.87 basic properties of norms of linear maps Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then (a) ‚Äñùëá‚Äñ ‚â• 0; (b) ‚Äñùëá‚Äñ = 0 ‚ü∫ ùëá = 0; (c) ‚ÄñùúÜùëá‚Äñ = |ùúÜ| ‚Äñùëá‚Äñ for all ùúÜ ‚àà ùêÖ; (d) ‚ÄñùëÜ + ùëá‚Äñ ‚â§ ‚ÄñùëÜ‚Äñ+ ‚Äñùëá‚Äñ for all ùëÜ ‚àà ‚Ñí(ùëâ, ùëä). Proof (a) Because ‚Äñùëáùë£‚Äñ ‚â• 0for every ùë£ ‚àà ùëâ, the definition of‚Äñùëá‚Äñ implies that ‚Äñùëá‚Äñ ‚â• 0. (b) Suppose ‚Äñùëá‚Äñ = 0. Thus ùëáùë£ = 0for all ùë£ ‚àà ùëâ with ‚Äñùë£‚Äñ ‚â§ 1. If ùë¢ ‚àà ùëâ with ùë¢ ‚â† 0, then ùëáùë¢ = ‚Äñùë¢‚Äñ ùëá( ùë¢ ‚Äñùë¢‚Äñ )= 0, where the last equality holds because ùë¢/‚Äñùë¢‚Äñ has norm 1. Because ùëáùë¢ = 0for all ùë¢ ‚àà ùëâ, we have ùëá = 0. Conversely, if ùëá = 0then ùëáùë£ = 0for all ùë£ ‚àà ùëâ and hence ‚Äñùëá‚Äñ = 0. (c) Suppose ùúÜ ‚àà ùêÖ. Then ‚ÄñùúÜùëá‚Äñ = max{‚ÄñùúÜùëáùë£‚Äñ ‚à∂ ùë£ ‚àà ùëâ and ‚Äñùë£‚Äñ ‚â§ 1} = |ùúÜ| max{‚Äñùëáùë£‚Äñ ‚à∂ ùë£ ‚àà ùëâ and ‚Äñùë£‚Äñ ‚â§ 1} = |ùúÜ| ‚Äñùëá‚Äñ. (d) Suppose ùëÜ ‚àà ‚Ñí(ùëâ, ùëä). The definition of‚ÄñùëÜ + ùëá‚Äñ implies that there exists ùë£ ‚àà ùëâ such that ‚Äñùë£‚Äñ ‚â§ 1and ‚ÄñùëÜ + ùëá‚Äñ = ‚à•(ùëÜ + ùëá)ùë£‚à•. Now ‚ÄñùëÜ + ùëá‚Äñ = ‚à•(ùëÜ + ùëá)ùë£‚à• = ‚ÄñùëÜùë£ + ùëáùë£‚Äñ ‚â§ ‚ÄñùëÜùë£‚Äñ+ ‚Äñùëáùë£‚Äñ ‚â§ ‚ÄñùëÜ‚Äñ+ ‚Äñùëá‚Äñ, completing the proof of (d). 282 Chapter 7 Operators on Inner Product Spaces For ùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä), the quantity ‚ÄñùëÜ ‚àí ùëá‚Äñ is often called the distance between ùëÜ and ùëá. Informally, think of the condition that ‚ÄñùëÜ ‚àí ùëá‚Äñ is a small number as meaning that ùëÜ and ùëá are close together. For example, Exercise 9 asserts that for every ùëá ‚àà ‚Ñí(ùëâ), there is an invertible operator as close to ùëá as we wish. 7.88 alternative formulas for ‚Äñùëá‚Äñ Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then (a) ‚Äñùëá‚Äñ = the largest singular value of ùëá; (b) ‚Äñùëá‚Äñ = max{‚Äñùëáùë£‚Äñ ‚à∂ ùë£ ‚àà ùëâ and ‚Äñùë£‚Äñ = 1}; (c) ‚Äñùëá‚Äñ = the smallest number ùëê such that ‚Äñùëáùë£‚Äñ ‚â§ ùëê‚Äñùë£‚Äñfor all ùë£ ‚àà ùëâ. Proof (a) See 7.85. (b) Let ùë£ ‚àà ùëâ be such that 0 < ‚Äñùë£‚Äñ ‚â§ 1. Let ùë¢ = ùë£/‚Äñùë£‚Äñ. Then ‚Äñùë¢‚Äñ = ‚à• ùë£ ‚Äñùë£‚Äñ ‚à• = 1 and ‚Äñùëáùë¢‚Äñ = ‚à•ùëá(ùë£ ‚Äñùë£‚Äñ )‚à•= ‚Äñùëáùë£‚Äñ ‚Äñùë£‚Äñ ‚â• ‚Äñùëáùë£‚Äñ. Thus when finding the maximum of‚Äñùëáùë£‚Äñ with ‚Äñùë£‚Äñ ‚â§ 1, we can restrict attention to vectors in ùëâ with norm 1, proving (b). (c) Suppose ùë£ ‚àà ùëâ and ùë£ ‚â† 0. Then the definition of‚Äñùëá‚Äñ implies that ‚à•ùëá(ùë£ ‚Äñùë£‚Äñ )‚à•‚â§ ‚Äñùëá‚Äñ, which implies that 7.89 ‚Äñùëáùë£‚Äñ ‚â§ ‚Äñùëá‚Äñ ‚Äñùë£‚Äñ. Now suppose ùëê ‚â• 0and ‚Äñùëáùë£‚Äñ ‚â§ ùëê‚Äñùë£‚Äñfor all ùë£ ‚àà ùëâ. This implies that ‚Äñùëáùë£‚Äñ ‚â§ ùëê for all ùë£ ‚àà ùëâ with ‚Äñùë£‚Äñ ‚â§ 1. Taking the maximum of the left side of the inequality above over all ùë£ ‚àà ùëâ with ‚Äñùë£‚Äñ ‚â§ 1shows that ‚Äñùëá‚Äñ ‚â§ ùëê. Thus ‚Äñùëá‚Äñ is the smallest number ùëê such that ‚Äñùëáùë£‚Äñ ‚â§ ùëê‚Äñùë£‚Äñfor all ùë£ ‚àà ùëâ. When working with norms of linear maps, you will probably frequently use the inequality 7.89. For computing an approximation of the norm of a linear map ùëá given the matrix of ùëá with respect to some orthonormal bases, 7.88(a) is likely to be most useful. The matrix of ùëá‚àóùëá is quickly computable from matrix multiplication. Then a computer can be asked to find an approximation for the largest eigenvalue of ùëá‚àóùëá (excellent numeric algorithms exist for this purpose). Then taking the square root and using 7.88(a) gives an approximation for the norm of ùëá (which usually cannot be computed exactly). Section 7F Consequences of Singular Value Decomposition 283 You should verify all assertions in the example below. 7.90 example:norms ‚Ä¢ If ùêº denotes the usual identity operator on ùëâ, then ‚Äñùêº‚Äñ = 1. ‚Ä¢ If ùëá ‚àà ‚Ñí(ùêÖùëõ)and the matrix of ùëá with respect to the standard basis of ùêÖùëõ consists of all 1‚Äôs, then ‚Äñùëá‚Äñ = ùëõ. ‚Ä¢ If ùëá ‚àà ‚Ñí(ùëâ) and ùëâ has an orthonormal basis consisting of eigenvectors of ùëá with corresponding eigenvalues ùúÜ1, ‚Ä¶, ùúÜùëõ, then ‚Äñùëá‚Äñ is the maximum of the numbers |ùúÜ1|, ‚Ä¶, |ùúÜùëõ|. ‚Ä¢ Suppose ùëá ‚àà ‚Ñí(ùêë5)is the operator whose matrix (with respect to the stan- dard basis) is the 5-by-5matrix whose entry in row ùëó, column ùëò is 1/(ùëó 2 + ùëò). Standard mathematical software shows that the largest singular value of ùëá is approximately 0.8and the smallest singular value of ùëá is approximately 10 ‚àí6. Thus ‚Äñùëá‚Äñ ‚âà 0.8and (using Exercise 10 in Section 7E) ‚à•ùëá‚àí1‚à• ‚âà 10 6. It is not possible to find exact formulas for these norms. A linear map and its adjoint have the same norm, as shown by the next result. 7.91 norm of the adjoint Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Then ‚à•ùëá‚àó‚à• = ‚Äñùëá‚Äñ. Proof Suppose ùë§ ‚àà ùëä. Then ‚à•ùëá‚àóùë§‚à• 2 = ‚ü®ùëá‚àóùë§, ùëá‚àóùë§‚ü©= ‚ü®ùëáùëá‚àóùë§, ùë§‚ü©‚â§‚à•ùëáùëá‚àóùë§‚à• ‚Äñùë§‚Äñ ‚â§ ‚Äñùëá‚Äñ‚à•ùëá‚àóùë§‚à• ‚Äñùë§‚Äñ. The inequality above implies that ‚à•ùëá‚àóùë§‚à• ‚â§ ‚Äñùëá‚Äñ ‚Äñùë§‚Äñ, which along with 7.88(ùëê) implies that ‚à•ùëá‚àó‚à• ‚â§ ‚Äñùëá‚Äñ. Replacing ùëá with ùëá‚àó in the inequality ‚à•ùëá‚àó‚à• ‚â§ ‚Äñùëá‚Äñand then using the equation (ùëá‚àó) ‚àó = ùëá shows that ‚Äñùëá‚Äñ ‚â§‚à•ùëá‚àó‚à•. Thus ‚à•ùëá‚àó‚à• = ‚Äñùëá‚Äñ, as desired. You may want to construct an alternative proof of the result above using Exercise 9 in Section 7E, which asserts that a linear map and its adjoint have the same positive singular values. Approximation by Linear Maps with Lower-Dimensional Range The next result is a spectacular application of the singular value decomposition. It says that to best approximate a linear map by a linear map whose range has dimension at most ùëò, chop off the singular value decomposition after the first ùëò terms. Specifically, the linear mapùëáùëò in the next result has the property that dim range ùëáùëò = ùëò and ùëáùëò minimizes the distance to ùëá among all linear maps with range of dimension at most ùëò. This result leads to algorithms for compressing huge matrices while preserving their most important information. 284 Chapter 7 Operators on Inner Product Spaces 7.92 best approximation by linear map whose range has dimension ‚â§ ùëò Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùë†1 ‚â• ‚ãØ ‚â• ùë†ùëö are the positive singular values of ùëá. Suppose 1 ‚â§ ùëò < ùëö. Then min{‚Äñùëá ‚àí ùëÜ‚Äñ ‚à∂ ùëÜ ‚àà ‚Ñí(ùëâ, ùëä) and dim range ùëÜ ‚â§ ùëò}= ùë†ùëò + 1. Furthermore, if ùëáùë£ = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü© ùëìùëö is a singular value decomposition of ùëá and ùëáùëò ‚àà ‚Ñí(ùëâ, ùëä) is defined by ùëáùëòùë£ = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëò‚ü®ùë£, ùëíùëò‚ü© ùëìùëò for each ùë£ ‚àà ùëâ, then dim range ùëáùëò = ùëò and ‚Äñùëá ‚àí ùëáùëò‚Äñ = ùë†ùëò + 1. Proof If ùë£ ‚àà ùëâ then ‚à•(ùëá ‚àí ùëáùëò)ùë£‚à•2 = ‚à•ùë†ùëò + 1‚ü®ùë£, ùëíùëò + 1‚ü© ùëìùëò + 1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü© ùëìùëö‚à• 2 = ùë†ùëò + 1 2 ‚à£‚ü®ùë£, ùëíùëò + 1‚ü©‚à£2 + ‚ãØ + ùë†ùëö 2 ‚à£‚ü®ùë£, ùëíùëö‚ü©‚à£2 ‚â§ ùë†ùëò + 1 2(‚à£‚ü®ùë£, ùëíùëò + 1‚ü©‚à£2 + ‚ãØ + ‚à£‚ü®ùë£, ùëíùëö‚ü©‚à£2) ‚â§ ùë†ùëò + 1 2 ‚Äñùë£‚Äñ 2. Thus ‚Äñùëá ‚àí ùëáùëò‚Äñ ‚â§ ùë†ùëò + 1. The equation (ùëá ‚àí ùëáùëò)ùëíùëò + 1 = ùë†ùëò + 1 ùëìùëò + 1 now shows that ‚Äñùëá ‚àí ùëáùëò‚Äñ = ùë†ùëò + 1. Suppose ùëÜ ‚àà ‚Ñí(ùëâ, ùëä) and dim range ùëÜ ‚â§ ùëò. Thus ùëÜùëí1, ‚Ä¶, ùëÜùëíùëò + 1, which is a list of length ùëò + 1, is linearly dependent. Hence there exist ùëé1, ‚Ä¶, ùëéùëò + 1 ‚àà ùêÖ, not all 0, such that ùëé1ùëÜùëí1 + ‚ãØ + ùëéùëò + 1ùëÜùëíùëò + 1 = 0. Now ùëé1ùëí1 + ‚ãØ + ùëéùëò + 1ùëíùëò + 1 ‚â† 0because ùëé1, ‚Ä¶, ùëéùëò + 1 are not all 0. We have ‚à•(ùëá ‚àí ùëÜ)(ùëé1ùëí1 + ‚ãØ + ùëéùëò + 1ùëíùëò + 1)‚à• 2 = ‚à•ùëá(ùëé1ùëí1 + ‚ãØ + ùëéùëò + 1ùëíùëò + 1)‚à• 2 = ‚Äñùë†1ùëé1 ùëì1 + ‚ãØ + ùë†ùëò + 1ùëéùëò + 1 ùëìùëò + 1‚Äñ 2 = ùë†1 2 |ùëé1| 2 + ‚ãØ + ùë†ùëò + 1 2 |ùëéùëò + 1| 2 ‚â• ùë†ùëò + 1 2(|ùëé1| 2 + ‚ãØ + |ùëéùëò + 1| 2) = ùë†ùëò + 1 2 ‚Äñùëé1ùëí1 + ‚ãØ + ùëéùëò + 1ùëíùëò + 1‚Äñ 2. Because ùëé1ùëí1 + ‚ãØ + ùëéùëò + 1ùëíùëò + 1 ‚â† 0, the inequality above implies that ‚Äñùëá ‚àí ùëÜ‚Äñ ‚â• ùë†ùëò + 1. Thus ùëÜ = ùëáùëò minimizes ‚Äñùëá ‚àí ùëÜ‚Äñ among ùëÜ ‚àà ‚Ñí(ùëâ, ùëä) with dim range ùëÜ ‚â§ ùëò. For other examples of the use of the singular value decomposition in best approximation, see Exercise 22, which finds a subspace of given dimension on which the restriction of a linear map is as small as possible, and Exercise 27, which finds a unitary operator that is as close as possible to a given operator. Section 7F Consequences of Singular Value Decomposition 285 Polar Decomposition Recall our discussion before 7.54 of the analogy between complex numbers ùëß with |ùëß| = 1and unitary operators. Continuing with this analogy, note that every complex number ùëß except 0can be written in the form ùëß = ( ùëß |ùëß| )|ùëß| = ( ùëß |ùëß| )‚àöùëßùëß, where the first factor, namely,ùëß/|ùëß|, has absolute value 1. Our analogy leads us to guess that every operator ùëá ‚àà ‚Ñí(ùëâ) can be written as a unitary operator times ‚àöùëá‚àóùëá. That guess is indeed correct. The corresponding result is called the polar decomposition, which gives a beautiful description of an arbitrary operator on ùëâ. Note that if ùëá ‚àà ‚Ñí(ùëâ), then ùëá‚àóùëá is a positive operator [as was shown in 7.64(a)]. Thus the operator ‚àöùëá‚àóùëá makes sense and is well defined as a positive operator on ùëâ. The polar decomposition that we are about to state and prove says that every operator on ùëâ is the product of a unitary operator and a positive operator. Thus we can write an arbitrary operator on ùëâ as the product of two nice operators, each of which comes from a class that we can completely describe and that we understand reasonably well. The unitary operators are described by 7.55 if ùêÖ = ùêÇ; the positive operators are described by the real and complex spectral theorems (7.29 and 7.31). Specifically, consider the caseùêÖ = ùêÇ, and suppose ùëá = ùëÜ‚àöùëá‚àóùëá is a polar decomposition of an operator ùëá ‚àà ‚Ñí(ùëâ), where ùëÜ is a unitary operator. Then there is an orthonormal basis of ùëâ with respect to which ùëÜ has a diagonal matrix, and there is an orthonormal basis of ùëâ with respect to which ‚àöùëá‚àóùëá has a diagonal matrix. Warning: There may not exist an orthonormal basis that simultaneously puts the matrices of both ùëÜ and ‚àöùëá‚àóùëá into these nice diagonal forms‚ÄîùëÜ may require one orthonormal basis and ‚àöùëá‚àóùëá may require a different orthonormal basis. However (still assuming that ùêÖ = ùêÇ), if ùëá is normal, then an orthonormal basis of ùëâ can be chosen such that both ùëÜ and ‚àöùëá‚àóùëá have diagonal matrices with respect to this basis‚Äîsee Exercise 31. The converse is also true: If ùëá ‚àà ‚Ñí(ùëâ) and ùëá = ùëÜ‚àöùëá‚àóùëá for some unitary operator ùëÜ ‚àà ‚Ñí(ùëâ) such that ùëÜ and ‚àöùëá‚àóùëá both have diagonal matrices with respect to the same orthonormal basis of ùëâ, then ùëá is normal. This holds because ùëá then has a diagonal matrix with respect to this same orthonormal basis, which implies that ùëá is normal [by the equivalence of (c) and (a) in 7.31]. 286 Chapter 7 Operators on Inner Product Spaces The polar decomposition below is valid on both real and complex inner product spaces and for all operators on those spaces. 7.93 polar decomposition Suppose ùëá ‚àà ‚Ñí(ùëâ). Then there exists a unitary operator ùëÜ ‚àà ‚Ñí(ùëâ) such that ùëá = ùëÜ‚àöùëá‚àóùëá. Proof Let ùë†1, ‚Ä¶, ùë†ùëö be the positive singular values of ùëá, and let ùëí1, ‚Ä¶, ùëíùëö and ùëì1, ‚Ä¶, ùëìùëö be orthonormal lists in ùëâ such that 7.94 ùëáùë£ = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü© ùëìùëö for every ùë£ ‚àà ùëâ. Extend ùëí1, ‚Ä¶, ùëíùëö and ùëì1, ‚Ä¶, ùëìùëö to orthonormal bases ùëí1, ‚Ä¶, ùëíùëõ and ùëì1, ‚Ä¶, ùëìùëõ of ùëâ. DefineùëÜ ‚àà ‚Ñí(ùëâ) by ùëÜùë£ = ‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ‚ü®ùë£, ùëíùëõ‚ü© ùëìùëõ for each ùë£ ‚àà ùëâ. Then ‚ÄñùëÜùë£‚Äñ 2 = ‚à•‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ‚ü®ùë£, ùëíùëõ‚ü© ùëìùëõ‚à• 2 = ‚à£‚ü®ùë£, ùëí1‚ü©‚à£2 + ‚ãØ + ‚à£‚ü®ùë£, ùëíùëõ‚ü©‚à£2 = ‚Äñùë£‚Äñ2. Thus ùëÜ is a unitary operator. Applying ùëá‚àó to both sides of 7.94 and then using the formula for ùëá‚àó given by 7.77 shows that ùëá‚àóùëáùë£ = ùë†1 2‚ü®ùë£, ùëí1‚ü©ùëí1 + ‚ãØ + ùë†ùëö 2‚ü®ùë£, ùëíùëö‚ü©ùëíùëö for every ùë£ ‚àà ùëâ. Thus if ùë£ ‚àà ùëâ, then ‚àöùëá‚àóùëáùë£ = ùë†1‚ü®ùë£, ùëí1‚ü©ùëí1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü©ùëíùëö because the operator that sends ùë£ to the right side of the equation above is a positive operator whose square equals ùëá‚àóùëá. Now ùëÜ‚àöùëá‚àóùëáùë£ = ùëÜ(ùë†1‚ü®ùë£, ùëí1‚ü©ùëí1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü©ùëíùëö) = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëö‚ü®ùë£, ùëíùëö‚ü© ùëìùëö = ùëáùë£, where the last equation follows from 7.94. Exercise 27 shows that the unitary operator ùëÜ produced in the proof above is as close as a unitary operator can be to ùëá. Alternative proofs of the polar decomposition directly use the spectral theorem, avoiding the singular value decomposition. However, the proof above seems cleaner than those alternative proofs. Section 7F Consequences of Singular Value Decomposition 287 Operators Applied to Ellipsoids and Parallelepipeds 7.95 definition:ball, ùêµ The ball in ùëâ of radius 1centered at 0, denoted by ùêµ, is defined by ùêµ = {ùë£ ‚àà ùëâ ‚à∂ ‚Äñùë£‚Äñ < 1}. The ball ùêµ in ùêë2. If dim ùëâ = 2, the word disk is sometimes used instead of ball. However, using ball in all dimensions is less confusing. Similarly, if dim ùëâ = 2, then the word ellipse is sometimes used instead of the word ellipsoid that we are about to define. Again, using ellipsoid in all dimensions is less confusing. You can think of the ellipsoid defined below as obtained by starting with the ball ùêµ and then stretching by a factor of ùë†ùëò along each ùëìùëò axis. 7.96 definition:ellipsoid, ùê∏(ùë†1 ùëì1, ‚Ä¶, ùë†ùëõ ùëìùëõ), principal axes Suppose that ùëì1, ‚Ä¶, ùëìùëõ is an orthonormal basis of ùëâ and ùë†1, ‚Ä¶, ùë†ùëõ are positive numbers. The ellipsoid ùê∏(ùë†1 ùëì1, ‚Ä¶, ùë†ùëõ ùëìùëõ) with principal axes ùë†1 ùëì1, ‚Ä¶, ùë†ùëõ ùëìùëõ is defined by ùê∏(ùë†1 ùëì1, ‚Ä¶, ùë†ùëõ ùëìùëõ) = {ùë£ ‚àà ùëâ ‚à∂ |‚ü®ùë£, ùëì1‚ü©| 2 ùë†1 2 + ‚ãØ + |‚ü®ùë£, ùëìùëõ‚ü©| 2 ùë†ùëõ 2 < 1}. The ellipsoid notation ùê∏(ùë†1 ùëì1, ‚Ä¶, ùë†ùëõ ùëìùëõ) does not explicitly include the inner product space ùëâ, even though the definition above depends onùëâ. However, the in- ner product space ùëâ should be clear from the context and also from the requirement that ùëì1, ‚Ä¶, ùëìùëõ be an orthonormal basis of ùëâ. 7.97 example:ellipsoids The ellipsoid ùê∏(2 ùëì1, ùëì2) in ùêë2, where ùëì1, ùëì2 is the standard basis of ùêë2. The ellipsoid ùê∏(2 ùëì1, ùëì2) in ùêë2, where ùëì1 = ( 1 ‚àö2 , 1 ‚àö2 )and ùëì2 = (‚àí 1 ‚àö2 , 1 ‚àö2 ). 288 Chapter 7 Operators on Inner Product Spaces The ellipsoid ùê∏(4 ùëì1, 3 ùëì2, 2 ùëì3) in ùêë3, where ùëì1, ùëì2, ùëì3 is the standard basis of ùêë3. The ellipsoid ùê∏( ùëì1, ‚Ä¶, ùëìùëõ) equals the ball ùêµ in ùëâ for every orthonormal basis ùëì1, ‚Ä¶, ùëìùëõ of ùëâ [by Parseval‚Äôs identity 6.30(b)]. 7.98 notation:ùëá(Œ©) For ùëá a function defined onùëâ and Œ© ‚äÜ ùëâ, defineùëá(Œ©) by ùëá(Œ©) = {ùëáùë£ ‚à∂ ùë£ ‚àà Œ©}. Thus if ùëá is a function defined onùëâ, then ùëá(ùëâ) = range ùëá. The next result states that every invertible operator ùëá ‚àà ‚Ñí(ùëâ) maps the ball ùêµ in ùëâ onto an ellipsoid in ùëâ. The proof shows that the principal axes of this ellipsoid come from the singular value decomposition of ùëá. 7.99 invertible operator takes ball to ellipsoid Suppose ùëá ‚àà ‚Ñí(ùëâ) is invertible. Then ùëá maps the ball ùêµ in ùëâ onto an ellipsoid in ùëâ. Proof Suppose ùëá has singular value decomposition 7.100 ùëáùë£ = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëõ‚ü®ùë£, ùëíùëõ‚ü© ùëìùëõ for all ùë£ ‚àà ùëâ, where ùë†1, ‚Ä¶, ùë†ùëõ are the singular values of ùëá and ùëí1, ‚Ä¶, ùëíùëõ and ùëì1, ‚Ä¶, ùëìùëõ are both orthonormal bases of ùëâ. We will show that ùëá(ùêµ) = ùê∏(ùë†1 ùëì1, ‚Ä¶, ùë†ùëõ ùëìùëõ). First suppose ùë£ ‚àà ùêµ. Because ùëá is invertible, none of the singular values ùë†1, ‚Ä¶, ùë†ùëõ equals 0(see 7.68). Thus 7.100 implies that ‚à£‚ü®ùëáùë£, ùëì1‚ü©‚à£2 ùë†1 2 + ‚ãØ + ‚à£‚ü®ùëáùë£, ùëìùëõ‚ü©‚à£2 ùë†ùëõ 2 = |‚ü®ùë£, ùëí1‚ü©| 2 + ‚ãØ + |‚ü®ùë£, ùëíùëõ‚ü©| 2 < 1. Thus ùëáùë£ ‚àà ùê∏(ùë†1 ùëì1, ‚Ä¶, ùë†ùëõ ùëìùëõ). Hence ùëá(ùêµ) ‚äÜ ùê∏(ùë†1 ùëì1, ‚Ä¶, ùë†ùëõ ùëìùëõ). To prove inclusion in the other direction, now suppose ùë§ ‚àà ùê∏(ùë†1 ùëì1, ‚Ä¶, ùë†ùëõ ùëìùëõ). Let ùë£ = ‚ü®ùë§, ùëì1‚ü© ùë†1 ùëí1 + ‚ãØ + ‚ü®ùë§, ùëìùëõ‚ü© ùë†ùëõ ùëíùëõ. Then ‚Äñùë£‚Äñ < 1and 7.100 implies that ùëáùë£ = ‚ü®ùë§, ùëì1‚ü© ùëì1 + ‚ãØ + ‚ü®ùë§, ùëìùëõ‚ü© ùëìùëõ = ùë§. Thus ùëá(ùêµ) ‚äá ùê∏(ùë†1 ùëì1, ‚Ä¶, ùë†ùëõ ùëìùëõ). Section 7F Consequences of Singular Value Decomposition 289 We now use the previous result to show that invertible operators take all ellipsoids, not just the ball of radius 1, to ellipsoids. 7.101 invertible operator takes ellipsoids to ellipsoids Suppose ùëá ‚àà ‚Ñí(ùëâ) is invertible and ùê∏ is an ellipsoid in ùëâ. Then ùëá(ùê∏) is an ellipsoid in ùëâ. Proof There exist orthonormal basis ùëì1, ‚Ä¶, ùëìùëõ of ùëâ and positive numbers ùë†1, ‚Ä¶, ùë†ùëõ such that ùê∏ = ùê∏(ùë†1 ùëì1, ‚Ä¶, ùë†ùëõ ùëìùëõ). DefineùëÜ ‚àà ‚Ñí(ùëâ) by ùëÜ(ùëé1 ùëì1 + ‚ãØ + ùëéùëõ ùëìùëõ) = ùëé1ùë†1 ùëì1 + ‚ãØ + ùëéùëõùë†ùëõ ùëìùëõ. Then ùëÜ maps the ball ùêµ of ùëâ onto ùê∏, as you can verify. Thus ùëá(ùê∏) = ùëá(ùëÜ(ùêµ))= (ùëáùëÜ)(ùêµ). The equation above and 7.99, applied to ùëáùëÜ, show that ùëá(ùê∏) is an ellipsoid in ùëâ. Recall (see 3.95) that if ùë¢ ‚àà ùëâ and Œ© ‚äÜ ùëâthen ùë¢ + Œ© is defined by ùë¢ + Œ© = {ùë¢ + ùë§ ‚à∂ ùë§ ‚àà Œ©}. Geometrically, the sets Œ© and ùë¢ + Œ© look the same, but they are in different locations. In the following definition, ifdim ùëâ = 2then the word parallelogram is often used instead of parallelepiped. 7.102 definition:ùëÉ(ùë£1, ‚Ä¶, ùë£ùëõ), parallelepiped Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Let ùëÉ(ùë£1, ‚Ä¶, ùë£ùëõ) = {ùëé1ùë£1 + ‚ãØ + ùëéùëõùë£ùëõ ‚à∂ ùëé1, ‚Ä¶, ùëéùëõ ‚àà (0, 1)}. A parallelepiped is a set of the form ùë¢ + ùëÉ(ùë£1, ‚Ä¶, ùë£ùëõ) for some ùë¢ ‚àà ùëâ. The vectors ùë£1, ‚Ä¶, ùë£ùëõ are called the edges of this parallelepiped. 7.103 example:parallelepipeds The parallelepiped (0.3, 0.5)+ ùëÉ((1, 0), (1, 1))in ùêë2. A parallelepiped in ùêë3. 290 Chapter 7 Operators on Inner Product Spaces 7.104 invertible operator takes parallelepipeds to parallelepipeds Suppose ùë¢ ‚àà ùëâ and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. Suppose ùëá ‚àà ‚Ñí(ùëâ) is invertible. Then ùëá(ùë¢ + ùëÉ(ùë£1, ‚Ä¶, ùë£ùëõ))= ùëáùë¢ + ùëÉ(ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ). Proof Because ùëá is invertible, the list ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ is a basis of ùëâ. The linearity of ùëá implies that ùëá(ùë¢ + ùëé1ùë£1 + ‚ãØ + ùëéùëõùë£ùëõ) = ùëáùë¢ + ùëé1ùëáùë£1 + ‚ãØ + ùëéùëõùëáùë£ùëõ for all ùëé1, ‚Ä¶, ùëéùëõ ‚àà (0, 1). Thus ùëá(ùë¢ + ùëÉ(ùë£1, ‚Ä¶, ùë£ùëõ))= ùëáùë¢ + ùëÉ(ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ). Just as the rectangles are distinguished among the parallelograms in ùêë2, we give a special name to the parallelepipeds in ùëâ whose defining edges are orthogonal to each other. 7.105 definition:box A box in ùëâ is a set of the form ùë¢ + ùëÉ(ùëü1ùëí1, ‚Ä¶, ùëüùëõùëíùëõ), where ùë¢ ‚àà ùëâ and ùëü1, ‚Ä¶, ùëüùëõ are positive numbers and ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ. Note that in the special case of ùêë2 each box is a rectangle, but the terminology box can be used in all dimensions. 7.106 example:boxes The box (1, 0)+ ùëÉ(‚àö2 ùëí1, ‚àö2 ùëí2), where ùëí1 = ( 1 ‚àö2 , 1 ‚àö2 )and ùëí2 = (‚àí 1 ‚àö2 , 1 ‚àö2 ). The box ùëÉ(ùëí1, 2ùëí2, ùëí3), where ùëí1, ùëí2, ùëí3 is the standard basis of ùêë3. Suppose ùëá ‚àà ‚Ñí(ùëâ) is invertible. Then ùëá maps every parallelepiped in ùëâ to a parallelepiped in ùëâ (by 7.104). In particular, ùëá maps every box in ùëâ to a parallelepiped in ùëâ. This raises the question of whether ùëá maps some boxes in ùëâ to boxes in ùëâ. The following result answers this question, with the help of the singular value decomposition. Section 7F Consequences of Singular Value Decomposition 291 7.107 every invertible operator takes some boxes to boxes Suppose ùëá ‚àà ‚Ñí(ùëâ) is invertible. Suppose ùëá has singular value decomposition ùëáùë£ = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëõ‚ü®ùë£, ùëíùëõ‚ü© ùëìùëõ, where ùë†1, ‚Ä¶, ùë†ùëõ are the singular values of ùëá and ùëí1, ‚Ä¶, ùëíùëõ and ùëì1, ‚Ä¶, ùëìùëõ are orthonormal bases of ùëâ and the equation above holds for all ùë£ ‚àà ùëâ. Then ùëá maps the box ùë¢ + ùëÉ(ùëü1ùëí1, ‚Ä¶, ùëüùëõùëíùëõ) onto the box ùëáùë¢ + ùëÉ(ùëü1ùë†1 ùëì1, ‚Ä¶, ùëüùëõùë†ùëõ ùëìùëõ) for all positive numbers ùëü1, ‚Ä¶, ùëüùëõ and all ùë¢ ‚àà ùëâ. Proof If ùëé1, ‚Ä¶, ùëéùëõ ‚àà (0, 1)and ùëü1, ‚Ä¶, ùëüùëõ are positive numbers and ùë¢ ‚àà ùëâ, then ùëá(ùë¢ + ùëé1ùëü1ùëí1 + ‚ãØ + ùëéùëõùëüùëõùëíùëõ) = ùëáùë¢ + ùëé1ùëü1ùë†1 ùëì1 + ‚ãØ + ùëéùëõùëüùëõùë†ùëõ ùëìùëõ. Thus ùëá(ùë¢ + ùëÉ(ùëü1ùëí1, ‚Ä¶, ùëüùëõùëíùëõ))= ùëáùë¢ + ùëÉ(ùëü1ùë†1 ùëì1, ‚Ä¶, ùëüùëõùë†ùëõ ùëìùëõ). Volume via Singular Values Our goal in this subsection is to understand how an operator changes the volume of subsets of its domain. Because notions of volume belong to analysis rather than to linear algebra, we will work only with an intuitive notion of volume. Our intuitive approach to volume can be converted into appropriate correct definitions, correct statements, and correct proofs using the machinery of analysis. Our intuition about volume works best in real inner product spaces. Thus the assumption that ùêÖ = ùêë will appear frequently in the rest of this subsection. If dim ùëâ = ùëõ, then by volume we will mean ùëõ-dimensional volume. You should be familiar with this concept in ùêë3. When ùëõ = 2, this is usually called area instead of volume, but for consistency we use the word volume in all dimensions. The most fundamental intuition about volume is that the volume of a box (whose defining edges are by definition orthogonal to each other) is the product of the lengths of the defining edges. Thus we make the following definition. 7.108 definition:volume of a box Suppose ùêÖ = ùêë. If ùë¢ ‚àà ùëâ and ùëü1, ‚Ä¶, ùëüùëõ are positive numbers and ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ, then volume(ùë¢ + ùëÉ(ùëü1ùëí1, ‚Ä¶, ùëüùëõùëíùëõ))= ùëü1 √ó ‚ãØ √ó ùëüùëõ. The definition above agrees with the familiar formulas for the area (which we are calling the volume) of a rectangle in ùêë2 and for the volume of a box in ùêë3. For example, the first box in Example7.106 has two-dimensional volume (or area) 2 because the defining edges of that box have length‚àö2and ‚àö2. The second box in Example 7.106 has three-dimensional volume 2because the defining edges of that box have length 1, 2, and 1. 292 Chapter 7 Operators on Inner Product Spaces Volume of this ball ‚âà sum of the volumes of the five boxes. To define the volume of a subset ofùëâ, approximate the subset by a finite collection of disjoint boxes, and then add up the volumes of the approximating collection of boxes. As we approximate a subset of ùëâ more accurately by disjoint unions of more boxes, we get a better approximation to the volume. These ideas should remind you of how the Riemann integral is defined by approximating the area under a curve by a disjoint collection of rectangles. This discussion leads to the following nonrigorous but intuitive definition. 7.109 definition:volume Suppose ùêÖ = ùêë and Œ© ‚äÜ ùëâ. Then the volume of Œ©, denoted by volume Œ©, is approximately the sum of the volumes of a collection of disjoint boxes that approximate Œ©. We are ignoring many reasonable questions by taking an intuitive approach to volume. For example, if we approximate Œ© by boxes with respect to one basis, do we get the same volume if we approximate Œ© by boxes with respect to a different basis? If Œ©1 and Œ©2 are disjoint subsets of ùëâ, is volume(Œ©1 ‚à™ Œ©1) = volume Œ©1 + volume Œ©2? Provided that we consider only reasonably nice subsets of ùëâ, techniques of analysis show that both these questions have affirmative answers that agree with our intuition about volume. 7.110 example:volume change by a linear map Each box here has twice the width and the same height as the boxes in the previous figure. Suppose that ùëá ‚àà ‚Ñí(ùêë2)is defined by ùëáùë£ = 2‚ü®ùë£, ùëí1‚ü©ùëí1 + ‚ü®ùë£, ùëí2‚ü©ùëí2, where ùëí1, ùëí2 is the standard basis of ùêë2. This linear map stretches by a factor of 2along the ùëí1 axis. The ball approximated by five boxes above gets mapped by ùëá to the ellipsoid shown here. Each of the five boxes in the original figure gets mapped to a box of twice the width and the same height as in the original figure. Hence each box gets mapped to a box of twice the volume (area) as in the original figure. The sum of the volumes of the five new boxes approximates the volume of the ellipsoid. Thus ùëá changes the volume of the ball by a factor of 2. In the example above, ùëá maps boxes with respect to the basis ùëí1, ùëí2 to boxes with respect to the same basis; thus we can see how ùëá changes volume. In general, an operator maps boxes to parallelepipeds that are not boxes. However, if we choose the right basis (coming from the singular value decomposition!), then boxes with respect to that basis get mapped to boxes with respect to a possibly different basis, as shown in 7.107. This observation leads to a natural proof of the following result. Section 7F Consequences of Singular Value Decomposition 293 7.111 volume changes by a factor of the product of the singular values Suppose ùêÖ = ùêë, ùëá ‚àà ‚Ñí(ùëâ) is invertible, and Œ© ‚äÜ ùëâ. Then volume ùëá(Œ©) = (product of singular values of ùëá)(volume Œ©). Proof Suppose ùëá has singular value decomposition ùëáùë£ = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëõ‚ü®ùë£, ùëíùëõ‚ü© ùëìùëõ for all ùë£ ‚àà ùëâ, where ùëí1, ‚Ä¶, ùëíùëõ and ùëì1, ‚Ä¶, ùëìùëõ are orthonormal bases of ùëâ. Approximate Œ© by boxes of the form ùë¢ + ùëÉ(ùëü1ùëí1, ‚Ä¶, ùëüùëõùëíùëõ), which have volume ùëü1 √ó ‚ãØ √ó ùëüùëõ. The operator ùëá maps each box ùë¢ + ùëÉ(ùëü1ùëí1, ‚Ä¶, ùëüùëõùëíùëõ) onto the box ùëáùë¢ + ùí´(ùëü1ùë†1 ùëì1, ‚Ä¶, ùëüùëõùë†ùëõ ùëìùëõ), which has volume (ùë†1 √ó ‚ãØ √ó ùë†ùëõ)(ùëü1 √ó ‚ãØ √ó ùëüùëõ). The operator ùëá maps a collection of boxes that approximate Œ© onto a collection of boxes that approximate ùëá(Œ©). Because ùëá changes the volume of each box in a collection that approximates Œ© by a factor of ùë†1 √ó ‚ãØ √ó ùë†ùëõ, the linear map ùëá changes the volume of Œ© by the same factor. Suppose ùëá ‚àà ‚Ñí(ùëâ). As we will see when we get to determinants, the product of the singular values of ùëá equals |det ùëá|; see 9.60 and 9.61. Properties of an Operator as Determined by Its Eigenvalues We conclude this chapter by presenting the table below. The context of this table is a finite-dimensional complex inner product space. The first column of the table shows a property that a normal operator on such a space might have. The second column of the table shows a subset of ùêÇ such that the operator has the corresponding property if and only if all eigenvalues of the operator lie in the specified subset. For example, the first row of the table states that a normal operator is invertible if and only if all its eigenvalues are nonzero (this first row is the only one in the table that does not need the hypothesis that the operator is normal). Make sure you can explain why all results in the table hold. For example, the last row of the table holds because the norm of an operator equals its largest singular value (by 7.85) and the singular values of a normal operator, assuming ùêÖ = ùêÇ, equal the absolute values of the eigenvalues (by Exercise 7 in Section 7E). properties of a normal operator eigenvalues are contained in invertible ùêÇ\\{0} self-adjoint ùêë skew {ùúÜ ‚àà ùêÇ ‚à∂ Re ùúÜ = 0} orthogonal projection {0, 1} positive [0, ‚àû) unitary {ùúÜ ‚àà ùêÇ ‚à∂ |ùúÜ| = 1} norm is less than 1 {ùúÜ ‚àà ùêÇ ‚à∂ |ùúÜ| < 1} 294 Chapter 7 Operators on Inner Product Spaces Exercises 7F 1 Prove that if ùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä), then ‚à£ ‚ÄñùëÜ‚Äñ ‚àí ‚Äñùëá‚Äñ ‚à£ ‚â§ ‚ÄñùëÜ ‚àí ùëá‚Äñ. The inequality above is called the reverse triangle inequality. 2 Suppose that ùëá ‚àà ‚Ñí(ùëâ) is self-adjoint or that ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ) is normal. Prove that ‚Äñùëá‚Äñ = max{|ùúÜ| ‚à∂ ùúÜ is an eigenvalue of ùëá}. 3 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùë£ ‚àà ùëâ. Prove that ‚Äñùëáùë£‚Äñ = ‚Äñùëá‚Äñ ‚Äñùë£‚Äñ ‚ü∫ ùëá‚àóùëáùë£ = ‚Äñùëá‚Äñ2ùë£. 4 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä), ùë£ ‚àà ùëâ, and ‚Äñùëáùë£‚Äñ = ‚Äñùëá‚Äñ ‚Äñùë£‚Äñ. Prove that if ùë¢ ‚àà ùëâ and ‚ü®ùë¢, ùë£‚ü© = 0, then ‚ü®ùëáùë¢, ùëáùë£‚ü© = 0. 5 Suppose ùëà is a finite-dimensional inner product space,ùëá ‚àà ‚Ñí(ùëâ, ùëà), and ùëÜ ‚àà ‚Ñí(ùëà, ùëä). Prove that ‚ÄñùëÜùëá‚Äñ ‚â§ ‚ÄñùëÜ‚Äñ ‚Äñùëá‚Äñ. 6 Prove or give a counterexample: If ùëÜ, ùëá ‚àà ‚Ñí(ùëâ), then ‚ÄñùëÜùëá‚Äñ = ‚ÄñùëáùëÜ‚Äñ. 7 Show that definingùëë(ùëÜ, ùëá) = ‚ÄñùëÜ ‚àí ùëá‚Äñ for ùëÜ, ùëá ‚àà ‚Ñí(ùëâ, ùëä) makes ùëë a metric on ‚Ñí(ùëâ, ùëä). This exercise is intended for readers who are familiar with metric spaces. 8 (a) Prove that if ùëá ‚àà ‚Ñí(ùëâ) and ‚Äñùêº ‚àí ùëá‚Äñ < 1, then ùëá is invertible. (b) Suppose that ùëÜ ‚àà ‚Ñí(ùëâ) is invertible. Prove that if ùëá ‚àà ‚Ñí(ùëâ) and ‚ÄñùëÜ ‚àí ùëá‚Äñ < 1/‚à•ùëÜ ‚àí1‚à•, then ùëá is invertible. This exercise shows that the set of invertible operators in ‚Ñí(ùëâ) is an open subset of ‚Ñí(ùëâ), using the metric defined in Exercise 7. 9 Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that for every ùúñ > 0, there exists an invertible operator ùëÜ ‚àà ‚Ñí(ùëâ) such that 0 < ‚Äñùëá ‚àí ùëÜ‚Äñ < ùúñ. 10 Suppose dim ùëâ > 1and ùëá ‚àà ‚Ñí(ùëâ) is not invertible. Prove that for every ùúñ > 0, there exists ùëÜ ‚àà ‚Ñí(ùëâ) such that 0 < ‚Äñùëá ‚àí ùëÜ‚Äñ < ùúñand ùëÜ is not invertible. 11 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Prove that for every ùúñ > 0there exists a diagonalizable operator ùëÜ ‚àà ‚Ñí(ùëâ) such that 0 < ‚Äñùëá ‚àí ùëÜ‚Äñ < ùúñ. 12 Suppose ùëá ‚àà ‚Ñí(ùëâ) is a positive operator. Show that ‚à•‚àöùëá ‚à• = ‚àö‚Äñùëá‚Äñ. 13 Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) are positive operators. Show that ‚ÄñùëÜ ‚àí ùëá‚Äñ ‚â§max{‚ÄñùëÜ‚Äñ, ‚Äñùëá‚Äñ}‚â§ ‚ÄñùëÜ+ ùëá‚Äñ. 14 Suppose ùëà and ùëä are subspaces of ùëâ such that ‚ÄñùëÉùëà ‚àí ùëÉùëä‚Äñ < 1. Prove that dim ùëà = dim ùëä. Section 7F Consequences of Singular Value Decomposition 295 15 Defineùëá ‚àà ‚Ñí(ùêÖ3)by ùëá(ùëß1, ùëß2, ùëß3) = (ùëß3, 2ùëß1, 3ùëß2). Find (explicitly) a unitary operator ùëÜ ‚àà ‚Ñí(ùêÖ3)such that ùëá = ùëÜ‚àöùëá‚àóùëá. 16 Suppose ùëÜ ‚àà ‚Ñí(ùëâ) is a positive invertible operator. Prove that there exists ùõø > 0such that ùëá is a positive operator for every self-adjoint operator ùëá ‚àà ‚Ñí(ùëâ) with ‚ÄñùëÜ ‚àí ùëá‚Äñ < ùõø. 17 Prove that if ùë¢ ‚àà ùëâ and ùúëùë¢ is the linear functional on ùëâ defined by the equation ùúëùë¢(ùë£) = ‚ü®ùë£, ùë¢‚ü©, then ‚Äñùúëùë¢‚Äñ = ‚Äñùë¢‚Äñ. Here we are thinking of the scalar field ùêÖ as an inner product space with ‚ü®ùõº, ùõΩ‚ü© = ùõºùõΩfor all ùõº, ùõΩ ‚àà ùêÖ. Thus ‚Äñùúëùë¢‚Äñ means the norm of ùúëùë¢ as a linear map from ùëâ to ùêÖ. 18 Suppose ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ and ùëá ‚àà ‚Ñí(ùëâ, ùëä). (a) Prove that max{‚Äñùëáùëí1‚Äñ, ‚Ä¶, ‚Äñùëáùëíùëõ‚Äñ} ‚â§ ‚Äñùëá‚Äñ ‚â§(‚Äñùëáùëí1‚Äñ2 + ‚ãØ + ‚Äñùëáùëíùëõ‚Äñ2) 1/2. (b) Prove that ‚Äñùëá‚Äñ = (‚Äñùëáùëí1‚Äñ2 +‚ãØ+‚Äñùëáùëíùëõ‚Äñ2) 1/2 if and only if dim range ùëá ‚â§ 1. Here ùëí1, ‚Ä¶, ùëíùëõ is an arbitrary orthonormal basis of ùëâ, not necessarily con- nected with a singular value decomposition of ùëá. If ùë†1, ‚Ä¶, ùë†ùëõ is the list of singular values of ùëá, then the right side of the inequality above equals (ùë†1 2 + ‚ãØ + ùë†ùëõ 2) 1/2, as was shown in Exercise 11(a) in Section 7E. 19 Prove that if ùëá ‚àà ‚Ñí(ùëâ, ùëä), then ‚à•ùëá‚àóùëá‚à• = ‚Äñùëá‚Äñ2. This formula for ‚à•ùëá‚àóùëá‚à• leads to the important subject of ùê∂‚àó-algebras. 20 Suppose ùëá ‚àà ‚Ñí(ùëâ) is normal. Prove that ‚à•ùëáùëò‚à• = ‚Äñùëá‚Äñ ùëò for every positive integer ùëò. 21 Suppose dim ùëâ > 1and dim ùëä > 1. Prove that the norm on ‚Ñí(ùëâ, ùëä) does not come from an inner product. In other words, prove that there does not exist an inner product on ‚Ñí(ùëâ, ùëä) such that max{‚Äñùëáùë£‚Äñ ‚à∂ ùë£ ‚àà ùëâ and ‚Äñùë£‚Äñ ‚â§ 1}= ‚àö‚ü®ùëá, ùëá‚ü© for all ùëá ‚àà ‚Ñí(ùëâ, ùëä). 22 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Let ùëõ = dim ùëâ and let ùë†1 ‚â• ‚ãØ ‚â• ùë†ùëõ denote the singular values of ùëá. Prove that if 1 ‚â§ ùëò ‚â§ ùëõ, then min{‚Äñùëá|ùëà‚Äñ ‚à∂ ùëà is a subspace of ùëâ with dim ùëà = ùëò}= ùë†ùëõ ‚àí ùëò + 1. 23 Suppose ùëá ‚àà ‚Ñí(ùëâ, ùëä). Show that ùëá is uniformly continuous with respect to the metrics on ùëâ and ùëä that arise from the norms on those spaces (see Exercise 23 in Section 6B). 24 Suppose ùëá ‚àà ‚Ñí(ùëâ) is invertible. Prove that ‚à•ùëá‚àí1‚à• = ‚Äñùëá‚Äñ‚àí1 ‚ü∫ ùëá ‚Äñùëá‚Äñ is a unitary operator. 296 Chapter 7 Operators on Inner Product Spaces 25 Fix ùë¢, ùë• ‚àà ùëâ with ùë¢ ‚â† 0. Defineùëá ‚àà ‚Ñí(ùëâ) by ùëáùë£ = ‚ü®ùë£, ùë¢‚ü©ùë•for every ùë£ ‚àà ùëâ. Prove that ‚àöùëá‚àóùëáùë£ = ‚Äñùë•‚Äñ ‚Äñùë¢‚Äñ ‚ü®ùë£, ùë¢‚ü©ùë¢ for every ùë£ ‚àà ùëâ. 26 Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is invertible if and only if there exists a unique unitary operator ùëÜ ‚àà ‚Ñí(ùëâ) such that ùëá = ùëÜ‚àöùëá‚àóùëá. 27 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùë†1, ‚Ä¶, ùë†ùëõ are the singular values of ùëá. Let ùëí1, ‚Ä¶, ùëíùëõ and ùëì1, ‚Ä¶, ùëìùëõ be orthonormal bases of ùëâ such that ùëáùë£ = ùë†1‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ùë†ùëõ‚ü®ùë£, ùëíùëõ‚ü© ùëìùëõ for all ùë£ ‚àà ùëâ. DefineùëÜ ‚àà ‚Ñí(ùëâ) by ùëÜùë£ = ‚ü®ùë£, ùëí1‚ü© ùëì1 + ‚ãØ + ‚ü®ùë£, ùëíùëõ‚ü© ùëìùëõ. (a) Show that ùëÜ is unitary and ‚Äñùëá ‚àí ùëÜ‚Äñ = max{|ùë†1 ‚àí 1|, ‚Ä¶, |ùë†ùëõ ‚àí 1|}. (b) Show that if ùê∏ ‚àà ‚Ñí(ùëâ) is unitary, then ‚Äñùëá ‚àí ùê∏‚Äñ ‚â• ‚Äñùëá ‚àí ùëÜ‚Äñ. This exercise finds a unitary operator ùëÜ that is as close as possible (among the unitary operators) to a given operator ùëá. 28 Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that there exists a unitary operator ùëÜ ‚àà ‚Ñí(ùëâ) such that ùëá = ‚àöùëáùëá‚àó ùëÜ. 29 Suppose ùëá ‚àà ‚Ñí(ùëâ). (a) Use the polar decomposition to show that there exists a unitary operator ùëÜ ‚àà ‚Ñí(ùëâ) such that ùëáùëá‚àó = ùëÜùëá‚àóùëáùëÜ‚àó. (b) Show how (a) implies that ùëá and ùëá‚àó have the same singular values. 30 Suppose ùëá ‚àà ‚Ñí(ùëâ), ùëÜ ‚àà ‚Ñí(ùëâ) is a unitary operator, and ùëÖ ‚àà ‚Ñí(ùëâ) is a positive operator such that ùëá = ùëÜùëÖ. Prove that ùëÖ = ‚àöùëá‚àóùëá. This exercise shows that if we write ùëá as the product of a unitary operator and a positive operator (as in the polar decomposition 7.93), then the positive operator equals ‚àöùëá‚àóùëá. 31 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ) is normal. Prove that there exists a unitary operator ùëÜ ‚àà ‚Ñí(ùëâ) such that ùëá = ùëÜ‚àöùëá‚àóùëá and such that ùëÜ and ‚àöùëá‚àóùëá both have diagonal matrices with respect to the same orthonormal basis of ùëâ. 32 Suppose that ùëá ‚àà ‚Ñí(ùëâ, ùëä) and ùëá ‚â† 0. Let ùë†1, ‚Ä¶, ùë†ùëö denote the positive singular values of ùëá. Show that there exists an orthonormal basis ùëí1, ‚Ä¶, ùëíùëö of (null ùëá) ‚üÇ such that ùëá(ùê∏( ùëí1 ùë†1 , ‚Ä¶, ùëíùëö ùë†ùëö )) equals the ball in range ùëá of radius 1centered at 0. Chapter 8 Operators on Complex Vector Spaces In this chapter we delve deeper into the structure of operators, with most of the attention on complex vector spaces. Some of the results in this chapter apply to both real and complex vector spaces; thus we do not make a standing assumption that ùêÖ = ùêÇ. Also, an inner product does not help with this material, so we return to the general setting of a finite-dimensional vector space. Even on a finite-dimensional complex vector space, an operator may not have enough eigenvectors to form a basis of the vector space. Thus we will consider the closely related objects called generalized eigenvectors. We will see that for each operator on a finite-dimensional complex vector space, there is a basis of the vector space consisting of generalized eigenvectors of the operator. The generalized eigenspace decomposition then provides a good description of arbitrary operators on a finite-dimensional complex vector space. Nilpotent operators, which are operators that when raised to some power equal 0, have an important role in these investigations. Nilpotent operators provide a key tool in our proof that every invertible operator on a finite-dimensional complex vector space has a square root and in our approach to Jordan form. This chapter concludes by defining the trace and proving its key properties. standing assumptions for this chapter ‚Ä¢ ùêÖ denotes ùêë or ùêÇ. ‚Ä¢ ùëâ denotes a finite-dimensional nonzero vector space overùêÖ.DavidIliffCCBY-SA The Long Room of the Old Library at the University of Dublin, where William Hamilton (1805‚Äì1865) was a student and then a faculty member. Hamilton proved a special case of what we now call the Cayley‚ÄìHamilton theorem in 1853. 297 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0_8 ¬© Sheldon Axler 2024 298 Chapter 8 Operators on Complex Vector Spaces 8A Generalized Eigenvectors and Nilpotent Operators Null Spaces of Powers of an Operator We begin this chapter with a study of null spaces of powers of an operator. 8.1 sequence of increasing null spaces Suppose ùëá ‚àà ‚Ñí(ùëâ). Then {0} =null ùëá0 ‚äÜnull ùëá1 ‚äÜ ‚ãØ ‚äÜnull ùëáùëò ‚äÜnull ùëáùëò + 1 ‚äÜ ‚ãØ . Proof Suppose ùëò is a nonnegative integer and ùë£ ‚àà null ùëáùëò. Then ùëáùëòùë£ = 0, which implies that ùëáùëò + 1ùë£ = ùëá(ùëáùëòùë£)= ùëá(0) = 0. Thus ùë£ ‚àà null ùëáùëò + 1. Hence null ùëáùëò ‚äÜnull ùëáùëò + 1, as desired. For similar results about decreasing sequences of ranges, see Exercises 6, 7, and 8. The following result states that if two consecutive terms in the sequence of sub- spaces above are equal, then all later terms in the sequence are equal. 8.2 equality in the sequence of null spaces Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëö is a nonnegative integer such that null ùëáùëö = null ùëáùëö + 1. Then null ùëáùëö = null ùëáùëö + 1 = null ùëáùëö + 2 = null ùëáùëö + 3 = ‚ãØ . Proof Let ùëò be a positive integer. We want to prove that null ùëáùëö + ùëò = null ùëáùëö + ùëò + 1. We already know from 8.1 that null ùëáùëö + ùëò ‚äÜnull ùëáùëö + ùëò + 1. To prove the inclusion in the other direction, suppose ùë£ ‚àà null ùëáùëö + ùëò + 1. Then ùëáùëö + 1(ùëáùëòùë£)= ùëáùëö + ùëò + 1ùë£ = 0. Hence ùëáùëòùë£ ‚àà null ùëáùëö + 1 = null ùëáùëö. Thus ùëáùëö + ùëòùë£ = ùëáùëö(ùëáùëòùë£)= 0, which means that ùë£ ‚àà null ùëáùëö + ùëò. This implies that null ùëáùëö + ùëò + 1 ‚äÜnull ùëáùëö + ùëò, completing the proof. The result above raises the question of whether there exists a nonnegative integer ùëö such that null ùëáùëö = null ùëáùëö + 1. The next result shows that this equality holds at least when ùëö equals the dimension of the vector space on which ùëá operates. Section 8A Generalized Eigenvectors and Nilpotent Operators 299 8.3 null spaces stop growing Suppose ùëá ‚àà ‚Ñí(ùëâ). Then null ùëádim ùëâ = null ùëádim ùëâ + 1 = null ùëádim ùëâ + 2 = ‚ãØ . Proof We only need to prove that null ùëádim ùëâ = null ùëádim ùëâ + 1 (by 8.2). Suppose this is not true. Then, by 8.1 and 8.2, we have {0} =null ùëá0 ‚ää null ùëá1 ‚ää ‚ãØ ‚ää null ùëádim ùëâ ‚ää null ùëádim ùëâ + 1, where the symbol ‚ää means ‚Äúcontained in but not equal to‚Äù. At each of the strict inclusions in the chain above, the dimension increases by at least 1. Thus dim null ùëádim ùëâ + 1 ‚â•dim ùëâ + 1, a contradiction because a subspace of ùëâ cannot have a larger dimension than dim ùëâ. It is not true that ùëâ = null ùëá ‚äï range ùëá for every ùëá ‚àà ‚Ñí(ùëâ). However, the next result can be a useful substitute. 8.4 ùëâ is the direct sum of null ùëádim ùëâ and range ùëádim ùëâ Suppose ùëá ‚àà ‚Ñí(ùëâ). Then ùëâ = null ùëádim ùëâ ‚äï range ùëádim ùëâ. Proof Let ùëõ = dim ùëâ. First we show that 8.5 (null ùëáùëõ)‚à©(range ùëáùëõ)= {0}. Suppose ùë£ ‚àà (null ùëáùëõ)‚à©(range ùëáùëõ). Then ùëáùëõùë£ = 0, and there exists ùë¢ ‚àà ùëâ such that ùë£ = ùëáùëõùë¢. Applying ùëáùëõ to both sides of the last equation shows that ùëáùëõùë£ = ùëá2ùëõùë¢. Hence ùëá2ùëõùë¢ = 0, which implies that ùëáùëõùë¢ = 0(by 8.3). Thus ùë£ = ùëáùëõùë¢ = 0, completing the proof of 8.5. Now 8.5 implies that null ùëáùëõ + range ùëáùëõ is a direct sum (by 1.46). Also, dim(null ùëáùëõ ‚äï range ùëáùëõ)= dim null ùëáùëõ + dim range ùëáùëõ = dim ùëâ, where the first equality above comes from3.94 and the second equality comes from the fundamental theorem of linear maps (3.21). The equation above implies that null ùëáùëõ ‚äï range ùëáùëõ = ùëâ (see 2.39), as desired. For an improvement of the result above, see Exercise 19. 8.6 example:ùêÖ3 = null ùëá3 ‚äï range ùëá3 for ùëá ‚àà ‚Ñí(ùêÖ3) Suppose ùëá ‚àà ‚Ñí(ùêÖ3)is defined by ùëá(ùëß1, ùëß2, ùëß3) = (4ùëß2, 0, 5ùëß3). 300 Chapter 8 Operators on Complex Vector Spaces Then null ùëá = {(ùëß1, 0, 0)‚à∂ ùëß1 ‚àà ùêÖ}and range ùëá = {(ùëß1, 0, ùëß3) ‚à∂ ùëß1, ùëß3 ‚àà ùêÖ}. Thus null ùëá ‚à©range ùëá ‚â† {0}. Hence null ùëá + range ùëá is not a direct sum. Also note that null ùëá + range ùëá ‚â† ùêÖ3. However, we have ùëá3(ùëß1, ùëß2, ùëß3) = (0, 0, 125ùëß3). Thus we see that null ùëá3 = {(ùëß1, ùëß2, 0)‚à∂ ùëß1, ùëß2 ‚àà ùêÖ} and range ùëá3 = {(0, 0, ùëß3) ‚à∂ ùëß3 ‚àà ùêÖ}. Hence ùêÖ3 = null ùëá3 ‚äï range ùëá3, as expected by 8.4. Generalized Eigenvectors Some operators do not have enough eigenvectors to lead to good descriptions of their behavior. Thus in this subsection we introduce the concept of generalized eigenvectors, which will play a major role in our description of the structure of an operator. To understand why we need more than eigenvectors, let‚Äôs examine the question of describing an operator by decomposing its domain into invariant subspaces. Fix ùëá ‚àà ‚Ñí(ùëâ). We seek to describe ùëá by finding a ‚Äúnice‚Äù direct sum decomposition ùëâ = ùëâ1 ‚äï ‚ãØ ‚äï ùëâùëö, where each ùëâùëò is a subspace of ùëâ invariant under ùëá. The simplest possible nonzero invariant subspaces are one-dimensional. A decomposition as above in which each ùëâùëò is a one-dimensional subspace of ùëâ invariant under ùëá is possible if and only if ùëâ has a basis consisting of eigenvectors of ùëá (see 5.55). This happens if and only if ùëâ has an eigenspace decomposition 8.7 ùëâ = ùê∏(ùúÜ1, ùëá) ‚äï ‚ãØ ‚äï ùê∏(ùúÜùëö, ùëá), where ùúÜ1, ‚Ä¶, ùúÜùëö are the distinct eigenvalues of ùëá (see 5.55). The spectral theorem in the previous chapter shows that if ùëâ is an inner product space, then a decomposition of the form 8.7 holds for every self-adjoint operator if ùêÖ = ùêë and for every normal operator if ùêÖ = ùêÇ because operators of those types have enough eigenvectors to form a basis of ùëâ (see 7.29 and 7.31). However, a decomposition of the form 8.7 may not hold for more general operators, even on a complex vector space. An example was given by the operator in 5.57, which does not have enough eigenvectors for 8.7 to hold. Generalized eigenvectors and generalized eigenspaces, which we now introduce, will remedy this situation. 8.8 definition: generalized eigenvector Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ is an eigenvalue of ùëá. A vector ùë£ ‚àà ùëâ is called a generalized eigenvector of ùëá corresponding to ùúÜ if ùë£ ‚â† 0and (ùëá ‚àí ùúÜùêº)ùëòùë£ = 0 for some positive integer ùëò. Section 8A Generalized Eigenvectors and Nilpotent Operators 301 Generalized eigenvalues are not de- fined because doing so would not lead to anything new. Reason: if (ùëá ‚àí ùúÜùêº)ùëò is not injective for some positive inte- ger ùëò, then ùëá ‚àí ùúÜùêº is not injective, and hence ùúÜ is an eigenvalue of ùëá. A nonzero vector ùë£ ‚àà ùëâ is a general- ized eigenvector of ùëá corresponding to ùúÜ if and only if (ùëá ‚àí ùúÜùêº)dim ùëâùë£ = 0, as follows from applying 8.1 and 8.3 to the operator ùëá ‚àí ùúÜùêº. As we know, an operator on a complex vector space may not have enough eigenvectors to form a basis of the domain. The next result shows that on a complex vector space there are enough generalized eigenvectors to do this. 8.9 a basis of generalized eigenvectors Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Then there is a basis of ùëâ consisting of generalized eigenvectors of ùëá. Proof Let ùëõ = dim ùëâ. We will use induction on ùëõ. To get started, note that the desired result holds if ùëõ = 1because then every nonzero vector in ùëâ is an eigenvector of ùëá. This step is where we use the hypothesis that ùêÖ = ùêÇ, because if ùêÖ = ùêë then ùëá may not have any eigenvalues. Now suppose ùëõ > 1and the de- sired result holds for all smaller values of dim ùëâ. Let ùúÜ be an eigenvalue of ùëá. Applying 8.4 to ùëá ‚àí ùúÜùêº shows that ùëâ = null(ùëá ‚àí ùúÜùêº)ùëõ ‚äï range(ùëá ‚àí ùúÜùêº)ùëõ. If null(ùëá ‚àí ùúÜùêº)ùëõ = ùëâ, then every nonzero vector in ùëâ is a generalized eigen- vector of ùëá, and thus in this case there is a basis of ùëâ consisting of generalized eigenvectors of ùëá. Hence we can assume that null(ùëá ‚àí ùúÜùêº)ùëõ ‚â† ùëâ, which implies that range(ùëá ‚àí ùúÜùêº)ùëõ ‚â† {0}. Also, null(ùëá ‚àí ùúÜùêº)ùëõ ‚â† {0}, because ùúÜ is an eigenvalue of ùëá. Thus we have 0 <dim range(ùëá ‚àí ùúÜùêº) ùëõ < ùëõ. Furthermore, range(ùëá ‚àí ùúÜùêº)ùëõ is invariant under ùëá [by 5.18 with ùëù(ùëß) = (ùëß ‚àí ùúÜ)ùëõ]. Let ùëÜ ‚àà ‚Ñí(range(ùëá ‚àí ùúÜùêº)ùëõ)equal ùëá restricted to range(ùëá ‚àí ùúÜùêº)ùëõ. Our induction hypothesis applied to the operator ùëÜ implies that there is a basis of range(ùëá ‚àí ùúÜùêº)ùëõ consisting of generalized eigenvectors of ùëÜ, which of course are generalized eigenvectors of ùëá. Adjoining that basis of range(ùëá‚àíùúÜùêº)ùëõ to a basis of null(ùëá‚àíùúÜùêº)ùëõ gives a basis of ùëâ consisting of generalized eigenvectors of ùëá. If ùêÖ = ùêë and dim ùëâ > 1, then some operators on ùëâ have the property that there exists a basis of ùëâ consisting of generalized eigenvectors of the operator, and (unlike what happens when ùêÖ = ùêÇ) other operators do not have this property. See Exercise 11 for a necessary and sufficient condition that determines whether an operator has this property. 302 Chapter 8 Operators on Complex Vector Spaces 8.10 example: generalized eigenvectors of an operator on ùêÇ 3 Defineùëá ‚àà ‚Ñí(ùêÇ 3)by ùëá(ùëß1, ùëß2, ùëß3) = (4ùëß2, 0, 5ùëß3) for each (ùëß1, ùëß2, ùëß3) ‚àà ùêÇ3. A routine use of the definition of eigenvalue shows that the eigenvalues of ùëá are 0and 5. Furthermore, the eigenvectors corresponding to the eigenvalue 0are the nonzero vectors of the form (ùëß1, 0, 0), and the eigenvectors corresponding to the eigenvalue 5are the nonzero vectors of the form (0, 0, ùëß3). Hence this operator does not have enough eigenvectors to span its domain ùêÇ 3. We compute that ùëá3(ùëß1, ùëß2, ùëß3) = (0, 0, 125ùëß3). Thus 8.1 and 8.3 imply that the generalized eigenvectors of ùëá corresponding to the eigenvalue 0are the nonzero vectors of the form (ùëß1, ùëß2, 0). We also have (ùëá ‚àí 5ùêº) 3(ùëß1, ùëß2, ùëß3) = (‚àí125ùëß1 + 300ùëß2, ‚àí125ùëß2, 0). Thus the generalized eigenvectors of ùëá corresponding to the eigenvalue 5are the nonzero vectors of the form (0, 0, ùëß3). The paragraphs above show that each of the standard basis vectors of ùêÇ 3 is a generalized eigenvector of ùëá. Thus ùêÇ 3 indeed has a basis consisting of generalized eigenvectors of ùëá, as promised by 8.9. If ùë£ is an eigenvector of ùëá ‚àà ‚Ñí(ùëâ), then the corresponding eigenvalue ùúÜ is uniquely determined by the equation ùëáùë£ = ùúÜùë£, which can be satisfied by only one ùúÜ ‚àà ùêÖ (because ùë£ ‚â† 0). However, if ùë£ is a generalized eigenvector of ùëá, then it is not obvious that the equation (ùëá ‚àí ùúÜùêº) dim ùëâùë£ = 0can be satisfied by only one ùúÜ ‚àà ùêÖ. Fortunately, the next result tells us that all is well on this issue. 8.11 generalized eigenvector corresponds to a unique eigenvalue Suppose ùëá ‚àà ‚Ñí(ùëâ). Then each generalized eigenvector of ùëá corresponds to only one eigenvalue of ùëá. Proof Suppose ùë£ ‚àà ùëâ is a generalized eigenvector of ùëá corresponding to eigen- values ùõº and ùúÜ of ùëá. Let ùëö be the smallest positive integer such that (ùëá‚àíùõºùêº)ùëöùë£ = 0. Let ùëõ = dim ùëâ. Then 0 = (ùëá ‚àí ùúÜùêº) ùëõùë£ = ((ùëá ‚àí ùõºùêº) + (ùõº ‚àí ùúÜ)ùêº) ùëõùë£ = ùëõ ‚àë ùëò = 0 ùëèùëò(ùõº ‚àí ùúÜ)ùëõ ‚àí ùëò(ùëá ‚àí ùõºùêº)ùëòùë£, where ùëè0 = 1and the values of the other binomial coefficients ùëèùëò do not matter. Apply the operator (ùëá ‚àí ùõºùêº)ùëö ‚àí 1 to both sides of the equation above, getting 0 = (ùõº ‚àí ùúÜ) ùëõ(ùëá ‚àí ùõºùêº)ùëö ‚àí 1ùë£. Because (ùëá ‚àí ùõºùêº)ùëö ‚àí 1ùë£ ‚â† 0, the equation above implies that ùõº = ùúÜ, as desired. Section 8A Generalized Eigenvectors and Nilpotent Operators 303 We saw earlier (5.11) that eigenvectors corresponding to distinct eigenvalues are linearly independent. Now we prove a similar result for generalized eigen- vectors, with a proof that roughly follows the pattern of the proof of that earlier result. 8.12 linearly independent generalized eigenvectors Suppose that ùëá ‚àà ‚Ñí(ùëâ). Then every list of generalized eigenvectors of ùëá corresponding to distinct eigenvalues of ùëá is linearly independent. Proof Suppose the desired result is false. Then there exists a smallest positive integer ùëö such that there exists a linearly dependent list ùë£1, ‚Ä¶, ùë£ùëö of generalized eigenvectors of ùëá corresponding to distinct eigenvalues ùúÜ1, ‚Ä¶, ùúÜùëö of ùëá (note that ùëö ‚â• 2because a generalized eigenvector is, by definition, nonzero). Thus there exist ùëé1, ‚Ä¶, ùëéùëö ‚àà ùêÖ, none of which are 0(because of the minimality of ùëö), such that ùëé1ùë£1 + ‚ãØ + ùëéùëöùë£ùëö = 0. Let ùëõ = dim ùëâ. Apply (ùëá ‚àí ùúÜùëöùêº) ùëõ to both sides of the equation above, getting 8.13 ùëé1(ùëá ‚àí ùúÜùëöùêº) ùëõùë£1 + ‚ãØ + ùëéùëö ‚àí 1(ùëá ‚àí ùúÜùëöùêº) ùëõùë£ùëö ‚àí 1 = 0. Suppose ùëò ‚àà {1, ‚Ä¶, ùëö ‚àí 1}. Then (ùëá ‚àí ùúÜùëöùêº) ùëõùë£ùëò ‚â† 0 because otherwise ùë£ùëò would be a generalized eigenvector of ùëá corresponding to the distinct eigenvalues ùúÜùëò and ùúÜùëö, which would contradict 8.11. However, (ùëá ‚àí ùúÜùëòùêº) ùëõ((ùëá ‚àí ùúÜùëöùêº) ùëõùë£ùëò)= (ùëá ‚àí ùúÜùëöùêº) ùëõ((ùëá ‚àí ùúÜùëòùêº) ùëõùë£ùëò)= 0. Thus the last two displayed equations show that (ùëá ‚àí ùúÜùëöùêº) ùëõùë£ùëò is a generalized eigenvector of ùëá corresponding to the eigenvalue ùúÜùëò. Hence (ùëá ‚àí ùúÜùëöùêº) ùëõùë£1, ‚Ä¶, (ùëá ‚àí ùúÜùëöùêº) ùëõùë£ùëö ‚àí 1 is a linearly dependent list (by 8.13) of ùëö ‚àí 1generalized eigenvectors correspond- ing to distinct eigenvalues, contradicting the minimality of ùëö. This contradiction completes the proof. Nilpotent Operators 8.14 definition: nilpotent An operator is called nilpotent if some power of it equals 0. Thus an operator on ùëâ is nilpotent if every nonzero vector in ùëâ is a generalized eigenvector of ùëá corresponding to the eigenvalue 0. 304 Chapter 8 Operators on Complex Vector Spaces 8.15 example: nilpotent operators (a) The operator ùëá ‚àà ‚Ñí(ùêÖ4)defined by ùëá(ùëß1, ùëß2, ùëß3, ùëß4) = (0, 0, ùëß1, ùëß2) is nilpotent because ùëá2 = 0. (b) The operator on ùêÖ3 whose matrix (with respect to the standard basis) is ‚éõ‚éú‚éú‚éú ‚éù ‚àí3 9 0 ‚àí7 9 6 4 0 ‚àí6 ‚éû‚éü‚éü‚éü ‚é† is nilpotent, as can be shown by cubing the matrix above to get the zero matrix. (c) The operator of differentiation on ùí´ùëö(ùêë) is nilpotent because the (ùëö + 1) th derivative of every polynomial of degree at most ùëö equals 0. Note that on this space of dimension ùëö + 1, we need to raise the nilpotent operator to the power ùëö + 1to get the 0operator. The Latin word nil means nothing or zero; the Latin word potens means having power. Thus nilpotent literally means having a power that is zero. The next result shows that when rais- ing a nilpotent operator to a power, we never need to use a power higher than the dimension of the space. For a slightly stronger result, see Exercise 18. 8.16 nilpotent operator raised to dimension of domain is 0 Suppose ùëá ‚àà ‚Ñí(ùëâ) is nilpotent. Then ùëádim ùëâ = 0. Proof Because ùëá is nilpotent, there exists a positive integer ùëò such that ùëáùëò = 0. Thus null ùëáùëò = ùëâ. Now 8.1 and 8.3 imply that null ùëádim ùëâ = ùëâ. Thus ùëádim ùëâ = 0. 8.17 eigenvalues of nilpotent operator Suppose ùëá ‚àà ‚Ñí(ùëâ). (a) If ùëá is nilpotent, then 0is an eigenvalue of ùëá and ùëá has no other eigenvalues. (b) If ùêÖ = ùêÇ and 0is the only eigenvalue of ùëá, then ùëá is nilpotent. Proof (a) To prove (a), suppose ùëá is nilpotent. Hence there is a positive integer ùëö such that ùëáùëö = 0. This implies that ùëá is not injective. Thus 0is an eigenvalue of ùëá. Section 8A Generalized Eigenvectors and Nilpotent Operators 305 To show that ùëá has no other eigenvalues, suppose ùúÜ is an eigenvalue of ùëá. Then there exists a nonzero vector ùë£ ‚àà ùëâ such that ùúÜùë£ = ùëáùë£. Repeatedly applying ùëá to both sides of this equation shows that ùúÜ ùëöùë£ = ùëáùëöùë£ = 0. Thus ùúÜ = 0, as desired. (b) Suppose ùêÖ = ùêÇ and 0is the only eigenvalue of ùëá. By 5.27(b), the minimal polynomial of ùëá equals ùëßùëö for some positive integer ùëö. Thus ùëáùëö = 0. Hence ùëá is nilpotent. Exercise 23 shows that the hypothesis that ùêÖ = ùêÇ cannot be deleted in (b) of the result above. Given an operator on ùëâ, we want to find a basis ofùëâ such that the matrix of the operator with respect to this basis is as simple as possible, meaning that the matrix contains many 0‚Äôs. The next result shows that if ùëá is nilpotent, then we can choose a basis of ùëâ such that the matrix of ùëá with respect to this basis has more than half of its entries equal to 0. Later in this chapter we will do even better. 8.18 minimal polynomial and upper-triangular matrix of nilpotent operator Suppose ùëá ‚àà ‚Ñí(ùëâ). Then the following are equivalent. (a) ùëá is nilpotent. (b) The minimal polynomial of ùëá is ùëßùëö for some positive integer ùëö. (c) There is a basis of ùëâ with respect to which the matrix of ùëá has the form ‚éõ‚éú‚éú‚éú ‚éù 0 ‚àó ‚ã± 0 0 ‚éû‚éü‚éü‚éü ‚é† , where all entries on and below the diagonal equal 0. Proof Suppose (a) holds, so ùëá is nilpotent. Thus there exists a positive integer ùëõ such that ùëáùëõ = 0. Now 5.29 implies that ùëßùëõ is a polynomial multiple of the minimal polynomial of ùëá. Thus the minimal polynomial of ùëá is ùëßùëö for some positive integer ùëö, proving that (a) implies (b). Now suppose (b) holds, so the minimal polynomial of ùëá is ùëß ùëö for some positive integer ùëö. This implies, by 5.27(a), that 0(which is the only zero of ùëß ùëö)is the only eigenvalue of ùëá. This further implies, by 5.44, that there is a basis of ùëâ with respect to which the matrix of ùëá is upper triangular. This also implies, by 5.41, that all entries on the diagonal of this matrix are 0, proving that (b) implies (c). Now suppose (c) holds. Then 5.40 implies that ùëádim ùëâ = 0. Thus ùëá is nilpotent, proving that (c) implies (a). 306 Chapter 8 Operators on Complex Vector Spaces Exercises 8A 1 Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that if dim null ùëá4 = 8and dim null ùëá6 = 9, then dim null ùëáùëö = 9for all integers ùëö ‚â• 5. 2 Suppose ùëá ‚àà ‚Ñí(ùëâ), ùëö is a positive integer, ùë£ ‚àà ùëâ, and ùëáùëö ‚àí 1ùë£ ‚â† 0but ùëáùëöùë£ = 0. Prove that ùë£, ùëáùë£, ùëá2ùë£, ‚Ä¶, ùëáùëö ‚àí 1ùë£ is linearly independent. The result in this exercise is used in the proof of 8.45. 3 Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëâ = null ùëá ‚äï range ùëá ‚ü∫ null ùëá2 = null ùëá. 4 Suppose ùëá ‚àà ‚Ñí(ùëâ), ùúÜ ‚àà ùêÖ, and ùëö is a positive integer such that the minimal polynomial of ùëá is a polynomial multiple of (ùëß ‚àí ùúÜ)ùëö. Prove that dim null(ùëá ‚àí ùúÜùêº)ùëö ‚â• ùëö. 5 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëö is a positive integer. Prove that dim null ùëáùëö ‚â§ ùëödim null ùëá. Hint: Exercise 21 in Section 3B may be useful. 6 Suppose ùëá ‚àà ‚Ñí(ùëâ). Show that ùëâ = range ùëá0 ‚äárange ùëá1 ‚äá ‚ãØ ‚äárange ùëáùëò ‚äárange ùëáùëò + 1 ‚äá ‚ãØ . 7 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëö is a nonnegative integer such that range ùëáùëö = range ùëáùëö + 1. Prove that range ùëáùëò = range ùëáùëö for all ùëò > ùëö. 8 Suppose ùëá ‚àà ‚Ñí(ùëâ). Prove that range ùëádim ùëâ = range ùëádim ùëâ + 1 = range ùëádim ùëâ + 2 = ‚ãØ . 9 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëö is a nonnegative integer. Prove that null ùëáùëö = null ùëáùëö + 1 ‚ü∫ range ùëáùëö = range ùëáùëö + 1. 10 Defineùëá ‚àà ‚Ñí(ùêÇ 2)by ùëá(ùë§, ùëß) = (ùëß, 0). Find all generalized eigenvectors of ùëá. 11 Suppose that ùëá ‚àà ‚Ñí(ùëâ). Prove that there is a basis of ùëâ consisting of generalized eigenvectors of ùëá if and only if the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëö) for some ùúÜ1, ‚Ä¶, ùúÜùëö ‚àà ùêÖ. Assume ùêÖ = ùêë because the case ùêÖ = ùêÇ follows from 5.27(b) and 8.9. This exercise states that the condition for there to be a basis of ùëâ consisting of generalized eigenvectors of ùëá is the same as the condition for there to be a basis with respect to which ùëá has an upper-triangular matrix (see 5.44). Caution: If ùëá has an upper-triangular matrix with respect to a basis ùë£1, ‚Ä¶, ùë£ùëõ of ùëâ, then ùë£1 is an eigenvector of ùëá but it is not necessarily true that ùë£2, ‚Ä¶, ùë£ùëõ are generalized eigenvectors of ùëá. Section 8A Generalized Eigenvectors and Nilpotent Operators 307 12 Suppose ùëá ‚àà ‚Ñí(ùëâ) is such that every vector in ùëâ is a generalized eigenvector of ùëá. Prove that there exists ùúÜ ‚àà ùêÖ such that ùëá ‚àí ùúÜùêº is nilpotent. 13 Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) and ùëÜùëá is nilpotent. Prove that ùëáùëÜ is nilpotent. 14 Suppose ùëá ‚àà ‚Ñí(ùëâ) is nilpotent and ùëá ‚â† 0. Prove ùëá is not diagonalizable. 15 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Prove that ùëá is diagonalizable if and only if every generalized eigenvector of ùëá is an eigenvector of ùëá. For ùêÖ = ùêÇ, this exercise adds another equivalence to the list of conditions for diagonalizability in 5.55. 16 (a) Give an example of nilpotent operators ùëÜ, ùëá on the same vector space such that neither ùëÜ + ùëá nor ùëÜùëá is nilpotent. (b) Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) are nilpotent and ùëÜùëá = ùëáùëÜ. Prove that ùëÜ + ùëá and ùëÜùëá are nilpotent. 17 Suppose ùëá ‚àà ‚Ñí(ùëâ) is nilpotent and ùëö is a positive integer such that ùëáùëö = 0. (a) Prove that ùêº ‚àí ùëá is invertible and that (ùêº ‚àí ùëá)‚àí1 = ùêº + ùëá + ‚ãØ + ùëáùëö ‚àí 1. (b) Explain how you would guess the formula above. 18 Suppose ùëá ‚àà ‚Ñí(ùëâ) is nilpotent. Prove that ùëá1 + dim range ùëá = 0. If dim range ùëá < dim ùëâ ‚àí 1, then this exercise improves 8.16. 19 Suppose ùëá ‚àà ‚Ñí(ùëâ) is not nilpotent. Show that ùëâ = null ùëádim ùëâ ‚àí 1 ‚äï range ùëádim ùëâ ‚àí 1. For operators that are not nilpotent, this exercise improves 8.4. 20 Suppose ùëâ is an inner product space and ùëá ‚àà ‚Ñí(ùëâ) is normal and nilpotent. Prove that ùëá = 0. 21 Suppose ùëá ‚àà ‚Ñí(ùëâ) is such that null ùëádim ùëâ ‚àí 1 ‚â† null ùëádim ùëâ. Prove that ùëá is nilpotent and that dim null ùëáùëò = ùëò for every integer ùëò with 0 ‚â§ ùëò ‚â§dim ùëâ. 22 Suppose ùëá ‚àà ‚Ñí(ùêÇ 5)is such that range ùëá4 ‚â† range ùëá5. Prove that ùëá is nilpotent. 23 Give an example of an operator ùëá on a finite-dimensional real vector space such that 0is the only eigenvalue of ùëá but ùëá is not nilpotent. This exercise shows that the implication (b) ‚üπ (a) in 8.17 does not hold without the hypothesis that ùêÖ = ùêÇ. 24 For each item in Example 8.15, find a basis of the domain vector space such that the matrix of the nilpotent operator with respect to that basis has the upper-triangular form promised by 8.18(c). 25 Suppose that ùëâ is an inner product space and ùëá ‚àà ‚Ñí(ùëâ) is nilpotent. Show that there is an orthonormal basis of ùëâ with respect to which the matrix of ùëá has the upper-triangular form promised by 8.18(c). 308 Chapter 8 Operators on Complex Vector Spaces 8B Generalized Eigenspace Decomposition Generalized Eigenspaces 8.19 definition: generalized eigenspace, ùê∫(ùúÜ, ùëá) Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ ‚àà ùêÖ. The generalized eigenspace of ùëá correspond- ing to ùúÜ, denoted by ùê∫(ùúÜ, ùëá), is defined by ùê∫(ùúÜ, ùëá) = {ùë£ ‚àà ùëâ ‚à∂ (ùëá ‚àí ùúÜùêº)ùëòùë£ = 0for some positive integer ùëò}. Thus ùê∫(ùúÜ, ùëá) is the set of generalized eigenvectors of ùëá corresponding to ùúÜ, along with the 0vector. Because every eigenvector of ùëá is a generalized eigenvector of ùëá (take ùëò = 1 in the definition of generalized eigenvector), each eigenspace is contained in the corresponding generalized eigenspace. In other words, if ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ ‚àà ùêÖ, then ùê∏(ùúÜ, ùëá) ‚äÜ ùê∫(ùúÜ, ùëá). The next result implies that if ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ ‚àà ùêÖ, then the generalized eigenspace ùê∫(ùúÜ, ùëá) is a subspace of ùëâ (because the null space of each linear map on ùëâ is a subspace of ùëâ). 8.20 description of generalized eigenspaces Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ ‚àà ùêÖ. Then ùê∫(ùúÜ, ùëá) = null(ùëá ‚àí ùúÜùêº)dim ùëâ. Proof Suppose ùë£ ‚àà null(ùëá ‚àí ùúÜùêº)dim ùëâ. The definitions implyùë£ ‚àà ùê∫(ùúÜ, ùëá). Thus ùê∫(ùúÜ, ùëá) ‚äánull(ùëá ‚àí ùúÜùêº)dim ùëâ. Conversely, suppose ùë£ ‚àà ùê∫(ùúÜ, ùëá). Thus there is a positive integer ùëò such that ùë£ ‚àà null(ùëá ‚àí ùúÜùêº)ùëò. From 8.1 and 8.3 (with ùëá ‚àí ùúÜùêº replacing ùëá), we get ùë£ ‚àà null(ùëá ‚àí ùúÜùêº)dim ùëâ. Thus ùê∫(ùúÜ, ùëá) ‚äÜnull(ùëá ‚àí ùúÜùêº)dim ùëâ, completing the proof. 8.21 example: generalized eigenspaces of an operator on ùêÇ 3 Defineùëá ‚àà ‚Ñí(ùêÇ 3)by ùëá(ùëß1, ùëß2, ùëß3) = (4ùëß2, 0, 5ùëß3). In Example 8.10, we saw that the eigenvalues of ùëá are 0and 5, and we found the corresponding sets of generalized eigenvectors. Taking the union of those sets with {0}, we have ùê∫(0, ùëá) = {(ùëß1, ùëß2, 0)‚à∂ ùëß1, ùëß2 ‚àà ùêÇ} and ùê∫(5, ùëá) = {(0, 0, ùëß3) ‚à∂ ùëß3 ‚àà ùêÇ}. Note that ùêÇ 3 = ùê∫(0, ùëá) ‚äï ùê∫(5, ùëá). Section 8B Generalized Eigenspace Decomposition 309 In Example 8.21, the domain space ùêÇ 3 is the direct sum of the generalized eigenspaces of the operator ùëá in that example. Our next result shows that this behavior holds in general. Specifically, the following major result shows that if ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ), then ùëâ is the direct sum of the generalized eigenspaces of ùëá, each of which is invariant under ùëá and on which ùëá is a nilpotent operator plus a scalar multiple of the identity. Thus the next result achieves our goal of decomposing ùëâ into invariant subspaces on which ùëá has a known behavior. As we will see, the proof follows from putting together what we have learned about generalized eigenspaces and then using our result that for each operator ùëá ‚àà ‚Ñí(ùëâ), there exists a basis of ùëâ consisting of generalized eigenvectors of ùëá. 8.22 generalized eigenspace decomposition Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Let ùúÜ1, ‚Ä¶, ùúÜùëö be the distinct eigenvalues of ùëá. Then (a) ùê∫(ùúÜùëò, ùëá) is invariant under ùëá for each ùëò = 1, ‚Ä¶, ùëö; (b) (ùëá ‚àí ùúÜùëòùêº)|ùê∫( ùúÜùëò, ùëá)is nilpotent for each ùëò = 1, ‚Ä¶, ùëö; (c) ùëâ = ùê∫(ùúÜ1, ùëá) ‚äï ‚ãØ ‚äï ùê∫(ùúÜùëö, ùëá). Proof (a) Suppose ùëò ‚àà {1, ‚Ä¶, ùëö}. Then 8.20 shows that ùê∫(ùúÜùëò, ùëá) = null(ùëá ‚àí ùúÜùëòùêº) dim ùëâ. Thus 5.18, with ùëù(ùëß) = (ùëß‚àí ùúÜùëò)dim ùëâ, implies that ùê∫(ùúÜùëò, ùëá) is invariant under ùëá, proving (a). (b) Suppose ùëò ‚àà {1, ‚Ä¶, ùëö}. If ùë£ ‚àà ùê∫(ùúÜùëò, ùëá), then (ùëá ‚àí ùúÜùëòùêº) dim ùëâùë£ = 0(by 8.20). Thus ((ùëá ‚àí ùúÜùëòùêº)|ùê∫( ùúÜùëò, ùëá)) dim ùëâ = 0. Hence (ùëá ‚àí ùúÜùëòùêº)|ùê∫( ùúÜùëò, ùëá)is nilpotent, proving (b). (c) To show that ùê∫(ùúÜ1, ùëá) + ‚ãØ + ùê∫(ùúÜùëö, ùëá) is a direct sum, suppose ùë£1 + ‚ãØ + ùë£ùëö = 0, where each ùë£ùëò is in ùê∫(ùúÜùëò, ùëá). Because generalized eigenvectors of ùëá cor- responding to distinct eigenvalues are linearly independent (by 8.12), this implies that each ùë£ùëò equals 0. Thus ùê∫(ùúÜ1, ùëá) + ‚ãØ + ùê∫(ùúÜùëö, ùëá) is a direct sum (by 1.45). Finally, each vector in ùëâ can be written as a finite sum of generalized eigen- vectors of ùëá (by 8.9). Thus ùëâ = ùê∫(ùúÜ1, ùëá) ‚äï ‚ãØ ‚äï ùê∫(ùúÜùëö, ùëá), proving (c). For the analogous result when ùêÖ = ùêë, see Exercise 8. 310 Chapter 8 Operators on Complex Vector Spaces Multiplicity of an Eigenvalue If ùëâ is a complex vector space and ùëá ‚àà ‚Ñí(ùëâ), then the decomposition of ùëâ pro- vided by the generalized eigenspace decomposition (8.22) can be a powerful tool. The dimensions of the subspaces involved in this decomposition are sufficiently important to get a name, which is given in the next definition. 8.23 definition: multiplicity ‚Ä¢ Suppose ùëá ‚àà ‚Ñí(ùëâ). The multiplicity of an eigenvalue ùúÜ of ùëá is defined to be the dimension of the corresponding generalized eigenspace ùê∫(ùúÜ, ùëá). ‚Ä¢ In other words, the multiplicity of an eigenvalue ùúÜ of ùëá equals dim null(ùëá ‚àí ùúÜùêº)dim ùëâ. The second bullet point above holds because ùê∫(ùúÜ, ùëá) = null(ùëá ‚àí ùúÜùêº) dim ùëâ (see 8.20). 8.24 example: multiplicity of each eigenvalue of an operator Suppose ùëá ‚àà ‚Ñí(ùêÇ 3)is defined by ùëá(ùëß1, ùëß2, ùëß3) = (6ùëß1 + 3ùëß2 + 4ùëß3, 6ùëß2 + 2ùëß3, 7ùëß3). The matrix of ùëá (with respect to the standard basis) is ‚éõ‚éú‚éú‚éú ‚éù 6 3 4 0 6 2 0 0 7 ‚éû‚éü‚éü‚éü ‚é† . The eigenvalues of ùëá are the diagonal entries 6and 7, as follows from 5.41. You can verify that the generalized eigenspaces of ùëá are as follows: ùê∫(6, ùëá) = span((1, 0, 0), (0, 1, 0)) and ùê∫(7, ùëá) = span((10, 2, 1)). In this example, the multiplicity of each eigenvalue equals the number of times that eigenvalue appears on the diago- nal of an upper-triangular matrix rep- resenting the operator. This behavior always happens, as we will see in 8.31. Thus the eigenvalue 6has multiplicity 2 and the eigenvalue 7has multiplicity 1. The direct sum ùêÇ 3 = ùê∫(6, ùëá) ‚äï ùê∫(7, ùëá) is the generalized eigenspace decom- position promised by 8.22. A basis of ùêÇ 3 consisting of generalized eigen- vectors of ùëá, as promised by 8.9, is (1, 0, 0), (0, 1, 0), (10, 2, 1). There does not exist a basis of ùêÇ 3 consisting of eigen- vectors of this operator. In the example above, the sum of the multiplicities of the eigenvalues of ùëá equals 3, which is the dimension of the domain of ùëá. The next result shows that this holds for all operators on finite-dimensional complex vector spaces. Section 8B Generalized Eigenspace Decomposition 311 8.25 sum of the multiplicities equals dim ùëâ Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Then the sum of the multiplicities of all eigenvalues of ùëá equals dim ùëâ. Proof The desired result follows from the generalized eigenspace decomposition (8.22) and the formula for the dimension of a direct sum (see 3.94). The terms algebraic multiplicity and geometric multiplicity are used in some books. In case you encounter this terminology, be aware that the algebraic multi- plicity is the same as the multiplicity defined here and the geometric multiplicity is the dimension of the corresponding eigenspace. In other words, if ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ is an eigenvalue of ùëá, then algebraic multiplicity of ùúÜ = dim null(ùëá ‚àí ùúÜùêº)dim ùëâ = dim ùê∫(ùúÜ, ùëá), geometric multiplicity of ùúÜ = dim null(ùëá ‚àí ùúÜùêº) = dim ùê∏(ùúÜ, ùëá). Note that as defined above, the algebraic multiplicity also has a geometric meaning as the dimension of a certain null space. The definition of multiplicity given here is cleaner than the traditional definition that involves determinants;9.62 implies that these definitions are equivalent. If ùëâ is an inner product space, ùëá ‚àà ‚Ñí(ùëâ) is normal, and ùúÜ is an eigenvalue of ùëá, then the algebraic multiplicity of ùúÜ equals the geometric multiplicity of ùúÜ, as can be seen from applying Exercise 27 in Section 7A to the normal operator ùëá ‚àí ùúÜùêº. As a special case, the singular values of ùëÜ ‚àà ‚Ñí(ùëâ, ùëä) (here ùëâ and ùëä are both finite-dimensional inner product spaces) depend on the multiplicities (either algebraic or geometric) of the eigenvalues of the self-adjoint operator ùëÜ‚àóùëÜ. The next definition associates a monic polynomial with each operator on a finite-dimensional complex vector space. 8.26 definition:characteristic polynomial Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Let ùúÜ1, ‚Ä¶, ùúÜùëö denote the distinct eigenvalues of ùëá, with multiplicities ùëë1, ‚Ä¶, ùëëùëö. The polynomial (ùëß ‚àí ùúÜ1) ùëë1‚ãØ(ùëß ‚àí ùúÜùëö) ùëëùëö is called the characteristic polynomial of ùëá. 8.27 example:the characteristic polynomial of an operator Suppose ùëá ‚àà ‚Ñí(ùêÇ 3)is defined as in Example8.24. Because the eigenvalues of ùëá are 6, with multiplicity 2, and 7, with multiplicity 1, we see that the characteristic polynomial of ùëá is (ùëß ‚àí 6) 2(ùëß ‚àí 7). 312 Chapter 8 Operators on Complex Vector Spaces 8.28 degree and zeros of characteristic polynomial Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Then (a) the characteristic polynomial of ùëá has degree dim ùëâ; (b) the zeros of the characteristic polynomial of ùëá are the eigenvalues of ùëá. Proof Our result about the sum of the multiplicities (8.25) implies (a). The definition of the characteristic polynomial implies (b). Most texts define the characteristic polynomial using determinants (the two definitions are equivalent by9.62). The approach taken here, which is considerably simpler, leads to the following nice proof of the Cayley‚ÄìHamilton theorem. 8.29 Cayley‚ÄìHamilton theorem Suppose ùêÖ = ùêÇ, ùëá ‚àà ‚Ñí(ùëâ), and ùëû is the characteristic polynomial of ùëá. Then ùëû(ùëá) = 0. Proof Let ùúÜ1, ‚Ä¶, ùúÜùëö be the distinct eigenvalues of ùëá, and let ùëëùëò = dim ùê∫(ùúÜùëò, ùëá). For each ùëò ‚àà {1, ‚Ä¶, ùëö}, we know that (ùëá ‚àí ùúÜùëòùêº)|ùê∫( ùúÜùëò, ùëá)is nilpotent. Thus we have Arthur Cayley (1821‚Äì1895) published three mathematics papers before com- pleting his undergraduate degree. (ùëá ‚àí ùúÜùëòùêº) ùëëùëò|ùê∫( ùúÜùëò, ùëá)= 0 (by 8.16) for each ùëò ‚àà {1, ‚Ä¶, ùëö}. The generalized eigenspace decom- position (8.22) states that every vector in ùëâ is a sum of vectors in ùê∫(ùúÜ1, ùëá), ‚Ä¶, ùê∫(ùúÜùëö, ùëá). Thus to prove that ùëû(ùëá) = 0, we only need to show that ùëû(ùëá)|ùê∫( ùúÜùëò, ùëá)= 0for each ùëò. Fix ùëò ‚àà {1, ‚Ä¶, ùëö}. We have ùëû(ùëá) = (ùëá ‚àí ùúÜ1ùêº) ùëë1‚ãØ(ùëá ‚àí ùúÜùëöùêº) ùëëùëö. The operators on the right side of the equation above all commute, so we can move the factor (ùëá ‚àí ùúÜùëòùêº) ùëëùëò to be the last term in the expression on the right. Because (ùëá ‚àí ùúÜùëòùêº) ùëëùëò|ùê∫( ùúÜùëò, ùëá)= 0, we have ùëû(ùëá)|ùê∫( ùúÜùëò, ùëá)= 0, as desired. The next result implies that if the minimal polynomial of an operator ùëá ‚àà ‚Ñí(ùëâ) has degree dim ùëâ (as happens almost always‚Äîsee the paragraphs following 5.24), then the characteristic polynomial of ùëá equals the minimal polynomial of ùëá. 8.30 characteristic polynomial is a multiple of minimal polynomial Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Then the characteristic polynomial of ùëá is a polynomial multiple of the minimal polynomial of ùëá. Proof The desired result follows immediately from the Cayley‚ÄìHamilton theo- rem (8.29) and 5.29. Section 8B Generalized Eigenspace Decomposition 313 Now we can prove that the result suggested by Example 8.24 holds for all operators on finite-dimensional complex vector spaces. 8.31 multiplicity of an eigenvalue equals number of times on diagonal Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Suppose ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ such that ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ))is upper triangular. Then the number of times that each eigenvalue ùúÜ of ùëá appears on the diagonal of ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ))equals the multiplicity of ùúÜ as an eigenvalue of ùëá. Proof Let ùê¥ = ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ)). Thus ùê¥ is an upper-triangular matrix. Let ùúÜ1, ‚Ä¶, ùúÜùëõ denote the entries on the diagonal of ùê¥. Thus for each ùëò ‚àà {1, ‚Ä¶, ùëõ}, we have ùëáùë£ùëò = ùë¢ùëò + ùúÜùëòùë£ùëò for some ùë¢ùëò ‚àà span(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1). Hence if ùëò ‚àà {1, ‚Ä¶, ùëõ} and ùúÜùëò ‚â† 0, then ùëáùë£ùëò is not a linear combination of ùëáùë£1, ‚Ä¶, ùëáùë£ùëò ‚àí 1. The linear dependence lemma (2.19) now implies that the list of those ùëáùë£ùëò such that ùúÜùëò ‚â† 0is linearly independent. Let ùëë denote the number of indices ùëò ‚àà {1, ‚Ä¶, ùëõ} such that ùúÜùëò = 0. The conclusion of the previous paragraph implies that dim range ùëá ‚â• ùëõ ‚àí ùëë. Because ùëõ = dim ùëâ = dim null ùëá + dim range ùëá, the inequality above implies that 8.32 dim null ùëá ‚â§ ùëë. The matrix of the operator ùëáùëõ with respect to the basis ùë£1, ‚Ä¶, ùë£ùëõ is the upper- triangular matrix ùê¥ ùëõ, which has diagonal entries ùúÜ1 ùëõ, ‚Ä¶, ùúÜùëõ ùëõ [see Exercise 2(b) in Section 5C]. Because ùúÜùëò ùëõ = 0if and only if ùúÜùëò = 0, the number of times that 0 appears on the diagonal of ùê¥ ùëõ equals ùëë. Thus applying 8.32 with ùëá replaced with ùëáùëõ, we have 8.33 dim null ùëáùëõ ‚â§ ùëë. For ùúÜ an eigenvalue of ùëá, let ùëö ùúÜ denote the multiplicity of ùúÜ as an eigenvalue of ùëá and let ùëë ùúÜ denote the number of times that ùúÜ appears on the diagonal of ùê¥. Replacing ùëá in 8.33 with ùëá ‚àí ùúÜùêº, we see that 8.34 ùëö ùúÜ ‚â§ ùëëùúÜ for each eigenvalue ùúÜ of ùëá. The sum of the multiplicities ùëö ùúÜ over all eigenvalues ùúÜ of ùëá equals ùëõ, the dimension of ùëâ (by 8.25). The sum of the numbers ùëë ùúÜ over all eigenvalues ùúÜ of ùëá also equals ùëõ, because the diagonal of ùê¥ has length ùëõ. Thus summing both sides of 8.34 over all eigenvalues ùúÜ of ùëá produces an equality. Hence 8.34 must actually be an equality for each eigenvalue ùúÜ of ùëá. Thus the multiplicity of ùúÜ as an eigenvalue of ùëá equals the number of times that ùúÜ appears on the diagonal of ùê¥, as desired. ‚âà 100ùúã Chapter 8 Operators on Complex Vector Spaces Block Diagonal Matrices Often we can understand a matrix better by thinking of it as composed of smaller matrices. To interpret our results in matrix form, we make the following definition, gener- alizing the notion of a diagonal matrix. If each matrix ùê¥ùëò in the definition below is a 1-by-1matrix, then we actually have a diagonal matrix. 8.35 definition: block diagonal matrix A block diagonal matrix is a square matrix of the form ‚éõ‚éú‚éú‚éú ‚éù ùê¥1 0 ‚ã± 0 ùê¥ùëö ‚éû‚éü‚éü‚éü ‚é† , where ùê¥1, ‚Ä¶, ùê¥ùëö are square matrices lying along the diagonal and all other entries of the matrix equal 0. 8.36 example:a block diagonal matrix The 5-by-5matrix ùê¥ = ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú ‚éù (4) 0 0 0 0 0 0 ‚éõ‚éú ‚éù 2 ‚àí3 0 2 ‚éû‚éü ‚é† 0 0 0 0 0 0 0 0 0 0 ‚éõ‚éú ‚éù 1 7 0 1 ‚éû‚éü ‚é† ‚éû‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü ‚é† is a block diagonal matrix with ùê¥ = ‚éõ‚éú‚éú‚éú‚éú‚éú ‚éù ùê¥1 0 ùê¥2 0 ùê¥3 ‚éû‚éü‚éü‚éü‚éü‚éü ‚é† , where ùê¥1 = (4), ùê¥2 = ‚éõ‚éú ‚éù 2 ‚àí3 0 2 ‚éû‚éü ‚é† , ùê¥3 = ‚éõ‚éú ‚éù 1 7 0 1 ‚éû‚éü ‚é† . Here the inner matrices in the 5-by-5matrix above are blocked off to show how we can think of it as a block diagonal matrix. Note that in the example above, each of ùê¥1, ùê¥2, ùê¥3 is an upper-triangular matrix whose diagonal entries are all equal. The next result shows that with respect to an appropriate basis, every operator on a finite-dimensional complex vector space has a matrix of this form. Note that this result gives us many more zeros in the matrix than are needed to make it upper triangular. Section 8B Generalized Eigenspace Decomposition 315 8.37 block diagonal matrix with upper-triangular blocks Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Let ùúÜ1, ‚Ä¶, ùúÜùëö be the distinct eigenvalues of ùëá, with multiplicities ùëë1, ‚Ä¶, ùëëùëö. Then there is a basis of ùëâ with respect to which ùëá has a block diagonal matrix of the form ‚éõ‚éú‚éú‚éú ‚éù ùê¥1 0 ‚ã± 0 ùê¥ùëö ‚éû‚éü‚éü‚éü ‚é† , where each ùê¥ùëò is a ùëëùëò-by-ùëëùëò upper-triangular matrix of the form ùê¥ùëò = ‚éõ‚éú‚éú‚éú ‚éù ùúÜùëò ‚àó ‚ã± 0 ùúÜùëò ‚éû‚éü‚éü‚éü ‚é† . Proof Each (ùëá ‚àí ùúÜùëòùêº)|ùê∫( ùúÜùëò, ùëá)is nilpotent (see 8.22). For each ùëò, choose a basis of ùê∫(ùúÜùëò, ùëá), which is a vector space of dimension ùëëùëò, such that the matrix of (ùëá ‚àí ùúÜùëòùêº)|ùê∫( ùúÜùëò, ùëá)with respect to this basis is as in 8.18(c). Thus with respect to this basis, the matrix of ùëá|ùê∫( ùúÜùëò, ùëá), which equals (ùëá ‚àí ùúÜùëòùêº)|ùê∫( ùúÜùëò, ùëá)+ ùúÜùëòùêº|ùê∫( ùúÜùëò, ùëá), looks like the desired form shown above for ùê¥ùëò. The generalized eigenspace decomposition (8.22) shows that putting together the bases of the ùê∫(ùúÜùëò, ùëá)‚Äôs chosen above gives a basis of ùëâ. The matrix of ùëá with respect to this basis has the desired form. 8.38 example: block diagonal matrix via generalized eigenvectors Let ùëá ‚àà ‚Ñí(ùêÇ 3)be defined byùëá(ùëß1, ùëß2, ùëß3) = (6ùëß1 + 3ùëß2 + 4ùëß3, 6ùëß2 + 2ùëß3, 7ùëß3). The matrix of ùëá (with respect to the standard basis) is ‚éõ‚éú‚éú‚éú ‚éù 6 3 4 0 6 2 0 0 7 ‚éû‚éü‚éü‚éü ‚é† , which is an upper-triangular matrix but is not of the form promised by 8.37. As we saw in Example 8.24, the eigenvalues of ùëá are 6and 7, and ùê∫(6, ùëá) = span((1, 0, 0), (0, 1, 0)) and ùê∫(7, ùëá) = span((10, 2, 1)). We also saw that a basis of ùêÇ 3 consisting of generalized eigenvectors of ùëá is (1, 0, 0), (0, 1, 0), (10, 2, 1). The matrix of ùëá with respect to this basis is ‚éõ‚éú‚éú‚éú ‚éù ( 6 3 0 6 ) 0 0 0 0 (7) ‚éû‚éü‚éü‚éü ‚é† , which is a matrix of the block diagonal form promised by 8.37. 316 Chapter 8 Operators on Complex Vector Spaces Exercises 8B 1 Defineùëá ‚àà ‚Ñí(ùêÇ 2)by ùëá(ùë§, ùëß) = (‚àíùëß, ùë§). Find the generalized eigenspaces corresponding to the distinct eigenvalues of ùëá. 2 Suppose ùëá ‚àà ‚Ñí(ùëâ) is invertible. Prove that ùê∫(ùúÜ, ùëá) = ùê∫( 1 ùúÜ , ùëá‚àí1)for every ùúÜ ‚àà ùêÖ with ùúÜ ‚â† 0. 3 Suppose ùëá ‚àà ‚Ñí(ùëâ). Suppose ùëÜ ‚àà ‚Ñí(ùëâ) is invertible. Prove that ùëá and ùëÜ ‚àí1ùëáùëÜ have the same eigenvalues with the same multiplicities. 4 Suppose dim ùëâ ‚â• 2and ùëá ‚àà ‚Ñí(ùëâ) is such that null ùëádim ùëâ ‚àí 2 ‚â† null ùëádim ùëâ ‚àí 1. Prove that ùëá has at most two distinct eigenvalues. 5 Suppose ùëá ‚àà ‚Ñí(ùëâ) and 3and 8are eigenvalues of ùëá. Let ùëõ = dim ùëâ. Prove that ùëâ = (null ùëáùëõ ‚àí 2)‚äï (range ùëáùëõ ‚àí 2). 6 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ is an eigenvalue of ùëá. Explain why the exponent of ùëß ‚àí ùúÜ in the factorization of the minimal polynomial of ùëá is the smallest positive integer ùëö such that (ùëá ‚àí ùúÜùêº)ùëö|ùê∫( ùúÜ, ùëá)= 0. 7 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ is an eigenvalue of ùëá with multiplicity ùëë. Prove that ùê∫(ùúÜ, ùëá) = null(ùëá ‚àí ùúÜùêº)ùëë. If ùëë < dim ùëâ, then this exercise improves 8.20. 8 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ1, ‚Ä¶, ùúÜùëö are the distinct eigenvalues of ùëá. Prove that ùëâ = ùê∫(ùúÜ1, ùëá) ‚äï ‚ãØ ‚äï ùê∫(ùúÜùëö, ùëá) if and only if the minimal polynomial of ùëá equals (ùëß ‚àí ùúÜ1)ùëò1‚ãØ(ùëß ‚àí ùúÜùëö) ùëòùëö for some positive integers ùëò1, ‚Ä¶, ùëòùëö. The case ùêÖ = ùêÇ follows immediately from 5.27(b) and the generalized eigenspace decomposition (8.22); thus this exercise is interesting only when ùêÖ = ùêë. 9 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Prove that there exist ùê∑, ùëÅ ‚àà ‚Ñí(ùëâ) such that ùëá = ùê∑ + ùëÅ, the operator ùê∑ is diagonalizable, ùëÅ is nilpotent, and ùê∑ùëÅ = ùëÅùê∑. 10 Suppose ùëâ is a complex inner product space, ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëá, and ùëá ‚àà ‚Ñí(ùëâ). Let ùúÜ1, ‚Ä¶, ùúÜùëõ be the eigenvalues of ùëá, each included as many times as its multiplicity. Prove that |ùúÜ1| 2 + ‚ãØ + |ùúÜùëõ| 2 ‚â§ ‚Äñùëáùëí1‚Äñ 2 + ‚ãØ + ‚Äñùëáùëíùëõ‚Äñ2. See the comment after Exercise 5 in Section 7A. 11 Give an example of an operator on ùêÇ 4 whose characteristic polynomial equals (ùëß ‚àí 7) 2(ùëß ‚àí 8) 2. Section 8B Generalized Eigenspace Decomposition 317 12 Give an example of an operator on ùêÇ 4 whose characteristic polynomial equals (ùëß ‚àí 1)(ùëß ‚àí 5) 3 and whose minimal polynomial equals (ùëß ‚àí 1)(ùëß ‚àí 5) 2. 13 Give an example of an operator on ùêÇ 4 whose characteristic and minimal polynomials both equal ùëß(ùëß ‚àí 1) 2(ùëß ‚àí 3). 14 Give an example of an operator on ùêÇ 4 whose characteristic polynomial equals ùëß(ùëß ‚àí 1) 2(ùëß ‚àí 3)and whose minimal polynomial equals ùëß(ùëß ‚àí 1)(ùëß ‚àí 3). 15 Let ùëá be the operator on ùêÇ 4 defined byùëá(ùëß1, ùëß2, ùëß3, ùëß4) = (0, ùëß1, ùëß2, ùëß3). Find the characteristic polynomial and the minimal polynomial of ùëá. 16 Let ùëá be the operator on ùêÇ 6 defined by ùëá(ùëß1, ùëß2, ùëß3, ùëß4, ùëß5, ùëß6) = (0, ùëß1, ùëß2, 0, ùëß4, 0). Find the characteristic polynomial and the minimal polynomial of ùëá. 17 Suppose ùêÖ = ùêÇ and ùëÉ ‚àà ‚Ñí(ùëâ) is such that ùëÉ2 = ùëÉ. Prove that the characteris- tic polynomial of ùëÉ is ùëßùëö(ùëß‚àí1) ùëõ, where ùëö = dim null ùëÉ and ùëõ = dim range ùëÉ. 18 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ is an eigenvalue of ùëá. Explain why the following four numbers equal each other. (a) The exponent of ùëß ‚àí ùúÜ in the factorization of the minimal polynomial of ùëá. (b) The smallest positive integer ùëö such that (ùëá ‚àí ùúÜùêº)ùëö|ùê∫( ùúÜ, ùëá)= 0. (c) The smallest positive integer ùëö such that null(ùëá ‚àí ùúÜùêº)ùëö = null(ùëá ‚àí ùúÜùêº)ùëö + 1. (d) The smallest positive integer ùëö such that range(ùëá ‚àí ùúÜùêº)ùëö = range(ùëá ‚àí ùúÜùêº)ùëö + 1. 19 Suppose ùêÖ = ùêÇ and ùëÜ ‚àà ‚Ñí(ùëâ) is a unitary operator. Prove that the constant term in the characteristic polynomial of ùëÜ has absolute value 1. 20 Suppose that ùêÖ = ùêÇ and ùëâ1, ‚Ä¶, ùëâùëö are nonzero subspaces of ùëâ such that ùëâ = ùëâ1 ‚äï ‚ãØ ‚äï ùëâùëö. Suppose ùëá ‚àà ‚Ñí(ùëâ) and each ùëâùëò is invariant under ùëá. For each ùëò, let ùëùùëò denote the characteristic polynomial of ùëá|ùëâùëò. Prove that the characteristic polynomial of ùëá equals ùëù1‚ãØùëùùëö. 21 Suppose ùëù, ùëû ‚àà ùí´(ùêÇ) are monic polynomials with the same zeros and ùëû is a polynomial multiple of ùëù. Prove that there exists ùëá ‚àà ‚Ñí(ùêÇ deg ùëû)such that the characteristic polynomial of ùëá is ùëû and the minimal polynomial of ùëá is ùëù. This exercise implies that every monic polynomial is the characteristic polynomial of some operator. 318 Chapter 8 Operators on Complex Vector Spaces 22 Suppose ùê¥ and ùêµ are block diagonal matrices of the form ùê¥ = ‚éõ‚éú‚éú‚éú ‚éù ùê¥1 0 ‚ã± 0 ùê¥ùëö ‚éû‚éü‚éü‚éü ‚é† , ùêµ = ‚éõ‚éú‚éú‚éú ‚éù ùêµ1 0 ‚ã± 0 ùêµùëö ‚éû‚éü‚éü‚éü ‚é† , where ùê¥ùëò and ùêµùëò are square matrices of the same size for each ùëò = 1, ‚Ä¶, ùëö. Show that ùê¥ùêµ is a block diagonal matrix of the form ùê¥ùêµ = ‚éõ‚éú‚éú‚éú ‚éù ùê¥1ùêµ1 0 ‚ã± 0 ùê¥ùëöùêµùëö ‚éû‚éü‚éü‚éü ‚é† . 23 Suppose ùêÖ = ùêë, ùëá ‚àà ‚Ñí(ùëâ), and ùúÜ ‚àà ùêÇ. (a) Show that ùë¢ + ùëñùë£ ‚àà ùê∫(ùúÜ, ùëáùêÇ) if and only if ùë¢ ‚àí ùëñùë£ ‚àà ùê∫(ùúÜ, ùëáùêÇ). (b) Show that the multiplicity of ùúÜ as an eigenvalue of ùëáùêÇ equals the multiplicity of ùúÜ as an eigenvalue of ùëáùêÇ. (c) Use (b) and the result about the sum of the multiplicities (8.25) to show that if dim ùëâ is an odd number, then ùëáùêÇ has a real eigenvalue. (d) Use (c) and the result about real eigenvalues of ùëáùêÇ (Exercise 17 in Section 5A) to show that if dim ùëâ is an odd number, then ùëá has an eigenvalue (thus giving an alternative proof of 5.34). See Exercise 33 in Section 3B for the definition of the complexification ùëáùêÇ. Open Access This chapter is licensed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (https://creativecommons.org/licenses/by-nc/4.0), which permits any noncommercial use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to original author and source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this chapter are included in the chapter‚Äôs Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter‚Äôs Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. Section 8C Consequences of Generalized Eigenspace Decomposition 319 8C Consequences of Generalized Eigenspace Decomposition Square Roots of Operators Recall that a square root of an operator ùëá ‚àà ‚Ñí(ùëâ) is an operator ùëÖ ‚àà ‚Ñí(ùëâ) such that ùëÖ2 = ùëá (see 7.36). Every complex number has a square root, but not every operator on a complex vector space has a square root. For example, the operator on ùêÇ 3 defined byùëá(ùëß1, ùëß2, ùëß3) = (ùëß2, ùëß3, 0)does not have a square root, as you are asked to show in Exercise 1. The noninvertibility of that operator is no accident, as we will soon see. We begin by showing that the identity plus any nilpotent operator has a square root. 8.39 identity plus nilpotent has a square root Suppose ùëá ‚àà ‚Ñí(ùëâ) is nilpotent. Then ùêº + ùëá has a square root. Proof Consider the Taylor series for the function ‚àö1+ ùë•: 8.40 ‚àö1+ ùë• = 1+ ùëé1ùë• + ùëé2ùë•2 + ‚ãØ . Because ùëé1 = 1 2 , the formula above implies that 1+ ùë• 2 is a good estimate for ‚àö1+ ùë• when ùë• is small. We do not find an explicit formula for the coefficients or worry about whether the infinite sum converges because we use this equation only as motivation. Because ùëá is nilpotent, ùëáùëö = 0for some positive integer ùëö. In 8.40, suppose we replace ùë• with ùëá and 1with ùêº. Then the infinite sum on the right side becomes a finite sum (becauseùëáùëò = 0for all ùëò ‚â• ùëö). Thus we guess that there is a square root of ùêº + ùëá of the form ùêº + ùëé1ùëá + ùëé2ùëá2 + ‚ãØ + ùëéùëö ‚àí 1ùëáùëö ‚àí 1. Having made this guess, we can try to choose ùëé1, ùëé2, ‚Ä¶, ùëéùëö ‚àí 1 such that the operator above has its square equal to ùêº + ùëá. Now (ùêº+ùëé1ùëá + ùëé2ùëá2 + ùëé3ùëá3 + ‚ãØ + ùëéùëö ‚àí 1ùëáùëö ‚àí 1) 2 = ùêº + 2ùëé1ùëá + (2ùëé2 + ùëé1 2)ùëá2 + (2ùëé3 + 2ùëé1ùëé2)ùëá3 + ‚ãØ + (2ùëéùëö ‚àí 1 + terms involving ùëé1, ‚Ä¶, ùëéùëö ‚àí 2)ùëáùëö ‚àí 1. We want the right side of the equation above to equal ùêº + ùëá. Hence choose ùëé1 such that 2ùëé1 = 1(thus ùëé1 = 1/2). Next, choose ùëé2 such that 2ùëé2 + ùëé1 2 = 0(thus ùëé2 = ‚àí1/8). Then choose ùëé3 such that the coefficient of ùëá3 on the right side of the equation above equals 0(thus ùëé3 = 1/16). Continue in this fashion for each ùëò = 4, ‚Ä¶, ùëö ‚àí 1, at each step solving for ùëéùëò so that the coefficient of ùëáùëò on the right side of the equation above equals 0. Actually we do not care about the explicit formula for the ùëéùëò‚Äôs. We only need to know that some choice of the ùëéùëò‚Äôs gives a square root of ùêº + ùëá. 320 Chapter 8 Operators on Complex Vector Spaces The previous lemma is valid on real and complex vector spaces. However, the result below holds only on complex vector spaces. For example, the operator of multiplication by ‚àí1on the one-dimensional real vector space ùêë has no square root. Representation of a complex number with polar coordinates. For the proof below, we need to know that every ùëß ‚àà ùêÇ has a square root in ùêÇ. To show this, write ùëß = ùëü(cos ùúÉ + ùëñ sin ùúÉ), where ùëü is the length of the line segment in the complex plane from the origin to ùëß and ùúÉ is the angle of that line segment with the positive horizontal axis. Then ‚àö ùëü(cos ùúÉ 2 + ùëñ sin ùúÉ 2 ) is a square root of ùëß, as you can verify by showing that the square of the complex number above equals ùëß. 8.41 over ùêÇ, invertible operators have square roots Suppose ùëâ is a complex vector space and ùëá ‚àà ‚Ñí(ùëâ) is invertible. Then ùëá has a square root. Proof Let ùúÜ1, ‚Ä¶, ùúÜùëö be the distinct eigenvalues of ùëá. For each ùëò, there exists a nilpotent operator ùëáùëò ‚àà ‚Ñí(ùê∫(ùúÜùëò, ùëá))such that ùëá|ùê∫( ùúÜùëò, ùëá)= ùúÜùëòùêº + ùëáùëò [see 8.22(c)]. Because ùëá is invertible, none of the ùúÜùëò‚Äôs equals 0, so we can write ùëá|ùê∫( ùúÜùëò, ùëá)= ùúÜùëò(ùêº + ùëáùëò ùúÜùëò ) for each ùëò. Because ùëáùëò/ùúÜùëò is nilpotent, ùêº + ùëáùëò/ùúÜùëò has a square root (by 8.39). Multiplying a square root of the complex number ùúÜùëò by a square root of ùêº + ùëáùëò/ùúÜùëò, we obtain a square root ùëÖùëò of ùëá|ùê∫( ùúÜùëò, ùëá). By the generalized eigenspace decomposition (8.22), a typical vector ùë£ ‚àà ùëâ can be written uniquely in the form ùë£ = ùë¢1 + ‚ãØ + ùë¢ùëö, where each ùë¢ùëò is in ùê∫(ùúÜùëò, ùëá). Using this decomposition, define an operator ùëÖ ‚àà ‚Ñí(ùëâ) by ùëÖùë£ = ùëÖ1ùë¢1 + ‚ãØ + ùëÖùëöùë¢ùëö. You should verify that this operator ùëÖ is a square root of ùëá, completing the proof. By imitating the techniques in this subsection, you should be able to prove that if ùëâ is a complex vector space and ùëá ‚àà ‚Ñí(ùëâ) is invertible, then ùëá has a ùëòth root for every positive integer ùëò. Section 8C Consequences of Generalized Eigenspace Decomposition 321 Jordan Form We know that if ùëâ is a complex vector space, then for every ùëá ‚àà ‚Ñí(ùëâ) there is a basis of ùëâ with respect to which ùëá has a nice upper-triangular matrix (see 8.37). In this subsection we will see that we can do even better‚Äîthere is a basis of ùëâ with respect to which the matrix of ùëá contains 0‚Äôs everywhere except possibly on the diagonal and the line directly above the diagonal. We begin by looking at two examples of nilpotent operators. 8.42 example: nilpotent operator with nice matrix Let ùëá be the operator on ùêÇ 4 defined by ùëá(ùëß1, ùëß2, ùëß3, ùëß4) = (0, ùëß1, ùëß2, ùëß3). Then ùëá4 = 0; thus ùëá is nilpotent. If ùë£ = (1, 0, 0, 0), then ùëá3ùë£, ùëá2ùë£, ùëáùë£, ùë£ is a basis of ùêÇ 4. The matrix of ùëá with respect to this basis is ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . The next example of a nilpotent operator has more complicated behavior than the example above. 8.43 example: nilpotent operator with slightly more complicated matrix Let ùëá be the operator on ùêÇ 6 defined by ùëá(ùëß1, ùëß2, ùëß3, ùëß4, ùëß5, ùëß6) = (0, ùëß1, ùëß2, 0, ùëß4, 0). Then ùëá3 = 0; thus ùëá is nilpotent. In contraast to the nice behavior of the nilpotent operator of the previous example, for this nilpotent operator there does not exist a vector ùë£ ‚àà ùêÇ6 such that ùëá5ùë£, ùëá4ùë£, ùëá3ùë£, ùëá2ùë£, ùëáùë£, ùë£ is a basis of ùêÇ 6. However, if we take ùë£1 = (1, 0, 0, 0, 0, 0), ùë£2 = (0, 0, 0, 1, 0, 0), and ùë£3 = (0, 0, 0, 0, 0, 1), then ùëá2ùë£1, ùëáùë£1, ùë£1, ùëáùë£2, ùë£2, ùë£3 is a basis of ùêÇ 6. The matrix of ùëá with respect to this basis is ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú ‚éù ‚éõ‚éú‚éú‚éú ‚éù 0 1 0 0 0 1 0 0 0 ‚éû‚éü‚éü‚éü ‚é† 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ( 0 1 0 0 ) 0 0 0 0 0 0 0(0) ‚éû‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . Here the inner matrices are blocked off to show that we can think of the 6-by-6 matrix above as a block diagonal matrix consisting of a 3-by-3block with 1‚Äôs on the line above the diagonal and 0‚Äôs elsewhere, a 2-by-2block with 1above the diagonal and 0‚Äôs elsewhere, and a 1-by-1block containing 0. 322 Chapter 8 Operators on Complex Vector Spaces Our next goal is to show that every nilpotent operator ùëá ‚àà ‚Ñí(ùëâ) behaves similarly to the operator in the previous example. Specifically, there is a finite collection of vectors ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùëâ such that there is a basis of ùëâ consisting of the vectors of the form ùëáùëóùë£ùëò, as ùëò varies from 1to ùëõ and ùëó varies (in reverse order) from 0to the largest nonnegative integer ùëöùëò such that ùëáùëöùëòùë£ùëò ‚â† 0. With respect to this basis, the matrix of ùëá looks like the matrix in the previous example. More specifically,ùëá has a block diagonal matrix with respect to this basis, with each block a square matrix that is 0everywhere except on the line above the diagonal. In the next definition, the diagonal of eachùê¥ùëò is filled with some eigenvalue ùúÜùëò of ùëá, the line directly above the diagonal of ùê¥ùëò is filled with1‚Äôs, and all other entries in ùê¥ùëò are 0(to understand why each ùúÜùëò is an eigenvalue of ùëá, see 5.41). The ùúÜùëò‚Äôs need not be distinct. Also, ùê¥ùëò may be a 1-by-1matrix (ùúÜùëò) containing just an eigenvalue of ùëá. If each ùúÜùëò is 0, then the next definition captures the behavior described in the paragraph above (recall that if ùëá is nilpotent, then 0is the only eigenvalue of ùëá). 8.44 definition: Jordan basis Suppose ùëá ‚àà ‚Ñí(ùëâ). A basis of ùëâ is called a Jordan basis for ùëá if with respect to this basis ùëá has a block diagonal matrix ‚éõ‚éú‚éú‚éú ‚éù ùê¥1 0 ‚ã± 0 ùê¥ùëù ‚éû‚éü‚éü‚éü ‚é† in which each ùê¥ùëò is an upper-triangular matrix of the form ùê¥ùëò = ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú ‚éù ùúÜùëò 1 0 ‚ã± ‚ã± ‚ã± 1 0 ùúÜùëò ‚éû‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . Most of the work in proving that every operator on a finite-dimensional com- plex vector space has a Jordan basis occurs in proving the special case below of nilpotent operators. This special case holds on real vector spaces as well as complex vector spaces. 8.45 every nilpotent operator has a Jordan basis Suppose ùëá ‚àà ‚Ñí(ùëâ) is nilpotent. Then there is a basis of ùëâ that is a Jordan basis for ùëá. Proof We will prove this result by induction on dim ùëâ. To get started, note that the desired result holds if dim ùëâ = 1(because in that case, the only nilpotent operator is the 0operator). Now assume that dim ùëâ > 1and that the desired result holds on all vector spaces of smaller dimension. Section 8C Consequences of Generalized Eigenspace Decomposition 323 Let ùëö be the smallest positive integer such that ùëáùëö = 0. Thus there exists ùë¢ ‚àà ùëâ such that ùëáùëö ‚àí 1ùë¢ ‚â† 0. Let ùëà = span(ùë¢, ùëáùë¢, ‚Ä¶, ùëáùëö ‚àí 1ùë¢). The list ùë¢, ùëáùë¢, ‚Ä¶, ùëáùëö ‚àí 1ùë¢ is linearly independent (see Exercise 2 in Section 8A). If ùëà = ùëâ, then writing this list in reverse order gives a Jordan basis for ùëá and we are done. Thus we can assume that ùëà ‚â† ùëâ. Note that ùëà is invariant under ùëá. By our induction hypothesis, there is a basis of ùëà that is a Jordan basis for ùëá|ùëà. The strategy of our proof is that we will find a subspace ùëä of ùëâ such that ùëä is also invariant under ùëá and ùëâ = ùëà ‚äï ùëä. Again by our induction hypothesis, there will be a basis of ùëä that is a Jordan basis for ùëá|ùëä. Putting together the Jordan bases for ùëá|ùëà and ùëá|ùëä, we will have a Jordan basis for ùëá. Let ùúë ‚àà ùëâ‚Ä≤ be such that ùúë(ùëáùëö ‚àí 1ùë¢)‚â† 0. Let ùëä = {ùë£ ‚àà ùëâ ‚à∂ ùúë(ùëáùëòùë£)= 0for each ùëò = 0, ‚Ä¶, ùëö ‚àí 1}. Then ùëä is a subspace of ùëâ that is invariant under ùëá (the invariance holds because if ùë£ ‚àà ùëä then ùúë(ùëáùëò(ùëáùë£))= 0for ùëò = 0, ‚Ä¶, ùëö ‚àí 1, where the case ùëò = ùëö ‚àí 1 holds because ùëáùëö = 0). We will show that ùëâ = ùëà ‚äï ùëä, which by the previous paragraph will complete the proof. To show that ùëà + ùëä is a direct sum, suppose ùë£ ‚àà ùëà ‚à© ùëäwith ùë£ ‚â† 0. Because ùë£ ‚àà ùëà, there exist ùëê0, ‚Ä¶, ùëêùëö ‚àí 1 ‚àà ùêÖ such that ùë£ = ùëê0ùë¢ + ùëê1ùëáùë¢ + ‚ãØ + ùëêùëö ‚àí 1ùëáùëö ‚àí 1ùë¢. Let ùëó be the smallest index such that ùëêùëó ‚â† 0. Apply ùëáùëö ‚àí ùëó ‚àí 1 to both sides of the equation above, getting ùëáùëö ‚àí ùëó ‚àí 1ùë£ = ùëêùëóùëáùëö ‚àí 1ùë¢, where we have used the equation ùëáùëö = 0. Now apply ùúë to both sides of the equation above, getting ùúë(ùëáùëö ‚àí ùëó ‚àí 1ùë£)= ùëêùëóùúë(ùëáùëö ‚àí 1ùë¢)‚â† 0. The equation above shows that ùë£ ‚àâ ùëä. Hence we have proved that ùëà ‚à© ùëä = {0}, which implies that ùëà + ùëä is a direct sum (see 1.46). To show that ùëà ‚äï ùëä = ùëâ, defineùëÜ‚à∂ ùëâ ‚Üí ùêÖùëö by ùëÜùë£ = (ùúë(ùë£), ùúë(ùëáùë£), ‚Ä¶, ùúë(ùëáùëö ‚àí 1ùë£)). Thus null ùëÜ = ùëä. Hence dim ùëä = dim null ùëÜ = dim ùëâ ‚àí dim range ùëÜ ‚â•dim ùëâ ‚àí ùëö, where the second equality comes from the fundamental theorem of linear maps (3.21). Using the inequality above, we have dim(ùëà ‚äï ùëä) = dim ùëà + dim ùëä ‚â• ùëö+ (dim ùëâ ‚àí ùëö) = dim ùëâ. Thus ùëà ‚äï ùëä = ùëâ (by 2.39), completing the proof. 324 Chapter 8 Operators on Complex Vector Spaces Camille Jordan (1838‚Äì1922) pub- lished a proof of 8.46 in 1870. Now the generalized eigenspace de- composition allows us to extend the pre- vious result to operators that may not be nilpotent. Doing this requires that we deal with complex vector spaces. 8.46 Jordan form Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Then there is a basis of ùëâ that is a Jordan basis for ùëá. Proof Let ùúÜ1, ‚Ä¶, ùúÜùëö be the distinct eigenvalues of ùëá. The generalized eigenspace decomposition states that ùëâ = ùê∫(ùúÜ1, ùëá) ‚äï ‚ãØ ‚äï ùê∫(ùúÜùëö, ùëá), where each (ùëá ‚àí ùúÜùëòùêº)|ùê∫( ùúÜùëò, ùëá)is nilpotent (see 8.22). Thus 8.45 implies that some basis of each ùê∫(ùúÜùëò, ùëá) is a Jordan basis for (ùëá ‚àí ùúÜùëòùêº)|ùê∫( ùúÜùëò, ùëá). Put these bases together to get a basis of ùëâ that is a Jordan basis for ùëá. Exercises 8C 1 Suppose ùëá ‚àà ‚Ñí(ùêÇ 3)is the operator defined byùëá(ùëß1, ùëß2, ùëß3) = (ùëß2, ùëß3, 0). Prove that ùëá does not have a square root. 2 Defineùëá ‚àà ‚Ñí(ùêÖ5)by ùëá(ùë•1, ùë•2, ùë•3, ùë•4, ùë•5) = (2ùë•2, 3ùë•3, ‚àíùë•4, 4ùë•5, 0). (a) Show that ùëá is nilpotent. (b) Find a square root of ùêº + ùëá. 3 Suppose ùëâ is a complex vector space. Prove that every invertible operator on ùëâ has a cube root. 4 Suppose ùëâ is a real vector space. Prove that the operator ‚àíùêº on ùëâ has a square root if and only if dim ùëâ is an even number. 5 Suppose ùëá ‚àà ‚Ñí(ùêÇ 2)is the operator defined byùëá(ùë§, ùëß) = (‚àíùë§ ‚àí ùëß, 9ùë§+ 5ùëß). Find a Jordan basis for ùëá. 6 Find a basis of ùí´4(ùêë) that is a Jordan basis for the differentiation operator ùê∑ on ùí´4(ùêë) defined byùê∑ùëù = ùëù‚Ä≤. 7 Suppose ùëá ‚àà ‚Ñí(ùëâ) is nilpotent and ùë£1, ‚Ä¶, ùë£ùëõ is a Jordan basis for ùëá. Prove that the minimal polynomial of ùëá is ùëß ùëö + 1, where ùëö is the length of the longest consecutive string of 1‚Äôs that appears on the line directly above the diagonal in the matrix of ùëá with respect to ùë£1, ‚Ä¶, ùë£ùëõ. 8 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ that is a Jordan basis for ùëá. Describe the matrix of ùëá2 with respect to this basis. Section 8C Consequences of Generalized Eigenspace Decomposition 325 9 Suppose ùëá ‚àà ‚Ñí(ùëâ) is nilpotent. Explain why there exist ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùëâ and nonnegative integers ùëö1, ‚Ä¶, ùëöùëõ such that (a) and (b) below both hold. (a) ùëáùëö1ùë£1, ‚Ä¶, ùëáùë£1, ùë£1, ‚Ä¶, ùëáùëöùëõùë£ùëõ, ‚Ä¶, ùëáùë£ùëõ, ùë£ùëõ is a basis of ùëâ. (b) ùëáùëö1 + 1ùë£1 = ‚ãØ = ùëáùëöùëõ + 1ùë£ùëõ = 0. 10 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ that is a Jordan basis for ùëá. Describe the matrix of ùëá with respect to the basis ùë£ùëõ, ‚Ä¶, ùë£1 obtained by reversing the order of the ùë£‚Äôs. 11 Suppose ùëá ‚àà ‚Ñí(ùëâ). Explain why every vector in each Jordan basis for ùëá is a generalized eigenvector of ùëá. 12 Suppose ùëá ‚àà ‚Ñí(ùëâ) is diagonalizable. Show that ‚Ñ≥(ùëá) is a diagonal matrix with respect to every Jordan basis for ùëá. 13 Suppose ùëá ‚àà ‚Ñí(ùëâ) is nilpotent. Prove that if ùë£1, ‚Ä¶, ùë£ùëõ are vectors in ùëâ and ùëö1, ‚Ä¶, ùëöùëõ are nonnegative integers such that ùëáùëö1ùë£1, ‚Ä¶, ùëáùë£1, ùë£1, ‚Ä¶, ùëáùëöùëõùë£ùëõ, ‚Ä¶, ùëáùë£ùëõ, ùë£ùëõ is a basis of ùëâ and ùëáùëö1 + 1ùë£1 = ‚ãØ = ùëáùëöùëõ + 1ùë£ùëõ = 0, then ùëáùëö1ùë£1, ‚Ä¶, ùëáùëöùëõùë£ùëõ is a basis of null ùëá. This exercise shows that ùëõ = dim null ùëá. Thus the positive integer ùëõ that appears above depends only on ùëá and not on the specific Jordan basis chosen for ùëá. 14 Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Prove that there does not exist a direct sum decomposition of ùëâ into two nonzero subspaces invariant under ùëá if and only if the minimal polynomial of ùëá is of the form (ùëß ‚àí ùúÜ) dim ùëâ for some ùúÜ ‚àà ùêÇ. 326 Chapter 8 Operators on Complex Vector Spaces 8D Trace: A Connection Between Matrices and Operators We begin this section by defining the trace of a square matrix. After developing some properties of the trace of a square matrix, we will use this concept to define the trace of an operator. 8.47 definition:trace of a matrix Suppose ùê¥ is a square matrix with entries in ùêÖ. The trace of ùê¥, denoted by tr ùê¥, is defined to be the sum of the diagonal entries ofùê¥. 8.48 example: trace of a 3-by-3matrix Suppose ùê¥ = ‚éõ‚éú‚éú‚éú ‚éù 3 ‚àí1 ‚àí2 3 2 ‚àí3 1 2 0 ‚éû‚éü‚éü‚éü ‚é† . The diagonal entries of ùê¥, which are shown in red above, are 3, 2, and 0. Thus tr ùê¥ = 3+ 2+ 0 = 5. Matrix multiplication is not commutative, but the next result shows that the order of matrix multiplication does not matter to the trace. 8.49 trace of ùê¥ùêµ equals trace of ùêµùê¥ Suppose ùê¥ is an ùëö-by-ùëõ matrix and ùêµ is an ùëõ-by-ùëö matrix. Then tr(ùê¥ùêµ) = tr(ùêµùê¥). Proof Suppose ùê¥ = ‚éõ‚éú‚éú‚éú‚éú ‚éù ùê¥1, 1 ‚ãØ ùê¥1, ùëõ ‚ãÆ ‚ãÆ ùê¥ùëö, 1 ‚ãØ ùê¥ùëö, ùëõ ‚éû‚éü‚éü‚éü‚éü ‚é† , ùêµ = ‚éõ‚éú‚éú‚éú‚éú ‚éù ùêµ1, 1 ‚ãØ ùêµ1, ùëö ‚ãÆ ‚ãÆ ùêµùëõ, 1 ‚ãØ ùêµùëõ, ùëö ‚éû‚éü‚éü‚éü‚éü ‚é† . The ùëóth term on the diagonal of the ùëö-by-ùëö matrix ùê¥ùêµ equals ‚àë ùëõ ùëò = 1 ùê¥ùëó, ùëòùêµùëò, ùëó. Thus tr(ùê¥ùêµ) = ùëö ‚àë ùëó = 1 ùëõ ‚àë ùëò = 1 ùê¥ùëó, ùëòùêµùëò, ùëó = ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1 ùêµùëò, ùëóùê¥ùëó, ùëò = ùëõ ‚àë ùëò = 1(ùëòth term on diagonal of the ùëõ-by-ùëõ matrix ùêµùê¥) = tr(ùêµùê¥), as desired. Section 8D Trace: A Connection Between Matrices and Operators 327 We want to define the trace of an operatorùëá ‚àà ‚Ñí(ùëâ) to be the trace of the matrix of ùëá with respect to some basis of ùëâ. However, this definition should not depend on the choice of basis. The following result will make this possible. 8.50 trace of matrix of operator does not depend on basis Suppose ùëá ‚àà ‚Ñí(ùëâ). Suppose ùë¢1, ‚Ä¶, ùë¢ùëõ and ùë£1, ‚Ä¶, ùë£ùëõ are bases of ùëâ. Then tr ‚Ñ≥(ùëá, (ùë¢1, ‚Ä¶, ùë¢ùëõ))= tr ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ)). Proof Let ùê¥ = ‚Ñ≥(ùëá, (ùë¢1, ‚Ä¶, ùë¢ùëõ))and ùêµ = ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ)). The change-of- basis formula tells us that there exists an invertible ùëõ-by-ùëõ matrix ùê∂ such that ùê¥ = ùê∂‚àí1ùêµùê∂ (see 3.84). Thus tr ùê¥ = tr((ùê∂‚àí1ùêµ)ùê∂) = tr(ùê∂(ùê∂‚àí1ùêµ)) = tr((ùê∂ùê∂‚àí1)ùêµ) = tr ùêµ, where the second line comes from 8.49. Because of 8.50, the following definition now makes sense. 8.51 definition: trace of an operator Suppose ùëá ‚àà ‚Ñí(ùëâ). The trace of ùëá, denote tr ùëá, is defined by tr ùëá = tr ‚Ñ≥(ùëá, (ùë£1, ‚Ä¶, ùë£ùëõ)), where ùë£1, ‚Ä¶, ùë£ùëõ is any basis of ùëâ. Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ is an eigenvalue of ùëá. Recall that we defined the multiplicity of ùúÜ to be the dimension of the generalized eigenspace ùê∫(ùúÜ, ùëá) (see 8.23); we proved that this multiplicity equals dim null(ùëá ‚àí ùúÜùêº)dim ùëâ (see 8.20). Recall also that if ùëâ is a complex vector space, then the sum of the multiplicities of all eigenvalues of ùëá equals dim ùëâ (see 8.25). In the definition below, the sum of the eigenvalues ‚Äúwith each eigenvalue included as many times as its multiplicity‚Äù means that ifùúÜ1, ‚Ä¶, ùúÜùëö are the distinct eigenvalues of ùëá with multiplicities ùëë1, ‚Ä¶, ùëëùëö, then the sum is ùëë1 ùúÜ1 + ‚ãØ + ùëëùëö ùúÜùëö. Or if you prefer to work with a list of not-necessarily-distinct eigenvalues, with each eigenvalue included as many times as its multiplicity, then the eigenvalues could be denoted by ùúÜ1, ‚Ä¶, ùúÜùëõ (where ùëõ equals dim ùëâ) and the sum is ùúÜ1 + ‚ãØ + ùúÜùëõ. 328 Chapter 8 Operators on Complex Vector Spaces 8.52 on complex vector spaces, trace equals sum of eigenvalues Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Then tr ùëá equals the sum of the eigenvalues of ùëá, with each eigenvalue included as many times as its multiplicity. Proof There is a basis of ùëâ with respect to which ùëá has an upper-triangular matrix with the diagonal entries of the matrix consisting of the eigenvalues of ùëá, with each eigenvalue included as many times as its multiplicity‚Äîsee 8.37. Thus the definition of the trace of an operator along with8.50, which allows us to use a basis of our choice, implies that tr ùëá equals the sum of the eigenvalues of ùëá, with each eigenvalue included as many times as its multiplicity. 8.53 example: trace of an operator on ùêÇ 3 Suppose ùëá ‚àà ‚Ñí(ùêÇ 3)is defined by ùëá(ùëß1, ùëß2, ùëß3) = (3ùëß1 ‚àí ùëß2 ‚àí 2ùëß3, 3ùëß1 + 2ùëß2 ‚àí 3ùëß3, ùëß1 + 2ùëß2). Then the matrix of ùëá with respect to the standard basis of ùêÇ 3 is ‚éõ‚éú‚éú‚éú ‚éù 3 ‚àí1 ‚àí2 3 2 ‚àí3 1 2 0 ‚éû‚éü‚éü‚éü ‚é† . Adding up the diagonal entries of this matrix, we see that tr ùëá = 5. The eigenvalues of ùëá are 1, 2+ 3ùëñ, and 2 ‚àí 3ùëñ, each with multiplicity 1, as you can verify. The sum of these eigenvalues, each included as many times as its multiplicity, is 1+ (2+ 3ùëñ)+ (2 ‚àí 3ùëñ), which equals 5, as expected by 8.52. The trace has a close connection with the characteristic polynomial. Suppose ùêÖ = ùêÇ, ùëá ‚àà ‚Ñí(ùëâ), and ùúÜ1, ‚Ä¶, ùúÜùëõ are the eigenvalues of ùëá, with each eigenvalue included as many times as its multiplicity. Then by definition (see8.26), the characteristic polynomial of ùëá equals (ùëß ‚àí ùúÜ1)‚ãØ(ùëß ‚àí ùúÜùëõ). Expanding the polynomial above, we can write the characteristic polynomial of ùëá in the form ùëßùëõ ‚àí (ùúÜ1 + ‚ãØ + ùúÜùëõ)ùëß ùëõ ‚àí 1 + ‚ãØ + (‚àí1) ùëõ(ùúÜ1‚ãØùúÜùëõ). The expression above immediately leads to the next result. Also see 9.65, which does not require the hypothesis that ùêÖ = ùêÇ. 8.54 trace and characteristic polynomial Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Let ùëõ = dim ùëâ. Then tr ùëá equals the negative of the coefficient of ùëß ùëõ ‚àí 1 in the characteristic polynomial of ùëá. Section 8D Trace: A Connection Between Matrices and Operators 329 The next result gives a nice formula for the trace of an operator on an inner product space. 8.55 trace on an inner product space Suppose ùëâ is an inner product space, ùëá ‚àà ‚Ñí(ùëâ), and ùëí1, ‚Ä¶, ùëíùëõ is an orthonor- mal basis of ùëâ. Then tr ùëá = ‚ü®ùëáùëí1, ùëí1‚ü©+ ‚ãØ + ‚ü®ùëáùëíùëõ, ùëíùëõ‚ü©. Proof The desired formula follows from the observation that the entry in row ùëò, column ùëò of ‚Ñ≥(ùëá, (ùëí1, ‚Ä¶, ùëíùëõ))equals ‚ü®ùëáùëíùëò, ùëíùëò‚ü©[use6.30(a) with ùë£ = ùëáùëíùëò]. The algebraic properties of the trace as defined on square matrices translate to algebraic properties of the trace as defined on operators, as shown in the next result. 8.56 trace is linear The function tr‚à∂ ‚Ñí(ùëâ) ‚Üí ùêÖ is a linear functional on ‚Ñí(ùëâ) such that tr(ùëÜùëá) = tr(ùëáùëÜ) for all ùëÜ, ùëá ‚àà ‚Ñí(ùëâ). Proof Choose a basis of ùëâ. All matrices of operators in this proof will be with respect to that basis. Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ). If ùúÜ ‚àà ùêÖ, then tr(ùúÜùëá) = tr ‚Ñ≥(ùúÜùëá) = tr(ùúÜ‚Ñ≥(ùëá))= ùúÜ tr ‚Ñ≥(ùëá) = ùúÜ tr ùëá, where the first and last equalities come from the definition of the trace of an operator, the second equality comes from 3.38, and the third equality follows from the definition of the trace of a square matrix. Also, tr(ùëÜ + ùëá) = tr ‚Ñ≥(ùëÜ + ùëá) = tr(‚Ñ≥(ùëÜ) + ‚Ñ≥(ùëá))= tr ‚Ñ≥(ùëÜ) + tr ‚Ñ≥(ùëá) = tr ùëÜ + tr ùëá, where the first and last equalities come from the definition of the trace of an operator, the second equality comes from 3.35, and the third equality follows from the definition of the trace of a square matrix. The two paragraphs above show that tr‚à∂ ‚Ñí(ùëâ) ‚Üí ùêÖ is a linear functional on ‚Ñí(ùëâ). Furthermore, tr(ùëÜùëá) = tr ‚Ñ≥(ùëÜùëá) = tr(‚Ñ≥(ùëÜ)‚Ñ≥(ùëá))= tr(‚Ñ≥(ùëá)‚Ñ≥(ùëÜ))= tr ‚Ñ≥(ùëáùëÜ) = tr(ùëáùëÜ), where the second and fourth equalities come from 3.43 and the crucial third equality comes from 8.49. The equations tr(ùëÜùëá) = tr(ùëáùëÜ) and tr ùêº = dim ùëâ uniquely characterize the trace among the linear functionals on ‚Ñí(ùëâ)‚Äîsee Exercise 10. 330 Chapter 8 Operators on Complex Vector Spaces The statement of the next result does not involve traces, but the short proof uses traces. When something like this happens in mathematics, then usually a good definition lurks in the back- ground. The equation tr(ùëÜùëá) = tr(ùëáùëÜ) leads to our next result, which does not hold on infinite-dimensional vector spaces (see Exercise 13). However, additional hy- potheses on ùëÜ, ùëá, and ùëâ lead to an infinite- dimensional generalization of the result below, with important applications to quantum theory. 8.57 identity operator is not the difference of ùëÜùëá and ùëáùëÜ There do not exist operators ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) such that ùëÜùëá ‚àí ùëáùëÜ = ùêº. Proof Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ). Then tr(ùëÜùëá ‚àí ùëáùëÜ) = tr(ùëÜùëá) ‚àí tr(ùëáùëÜ) = 0, where both equalities come from 8.56. The trace of ùêº equals dim ùëâ, which is not 0. Because ùëÜùëá ‚àí ùëáùëÜ and ùêº have different traces, they cannot be equal. Exercises 8D 1 Suppose ùëâ is an inner product space and ùë£, ùë§ ‚àà ùëâ. Define an operator ùëá ‚àà ‚Ñí(ùëâ) by ùëáùë¢ = ‚ü®ùë¢, ùë£‚ü©ùë§. Find a formula for tr ùëá. 2 Suppose ùëÉ ‚àà ‚Ñí(ùëâ) satisfiesùëÉ2 = ùëÉ. Prove that tr ùëÉ = dim range ùëÉ. 3 Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëá5 = ùëá. Prove that the real and imaginary parts of tr ùëá are both integers. 4 Suppose ùëâ is an inner product space and ùëá ‚àà ‚Ñí(ùëâ). Prove that tr ùëá‚àó = tr ùëá. 5 Suppose ùëâ is an inner product space. Suppose ùëá ‚àà ‚Ñí(ùëâ) is a positive operator and tr ùëá = 0. Prove that ùëá = 0. 6 Suppose ùëâ is an inner product space and ùëÉ, ùëÑ ‚àà ‚Ñí(ùëâ) are orthogonal projections. Prove that tr(ùëÉùëÑ) ‚â• 0. 7 Suppose ùëá ‚àà ‚Ñí(ùêÇ 3)is the operator whose matrix is ‚éõ‚éú‚éú‚éú ‚éù 51 ‚àí12 ‚àí21 60 ‚àí40 ‚àí28 57 ‚àí68 1 ‚éû‚éü‚éü‚éü ‚é† . Someone tells you (accurately) that ‚àí48and 24are eigenvalues of ùëá. Without using a computer or writing anything down, find the third eigenvalue ofùëá. Section 8D Trace: A Connection Between Matrices and Operators 331 8 Prove or give a counterexample: If ùëÜ, ùëá ‚àà ‚Ñí(ùëâ), then tr(ùëÜùëá) = (tr ùëÜ)(tr ùëá). 9 Suppose ùëá ‚àà ‚Ñí(ùëâ) is such that tr(ùëÜùëá) = 0for all ùëÜ ‚àà ‚Ñí(ùëâ). Prove that ùëá = 0. 10 Prove that the trace is the only linear functional ùúè‚à∂ ‚Ñí(ùëâ) ‚Üí ùêÖ such that ùúè(ùëÜùëá) = ùúè(ùëáùëÜ) for all ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) and ùúè(ùêº) = dim ùëâ. Hint: Suppose that ùë£1, ‚Ä¶, ùë£ùëõ is a basis of ùëâ. For ùëó, ùëò ‚àà {1, ‚Ä¶, ùëõ}, define ùëÉùëó, ùëò ‚àà ‚Ñí(ùëâ) by ùëÉùëó, ùëò(ùëé1ùë£1 + ‚ãØ + ùëéùëõùë£ùëõ) = ùëéùëòùë£ùëó. Prove that ùúè(ùëÉùëó, ùëò) = ‚éß{ ‚é®{‚é© 1 if ùëó = ùëò, 0 if ùëó ‚â† ùëò. Then for ùëá ‚àà ‚Ñí(ùëâ), use the equation ùëá = ‚àë ùëõ ùëò = 1 ‚àë ùëõ ùëó = 1 ‚Ñ≥(ùëá)ùëó, ùëòùëÉùëó, ùëò to show that ùúè(ùëá) = tr ùëá. 11 Suppose ùëâ and ùëä are inner product spaces and ùëá ‚àà ‚Ñí(ùëâ, ùëä). Prove that if ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ and ùëì1, ‚Ä¶, ùëìùëö is an orthonormal basis of ùëä, then tr(ùëá‚àóùëá)= ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1|‚ü®ùëáùëíùëò, ùëìùëó‚ü©| 2. The numbers ‚ü®ùëáùëíùëò, ùëìùëó‚ü©are the entries of the matrix of ùëá with respect to the orthonormal bases ùëí1, ‚Ä¶, ùëíùëõ and ùëì1, ‚Ä¶, ùëìùëö. These numbers depend on the bases, but tr(ùëá‚àóùëá) does not depend on a choice of bases. Thus this exercise shows that the sum of the squares of the absolute values of the matrix entries does not depend on which orthonormal bases are used. 12 Suppose ùëâ and ùëä are finite-dimensional inner product spaces. (a) Prove that ‚ü®ùëÜ, ùëá‚ü© =tr(ùëá‚àóùëÜ)defines an inner product on‚Ñí(ùëâ, ùëä). (b) Suppose ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ and ùëì1, ‚Ä¶, ùëìùëö is an or- thonormal basis of ùëä. Show that the inner product on ‚Ñí(ùëâ, ùëä) from (a) is the same as the standard inner product on ùêÖùëöùëõ, where we identify each element of ‚Ñí(ùëâ, ùëä) with its matrix (with respect to the bases just mentioned) and then with an element of ùêÖùëöùëõ. Caution: The norm of a linear map ùëá ‚àà ‚Ñí(ùëâ, ùëä) as defined by 7.86 is not the same as the norm that comes from the inner product in (a) above. Unless explicitly stated otherwise, always assume that ‚Äñùëá‚Äñ refers to the norm as defined by 7.86. The norm that comes from the inner product in (a) is called the Frobenius norm or the Hilbert‚ÄìSchmidt norm. 13 Find ùëÜ, ùëá ‚àà ‚Ñí(ùí´(ùêÖ))such that ùëÜùëá ‚àí ùëáùëÜ = ùêº. Hint: Make an appropriate modification of the operators in Example 3.9. This exercise shows that additional hypotheses are needed on ùëÜ and ùëá to extend 8.57 to the setting of infinite-dimensional vector spaces. Chapter 9 Multilinear Algebra and Determinants We begin this chapter by investigating bilinear forms and quadratic forms on a vector space. Then we will move on to multilinear forms. We will show that the vector space of alternating ùëõ-linear forms has dimension one on a vector space of dimension ùëõ. This result will allow us to give a clean basis-free definition of the determinant of an operator. This approach to the determinant via alternating multilinear forms leads to straightforward proofs of key properties of determinants. For example, we will see that the determinant is multiplicative, meaning that det(ùëÜùëá) = (det ùëÜ)(det ùëá) for all operators ùëÜ and ùëá on the same vector space. We will also see that ùëá is invertible if and only if det ùëá ‚â† 0. Another important result states that the determinant of an operator on a complex vector space equals the product of the eigenvalues of the operator, with each eigenvalue included as many times as its multiplicity. The chapter concludes with an introduction to tensor products. standing assumptions for this chapter ‚Ä¢ ùêÖ denotes ùêë or ùêÇ. ‚Ä¢ ùëâ and ùëä denote finite-dimensional nonzero vector spaces overùêÖ.MatthewPetroffCCBY-SA The Mathematical Institute at the University of G√∂ttingen. This building opened in 1930, when Emmy Noether (1882‚Äì1935) had already been a research mathematician and faculty member at the university for 15 years (the first eight years without salary). Noether was fired by the Nazi government in 1933. By then Noether and her collaborators had created many of the foundations of modern algebra, including an abstract algebra viewpoint that contributed to the development of linear algebra. 332 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0_9 ¬© Sheldon Axler 2024 Section 9A Bilinear Forms and Quadratic Forms 333 9A Bilinear Forms and Quadratic Forms Bilinear Forms A bilinear form on ùëâ is a function from ùëâ √ó ùëâ to ùêÖ that is linear in each slot separately, meaning that if we hold either slot fixed then we have a linear function in the other slot. Here is the formal definition. 9.1 definition: bilinear form A bilinear form on ùëâ is a function ùõΩ‚à∂ ùëâ √ó ùëâ ‚Üí ùêÖ such that ùë£ ‚Ü¶ ùõΩ(ùë£, ùë¢) and ùë£ ‚Ü¶ ùõΩ(ùë¢, ùë£) are both linear functionals on ùëâ for every ùë¢ ‚àà ùëâ. Recall that the term linear functional, used in the definition above, means a linear function that maps into the scalar field ùêÖ. Thus the term bilinear functional would be more consistent terminology than bilinear form, which unfortunately has become standard. For example, if ùëâ is a real inner prod- uct space, then the function that takes an ordered pair (ùë¢, ùë£) ‚àà ùëâ √ó ùëâ to ‚ü®ùë¢, ùë£‚ü©is a bilinear form on ùëâ. If ùëâ is a nonzero complex inner product space, then this function is not a bilinear form because the inner product is not linear in the sec- ond slot (complex scalars come out of the second slot as their complex conjugates). If ùêÖ = ùêë, then a bilinear form differs from an inner product in that an inner product requires symmetry [meaning that ùõΩ(ùë£, ùë§) = ùõΩ(ùë§, ùë£) for all ùë£, ùë§ ‚àà ùëâ] and positive definiteness[meaning that ùõΩ(ùë£, ùë£) > 0for all ùë£ ‚àà ùëâ\\{0}], but these properties are not required for a bilinear form. 9.2 example: bilinear forms ‚Ä¢ The function ùõΩ‚à∂ ùêÖ3 √ó ùêÖ3 ‚Üí ùêÖ defined by ùõΩ((ùë•1, ùë•2, ùë•3), (ùë¶1, ùë¶2, ùë¶3))= ùë•1ùë¶2 ‚àí 5ùë•2ùë¶3 + 2ùë•3ùë¶1 is a bilinear form on ùêÖ3. ‚Ä¢ Suppose ùê¥ is an ùëõ-by-ùëõ matrix with ùê¥ùëó, ùëò ‚àà ùêÖ in row ùëó, column ùëò. Define a bilinear form ùõΩùê¥ on ùêÖùëõ by ùõΩùê¥((ùë•1, ‚Ä¶, ùë•ùëõ), (ùë¶1, ‚Ä¶, ùë¶ùëõ))= ùëõ ‚àë ùëò = 1 ùëõ ‚àë ùëó = 1 ùê¥ùëó, ùëòùë•ùëóùë¶ùëò. The first bullet point is a special case of this bullet point withùëõ = 3and ùê¥ = ‚éõ‚éú‚éú‚éú ‚éù 0 1 0 0 0 ‚àí5 2 0 0 ‚éû‚éü‚éü‚éü ‚é† . 334 Chapter 9 Multilinear Algebra and Determinants ‚Ä¢ Suppose ùëâ is a real inner product space and ùëá ‚àà ‚Ñí(ùëâ). Then the function ùõΩ‚à∂ ùëâ √ó ùëâ ‚Üí ùêë defined by ùõΩ(ùë¢, ùë£) = ‚ü®ùë¢, ùëáùë£‚ü© is a bilinear form on ùëâ. ‚Ä¢ If ùëõ is a positive integer, then the function ùõΩ‚à∂ ùí´ùëõ(ùêë) √ó ùí´ùëõ(ùêë) ‚Üí ùêë defined by ùõΩ(ùëù, ùëû) = ùëù(2) ‚ãÖ ùëû ‚Ä≤(3) is a bilinear form on ùí´ùëõ(ùêë). ‚Ä¢ Suppose ùúë, ùúè ‚àà ùëâ‚Ä≤. Then the function ùõΩ‚à∂ ùëâ √ó ùëâ ‚Üí ùêÖ defined by ùõΩ(ùë¢, ùë£) = ùúë(ùë¢) ‚ãÖ ùúè(ùë£) is a bilinear form on ùëâ. ‚Ä¢ More generally, suppose that ùúë1, ‚Ä¶, ùúëùëõ, ùúè1, ‚Ä¶, ùúèùëõ ‚àà ùëâ‚Ä≤. Then the function ùõΩ‚à∂ ùëâ √ó ùëâ ‚Üí ùêÖ defined by ùõΩ(ùë¢, ùë£) = ùúë1(ùë¢) ‚ãÖ ùúè1(ùë£) + ‚ãØ + ùúëùëõ(ùë¢) ‚ãÖ ùúèùëõ(ùë£) is a bilinear form on ùëâ. A bilinear form on ùëâ is a function from ùëâ √ó ùëâ to ùêÖ. Because ùëâ √ó ùëâ is a vector space, this raises the question of whether a bilinear form can also be a linear map from ùëâ√ó ùëâ to ùêÖ. Note that none of the bilinear forms in 9.2 are linear maps except in some special cases in which the bilinear form is the zero map. Exercise 3 shows that a bilinear form ùõΩ on ùëâ is a linear map on ùëâ √ó ùëâ only if ùõΩ = 0. 9.3 definition: ùëâ(2) The set of bilinear forms on ùëâ is denoted by ùëâ(2). With the usual operations of addition and scalar multiplication of functions, ùëâ(2)is a vector space. For ùëá an operator on an ùëõ-dimensional vector space ùëâ and a basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ, we used an ùëõ-by-ùëõ matrix to provide information about ùëá. We now do the same thing for bilinear forms on ùëâ. 9.4 definition: matrix of a bilinear form, ‚Ñ≥(ùõΩ) Suppose ùõΩ is a bilinear form on ùëâ and ùëí1, ‚Ä¶, ùëíùëõ is a basis of ùëâ. The matrix of ùõΩ with respect to this basis is the ùëõ-by-ùëõ matrix ‚Ñ≥(ùõΩ) whose entry ‚Ñ≥(ùõΩ)ùëó, ùëò in row ùëó, column ùëò is given by ‚Ñ≥(ùõΩ)ùëó, ùëò = ùõΩ(ùëíùëó, ùëíùëò). If the basis ùëí1, ‚Ä¶, ùëíùëõ is not clear from the context, then the notation ‚Ñ≥(ùõΩ, (ùëí1, ‚Ä¶, ùëíùëõ))is used. Section 9A Bilinear Forms and Quadratic Forms 335 Recall that ùêÖùëõ, ùëõ denotes the vector space of ùëõ-by-ùëõ matrices with entries in ùêÖ and that dim ùêÖùëõ, ùëõ = ùëõ2 (see 3.39 and 3.40). 9.5 dim ùëâ(2)= (dim ùëâ) 2 Suppose ùëí1, ‚Ä¶, ùëíùëõ is a basis of ùëâ. Then the map ùõΩ ‚Ü¶ ‚Ñ≥(ùõΩ) is an isomorphism of ùëâ(2)onto ùêÖùëõ, ùëõ. Furthermore, dim ùëâ(2)= (dim ùëâ) 2. Proof The map ùõΩ ‚Ü¶ ‚Ñ≥(ùõΩ) is clearly a linear map of ùëâ(2)into ùêÖùëõ, ùëõ. For ùê¥ ‚àà ùêÖùëõ, ùëõ, define a bilinear formùõΩùê¥ on ùëâ by ùõΩùê¥(ùë•1ùëí1 + ‚ãØ + ùë•ùëõùëíùëõ, ùë¶1ùëí1 + ‚ãØ + ùë¶ùëõùëíùëõ) = ùëõ ‚àë ùëò = 1 ùëõ ‚àë ùëó = 1 ùê¥ùëó, ùëòùë•ùëóùë¶ùëò for ùë•1, ‚Ä¶, ùë•ùëõ, ùë¶1, ‚Ä¶, ùë¶ùëõ ‚àà ùêÖ (if ùëâ = ùêÖùëõ and ùëí1, ‚Ä¶, ùëíùëõ is the standard basis of ùêÖùëõ, this ùõΩùê¥ is the same as the bilinear form ùõΩùê¥ in the second bullet point of Example 9.2). The linear map ùõΩ ‚Ü¶ ‚Ñ≥(ùõΩ) from ùëâ(2)to ùêÖùëõ, ùëõ and the linear map ùê¥ ‚Ü¶ ùõΩùê¥ from ùêÖùëõ, ùëõ to ùëâ(2)are inverses of each other because ùõΩ‚Ñ≥(ùõΩ)= ùõΩ for all ùõΩ ‚àà ùëâ(2)and ‚Ñ≥(ùõΩùê¥) = ùê¥ for all ùê¥ ‚àà ùêÖùëõ, ùëõ, as you should verify. Thus both maps are isomorphisms and the two spaces that they connect have the same dimension. Hence dim ùëâ(2)= dim ùêÖùëõ, ùëõ = ùëõ2 = (dim ùëâ) 2. Recall that ùê∂ t denotes the transpose of a matrix ùê∂. The matrix ùê∂ t is obtained by interchanging the rows and the columns of ùê∂. 9.6 composition of a bilinear form and an operator Suppose ùõΩ is a bilinear form on ùëâ and ùëá ‚àà ‚Ñí(ùëâ). Define bilinear formsùõº and ùúå on ùëâ by ùõº(ùë¢, ùë£) = ùõΩ(ùë¢, ùëáùë£) and ùúå(ùë¢, ùë£) = ùõΩ(ùëáùë¢, ùë£). Let ùëí1, ‚Ä¶, ùëíùëõ be a basis of ùëâ. Then ‚Ñ≥(ùõº) = ‚Ñ≥(ùõΩ)‚Ñ≥(ùëá) and ‚Ñ≥(ùúå) = ‚Ñ≥(ùëá) t‚Ñ≥(ùõΩ). Proof If ùëó, ùëò ‚àà {1, ‚Ä¶, ùëõ}, then ‚Ñ≥(ùõº)ùëó, ùëò = ùõº(ùëíùëó, ùëíùëò) = ùõΩ(ùëíùëó, ùëáùëíùëò) = ùõΩ(ùëíùëó, ùëõ ‚àë ùëö = 1 ‚Ñ≥(ùëá)ùëö, ùëò ùëíùëö) = ùëõ ‚àë ùëö = 1 ùõΩ(ùëíùëó, ùëíùëö)‚Ñ≥(ùëá)ùëö, ùëò = (‚Ñ≥(ùõΩ)‚Ñ≥(ùëá)) ùëó, ùëò. Thus ‚Ñ≥(ùõº) = ‚Ñ≥(ùõΩ)‚Ñ≥(ùëá). The proof that ‚Ñ≥(ùúå) = ‚Ñ≥(ùëá) t‚Ñ≥(ùõΩ) is similar. 336 Chapter 9 Multilinear Algebra and Determinants The result below shows how the matrix of a bilinear form changes if we change the basis. The formula in the result below should be compared to the change- of-basis formula for the matrix of an operator (see 3.84). The two formulas are similar, except that the transpose ùê∂ t appears in the formula below and the inverse ùê∂‚àí1 appears in the change-of-basis formula for the matrix of an operator. 9.7 change-of-basis formula Suppose ùõΩ ‚àà ùëâ(2). Suppose ùëí1, ‚Ä¶, ùëíùëõ and ùëì1, ‚Ä¶, ùëìùëõ are bases of ùëâ. Let ùê¥ = ‚Ñ≥(ùõΩ, (ùëí1, ‚Ä¶, ùëíùëõ)) and ùêµ = ‚Ñ≥(ùõΩ, ( ùëì1, ‚Ä¶, ùëìùëõ)) and ùê∂ = ‚Ñ≥(ùêº, (ùëí1, ‚Ä¶, ùëíùëõ), ( ùëì1, ‚Ä¶, ùëìùëõ)). Then ùê¥ = ùê∂ tùêµùê∂. Proof The linear map lemma (3.4) tells us that there exists an operator ùëá ‚àà ‚Ñí(ùëâ) such that ùëá ùëìùëò = ùëíùëò for each ùëò = 1, ‚Ä¶, ùëõ. The definition of the matrix of an operator with respect to a basis implies that ‚Ñ≥(ùëá, ( ùëì1, ‚Ä¶, ùëìùëõ))= ùê∂. Define bilinear formsùõº, ùúå on ùëâ by ùõº(ùë¢, ùë£) = ùõΩ(ùë¢, ùëáùë£) and ùúå(ùë¢, ùë£) = ùõº(ùëáùë¢, ùë£) = ùõΩ(ùëáùë¢, ùëáùë£). Then ùõΩ(ùëíùëó, ùëíùëò) = ùõΩ(ùëá ùëìùëó, ùëá ùëìùëò) = ùúå( ùëìùëó, ùëìùëò) for all ùëó, ùëò ‚àà {1, ‚Ä¶, ùëõ}. Thus ùê¥ = ‚Ñ≥(ùúå, ( ùëì1, ‚Ä¶, ùëìùëõ)) = ùê∂ t‚Ñ≥(ùõº, ùëì1, ‚Ä¶, ùëìùëõ)) = ùê∂ tùêµùê∂, where the second and third lines each follow from 9.6. 9.8 example: the matrix of a bilinear form on ùí´2(ùêë) Define a bilinear formùõΩ on ùí´2(ùêë) by ùõΩ(ùëù, ùëû) = ùëù(2) ‚ãÖ ùëû ‚Ä≤(3). Let ùê¥ = ‚Ñ≥(ùõΩ, (1, ùë• ‚àí 2, (ùë• ‚àí 3) 2)) and ùêµ = ‚Ñ≥(ùõΩ, (1, ùë•, ùë•2)) and ùê∂ = ‚Ñ≥(ùêº, (1, ùë• ‚àí 2, (ùë• ‚àí 3) 2), (1, ùë•, ùë•2)). Then ùê¥ = ‚éõ‚éú‚éú‚éú ‚éù 0 1 0 0 0 0 0 1 0 ‚éû‚éü‚éü‚éü ‚é† and ùêµ = ‚éõ‚éú‚éú‚éú ‚éù 0 1 6 0 2 12 0 4 24 ‚éû‚éü‚éü‚éü ‚é† and ùê∂ = ‚éõ‚éú‚éú‚éú ‚éù 1 ‚àí2 9 0 1 ‚àí6 0 0 1 ‚éû‚éü‚éü‚éü ‚é† . Now the change-of-basis formula 9.7 asserts that ùê¥ = ùê∂ tùêµùê∂, which you can verify with matrix multiplication using the matrices above. Section 9A Bilinear Forms and Quadratic Forms 337 Symmetric Bilinear Forms 9.9 definition: symmetric bilinear form, ùëâ(2) sym A bilinear form ùúå ‚àà ùëâ(2)is called symmetric if ùúå(ùë¢, ùë§) = ùúå(ùë§, ùë¢) for all ùë¢, ùë§ ‚àà ùëâ. The set of symmetric bilinear forms on ùëâ is denoted by ùëâ(2) sym. 9.10 example: symmetric bilinear forms ‚Ä¢ If ùëâ is a real inner product space and ùúå ‚àà ùëâ(2)is defined by ùúå(ùë¢, ùë§) = ‚ü®ùë¢, ùë§‚ü©, then ùúå is a symmetric bilinear form on ùëâ. ‚Ä¢ Suppose ùëâ is a real inner product space and ùëá ‚àà ‚Ñí(ùëâ). Defineùúå ‚àà ùëâ(2)by ùúå(ùë¢, ùë§) = ‚ü®ùë¢, ùëáùë§‚ü©. Then ùúå is a symmetric bilinear form on ùëâ if and only if ùëá is a self-adjoint operator (the previous bullet point is the special case ùëá = ùêº). ‚Ä¢ Suppose ùúå‚à∂ ‚Ñí(ùëâ) √ó ‚Ñí(ùëâ) ‚Üí ùêÖ is defined by ùúå(ùëÜ, ùëá) = tr(ùëÜùëá). Then ùúå is a symmetric bilinear form on ‚Ñí(ùëâ) because trace is a linear functional on ‚Ñí(ùëâ) and tr(ùëÜùëá) = tr(ùëáùëÜ) for all ùëÜ, ùëá ‚àà ‚Ñí(ùëâ); see 8.56. 9.11 definition: symmetric matrix A square matrix ùê¥ is called symmetric if it equals its transpose. An operator on ùëâ may have a symmetric matrix with respect to some but not all bases of ùëâ. In contrast, the next result shows that a bilinear form on ùëâ has a sym- metric matrix with respect to either all bases of ùëâ or with respect to no bases of ùëâ. 9.12 symmetric bilinear forms are diagonalizable Suppose ùúå ‚àà ùëâ(2). Then the following are equivalent. (a) ùúå is a symmetric bilinear form on ùëâ. (b) ‚Ñ≥(ùúå, (ùëí1, ‚Ä¶, ùëíùëõ))is a symmetric matrix for every basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ. (c) ‚Ñ≥(ùúå, (ùëí1, ‚Ä¶, ùëíùëõ))is a symmetric matrix for some basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ. (d) ‚Ñ≥(ùúå, (ùëí1, ‚Ä¶, ùëíùëõ))is a diagonal matrix for some basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ. 338 Chapter 9 Multilinear Algebra and Determinants Proof First suppose (a) holds, so ùúå is a symmetric bilinear form. Suppose ùëí1, ‚Ä¶, ùëíùëõ is a basis of ùëâ and ùëó, ùëò ‚àà {1, ‚Ä¶, ùëõ}. Then ùúå(ùëíùëó, ùëíùëò) = ùúå(ùëíùëò, ùëíùëó) because ùúå is symmetric. Thus ‚Ñ≥(ùúå, (ùëí1, ‚Ä¶, ùëíùëõ))is a symmetric matrix, showing that (a) implies (b). Clearly (b) implies (c). Now suppose (c) holds and ùëí1, ‚Ä¶, ùëíùëõ is a basis of ùëâ such that ‚Ñ≥(ùúå, (ùëí1, ‚Ä¶, ùëíùëõ)) is a symmetric matrix. Suppose ùë¢, ùë§ ‚àà ùëâ. There exist ùëé1, ‚Ä¶, ùëéùëõ, ùëè1, ‚Ä¶, ùëèùëõ ‚àà ùêÖ such that ùë¢ = ùëé1ùëí1 + ‚ãØ + ùëéùëõùëíùëõ and ùë§ = ùëè1ùëí1 + ‚ãØ + ùëèùëõùëíùëõ. Now ùúå(ùë¢, ùë§) = ùúå(ùëõ ‚àë ùëó = 1 ùëéùëóùëíùëó, ùëõ ‚àë ùëò = 1 ùëèùëòùëíùëò) = ùëõ ‚àë ùëó = 1 ùëõ ‚àë ùëò = 1 ùëéùëóùëèùëòùúå(ùëíùëó, ùëíùëò) = ùëõ ‚àë ùëó = 1 ùëõ ‚àë ùëò = 1 ùëéùëóùëèùëòùúå(ùëíùëò, ùëíùëó) = ùúå( ùëõ ‚àë ùëò = 1 ùëèùëòùëíùëò, ùëõ ‚àë ùëó = 1 ùëéùëóùëíùëó) = ùúå(ùë§, ùë¢), where the third line holds because ‚Ñ≥(ùúå) is a symmetric matrix. The equation above shows that ùúå is a symmetric bilinear form, proving that (c) implies (a). At this point, we have proved that (a), (b), (c) are equivalent. Because every diagonal matrix is symmetric, (d) implies (c). To complete the proof, we will show that (a) implies (d) by induction on ùëõ = dim ùëâ. If ùëõ = 1, then (a) implies (d) because every 1-by-1matrix is diagonal. Now suppose ùëõ > 1and the implication (a) ‚üπ (d) holds for one less dimension. Suppose (a) holds, so ùúå is a symmetric bilinear form. If ùúå = 0, then the matrix of ùúå with respect to every basis of ùëâ is the zero matrix, which is a diagonal matrix. Hence we can assume that ùúå ‚â† 0, which means there exist ùë¢, ùë§ ‚àà ùëâ such that ùúå(ùë¢, ùë§) ‚â† 0. Now 2ùúå(ùë¢, ùë§) = ùúå(ùë¢ + ùë§, ùë¢ + ùë§) ‚àí ùúå(ùë¢, ùë¢) ‚àí ùúå(ùë§, ùë§). Because the left side of the equation above is nonzero, the three terms on the right cannot all equal 0. Hence there exists ùë£ ‚àà ùëâ such that ùúå(ùë£, ùë£) ‚â† 0. Let ùëà = {ùë¢ ‚àà ùëâ ‚à∂ ùúå(ùë¢, ùë£) = 0}. Thus ùëà is the null space of the linear functional ùë¢ ‚Ü¶ ùúå(ùë¢, ùë£) on ùëâ. This linear functional is not the zero linear functional because ùë£ ‚àâ ùëà. Thus dim ùëà = ùëõ ‚àí 1. By our induction hypothesis, there is a basis ùëí1, ‚Ä¶, ùëíùëõ ‚àí 1 of ùëà such that the symmetric bilinear form ùúå|ùëà √ó ùëà has a diagonal matrix with respect to this basis. Because ùë£ ‚àâ ùëà, the list ùëí1, ‚Ä¶, ùëíùëõ ‚àí 1, ùë£ is a basis of ùëâ. Suppose ùëò ‚àà {1, ‚Ä¶, ùëõ‚àí1}. Then ùúå(ùëíùëò, ùë£) = 0by the construction of ùëà. Because ùúå is symmetric, we also have ùúå(ùë£, ùëíùëò) = 0. Thus the matrix of ùúå with respect to ùëí1, ‚Ä¶, ùëíùëõ ‚àí 1, ùë£ is a diagonal matrix, completing the proof that (a) implies (d). Section 9A Bilinear Forms and Quadratic Forms 339 The previous result states that every symmetric bilinear form has a diagonal matrix with respect to some basis. If our vector space happens to be a real inner product space, then the next result shows that every symmetric bilinear form has a diagonal matrix with respect to some orthonormal basis. Note that the inner product here is unrelated to the bilinear form. 9.13 diagonalization of a symmetric bilinear form by an orthonormal basis Suppose ùëâ is a real inner product space and ùúå is a symmetric bilinear form on ùëâ. Then ùúå has a diagonal matrix with respect to some orthonormal basis of ùëâ. Proof Let ùëì1, ‚Ä¶, ùëìùëõ be an orthonormal basis of ùëâ. Let ùêµ = ‚Ñ≥(ùúå, ( ùëì1, ‚Ä¶, ùëìùëõ)). Then ùêµ is a symmetric matrix (by 9.12). Let ùëá ‚àà ‚Ñí(ùëâ) be the operator such that ‚Ñ≥(ùëá, ( ùëì1, ‚Ä¶, ùëìùëõ))= ùêµ. Thus ùëá is self-adjoint. The real spectral theorem (7.29) states that ùëá has a diagonal matrix with respect to some orthonormal basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ. Let ùê∂ = ‚Ñ≥(ùêº, (ùëí1, ‚Ä¶, ùëíùëõ), ( ùëì1, ‚Ä¶, ùëìùëõ)). Thus ùê∂‚àí1ùëáùê∂ is the matrix of ùëá with respect to the basis ùëí1, ‚Ä¶, ùëíùëõ (by 3.84). Hence ùê∂‚àí1ùëáùê∂ is a diagonal matrix. Now ùëÄ(ùúå, (ùëí1, ‚Ä¶, ùëíùëõ))= ùê∂ tùëáùê∂ = ùê∂‚àí1ùëáùê∂, where the first equality holds by9.7 and the second equality holds because ùê∂ is a unitary matrix with real entries (which implies that ùê∂‚àí1 = ùê∂ t; see 7.57). Now we turn our attention to alternating bilinear forms. Alternating multilinear forms will play a major role in our approach to determinants later in this chapter. 9.14 definition: alternating bilinear form, ùëâ(2) alt A bilinear form ùõº ‚àà ùëâ(2)is called alternating if ùõº(ùë£, ùë£) = 0 for all ùë£ ‚àà ùëâ. The set of alternating bilinear forms on ùëâ is denoted by ùëâ(2) alt . 9.15 example: alternating bilinear forms ‚Ä¢ Suppose ùëõ ‚â• 3and ùõº‚à∂ ùêÖùëõ √ó ùêÖùëõ ‚Üí ùêÖ is defined by ùõº((ùë•1, ‚Ä¶, ùë•ùëõ), (ùë¶1, ‚Ä¶, ùë¶ùëõ))= ùë•1ùë¶2 ‚àí ùë•2ùë¶1 + ùë•1ùë¶3 ‚àí ùë•3ùë¶1. Then ùõº is an alternating bilinear form on ùêÖùëõ. ‚Ä¢ Suppose ùúë, ùúè ‚àà ùëâ‚Ä≤. Then the bilinear form ùõº on ùëâ defined by ùõº(ùë¢, ùë§) = ùúë(ùë¢)ùúè(ùë§) ‚àí ùúë(ùë§)ùúè(ùë¢) is alternating. 340 Chapter 9 Multilinear Algebra and Determinants The next result shows that a bilinear form is alternating if and only if switching the order of the two inputs multiplies the output by ‚àí1. 9.16 characterization of alternating bilinear forms A bilinear form ùõº on ùëâ is alternating if and only if ùõº(ùë¢, ùë§) = ‚àíùõº(ùë§, ùë¢) for all ùë¢, ùë§ ‚àà ùëâ. Proof First suppose that ùõº is alternating. If ùë¢, ùë§ ‚àà ùëâ, then 0 = ùõº(ùë¢+ ùë§, ùë¢ + ùë§) = ùõº(ùë¢, ùë¢) + ùõº(ùë¢, ùë§) + ùõº(ùë§, ùë¢) + ùõº(ùë§, ùë§) = ùõº(ùë¢, ùë§) + ùõº(ùë§, ùë¢). Thus ùõº(ùë¢, ùë§) = ‚àíùõº(ùë§, ùë¢), as desired. To prove the implication in the other direction, suppose ùõº(ùë¢, ùë§) = ‚àíùõº(ùë§, ùë¢) for all ùë¢, ùë§ ‚àà ùëâ. Then ùõº(ùë£, ùë£) = ‚àíùõº(ùë£, ùë£) for all ùë£ ‚àà ùëâ, which implies that ùõº(ùë£, ùë£) = 0for all ùë£ ‚àà ùëâ. Thus ùõº is alternating. Now we show that the vector space of bilinear forms on ùëâ is the direct sum of the symmetric bilinear forms on ùëâ and the alternating bilinear forms on ùëâ. 9.17 ùëâ(2)= ùëâ(2) sym ‚äï ùëâ(2) alt The sets ùëâ(2) sym and ùëâ(2) alt are subspaces of ùëâ(2). Furthermore, ùëâ(2)= ùëâ(2) sym ‚äï ùëâ(2) alt . Proof The definition of symmetric bilinear form implies that the sum of any two symmetric bilinear forms on ùëâ is a bilinear form on ùëâ, and any scalar multiple of any bilinear form on ùëâ is a bilinear form on ùëâ. Thus ùëâ(2) sym is a subspace of ùëâ(2). Similarly, the verification thatùëâ(2) alt is a subspace of ùëâ(2)is straightforward. Next, we want to show that ùëâ(2)= ùëâ(2) sym + ùëâ(2) alt . To do this, suppose ùõΩ ‚àà ùëâ(2). Defineùúå, ùõº ‚àà ùëâ(2)by ùúå(ùë¢, ùë§) = ùõΩ(ùë¢, ùë§) + ùõΩ(ùë§, ùë¢) 2 and ùõº(ùë¢, ùë§) = ùõΩ(ùë¢, ùë§) ‚àí ùõΩ(ùë§, ùë¢) 2 . Then ùúå ‚àà ùëâ(2) sym and ùõº ‚àà ùëâ(2) alt , and ùõΩ = ùúå + ùõº. Thus ùëâ(2)= ùëâ(2) sym + ùëâ(2) alt . Finally, to show that the intersection of the two subspaces under consideration equals {0}, suppose ùõΩ ‚àà ùëâ(2) sym ‚à© ùëâ (2) alt . Then 9.16 implies that ùõΩ(ùë¢, ùë§) = ‚àíùõΩ(ùë§, ùë¢) = ‚àíùõΩ(ùë¢, ùë§) for all ùë¢, ùë§ ‚àà ùëâ, which implies that ùõΩ = 0. Thus ùëâ(2)= ùëâ(2) sym ‚äï ùëâ(2) alt , as implied by 1.46. Section 9A Bilinear Forms and Quadratic Forms 341 Quadratic Forms 9.18 definition: quadratic form associated with a bilinear form, ùëûùõΩ For ùõΩ a bilinear form on ùëâ, define a functionùëûùõΩ ‚à∂ ùëâ ‚Üí ùêÖ by ùëûùõΩ(ùë£) = ùõΩ(ùë£, ùë£). A function ùëû‚à∂ ùëâ ‚Üí ùêÖ is called a quadratic form on ùëâ if there exists a bilinear form ùõΩ on ùëâ such that ùëû = ùëûùõΩ. Note that if ùõΩ is a bilinear form, then ùëûùõΩ = 0if and only if ùõΩ is alternating. 9.19 example: quadratic form Suppose ùõΩ is the bilinear form on ùêë3 defined by ùõΩ((ùë•1, ùë•2, ùë•3), (ùë¶1, ùë¶2, ùë¶3))= ùë•1ùë¶1 ‚àí 4ùë•1ùë¶2 + 8ùë•1ùë¶3 ‚àí 3ùë•3ùë¶3. Then ùëûùõΩ is the quadratic form on ùêë3 given by the formula ùëûùõΩ(ùë•1, ùë•2, ùë•3) = ùë•1 2 ‚àí 4ùë•1ùë•2 + 8ùë•1ùë•3 ‚àí 3ùë•3 2. The quadratic form in the example above is typical of quadratic forms on ùêÖùëõ, as shown in the next result. 9.20 quadratic forms on ùêÖùëõ Suppose ùëõ is a positive integer and ùëû is a function from ùêÖùëõ to ùêÖ. Then ùëû is a quadratic form on ùêÖùëõ if and only if there exist numbers ùê¥ùëó, ùëò ‚àà ùêÖ for ùëó, ùëò ‚àà {1, ‚Ä¶, ùëõ} such that ùëû(ùë•1, ‚Ä¶, ùë•ùëõ) = ùëõ ‚àë ùëò = 1 ùëõ ‚àë ùëó = 1 ùê¥ùëó, ùëòùë•ùëóùë•ùëò for all (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêÖùëõ. Proof First suppose ùëû is a quadratic form on ùêÖùëõ. Thus there exists a bilinear form ùõΩ on ùêÖùëõ such that ùëû = ùëûùõΩ. Let ùê¥ be the matrix of ùõΩ with respect to the standard basis of ùêÖùëõ. Then for all (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêÖùëõ, we have the desired equation ùëû(ùë•1, ‚Ä¶, ùë•ùëõ) = ùõΩ((ùë•1, ‚Ä¶, ùë•ùëõ), (ùë•1, ‚Ä¶, ùë•ùëõ))= ùëõ ‚àë ùëò = 1 ùëõ ‚àë ùëó = 1 ùê¥ùëó, ùëòùë•ùëóùë•ùëò. Conversely, suppose there exist numbers ùê¥ùëó, ùëò ‚àà ùêÖ for ùëó, ùëò ‚àà {1, ‚Ä¶, ùëõ} such that ùëû(ùë•1, ‚Ä¶, ùë•ùëõ) = ùëõ ‚àë ùëò = 1 ùëò ‚àë ùëó = 1 ùê¥ùëó, ùëòùë•ùëóùë•ùëò for all (ùë•1, ‚Ä¶, ùë•ùëõ) ‚àà ùêÖùëõ. Define a bilinear formùõΩ on ùêÖùëõ by ùõΩ((ùë•1, ‚Ä¶, ùë•ùëõ), (ùë¶1, ‚Ä¶, ùë¶ùëõ))= ùëõ ‚àë ùëò = 1 ùëò ‚àë ùëó = 1 ùê¥ùëó, ùëòùë•ùëóùë¶ùëò. Then ùëû = ùëûùõΩ, as desired. 342 Chapter 9 Multilinear Algebra and Determinants Although quadratic forms are defined in terms of an arbitrary bilinear form, the equivalence of (a) and (b) in the result below shows that a symmetric bilinear form can always be used. 9.21 characterization of quadratic forms Suppose ùëû‚à∂ ùëâ ‚Üí ùêÖ is a function. The following are equivalent. (a) ùëû is a quadratic form. (b) There exists a unique symmetric bilinear form ùúå on ùëâ such that ùëû = ùëûùúå. (c) ùëû(ùúÜùë£) = ùúÜ2ùëû(ùë£) for all ùúÜ ‚àà ùêÖ and all ùë£ ‚àà ùëâ, and the function (ùë¢, ùë§) ‚Ü¶ ùëû(ùë¢ + ùë§) ‚àí ùëû(ùë¢) ‚àí ùëû(ùë§) is a symmetric bilinear form on ùëâ. (d) ùëû(2ùë£) = 4ùëû(ùë£)for all ùë£ ‚àà ùëâ, and the function (ùë¢, ùë§) ‚Ü¶ ùëû(ùë¢ + ùë§) ‚àí ùëû(ùë¢) ‚àí ùëû(ùë§) is a symmetric bilinear form on ùëâ. Proof First suppose (a) holds, so ùëû is a quadratic form. Hence there exists a bilinear form ùõΩ such that ùëû = ùëûùõΩ. By 9.17, there exist a symmetric bilinear form ùúå on ùëâ and an alternating bilinear form ùõº on ùëâ such that ùõΩ = ùúå + ùõº. Now ùëû = ùëûùõΩ = ùëûùúå + ùëûùõº = ùëûùúå. If ùúå ‚Ä≤ ‚àà ùëâ(2) sym also satisfiesùëûùúå‚Ä≤ = ùëû, then ùëûùúå‚Ä≤ ‚àí ùúå = 0; thus ùúå ‚Ä≤ ‚àí ùúå ‚àà ùëâ(2) sym ‚à© ùëâ (2) alt , which implies that ùúå ‚Ä≤ = ùúå (by 9.17). This completes the proof that (a) implies (b). Now suppose (b) holds, so there exists a symmetric bilinear form ùúå on ùëâ such that ùëû = ùëûùúå. If ùúÜ ‚àà ùêÖ and ùë£ ‚àà ùëâ then ùëû(ùúÜùë£) = ùúå(ùúÜùë£, ùúÜùë£) = ùúÜùúå(ùë£, ùúÜùë£) = ùúÜ2ùúå(ùë£, ùë£) = ùúÜ2ùëû(ùë£), showing that the first part of (c) holds. If ùë¢, ùë§ ‚àà ùëâ, then ùëû(ùë¢ + ùë§) ‚àí ùëû(ùë¢) ‚àí ùëû(ùë§) = ùúå(ùë¢ + ùë§, ùë¢ + ùë§) ‚àí ùúå(ùë¢, ùë¢) ‚àí ùúå(ùë§, ùë§) = 2ùúå(ùë¢, ùë§). Thus the function (ùë¢, ùë§) ‚Ü¶ ùëû(ùë¢+ùë§)‚àíùëû(ùë¢)‚àíùëû(ùë§) equals 2ùúå, which is a symmetric bilinear form on ùëâ, completing the proof that (b) implies (c). Clearly (c) implies (d). Now suppose (d) holds. Let ùúå be the symmetric bilinear form on ùëâ defined by ùúå(ùë¢, ùë§) = ùëû(ùë¢ + ùë§) ‚àí ùëû(ùë¢) ‚àí ùëû(ùë§) 2 . If ùë£ ‚àà ùëâ, then ùúå(ùë£, ùë£) = ùëû(2ùë£) ‚àí ùëû(ùë£) ‚àí ùëû(ùë£) 2 = 4ùëû(ùë£) ‚àí 2ùëû(ùë£) 2 = ùëû(ùë£). Thus ùëû = ùëûùúå, completing the proof that (d) implies (a). Section 9A Bilinear Forms and Quadratic Forms 343 9.22 example: symmetric bilinear form associated with a quadratic form Suppose ùëû is the quadratic form on ùêë3 given by the formula ùëû(ùë•1, ùë•2, ùë•3) = ùë•1 2 ‚àí 4ùë•1ùë•2 + 8ùë•1ùë•3 ‚àí 3ùë•3 2. A bilinear form ùõΩ on ùêë3 such that ùëû = ùëûùõΩ is given by Example 9.19, but this bilinear form is not symmetric, as promised by 9.21(b). However, the bilinear form ùúå on ùêë3 defined by ùúå((ùë•1, ùë•2, ùë•3), (ùë¶1, ùë¶2, ùë¶3))= ùë•1ùë¶1 ‚àí 2ùë•1ùë¶2 ‚àí 2ùë•2ùë¶1 + 4ùë•1ùë¶3 + 4ùë•3ùë¶1 ‚àí 3ùë•3ùë¶3 is symmetric and satisfiesùëû = ùëûùúå. The next result states that for each quadratic form we can choose a basis such that the quadratic form looks like a weighted sum of squares of the coordinates, meaning that there are no cross terms of the form ùë•ùëóùë•ùëò with ùëó ‚â† ùëò. 9.23 diagonalization of quadratic form Suppose ùëû is a quadratic form on ùëâ. (a) There exist a basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ and ùúÜ1, ‚Ä¶, ùúÜùëõ ‚àà ùêÖ such that ùëû(ùë•1ùëí1 + ‚ãØ + ùë•ùëõùëíùëõ) = ùúÜ1ùë•1 2 + ‚ãØ + ùúÜùëõùë•ùëõ 2 for all ùë•1, ‚Ä¶, ùë•ùëõ ‚àà ùêÖ. (b) If ùêÖ = ùêë and ùëâ is an inner product space, then the basis in (a) can be chosen to be an orthonormal basis of ùëâ. Proof (a) There exists a symmetric bilinear form ùúå on ùëâ such that ùëû = ùëûùúå (by 9.21). Now there exists a basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ such that ‚Ñ≥(ùúå, (ùëí1, ‚Ä¶, ùëíùëõ))is a diagonal matrix (by 9.12). Let ùúÜ1, ‚Ä¶, ùúÜùëõ denote the entries on the diagonal of this matrix. Thus ùúå(ùëíùëó, ùëíùëò) = ‚éß{ ‚é®{‚é© ùúÜùëó if ùëó = ùëò, 0 if ùëó ‚â† ùëò for all ùëó, ùëò ‚àà {1, ‚Ä¶, ùëõ}. If ùë•1, ‚Ä¶, ùë•ùëõ ‚àà ùêÖ, then ùëû(ùë•1ùëí1 + ‚ãØ + ùë•ùëõùëíùëõ) = ùúå(ùë•1ùëí1 + ‚ãØ + ùë•ùëõùëíùëõ, ùë•1ùëí1 + ‚ãØ + ùë•ùëõùëíùëõ) = ùëõ ‚àë ùëò = 1 ùëõ ‚àë ùëó = 1 ùë•ùëóùë•ùëòùúå(ùëíùëó, ùëíùëò) = ùúÜ1ùë•1 2 + ‚ãØ + ùúÜùëõùë•ùëõ 2, as desired. (b) Suppose ùêÖ = ùêë and ùëâ is an inner product space. Then 9.13 tells us that the basis in (a) can be chosen to be an orthonormal basis of ùëâ. 344 Chapter 9 Multilinear Algebra and Determinants Exercises 9A 1 Prove that if ùõΩ is a bilinear form on ùêÖ, then there exists ùëê ‚àà ùêÖ such that ùõΩ(ùë•, ùë¶) = ùëêùë•ùë¶ for all ùë•, ùë¶ ‚àà ùêÖ. 2 Let ùëõ = dim ùëâ. Suppose ùõΩ is a bilinear form on ùëâ. Prove that there exist ùúë1, ‚Ä¶, ùúëùëõ, ùúè1, ‚Ä¶, ùúèùëõ ‚àà ùëâ‚Ä≤ such that ùõΩ(ùë¢, ùë£) = ùúë1(ùë¢) ‚ãÖ ùúè1(ùë£) + ‚ãØ + ùúëùëõ(ùë¢) ‚ãÖ ùúèùëõ(ùë£) for all ùë¢, ùë£ ‚àà ùëâ. This exercise shows that if ùëõ = dim ùëâ, then every bilinear form on ùëâ is of the form given by the last bullet point of Example 9.2. 3 Suppose ùõΩ‚à∂ ùëâ√ó ùëâ ‚Üí ùêÖ is a bilinear form on ùëâ and also is a linear functional on ùëâ √ó ùëâ. Prove that ùõΩ = 0. 4 Suppose ùëâ is a real inner product space and ùõΩ is a bilinear form on ùëâ. Show that there exists a unique operator ùëá ‚àà ‚Ñí(ùëâ) such that ùõΩ(ùë¢, ùë£) = ‚ü®ùë¢, ùëáùë£‚ü© for all ùë¢, ùë£ ‚àà ùëâ. This exercise states that if ùëâ is a real inner product space, then every bilinear form on ùëâ is of the form given by the third bullet point in 9.2. 5 Suppose ùõΩ is a bilinear form on a real inner product space ùëâ and ùëá is the unique operator on ùëâ such that ùõΩ(ùë¢, ùë£) = ‚ü®ùë¢, ùëáùë£‚ü©for all ùë¢, ùë£ ‚àà ùëâ (see Exercise 4). Show that ùõΩ is an inner product on ùëâ if and only if ùëá is an invertible positive operator on ùëâ. 6 Prove or give a counterexample: If ùúå is a symmetric bilinear form on ùëâ, then {ùë£ ‚àà ùëâ ‚à∂ ùúå(ùë£, ùë£) = 0} is a subspace of ùëâ. 7 Explain why the proof of 9.13 (diagonalization of a symmetric bilinear form by an orthonormal basis on a real inner product space) fails if the hypothesis that ùêÖ = ùêë is dropped. 8 Find formulas for dim ùëâ(2) sym and dim ùëâ(2) alt in terms of dim ùëâ. 9 Suppose that ùëõ is a positive integer and ùëâ = {ùëù ‚àà ùí´ùëõ(ùêë) ‚à∂ ùëù(0) = ùëù(1)}. Defineùõº‚à∂ ùëâ √ó ùëâ ‚Üí ùêë by ùõº(ùëù, ùëû) = ‚à´ 1 0 ùëùùëû ‚Ä≤. Show that ùõº is an alternating bilinear form on ùëâ. Section 9A Bilinear Forms and Quadratic Forms 345 10 Suppose that ùëõ is a positive integer and ùëâ = {ùëù ‚àà ùí´ùëõ(ùêë) ‚à∂ ùëù(0) = ùëù(1)and ùëù ‚Ä≤(0) = ùëù ‚Ä≤(1)}. Defineùúå‚à∂ ùëâ √ó ùëâ ‚Üí ùêë by ùúå(ùëù, ùëû) = ‚à´1 0 ùëùùëû ‚Ä≥. Show that ùúå is a symmetric bilinear form on ùëâ. Open Access This chapter is licensed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (https://creativecommons.org/licenses/by-nc/4.0), which permits any noncommercial use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to original author and source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this chapter are included in the chapter‚Äôs Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter‚Äôs Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. 346 Chapter 9 Multilinear Algebra and Determinants 9B Alternating Multilinear Forms Multilinear Forms 9.24 definition: ùëâùëö For ùëö a positive integer, defineùëâùëö by ùëâùëö = ùëâ √ó ‚ãØ √ó ùëâ‚èü ùëö times . Now we can defineùëö-linear forms as a generalization of the bilinear forms that we discussed in the previous section. 9.25 definition: ùëö-linear form, ùëâ(ùëö), multilinear form ‚Ä¢ For ùëö a positive integer, an ùëö-linear form on ùëâ is a function ùõΩ‚à∂ ùëâùëö ‚Üí ùêÖ that is linear in each slot when the other slots are held fixed. This means that for each ùëò ‚àà {1, ‚Ä¶, ùëö} and all ùë¢1, ‚Ä¶, ùë¢ùëö ‚àà ùëâ, the function ùë£ ‚Ü¶ ùõΩ(ùë¢1, ‚Ä¶, ùë¢ùëò ‚àí 1, ùë£, ùë¢ùëò + 1, ‚Ä¶, ùë¢ùëö) is a linear map from ùëâ to ùêÖ. ‚Ä¢ The set of ùëö-linear forms on ùëâ is denoted by ùëâ(ùëö). ‚Ä¢ A function ùõΩ is called a multilinear form on ùëâ if it is an ùëö-linear form on ùëâ for some positive integer ùëö. In the definition above, the expressionùõΩ(ùë¢1, ‚Ä¶, ùë¢ùëò ‚àí 1, ùë£, ùë¢ùëò + 1, ‚Ä¶, ùë¢ùëö) means ùõΩ(ùë£, ùë¢2, ‚Ä¶, ùë¢ùëö) if ùëò = 1and means ùõΩ(ùë¢1, ‚Ä¶, ùë¢ùëö ‚àí 1, ùë£) if ùëò = ùëö. A 1-linear form on ùëâ is a linear functional on ùëâ. A 2-linear form on ùëâ is a bilinear form on ùëâ. You can verify that with the usual addition and scalar multiplication of functions, ùëâ(ùëö)is a vector space. 9.26 example:ùëö-linear forms ‚Ä¢ Suppose ùõº, ùúå ‚àà ùëâ(2). Define a functionùõΩ‚à∂ ùëâ4 ‚Üí ùêÖ by ùõΩ(ùë£1, ùë£2, ùë£3, ùë£4) = ùõº(ùë£1, ùë£2) ùúå(ùë£3, ùë£4). Then ùõΩ ‚àà ùëâ(4). ‚Ä¢ DefineùõΩ‚à∂ (‚Ñí(ùëâ)) ùëö ‚Üí ùêÖ by ùõΩ(ùëá1, ‚Ä¶, ùëáùëö) = tr(ùëá1‚ãØùëáùëö). Then ùõΩ is an ùëö-linear form on ‚Ñí(ùëâ). Section 9B Alternating Multilinear Forms 347 Alternating multilinear forms, which we now define, play an important role as we head toward defining determinants. 9.27 definition:alternating forms, ùëâ(ùëö) alt Suppose ùëö is a positive integer. ‚Ä¢ An ùëö-linear form ùõº on ùëâ is called alternating if ùõº(ùë£1, ‚Ä¶, ùë£ùëö) = 0whenever ùë£1, ‚Ä¶, ùë£ùëö is a list of vectors in ùëâ with ùë£ùëó = ùë£ùëò for some two distinct values of ùëó and ùëò in {1, ‚Ä¶, ùëö}. ‚Ä¢ ùëâ(ùëö) alt = {ùõº ‚àà ùëâ(ùëö)‚à∂ ùõº is an alternating ùëö-linear form on ùëâ}. You should verify that ùëâ(ùëö) alt is a subspace of ùëâ(ùëö). See Example 9.15 for examples of alternating 2-linear forms. See Exercise 2 for an example of an alternating 3-linear form. The next result tells us that if a linearly dependent list is input to an alternating multilinear form, then the output equals 0. 9.28 alternating multilinear forms and linear dependence Suppose ùëö is a positive integer and ùõº is an alternating ùëö-linear form on ùëâ. If ùë£1, ‚Ä¶, ùë£ùëö is a linearly dependent list in ùëâ, then ùõº(ùë£1, ‚Ä¶, ùë£ùëö) = 0. Proof Suppose ùë£1, ‚Ä¶, ùë£ùëö is a linearly dependent list in ùëâ. By the linear depen- dence lemma (2.19), some ùë£ùëò is a linear combination of ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1. Thus there exist ùëè1, ‚Ä¶, ùëèùëò ‚àí 1 such that ùë£ùëò = ùëè1ùë£1 + ‚ãØ + ùëèùëò ‚àí 1ùë£ùëò ‚àí 1. Now ùõº(ùë£1, ‚Ä¶, ùë£ùëö) = ùõº(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1, ùëò ‚àí 1 ‚àë ùëó = 1 ùëèùëóùë£ùëó, ùë£ùëò + 1, ‚Ä¶, ùë£ùëö) = ùëò ‚àí 1 ‚àë ùëó = 1 ùëèùëó ùõº(ùë£1, ‚Ä¶, ùë£ùëò ‚àí 1, ùë£ùëó, ùë£ùëò + 1, ‚Ä¶, ùë£ùëö) = 0. The next result states that if ùëö > dim ùëâ, then there are no alternating ùëö-linear forms on ùëâ other than the function on ùëâùëö that is identically 0. 9.29 no nonzero alternating ùëö-linear forms for ùëö > dim ùëâ Suppose ùëö > dim ùëâ. Then 0is the only alternating ùëö-linear form on ùëâ. Proof Suppose that ùõº is an alternating ùëö-linear form on ùëâ and ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ. Because ùëö > dim ùëâ, this list is not linearly independent (by 2.22). Thus 9.28 implies that ùõº(ùë£1, ‚Ä¶, ùë£ùëö) = 0. Hence ùõº is the zero function from ùëâùëö to ùêÖ. 348 Chapter 9 Multilinear Algebra and Determinants Alternating Multilinear Forms and Permutations 9.30 swapping input vectors in an alternating multilinear form Suppose ùëö is a positive integer, ùõº is an alternating ùëö-linear form on ùëâ, and ùë£1, ‚Ä¶, ùë£ùëö is a list of vectors in ùëâ. Then swapping the vectors in any two slots of ùõº(ùë£1, ‚Ä¶, ùë£ùëö) changes the value of ùõº by a factor of ‚àí1. Proof Put ùë£1 + ùë£2 in both the first two slots, getting 0 = ùõº(ùë£1 + ùë£2, ùë£1 + ùë£2, ùë£3, ‚Ä¶, ùë£ùëö). Use the multilinear properties of ùõº to expand the right side of the equation above (as in the proof of 9.16) to get ùõº(ùë£2, ùë£1, ùë£3, ‚Ä¶, ùë£ùëö) = ‚àíùõº(ùë£1, ùë£2, ùë£3, ‚Ä¶, ùë£ùëö). Similarly, swapping the vectors in any two slots of ùõº(ùë£1, ‚Ä¶, ùë£ùëö) changes the value of ùõº by a factor of ‚àí1. To see what can happen with multiple swaps, suppose ùõº is an alternating 3-linear form on ùëâ and ùë£1, ùë£2, ùë£3 ‚àà ùëâ. To evaluate ùõº(ùë£3, ùë£1, ùë£2) in terms of ùõº(ùë£1, ùë£2, ùë£3), start with ùõº(ùë£3, ùë£1, ùë£2) and swap the entries in the first and third slots, getting ùõº(ùë£3, ùë£1, ùë£2) = ‚àíùõº(ùë£2, ùë£1, ùë£3). Now in the last expression, swap the entries in the first and second slots, getting ùõº(ùë£3, ùë£1, ùë£2) = ‚àíùõº(ùë£2, ùë£1, ùë£3) = ùõº(ùë£1, ùë£2, ùë£3). More generally, we see that if we do an odd number of swaps, then the value of ùõº changes by a factor of ‚àí1, and if we do an even number of swaps, then the value of ùõº does not change. To deal with arbitrary multiple swaps, we need a bit of information about permutations. 9.31 definition: permutation, perm ùëö Suppose ùëö is a positive integer. ‚Ä¢ A permutation of (1, ‚Ä¶, ùëö) is a list (ùëó1, ‚Ä¶, ùëóùëö) that contains each of the numbers 1, ‚Ä¶, ùëö exactly once. ‚Ä¢ The set of all permutations of (1, ‚Ä¶, ùëö) is denoted by perm ùëö. For example, (2, 3, 4, 5, 1) ‚ààperm 5. You should think of an element of perm ùëö as a rearrangement of the firstùëö positive integers. The number of swaps used to change a permutation (ùëó1, ‚Ä¶, ùëóùëö) to the stan- dard order (1, ‚Ä¶, ùëö) can depend on the specific swaps selected. The following definition has the advantage of assigning a well-defined sign to every permutation. Section 9B Alternating Multilinear Forms 349 9.32 definition: sign of a permutation The sign of a permutation (ùëó1, ‚Ä¶, ùëóùëö) is defined by sign(ùëó1, ‚Ä¶, ùëóùëö) = (‚àí1) ùëÅ, where ùëÅ is the number of pairs of integers (ùëò, ‚Ñì) with 1 ‚â§ ùëò < ‚Ñì ‚â§ ùëösuch that ùëò appears after ‚Ñì in the list (ùëó1, ‚Ä¶, ùëóùëö). Hence the sign of a permutation equals 1if the natural order has been changed an even number of times and equals ‚àí1if the natural order has been changed an odd number of times. 9.33 example: signs ‚Ä¢ The permutation (1, ‚Ä¶, ùëö) [no changes in the natural order] has sign1. ‚Ä¢ The only pair of integers (ùëò, ‚Ñì) with ùëò < ‚Ñì such that ùëò appears after ‚Ñì in the list (2, 1, 3, 4)is (1, 2). Thus the permutation (2, 1, 3, 4)has sign ‚àí1. ‚Ä¢ In the permutation (2, 3, ‚Ä¶, ùëö, 1), the only pairs (ùëò, ‚Ñì) with ùëò < ‚Ñì that appear with changed order are (1, 2), (1, 3), ‚Ä¶, (1, ùëö). Because we have ùëö ‚àí 1such pairs, the sign of this permutation equals (‚àí1) ùëö ‚àí 1. 9.34 swapping two entries in a permutation Swapping two entries in a permutation multiplies the sign of the permutation by ‚àí1. Proof Suppose we have two permutations, where the second permutation is obtained from the first by swapping two entries. The two swapped entries were in their natural order in the first permutation if and only if they are not in their natural order in the second permutation. Thus we have a net change (so far) of 1 or ‚àí1(both odd numbers) in the number of pairs not in their natural order. Consider each entry between the two swapped entries. If an intermediate entry was originally in the natural order with respect to both swapped entries, then it is now in the natural order with respect to neither swapped entry. Similarly, if an intermediate entry was originally in the natural order with respect to neither of the swapped entries, then it is now in the natural order with respect to both swapped entries. If an intermediate entry was originally in the natural order with respect to exactly one of the swapped entries, then that is still true. Thus the net change (for each pair containing an entry between the two swapped entries) in the number of pairs not in their natural order is 2, ‚àí2, or 0(all even numbers). For all other pairs of entries, there is no change in whether or not they are in their natural order. Thus the total net change in the number of pairs not in their natural order is an odd number. Hence the sign of the second permutation equals ‚àí1times the sign of the first permutation. 350 Chapter 9 Multilinear Algebra and Determinants 9.35 permutations and alternating multilinear forms Suppose ùëö is a positive integer and ùõº ‚àà ùëâ(ùëö) alt . Then ùõº(ùë£ùëó1, ‚Ä¶, ùë£ùëóùëö) = (sign(ùëó1, ‚Ä¶, ùëóùëö))ùõº(ùë£1, ‚Ä¶, ùë£ùëö) for every list ùë£1, ‚Ä¶, ùë£ùëö of vectors in ùëâ and all (ùëó1, ‚Ä¶, ùëóùëö) ‚àà perm ùëö. Proof Suppose ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ and (ùëó1, ‚Ä¶, ùëóùëö) ‚àà perm ùëö. We can get from (ùëó1, ‚Ä¶, ùëóùëö) to (1, ‚Ä¶, ùëö) by a series of swaps of entries in different slots. Each such swap changes the value of ùõº by a factor of ‚àí1(by 9.30) and also changes the sign of the remaining permutation by a factor of ‚àí1(by 9.34). After an appropriate number of swaps, we reach the permutation 1, ‚Ä¶, ùëö, which has sign 1. Thus the value of ùõº changed signs an even number of times if sign(ùëó1, ‚Ä¶, ùëóùëö) = 1and an odd number of times if sign(ùëó1, ‚Ä¶, ùëóùëö) = ‚àí1, which gives the desired result. Our use of permutations now leads in a natural way to the following beautiful formula for alternating ùëõ-linear forms on an ùëõ-dimensional vector space. 9.36 formula for (dim ùëâ)-linear alternating forms on ùëâ Let ùëõ = dim ùëâ. Suppose ùëí1, ‚Ä¶, ùëíùëõ is a basis of ùëâ and ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùëâ. For each ùëò ‚àà {1, ‚Ä¶, ùëõ}, let ùëè1, ùëò, ‚Ä¶, ùëèùëõ, ùëò ‚àà ùêÖ be such that ùë£ùëò = ùëõ ‚àë ùëó = 1 ùëèùëó, ùëòùëíùëó. Then ùõº(ùë£1, ‚Ä¶, ùë£ùëõ) = ùõº(ùëí1, ‚Ä¶, ùëíùëõ) ‚àë (ùëó1, ‚Ä¶, ùëóùëõ) ‚ààperm ùëõ (sign(ùëó1, ‚Ä¶, ùëóùëõ))ùëèùëó1, 1‚ãØùëèùëóùëõ, ùëõ for every alternating ùëõ-linear form ùõº on ùëâ. Proof Suppose ùõº is an alternating ùëõ-linear form ùõº on ùëâ. Then ùõº(ùë£1, ‚Ä¶, ùë£ùëõ) = ùõº( ùëõ ‚àë ùëó1 = 1 ùëèùëó1, 1ùëíùëó1, ‚Ä¶, ùëõ ‚àë ùëóùëõ = 1 ùëèùëóùëõ, ùëõùëíùëóùëõ) = ùëõ ‚àë ùëó1 = 1 ‚ãØ ùëõ ‚àë ùëóùëõ = 1 ùëèùëó1, 1‚ãØùëèùëóùëõ, ùëõ ùõº(ùëíùëó1, ‚Ä¶, ùëíùëóùëõ) = ‚àë (ùëó1, ‚Ä¶, ùëóùëõ) ‚ààperm ùëõ ùëèùëó1, 1‚ãØùëèùëóùëõ, ùëõ ùõº(ùëíùëó1, ‚Ä¶, ùëíùëóùëõ) = ùõº(ùëí1, ‚Ä¶, ùëíùëõ) ‚àë (ùëó1, ‚Ä¶, ùëóùëõ) ‚ààperm ùëõ (sign(ùëó1, ‚Ä¶, ùëóùëõ))ùëèùëó1, 1‚ãØùëèùëóùëõ, ùëõ, where the third line holds because ùõº(ùëíùëó1, ‚Ä¶, ùëíùëóùëõ) = 0if ùëó1, ‚Ä¶, ùëóùëõ are not distinct integers, and the last line holds by 9.35. Section 9B Alternating Multilinear Forms 351 The following result will be the key to our definition of the determinant in the next section. 9.37 dim ùëâ(dim ùëâ) alt = 1 The vector space ùëâ(dim ùëâ) alt has dimension one. Proof Let ùëõ = dim ùëâ. Suppose ùõº and ùõº ‚Ä≤ are alternating ùëõ-linear forms on ùëâ with ùõº ‚â† 0. Let ùëí1, ‚Ä¶, ùëíùëõ be such that ùõº(ùëí1, ‚Ä¶, ùëíùëõ) ‚â† 0. There exists ùëê ‚àà ùêÖ such that ùõº ‚Ä≤(ùëí1, ‚Ä¶, ùëíùëõ) = ùëêùõº(ùëí1, ‚Ä¶, ùëíùëõ). Furthermore, 9.28 implies that ùëí1, ‚Ä¶, ùëíùëõ is linearly independent and thus is a basis of ùëâ. Suppose ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùëâ. Let ùëèùëó, ùëò be as in 9.36 for ùëó, ùëò = 1, ‚Ä¶, ùëõ. Then ùõº‚Ä≤(ùë£1, ‚Ä¶, ùë£ùëõ) = ùõº‚Ä≤(ùëí1, ‚Ä¶, ùëíùëõ) ‚àë (ùëó1, ‚Ä¶, ùëóùëõ) ‚ààperm ùëõ(sign(ùëó1, ‚Ä¶, ùëóùëõ))ùëèùëó1, 1‚ãØùëèùëóùëõ, ùëõ = ùëêùõº(ùëí1, ‚Ä¶, ùëíùëõ) ‚àë (ùëó1, ‚Ä¶, ùëóùëõ) ‚ààperm ùëõ(sign(ùëó1, ‚Ä¶, ùëóùëõ))ùëèùëó1, 1‚ãØùëèùëóùëõ, ùëõ = ùëêùõº(ùë£1, ‚Ä¶, ùë£ùëõ), where the first and last lines above come from9.36. The equation above implies that ùõº‚Ä≤ = ùëêùõº. Thus ùõº‚Ä≤, ùõº is not a linearly independent list, which implies that dim ùëâ(ùëõ) alt ‚â§ 1. To complete the proof, we only need to show that there exists a nonzero alternating ùëõ-linear form ùõº on ùëâ (thus eliminating the possibility that dim ùëâ(ùëõ) alt equals 0). To do this, let ùëí1, ‚Ä¶, ùëíùëõ be any basis of ùëâ, and let ùúë1, ‚Ä¶, ùúëùëõ ‚àà ùëâ‚Ä≤ be the linear functionals on ùëâ that allow us to express each element of ùëâ as a linear combination of ùëí1, ‚Ä¶, ùëíùëõ. In other words, ùë£ = ùëõ ‚àë ùëó = 1 ùúëùëó(ùë£)ùëíùëó for every ùë£ ‚àà ùëâ (see 3.114). Now for ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùëâ, define 9.38 ùõº(ùë£1, ‚Ä¶, ùë£ùëõ) = ‚àë (ùëó1, ‚Ä¶, ùëóùëõ) ‚ààperm ùëõ(sign(ùëó1, ‚Ä¶, ùëóùëõ))ùúëùëó1(ùë£1)‚ãØùúëùëóùëõ(ùë£ùëõ). The verification thatùõº is an ùëõ-linear form on ùëâ is straightforward. To see that ùõº is alternating, suppose ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùëâ with ùë£1 = ùë£2. For each (ùëó1, ‚Ä¶, ùëóùëõ) ‚àà perm ùëõ, the permutation (ùëó2, ùëó1, ùëó3, ‚Ä¶, ùëóùëõ) has the opposite sign. Be- cause ùë£1 = ùë£2, the contributions from these two permutations to the sum in 9.38 cancel either other. Hence ùõº(ùë£1, ùë£1, ùë£3, ‚Ä¶, ùë£ùëõ) = 0. Similarly, ùõº(ùë£1, ‚Ä¶, ùë£ùëõ) = 0if any two vectors in the list ùë£1, ‚Ä¶, ùë£ùëõ are equal. Thus ùõº is alternating. Finally, consider 9.38 with each ùë£ùëò = ùëíùëò. Because ùúëùëó(ùëíùëò) equals 0if ùëó ‚â† ùëò and equals 1if ùëó = ùëò, only the permutation (1, ‚Ä¶, ùëõ) makes a nonzero contribution to the right side of 9.38 in this case, giving the equation ùõº(ùëí1, ‚Ä¶, ùëíùëõ) = 1. Thus we have produced a nonzero alternating ùëõ-linear form ùõº on ùëâ, as desired. 352 Chapter 9 Multilinear Algebra and Determinants The formula 9.38 used in the last proof to construct a nonzero alternating ùëõ- linear form came from the formula in 9.36, and that formula arose naturally from the properties of an alternating multilinear form. Earlier we showed that the value of an alternating multilinear form applied to a linearly dependent list is 0; see 9.28. The next result provides a converse of 9.28 for ùëõ-linear multilinear forms when ùëõ = dim ùëâ. In the following result, the statement that ùõº is nonzero means (as usual for a function) that ùõº is not the function on ùëâùëõ that is identically 0. 9.39 alternating (dim ùëâ)-linear forms and linear independence Let ùëõ = dim ùëâ. Suppose ùõº is a nonzero alternating ùëõ-linear form on ùëâ and ùëí1, ‚Ä¶, ùëíùëõ is a list of vectors in ùëâ. Then ùõº(ùëí1, ‚Ä¶, ùëíùëõ) ‚â† 0 if and only if ùëí1, ‚Ä¶, ùëíùëõ is linearly independent. Proof First suppose ùõº(ùëí1, ‚Ä¶, ùëíùëõ) ‚â† 0. Then 9.28 implies that ùëí1, ‚Ä¶, ùëíùëõ is linearly independent. To prove the implication in the other direction, now suppose ùëí1, ‚Ä¶, ùëíùëõ is linearly independent. Because ùëõ = dim ùëâ, this implies that ùëí1, ‚Ä¶, ùëíùëõ is a basis of ùëâ (see 2.38). Because ùõº is not the zero ùëõ-linear form, there exist ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùëâ such that ùõº(ùë£1, ‚Ä¶, ùë£ùëõ) ‚â† 0. Now 9.36 implies that ùõº(ùëí1, ‚Ä¶, ùëíùëõ) ‚â† 0. Exercises 9B 1 Suppose ùëö is a positive integer. Show that dim ùëâ(ùëö)= (dim ùëâ) ùëö. 2 Suppose ùëõ ‚â• 3and ùõº‚à∂ ùêÖùëõ √ó ùêÖùëõ √ó ùêÖùëõ ‚Üí ùêÖ is defined by ùõº((ùë•1, ‚Ä¶, ùë•ùëõ), (ùë¶1, ‚Ä¶, ùë¶ùëõ), (ùëß1, ‚Ä¶, ùëßùëõ)) = ùë•1ùë¶2ùëß3 ‚àí ùë•2ùë¶1ùëß3 ‚àí ùë•3ùë¶2ùëß1 ‚àí ùë•1ùë¶3ùëß2 + ùë•3ùë¶1ùëß2 + ùë•2ùë¶3ùëß1. Show that ùõº is an alternating 3-linear form on ùêÖùëõ. 3 Suppose ùëö is a positive integer and ùõº is an ùëö-linear form on ùëâ such that ùõº(ùë£1, ‚Ä¶, ùë£ùëö) = 0whenever ùë£1, ‚Ä¶, ùë£ùëö is a list of vectors in ùëâ with ùë£ùëó = ùë£ùëó + 1 for some ùëó ‚àà {1, ‚Ä¶, ùëö ‚àí 1}. Prove that ùõº is an alternating ùëö-linear form on ùëâ. 4 Prove or give a counterexample: If ùõº ‚àà ùëâ(4) alt , then {(ùë£1, ùë£2, ùë£3, ùë£4) ‚àà ùëâ4 ‚à∂ ùõº(ùë£1, ùë£2, ùë£3, ùë£4) = 0} is a subspace of ùëâ4. Section 9B Alternating Multilinear Forms 353 5 Suppose ùëö is a positive integer and ùõΩ is an ùëö-linear form on ùëâ. Define an ùëö-linear form ùõº on ùëâ by ùõº(ùë£1, ‚Ä¶, ùë£ùëö) = ‚àë (ùëó1, ‚Ä¶, ùëóùëö) ‚ààperm ùëö(sign(ùëó1, ‚Ä¶, ùëóùëö))ùõΩ(ùë£ùëó1, ‚Ä¶, ùë£ùëóùëö) for ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ. Explain why ùõº ‚àà ùëâ(ùëö) alt . 6 Suppose ùëö is a positive integer and ùõΩ is an ùëö-linear form on ùëâ. Define an ùëö-linear form ùõº on ùëâ by ùõº(ùë£1, ‚Ä¶, ùë£ùëö) = ‚àë (ùëó1, ‚Ä¶, ùëóùëö) ‚ààperm ùëö ùõΩ(ùë£ùëó1, ‚Ä¶, ùë£ùëóùëö) for ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ. Explain why ùõº(ùë£ùëò1, ‚Ä¶, ùë£ùëòùëö) = ùõº(ùë£1, ‚Ä¶, ùë£ùëö) for all ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ and all (ùëò1, ‚Ä¶, ùëòùëö) ‚àà perm ùëö. 7 Give an example of a nonzero alternating 2-linear form ùõº on ùêë3 and a linearly independent list ùë£1, ùë£2 in ùêë3 such that ùõº(ùë£1, ùë£2) = 0. This exercise shows that 9.39 can fail if the hypothesis that ùëõ = dim ùëâ is deleted. 354 Chapter 9 Multilinear Algebra and Determinants 9C Determinants Defining the Determinant The next definition will lead us to a clean, beautiful, basis-free definition of the determinant of an operator. 9.40 definition: ùõºùëá Suppose that ùëö is a positive integer and ùëá ‚àà ‚Ñí(ùëâ). For ùõº ‚àà ùëâ(ùëö) alt , define ùõºùëá ‚àà ùëâ(ùëö) alt by ùõºùëá(ùë£1, ‚Ä¶, ùë£ùëö) = ùõº(ùëáùë£1, ‚Ä¶, ùëáùë£ùëö) for each list ùë£1, ‚Ä¶, ùë£ùëö of vectors in ùëâ. Suppose ùëá ‚àà ‚Ñí(ùëâ). If ùõº ‚àà ùëâ(ùëö) alt and ùë£1, ‚Ä¶, ùë£ùëö is a list of vectors in ùëâ with ùë£ùëó = ùë£ùëò for some ùëó ‚â† ùëò, then ùëáùë£ùëó = ùëáùë£ùëò, which implies that ùõºùëá(ùë£1, ‚Ä¶, ùë£ùëö) = ùõº(ùëáùë£1, ‚Ä¶, ùëáùë£ùëö) = 0. Thus the function ùõº ‚Ü¶ ùõºùëá is a linear map of ùëâ(ùëö) alt to itself. We know that dim ùëâ(dim ùëâ) alt = 1(see 9.37). Every linear map from a one- dimensional vector space to itself is multiplication by some unique scalar. For the linear map ùõº ‚Ü¶ ùõºùëá, we now definedet ùëá to be that scalar. 9.41 definition: determinant of an operator, det ùëá Suppose ùëá ‚àà ‚Ñí(ùëâ). The determinant of ùëá, denoted by det ùëá, is defined to be the unique number in ùêÖ such that ùõºùëá = (det ùëá) ùõº for all ùõº ‚àà ùëâ(dim ùëâ) alt . 9.42 example: determinants of operators Let ùëõ = dim ùëâ. ‚Ä¢ If ùêº is the identity operator on ùëâ, then ùõºùêº = ùõº for all ùõº ‚àà ùëâ(ùëõ) alt . Thus det ùêº = 1. ‚Ä¢ More generally, if ùúÜ ‚àà ùêÖ, then ùõº ùúÜùêº = ùúÜùëõùõº for all ùõº ‚àà ùëâ(ùëõ) alt . Thus det(ùúÜùêº) = ùúÜùëõ. ‚Ä¢ Still more generally, if ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ ‚àà ùêÖ, then ùõº ùúÜùëá = ùúÜùëõùõºùëá = ùúÜ ùëõ(det ùëá)ùõº for all ùõº ‚àà ùëâ(ùëõ) alt . Thus det(ùúÜùëá) = ùúÜùëõ det ùëá. ‚Ä¢ Suppose ùëá ‚àà ‚Ñí(ùëâ) and there is a basis ùëí1, ‚Ä¶, ùëíùëõ of ùëâ consisting of eigenvectors of ùëá, with corresponding eigenvalues ùúÜ1, ‚Ä¶, ùúÜùëõ. If ùõº ‚àà ùëâ(ùëõ) alt , then ùõºùëá(ùëí1, ‚Ä¶, ùëíùëõ) = ùõº(ùúÜ1ùëí1, ‚Ä¶, ùúÜùëõùëíùëõ) = (ùúÜ1‚ãØùúÜùëõ)ùõº(ùëí1, ‚Ä¶, ùëíùëõ). If ùõº ‚â† 0, then 9.39 implies ùõº(ùëí1, ‚Ä¶, ùëíùëõ) ‚â† 0. Thus the equation above implies det ùëá = ùúÜ1‚ãØùúÜùëõ. Section 9C Determinants 355 Our next task is to define and give a formula for the determinant of a square matrix. To do this, we associate with each square matrix an operator and then define the determinant of the matrix to be the determinant of the associated operator. 9.43 definition: determinant of a matrix, det ùê¥ Suppose that ùëõ is a positive integer and ùê¥ is an ùëõ-by-ùëõ square matrix with entries in ùêÖ. Let ùëá ‚àà ‚Ñí(ùêÖùëõ)be the operator whose matrix with respect to the standard basis of ùêÖùëõ equals ùê¥. The determinant of ùê¥, denoted by det ùê¥, is defined bydet ùê¥ = det ùëá. 9.44 example: determinants of matrices ‚Ä¢ If ùêº is the ùëõ-by-ùëõ identity matrix, then the corresponding operator on ùêÖùëõ is the identity operator ùêº on ùêÖùëõ. Thus the first bullet point of9.42 implies that the determinant of the identity matrix is 1. ‚Ä¢ Suppose ùê¥ is a diagonal matrix with ùúÜ1, ‚Ä¶, ùúÜùëõ on the diagonal. Then the corresponding operator on ùêÖùëõ has the standard basis of ùêÖùëõ as eigenvectors, with eigenvalues ùúÜ1, ‚Ä¶, ùúÜùëõ. Thus the last bullet point of 9.42 implies that det ùê¥ = ùúÜ1‚ãØùúÜùëõ. For the next result, think of each list ùë£1, ‚Ä¶, ùë£ùëõ of ùëõ vectors in ùêÖùëõ as a list of ùëõ-by-1column vectors. The notation (ùë£1 ‚ãØ ùë£ùëõ )then denotes the ùëõ-by-ùëõ square matrix whose ùëòth column is ùë£ùëò for each ùëò = 1, ‚Ä¶, ùëõ. 9.45 determinant is an alternating multilinear form Suppose that ùëõ is a positive integer. The map that takes a list ùë£1, ‚Ä¶, ùë£ùëõ of vectors in ùêÖùëõ to det (ùë£1 ‚ãØ ùë£ùëõ )is an alternating ùëõ-linear form on ùêÖùëõ. Proof Let ùëí1, ‚Ä¶, ùëíùëõ be the standard basis of ùêÖùëõ and suppose ùë£1, ‚Ä¶, ùë£ùëõ is a list of vectors in ùêÖùëõ. Let ùëá ‚àà ‚Ñí(ùêÖùëõ)be the operator such that ùëáùëíùëò = ùë£ùëò for ùëò = 1, ‚Ä¶, ùëõ. Thus ùëá is the operator whose matrix with respect to ùëí1, ‚Ä¶, ùëíùëõ is (ùë£1 ‚ãØ ùë£ùëõ ). Hence det (ùë£1 ‚ãØ ùë£ùëõ )= det ùëá, by definition of the determinant of a matrix. Let ùõº be an alternating ùëõ-linear form on ùêÖùëõ such that ùõº(ùëí1, ‚Ä¶, ùëíùëõ) = 1. Then det (ùë£1 ‚ãØ ùë£ùëõ )= det ùëá = (det ùëá) ùõº(ùëí1, ‚Ä¶, ùëíùëõ) = ùõº(ùëáùëí1, ‚Ä¶, ùëáùëíùëõ) = ùõº(ùë£1, ‚Ä¶, ùë£ùëõ), where the third line follows from the definition of the determinant of an operator. The equation above shows that the map that takes a list of vectors ùë£1, ‚Ä¶, ùë£ùëõ in ùêÖùëõ to det (ùë£1 ‚ãØ ùë£ùëõ )is the alternating ùëõ-linear form ùõº on ùêÖùëõ. 356 Chapter 9 Multilinear Algebra and Determinants The previous result has several important consequences. For example, it immediately implies that a matrix with two identical columns has determinant 0. We will come back to other consequences later, but for now we want to give a formula for the determinant of a square matrix. Recall that if ùê¥ is a matrix, then ùê¥ùëó, ùëò denotes the entry in row ùëó, column ùëò of ùê¥. 9.46 formula for determinant of a matrix Suppose that ùëõ is a positive integer and ùê¥ is an ùëõ-by-ùëõ square matrix. Then det ùê¥ = ‚àë (ùëó1, ‚Ä¶, ùëóùëõ) ‚ààperm ùëõ (sign(ùëó1, ‚Ä¶, ùëóùëõ))ùê¥ùëó1, 1‚ãØùê¥ùëóùëõ, ùëõ. Proof Apply 9.36 with ùëâ = ùêÖùëõ and ùëí1, ‚Ä¶, ùëíùëõ the standard basis of ùêÖùëõ and ùõº the alternating ùëõ-linear form on ùêÖùëõ that takes ùë£1, ‚Ä¶, ùë£ùëõ to det (ùë£1 ‚ãØ ùë£ùëõ )[see 9.45]. If eachùë£ùëò is the ùëòth column of ùê¥, then each ùëèùëó, ùëò in 9.36 equals ùê¥ùëó, ùëò. Finally, ùõº(ùëí1, ‚Ä¶, ùëíùëõ) = det (ùëí1 ‚ãØ ùëíùëõ )= det ùêº = 1. Thus the formula in 9.36 becomes the formula stated in this result. 9.47 example:explicit formula for determinant ‚Ä¢ If ùê¥ is a 2-by-2matrix, then the formula in 9.46 becomes det ùê¥ = ùê¥1, 1ùê¥2, 2 ‚àí ùê¥2, 1ùê¥1, 2. ‚Ä¢ If ùê¥ is a 3-by-3matrix, then the formula in 9.46 becomes det ùê¥ =ùê¥1, 1ùê¥2, 2ùê¥3, 3 ‚àí ùê¥2, 1ùê¥1, 2ùê¥3, 3 ‚àí ùê¥3, 1ùê¥2, 2ùê¥1, 3 ‚àí ùê¥1, 1ùê¥3, 2ùê¥2, 3 + ùê¥3, 1ùê¥1, 2ùê¥2, 3 + ùê¥2, 1ùê¥3, 2ùê¥1, 3. The sum in the formula in 9.46 contains ùëõ! terms. Because ùëõ! grows rapidly as ùëõ increases, the formula in 9.46 is not a viable method to evaluate determinants even for moderately sized ùëõ. For example, 10!is over three million, and 100!is approximately 10 158, leading to a sum that the fastest computer cannot evaluate. We will soon see some results that lead to faster evaluations of determinants than direct use of the sum in 9.46. 9.48 determinant of upper-triangular matrix Suppose that ùê¥ is an upper-triangular matrix with ùúÜ1, ‚Ä¶, ùúÜùëõ on the diagonal. Then det ùê¥ = ùúÜ1‚ãØùúÜùëõ. Proof If (ùëó1, ‚Ä¶, ùëóùëõ) ‚àà perm ùëõ with (ùëó1, ‚Ä¶, ùëóùëõ) ‚â† (1, ‚Ä¶, ùëõ), then ùëóùëò > ùëò for some ùëò ‚àà {1, ‚Ä¶, ùëõ}, which implies that ùê¥ùëóùëò, ùëò = 0. Thus the only permutation that can make a nonzero contribution to the sum in 9.46 is the permutation (1, ‚Ä¶, ùëõ). Because ùê¥ùëò, ùëò = ùúÜùëò for each ùëò = 1, ‚Ä¶, ùëõ, this implies that det ùê¥ = ùúÜ1‚ãØùúÜùëõ. Section 9C Determinants 357 Properties of Determinants Our definition of the determinant leads to the following magical proof that the determinant is multiplicative. 9.49 determinant is multiplicative (a) Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ). Then det(ùëÜùëá) = (det ùëÜ)(det ùëá). (b) Suppose ùê¥ and ùêµ are square matrices of the same size. Then det(ùê¥ùêµ) = (det ùê¥)(det ùêµ) Proof (a) Let ùëõ = dim ùëâ. Suppose ùõº ‚àà ùëâ(ùëõ) alt and ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùëâ. Then ùõºùëÜùëá(ùë£1, ‚Ä¶, ùë£ùëõ) = ùõº(ùëÜùëáùë£1, ‚Ä¶, ùëÜùëáùë£ùëõ) = (det ùëÜ)ùõº(ùëáùë£1, ‚Ä¶, ùëáùë£ùëõ) = (det ùëÜ)(det ùëá)ùõº(ùë£1, ‚Ä¶, ùë£ùëõ), where the first equation follows from the definition ofùõºùëÜùëá, the second equation follows from the definition ofdet ùëÜ, and the third equation follows from the definition ofdet ùëá. The equation above implies that det(ùëÜùëá) = (det ùëÜ)(det ùëá). (b) Let ùëÜ, ùëá ‚àà ‚Ñí(ùêÖùëõ)be such that ‚Ñ≥(ùëÜ) = ùê¥ and ‚Ñ≥(ùëá) = ùêµ, where all matrices of operators in this proof are with respect to the standard basis of ùêÖùëõ. Then ‚Ñ≥(ùëÜùëá) = ‚Ñ≥(ùëÜ)‚Ñ≥(ùëá) = ùê¥ùêµ (see 3.43). Thus det(ùê¥ùêµ) = det(ùëÜùëá) = (det ùëÜ)(det ùëá) = (det ùê¥)(det ùêµ), where the second equality comes from the result in (a). The determinant of an operator determines whether the operator is invertible. 9.50 invertible ‚ü∫ nonzero determinant An operator ùëá ‚àà ‚Ñí(ùëâ) is invertible if and only if det ùëá ‚â† 0. Furthermore, if ùëá is invertible, then det(ùëá‚àí1)= 1 det ùëá . Proof First suppose ùëá is invertible. Thus ùëáùëá‚àí1 = ùêº. Now 9.49 implies that 1 =det ùêº = det(ùëáùëá‚àí1)= (det ùëá)(det(ùëá‚àí1)). Hence det ùëá ‚â† 0and det(ùëá‚àí1)is the multiplicative inverse of det ùëá. To prove the other direction, now suppose det ùëá ‚â† 0. Suppose ùë£ ‚àà ùëâ and ùë£ ‚â† 0. Let ùë£, ùëí2, ‚Ä¶, ùëíùëõ be a basis of ùëâ and let ùõº ‚àà ùëâ(ùëõ) alt be such that ùõº ‚â† 0. Then ùõº(ùë£, ùëí2, ‚Ä¶, ùëíùëõ) ‚â† 0(by 9.39). Now ùõº(ùëáùë£, ùëáùëí2, ‚Ä¶, ùëáùëíùëõ) = (det ùëá)ùõº(ùë£, ùëí2, ‚Ä¶, ùëíùëõ) ‚â† 0, Thus ùëáùë£ ‚â† 0. Hence ùëá is invertible. 358 Chapter 9 Multilinear Algebra and Determinants An ùëõ-by-ùëõ matrix ùê¥ is invertible (see 3.80 for the definition of an invertible matrix) if and only if the operator on ùêÖùëõ associated with ùê¥ (via the standard basis of ùêÖùëõ)is invertible. Thus the previous result shows that a square matrix ùê¥ is invertible if and only if det ùê¥ ‚â† 0. 9.51 eigenvalues and determinants Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùúÜ ‚àà ùêÖ. Then ùúÜ is an eigenvalue of ùëá if and only if det(ùúÜùêº ‚àí ùëá) = 0. Proof The number ùúÜ is an eigenvalue of ùëá if and only if ùëá ‚àí ùúÜùêº is not invertible (see 5.7), which happens if and only if ùúÜùêº ‚àí ùëá is not invertible, which happens if and only if det(ùúÜùêº ‚àí ùëá) = 0(by 9.50). Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëÜ‚à∂ ùëä ‚Üí ùëâ is an invertible linear map. To prove that det(ùëÜ ‚àí1ùëáùëÜ)= det ùëá, we could try to use 9.49 and 9.50, writing det(ùëÜ ‚àí1ùëáùëÜ)= (det ùëÜ ‚àí1)(det ùëá)(det ùëÜ) = det ùëá. That proof works if ùëä = ùëâ, but if ùëä ‚â† ùëâ then it makes no sense because the determinant is defined only for linear maps from a vector space to itself, andùëÜ maps ùëä to ùëâ, making det ùëÜ undefined. The proof given below works around this issue and is valid when ùëä ‚â† ùëâ. 9.52 determinant is a similarity invariant Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëÜ‚à∂ ùëä ‚Üí ùëâ is an invertible linear map. Then det(ùëÜ ‚àí1ùëáùëÜ)= det ùëá. Proof Let ùëõ = dim ùëä = dim ùëâ. Suppose ùúè ‚àà ùëä(ùëõ) alt . Defineùõº ‚àà ùëâ(ùëõ) alt by ùõº(ùë£1, ‚Ä¶, ùë£ùëõ) = ùúè(ùëÜ ‚àí1ùë£1, ‚Ä¶, ùëÜ ‚àí1ùë£ùëõ) for ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùëâ. Suppose ùë§1, ‚Ä¶, ùë§ùëõ ‚àà ùëä. Then ùúèùëÜ‚àí1ùëáùëÜ(ùë§1, ‚Ä¶, ùë§ùëõ) = ùúè(ùëÜ ‚àí1ùëáùëÜùë§1, ‚Ä¶, ùëÜ ‚àí1ùëáùëÜùë§ùëõ) = ùõº(ùëáùëÜùë§1, ‚Ä¶, ùëáùëÜùë§ùëõ) = ùõºùëá(ùëÜùë§1, ‚Ä¶, ùëÜùë§ùëõ) = (det ùëá)ùõº(ùëÜùë§1, ‚Ä¶, ùëÜùë§ùëõ) = (det ùëá)ùúè(ùë§1, ‚Ä¶, ùë§ùëõ). The equation above and the definition of the determinant of the operatorùëÜ ‚àí1ùëáùëÜ imply that det(ùëÜ‚àí1ùëáùëÜ)= det ùëá. Section 9C Determinants 359 For the special case in which ùëâ = ùêÖùëõ and ùëí1, ‚Ä¶, ùëíùëõ is the standard basis of ùêÖùëõ, the next result is true by the definition of the determinant of a matrix. The left side of the equation in the next result does not depend on a choice of basis, which means that the right side is independent of the choice of basis. 9.53 determinant of operator equals determinant of its matrix Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëí1, ‚Ä¶, ùëíùëõ is a basis of ùëâ. Then det ùëá = det ‚Ñ≥(ùëá, (ùëí1, ‚Ä¶, ùëíùëõ)). Proof Let ùëì1, ‚Ä¶, ùëìùëõ be the standard basis of ùêÖùëõ. Let ùëÜ‚à∂ ùêÖùëõ ‚Üí ùëâ be the linear map such that ùëÜ ùëìùëò = ùëíùëò for each ùëò = 1, ‚Ä¶, ùëõ. Thus ‚Ñ≥(ùëÜ, ( ùëì1, ‚Ä¶, ùëìùëõ), (ùëí1, ‚Ä¶, ùëíùëõ)) and ‚Ñ≥(ùëÜ ‚àí1, (ùëí1, ‚Ä¶, ùëíùëõ), ( ùëì1, ‚Ä¶, ùëìùëõ))both equal the ùëõ-by-ùëõ identity matrix. Hence 9.54 ‚Ñ≥(ùëÜ‚àí1ùëáùëÜ, ( ùëì1, ‚Ä¶, ùëìùëõ))= ‚Ñ≥(ùëá, (ùëí1, ‚Ä¶, ùëíùëõ)), as follows from two applications of 3.43. Thus det ùëá = det(ùëÜ‚àí1ùëáùëÜ) = det ‚Ñ≥(ùëÜ ‚àí1ùëáùëÜ, ( ùëì1, ‚Ä¶, ùëìùëõ)) = det ‚Ñ≥(ùëá, (ùëí1, ‚Ä¶, ùëíùëõ)), where the first line comes from9.52, the second line comes from the definition of the determinant of a matrix, and the third line follows from 9.54. The next result gives a more intuitive way to think about determinants than the definition or the formula in9.46. We could make the characterization in the result below the definition of the determinant of an operator on a finite-dimensional complex vector space, with the current definition then becoming a consequence of that definition. 9.55 if ùêÖ = ùêÇ, then determinant equals product of eigenvalues Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Then det ùëá equals the product of the eigen- values of ùëá, with each eigenvalue included as many times as its multiplicity. Proof There is a basis of ùëâ with respect to which ùëá has an upper-triangular matrix with the diagonal entries of the matrix consisting of the eigenvalues of ùëá, with each eigenvalue included as many times as its multiplicity‚Äîsee 8.37. Thus 9.53 and 9.48 imply that det ùëá equals the product of the eigenvalues of ùëá, with each eigenvalue included as many times as its multiplicity. As the next result shows, the determinant interacts nicely with the transpose of a square matrix, with the dual of an operator, and with the adjoint of an operator on an inner product space. 360 Chapter 9 Multilinear Algebra and Determinants 9.56 determinant of transpose, dual, or adjoint (a) Suppose ùê¥ is a square matrix. Then det ùê¥ t = det ùê¥. (b) Suppose ùëá ‚àà ‚Ñí(ùëâ). Then det ùëá‚Ä≤ = det ùëá. (c) Suppose ùëâ is an inner product space and ùëá ‚àà ‚Ñí(ùëâ). Then det(ùëá‚àó)= det ùëá. Proof (a) Let ùëõ be a positive integer. Defineùõº‚à∂ (ùêÖùëõ) ùëõ ‚Üí ùêÖ by ùõº((ùë£1 ‚ãØ ùë£ùëõ ))= det((ùë£1 ‚ãØ ùë£ùëõ ) t) for all ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùêÖùëõ. The formula in 9.46 for the determinant of a matrix shows that ùõº is an ùëõ-linear form on ùêÖùëõ. Suppose ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùêÖùëõ and ùë£ùëó = ùë£ùëò for some ùëó ‚â† ùëò. If ùêµ is an ùëõ-by-ùëõ matrix, then (ùë£1 ‚ãØ ùë£ùëõ ) tùêµ cannot equal the identity matrix because row ùëó and row ùëò of (ùë£1 ‚ãØ ùë£ùëõ ) tùêµ are equal. Thus (ùë£1 ‚ãØ ùë£ùëõ ) t is not invertible, which implies that ùõº((ùë£1 ‚ãØ ùë£ùëõ ))= 0. Hence ùõº is an alternating ùëõ- linear form on ùêÖùëõ. Note that ùõº applied to the standard basis of ùêÖùëõ equals 1. Because the vector space of alternating ùëõ-linear forms on ùêÖùëõ has dimension one (by 9.37), this implies that ùõº is the determinant function. Thus (a) holds. (b) The equation det ùëá‚Ä≤ = det ùëá follows from (a) and 9.53 and 3.132. (c) Pick an orthonormal basis of ùëâ. The matrix of ùëá‚àó with respect to that basis is the conjugate transpose of the matrix of ùëá with respect to that basis (by 7.9). Thus 9.53, 9.46, and (a) imply that det(ùëá‚àó)= det ùëá. 9.57 helpful results in evaluating determinants (a) If either two columns or two rows of a square matrix are equal, then the determinant of the matrix equals 0. (b) Suppose ùê¥ is a square matrix and ùêµ is the matrix obtained from ùê¥ by swapping either two columns or two rows. Then det ùê¥ = ‚àí det ùêµ. (c) If one column or one row of a square matrix is multiplied by a scalar, then the value of the determinant is multiplied by the same scalar. (d) If a scalar multiple of one column of a square matrix to added to another column, then the value of the determinant is unchanged. (e) If a scalar multiple of one row of a square matrix to added to another row, then the value of the determinant is unchanged. Section 9C Determinants 361 Proof All the assertions in this result follow from the result that the maps ùë£1, ‚Ä¶, ùë£ùëõ ‚Ü¶ det (ùë£1 ‚ãØ ùë£ùëõ )and ùë£1, ‚Ä¶, ùë£ùëõ ‚Ü¶ det (ùë£1 ‚ãØ ùë£ùëõ ) t are both alternating ùëõ-linear forms on ùêÖùëõ [see 9.45 and 9.56(a)]. For example, to prove (d) suppose ùë£1, ‚Ä¶, ùë£ùëõ ‚àà ùêÖùëõ and ùëê ‚àà ùêÖ. Then det(ùë£1 + ùëêùë£2 ùë£2 ‚ãØ ùë£ùëõ ) = det (ùë£1 ùë£2 ‚ãØ ùë£ùëõ )+ ùëê det (ùë£2 ùë£2 ùë£3 ‚ãØ ùë£ùëõ ) = det (ùë£1 ùë£2 ‚ãØ ùë£ùëõ ), where the first equation follows from the multilinearity property and the second equation follows from the alternating property. The equation above shows that adding a multiple of the second column to the first column does not change the value of the determinant. The same conclusion holds for any two columns. Thus (d) holds. The proof of (e) follows from (d) and from 9.56(a). The proofs of (a), (b), and (c) use similar tools and are left to the reader. For matrices whose entries are concrete numbers, the result above leads to a much faster way to evaluate the determinant than direct application of the formula in 9.46. Specifically, apply the Gaussian elimination procedure of swapping rows [by 9.48(b), this changes the determinant by a factor of ‚àí1], multiplying a row by a nonzero constant [by 9.48(c), this changes the determinant by the same constant], and adding a multiple of one row to another row [by 9.48(e), this does not change the determinant]to produce an upper-triangular matrix, whose determinant is the product of the diagonal entries (by 9.48). If your software keeps track of the number of row swaps and of the constants used when multiplying a row by a constant, then the determinant of the original matrix can be computed. Because a number ùúÜ ‚àà ùêÖ is an eigenvalue of an operator ùëá ‚àà ‚Ñí(ùëâ) if and only if det(ùúÜùêº ‚àí ùëá) = 0(by 9.51), you may be tempted to think that one way to find eigenvalues quickly is to choose a basis ofùëâ, let ùê¥ = ‚Ñ≥(ùëá), evaluate det(ùúÜùêº ‚àí ùê¥), and then solve the equation det(ùúÜùêº ‚àí ùê¥) = 0for ùúÜ. However, that procedure is rarely efficient, except when dim ùëâ = 2(or when dim ùëâ equals 3or 4if you are willing to use the cubic or quartic formulas). One problem is that the procedure described in the paragraph above for evaluating a determinant does not work when the matrix includes a symbol (such as the ùúÜ in ùúÜùêº ‚àí ùê¥). This problem arises because decisions need to be made in the Gaussian elimination procedure about whether certain quantities equal 0, and those decisions become complicated in expressions involving a symbol ùúÜ. Recall that an operator on a finite-dimensional inner product space is unitary if it preserves norms (see 7.51 and the paragraph following it). Every eigenvalue of a unitary operator has absolute value 1(by 7.54). Thus the product of the eigenvalues of a unitary operator has absolute value 1. Hence (at least in the case ùêÖ = ùêÇ) the determinant of a unitary operator has absolute value 1(by 9.55). The next result gives a proof that works without the assumption that ùêÖ = ùêÇ. 362 Chapter 9 Multilinear Algebra and Determinants 9.58 every unitary operator has determinant with absolute value 1 Suppose ùëâ is an inner product space and ùëÜ ‚àà ‚Ñí(ùëâ) is a unitary operator. Then |det ùëÜ| = 1. Proof Because ùëÜ is unitary, ùêº = ùëÜ‚àóùëÜ (see 7.53). Thus 1 =det(ùëÜ‚àóùëÜ) = (det ùëÜ‚àó)(det ùëÜ) = (det ùëÜ)(det ùëÜ) = |det ùëÜ| 2, where the second equality comes from 9.49(a) and the third equality comes from 9.56(c). The equation above implies that |det ùëÜ| = 1. The determinant of a positive operator on an inner product space meshes well with the analogy that such operators correspond to the nonnegative real numbers. 9.59 every positive operator has nonnegative determinant Suppose ùëâ is an inner product space and ùëá ‚àà ‚Ñí(ùëâ) is a positive operator. Then det ùëá ‚â• 0. Proof By the spectral theorem (7.29 or 7.31), ùëâ has an orthonormal basis con- sisting of eigenvectors of ùëá. Thus by the last bullet point of 9.42, det ùëá equals a product of the eigenvalues of ùëá, possibly with repetitions. Each eigenvalue of ùëá is a nonnegative number (by 7.38). Thus we conclude that det ùëá ‚â• 0. Suppose ùëâ is an inner product space and ùëá ‚àà ‚Ñí(ùëâ). Recall that the list of nonnegative square roots of the eigenvalues of ùëá‚àóùëá (each included as many times as its multiplicity) is called the list of singular values of ùëá (see Section 7E). 9.60 |det ùëá| = product of singular values of ùëá Suppose ùëâ is an inner product space and ùëá ‚àà ‚Ñí(ùëâ). Then |det ùëá| = ‚àödet(ùëá‚àóùëá)= product of singular values of ùëá. Proof We have |det ùëá| 2 = (det ùëá)(det ùëá) = (det(ùëá‚àó))(det ùëá) = det(ùëá‚àóùëá), where the middle equality comes from 9.56(c) and the last equality comes from 9.49(a). Taking square roots of both sides of the equation above shows that |det ùëá| = ‚àödet(ùëá‚àóùëá). Let ùë†1, ‚Ä¶, ùë†ùëõ denote the list of singular values of ùëá. Thus ùë†1 2, ‚Ä¶, ùë†ùëõ 2 is the list of eigenvalues of ùëá‚àóùëá (with appropriate repetitions), corresponding to an orthonormal basis of ùëâ consisting of eigenvectors of ùëá‚àóùëá. Hence the last bullet point of 9.42 implies that det(ùëá‚àóùëá)= ùë†1 2‚ãØùë†ùëõ 2. Thus |det ùëá| = ùë†1‚ãØùë†ùëõ, as desired. Section 9C Determinants 363 An operator ùëá on a real inner product space changes volume by a factor of the product of the singular values (by 7.111). Thus the next result follows immediately from 7.111 and 9.60. This result explains why the absolute value of a determinant appears in the change of variables formula in multivariable calculus. 9.61 ùëá changes volume by factor of |det ùëá| Suppose ùëá ‚àà ‚Ñí(ùêëùëõ)and Œ© ‚äÜ ùêë ùëõ. Then volume ùëá(Œ©) = |det ùëá|(volume Œ©). For operators on finite-dimensional complex vector spaces, we now connect the determinant to a polynomial that we have previously seen. 9.62 if ùêÖ = ùêÇ, then characteristic polynomial of ùëá equals det(ùëßùêº ‚àí ùëá) Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). Let ùúÜ1, ‚Ä¶, ùúÜùëö denote the distinct eigenvalues of ùëá, and let ùëë1, ‚Ä¶, ùëëùëö denote their multiplicities. Then det(ùëßùêº ‚àí ùëá) = (ùëß ‚àí ùúÜ1) ùëë1‚ãØ(ùëß ‚àí ùúÜùëö)ùëëùëö. Proof There exists a basis of ùëâ with respect to which ùëá has an upper-triangular matrix with each ùúÜùëò appearing on the diagonal exactly ùëëùëò times (by 8.37). With respect to this basis, ùëßùêº ‚àí ùëá has an upper-triangular matrix with ùëß ‚àí ùúÜùëò appearing on the diagonal exactly ùëëùëò times for each ùëò. Thus 9.48 gives the desired equation. Suppose ùêÖ = ùêÇ and ùëá ‚àà ‚Ñí(ùëâ). The characteristic polynomial of ùëá was defined in8.26 as the polynomial on the right side of the equation in 9.62. We did not previously define the characteristic polynomial of an operator on a finite- dimensional real vector space because such operators may have no eigenvalues, making a definition using the right side of the equation in9.62 inappropriate. We now present a new definition of the characteristic polynomial, motivated by 9.62. This new definition is valid for both real and complex vector spaces. The equation in 9.62 shows that this new definition is equivalent to our previous definition whenùêÖ = ùêÇ (8.26). 9.63 definition:characteristic polynomial Suppose ùëá ‚àà ‚Ñí(ùëâ). The polynomial defined by ùëß ‚Ü¶ det(ùëßùêº ‚àí ùëá) is called the characteristic polynomial of ùëá. The formula in 9.46 shows that the characteristic polynomial of an opera- tor ùëá ‚àà ‚Ñí(ùëâ) is a monic polynomial of degree dim ùëâ. The zeros in ùêÖ of the characteristic polynomial of ùëá are exactly the eigenvalues of ùëá (by 9.51). 364 Chapter 9 Multilinear Algebra and Determinants Previously we proved the Cayley‚ÄìHamilton theorem (8.29) in the complex case. Now we can extend that result to operators on real vector spaces. 9.64 Cayley‚ÄìHamilton theorem Suppose ùëá ‚àà ‚Ñí(ùëâ) and ùëû is the characteristic polynomial of ùëá. Then ùëû(ùëá) = 0. Proof If ùêÖ = ùêÇ, then the equation ùëû(ùëá) = 0follows from 9.62 and 8.29. Now suppose ùêÖ = ùêë. Fix a basis of ùëâ, and let ùê¥ be the matrix of ùëá with respect to this basis. Let ùëÜ be the operator on ùêÇ dim ùëâ such that the matrix of ùëÜ (with respect to the standard basis of ùêÇ dim ùëâ)is ùê¥. For all ùëß ‚àà ùêë we have ùëû(ùëß) = det(ùëßùêº ‚àí ùëá) = det(ùëßùêº ‚àí ùê¥) = det(ùëßùêº ‚àí ùëÜ). Thus ùëû is the characteristic polynomial of ùëÜ. The case ùêÖ = ùêÇ (first sentence of this proof) now implies that 0 = ùëû(ùëÜ) = ùëû(ùê¥) = ùëû(ùëá). The Cayley‚ÄìHamilton theorem (9.64) implies that the characteristic polyno- mial of an operator ùëá ‚àà ‚Ñí(ùëâ) is a polynomial multiple of the minimal polynomial of ùëá (by 5.29). Thus if the degree of the minimal polynomial of ùëá equals dim ùëâ, then the characteristic polynomial of ùëá equals the minimal polynomial of ùëá. This happens for a very large percentage of operators, including over 99.999% of 4-by-4matrices with integer entries in [‚àí100, 100](see the paragraph following 5.25). The last sentence in our next result was previously proved in the complex case (see 8.54). Now we can give a proof that works on both real and complex vector spaces. 9.65 characteristic polynomial, trace, and determinant Suppose ùëá ‚àà ‚Ñí(ùëâ). Let ùëõ = dim ùëâ. Then the characteristic polynomial of ùëá can be written as ùëß ùëõ ‚àí (tr ùëá)ùëß ùëõ ‚àí 1 + ‚ãØ + (‚àí1) ùëõ(det ùëá). Proof The constant term of a polynomial function of ùëß is the value of the poly- nomial when ùëß = 0. Thus the constant term of the characteristic polynomial of ùëá equals det(‚àíùëá), which equals (‚àí1) ùëõ det ùëá (by the third bullet point of 9.42). Fix a basis of ùëâ, and let ùê¥ be the matrix of ùëá with respect to this basis. The matrix of ùëßùêº ‚àí ùëá with respect to this basis is ùëßùêº ‚àí ùê¥. The term coming from the identity permutation {1, ‚Ä¶, ùëõ} in the formula 9.46 for det(ùëßùêº ‚àí ùê¥) is (ùëß ‚àí ùê¥1, 1)‚ãØ(ùëß ‚àí ùê¥ùëõ, ùëõ). The coefficient of ùëß ùëõ ‚àí 1 in the expression above is ‚àí(ùê¥1, 1+‚ãØ+ùê¥ùëõ, ùëõ), which equals ‚àí tr ùëá. The terms in the formula for det(ùëßùêº ‚àí ùê¥) coming from other elements of perm ùëõ contain at most ùëõ ‚àí 2factors of the form ùëß ‚àí ùê¥ùëò, ùëò and thus do not contribute to the coefficient of ùëß ùëõ ‚àí 1 in the characteristic polynomial of ùëá. Section 9C Determinants 365 The next result was proved by Jacques Hadamard (1865‚Äì1963) in 1893. In the result below, think of the columns of the ùëõ-by-ùëõ matrix ùê¥ as ele- ments of ùêÖùëõ. The norms appearing below then arise from the standard inner product on ùêÖùëõ. Recall that the notation ùëÖ‚ãÖ, ùëò in the proof below means the ùëòth column of the matrix ùëÖ (as was defined in3.44). 9.66 Hadamard‚Äôs inequality Suppose ùê¥ is an ùëõ-by-ùëõ matrix. Let ùë£1, ‚Ä¶, ùë£ùëõ denote the columns of ùê¥. Then |det ùê¥| ‚â§ ùëõ ‚àè ùëò = 1 ‚Äñùë£ùëò‚Äñ. Proof If ùê¥ is not invertible, then det ùê¥ = 0and hence the desired inequality holds in this case. Thus assume that ùê¥ is invertible. The QR factorization (7.58) tells us that there exist a unitary matrix ùëÑ and an upper-triangular matrix ùëÖ whose diagonal contains only positive numbers such that ùê¥ = ùëÑùëÖ. We have |det ùê¥| = |det ùëÑ| |det ùëÖ| = |det ùëÖ| = ùëõ ‚àè ùëò = 1 ùëÖùëò, ùëò ‚â§ ùëõ ‚àè ùëò = 1 ‚ÄñùëÖ‚ãÖ, ùëò‚Äñ = ùëõ ‚àè ùëò = 1 ‚ÄñùëÑùëÖ‚ãÖ, ùëò‚Äñ = ùëõ ‚àè ùëò = 1 ‚Äñùë£ùëò‚Äñ, where the first line comes from9.49(b), the second line comes from 9.58, the third line comes from 9.48, and the fifth line holds becauseùëÑ is an isometry. To give a geometric interpretation to Hadamard‚Äôs inequality, suppose ùêÖ = ùêë. Let ùëá ‚àà ‚Ñí(ùêëùëõ)be the operator such that ùëáùëíùëò = ùë£ùëò for each ùëò = 1, ‚Ä¶, ùëõ, where ùëí1, ‚Ä¶, ùëíùëõ is the standard basis of ùêëùëõ. Then ùëá maps the box ùëÉ(ùëí1, ‚Ä¶, ùëíùëõ) onto the parallelepiped ùëÉ(ùë£1, ‚Ä¶, ùë£ùëõ) [see7.102 and 7.105 for a review of this notation and terminology]. Because the boxùëÉ(ùëí1, ‚Ä¶, ùëíùëõ) has volume 1, this implies (by 9.61) that the parallelepiped ùëÉ(ùë£1, ‚Ä¶, ùë£ùëõ) has volume |det ùëá|, which equals |det ùê¥|. Thus Hadamard‚Äôs inequality above can be interpreted to say that among all paral- lelepipeds whose edges have lengths ‚Äñùë£1‚Äñ, ‚Ä¶, ‚Äñùë£ùëõ‚Äñ, the ones with largest volume have orthogonal edges (and thus have volume ‚àè ùëõ ùëò = 1 ‚Äñùë£ùëò‚Äñ). For a necessary and sufficient condition for Hadamard‚Äôs inequality to be an equality, see Exercise 18. 366 Chapter 9 Multilinear Algebra and Determinants The matrix in the next result is called the Vandermonde matrix. Vandermonde matrices have important applications in polynomial interpolation, the discrete Fourier transform, and other areas of mathematics. The proof of the next result is a nice illustration of the power of switching between matrices and linear maps. 9.67 determinant of Vandermonde matrix Suppose ùëõ > 1and ùõΩ1, ‚Ä¶, ùõΩùëõ ‚àà ùêÖ. Then det ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 1 ùõΩ1 ùõΩ1 2 ‚ãØ ùõΩ1 ùëõ ‚àí 1 1 ùõΩ2 ùõΩ2 2 ‚ãØ ùõΩ2 ùëõ ‚àí 1 ‚ã± 1 ùõΩùëõ ùõΩùëõ 2 ‚ãØ ùõΩùëõ ùëõ ‚àí 1 ‚éû‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü ‚é† = ‚àè 1 ‚â§ ùëó < ùëò ‚â§ ùëõ(ùõΩùëò ‚àí ùõΩùëó). Proof Let 1, ùëß, ‚Ä¶, ùëßùëõ ‚àí 1 be the standard basis of ùí´ùëõ ‚àí 1(ùêÖ) and let ùëí1, ‚Ä¶, ùëíùëõ denote the standard basis of ùêÖùëõ. Define a linear mapùëÜ‚à∂ ùí´ùëõ ‚àí 1(ùêÖ) ‚Üí ùêÖùëõ by ùëÜùëù = (ùëù(ùõΩ1), ‚Ä¶, ùëù(ùõΩùëõ)). Let ùê¥ denote the Vandermonde matrix shown in the statement of this result. Note that ùê¥ = ‚Ñ≥(ùëÜ, (1, ùëß, ‚Ä¶, ùëß ùëõ ‚àí 1), (ùëí1, ‚Ä¶, ùëíùëõ)). Let ùëá‚à∂ ùí´ùëõ ‚àí 1(ùêÖ) ‚Üí ùí´ùëõ ‚àí 1(ùêÖ) be the operator on ùí´ùëõ ‚àí 1(ùêÖ) such that ùëá1 = 1 and ùëáùëß ùëò = (ùëß ‚àí ùõΩ1)(ùëß ‚àí ùõΩ2)‚ãØ(ùëß ‚àí ùõΩùëò) for ùëò = 1, ‚Ä¶, ùëõ ‚àí 1. Let ùêµ = ‚Ñ≥(ùëá, (1, ùëß, ‚Ä¶, ùëßùëõ ‚àí 1), (1, ùëß, ‚Ä¶, ùëß ùëõ ‚àí 1)). Then ùêµ is an upper-triangular matrix all of whose diagonal entries equal 1. Thus det ùêµ = 1(by 9.48). Let ùê∂ = ‚Ñ≥(ùëÜùëá, (1, ùëß, ‚Ä¶, ùëßùëõ ‚àí 1), (ùëí1, ‚Ä¶, ùëíùëõ)). Thus ùê∂ = ùê¥ùêµ (by 3.81), which implies that det ùê¥ = (det ùê¥)(det ùêµ) = det ùê∂. The definitions ofùê∂, ùëÜ, and ùëá show that ùê∂ equals ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú ‚éù 1 0 0 ‚ãØ 0 1 ùõΩ2 ‚àí ùõΩ1 0 ‚ãØ 0 1 ùõΩ2 ‚àí ùõΩ1 (ùõΩ3 ‚àí ùõΩ1)(ùõΩ3 ‚àí ùõΩ2) ‚ãØ 0 ‚ã± 1 ùõΩ2 ‚àí ùõΩ1 (ùõΩ3 ‚àí ùõΩ1)(ùõΩ3 ‚àí ùõΩ2) ‚ãØ (ùõΩùëõ ‚àí ùõΩ1)(ùõΩùëõ ‚àí ùõΩ2)‚ãØ(ùõΩùëõ ‚àí ùõΩùëõ ‚àí 1) ‚éû‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . Now det ùê¥ = det ùê∂ = ‚àè 1 ‚â§ ùëó < ùëò ‚â§ ùëõ(ùõΩùëò ‚àí ùõΩùëó), where we have used 9.56(a) and 9.48. Section 9C Determinants 367 Exercises 9C 1 Prove or give a counterexample: ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) ‚üπ det(ùëÜ+ùëá) = det ùëÜ+det ùëá. 2 Suppose the first column of a square matrixùê¥ consists of all zeros except possibly the first entryùê¥1, 1. Let ùêµ be the matrix obtained from ùê¥ by deleting the first row and the first column ofùê¥. Show that det ùê¥ = ùê¥1, 1 det ùêµ. 3 Suppose ùëá ‚àà ‚Ñí(ùëâ) is nilpotent. Prove that det(ùêº + ùëá) = 1. 4 Suppose ùëÜ ‚àà ‚Ñí(ùëâ). Prove that ùëÜ is unitary if and only if |det ùëÜ| = ‚ÄñùëÜ‚Äñ = 1. 5 Suppose ùê¥ is a block upper-triangular matrix ùê¥ = ‚éõ‚éú‚éú‚éú ‚éù ùê¥1 ‚àó ‚ã± 0 ùê¥ùëö ‚éû‚éü‚éü‚éü ‚é† , where each ùê¥ùëò along the diagonal is a square matrix. Prove that det ùê¥ = (det ùê¥1)‚ãØ(det ùê¥ùëö). 6 Suppose ùê¥ = (ùë£1 ‚ãØ ùë£ùëõ )is an ùëõ-by-ùëõ matrix, with ùë£ùëò denoting the ùëòth column of ùê¥. Show that if (ùëö1, ‚Ä¶, ùëöùëõ) ‚àà perm ùëõ, then det (ùë£ùëö1 ‚ãØ ùë£ùëöùëõ )= (sign(ùëö1, ‚Ä¶, ùëöùëõ))det ùê¥. 7 Suppose ùëá ‚àà ‚Ñí(ùëâ) is invertible. Let ùëù denote the characteristic polynomial of ùëá and let ùëû denote the characteristic polynomial of ùëá‚àí1. Prove that ùëû(ùëß) = 1 ùëù(0) ùëß dim ùëâ ùëù( 1 ùëß ) for all nonzero ùëß ‚àà ùêÖ. 8 Suppose ùëá ‚àà ‚Ñí(ùëâ) is an operator with no eigenvalues (which implies that ùêÖ = ùêë). Prove that det ùëá > 0. 9 Suppose that ùëâ is a real vector space of even dimension, ùëá ‚àà ‚Ñí(ùëâ), and det ùëá < 0. Prove that ùëá has at least two distinct eigenvalues. 10 Suppose ùëâ is a real vector space of odd dimension and ùëá ‚àà ‚Ñí(ùëâ). Without using the minimal polynomial, prove that ùëá has an eigenvalue. This result was previously proved without using determinants or the charac- teristic polynomial‚Äîsee 5.34. 11 Prove or give a counterexample: If ùêÖ = ùêë, ùëá ‚àà ‚Ñí(ùëâ), and det ùëá > 0, then ùëá has a square root. If ùêÖ = ùêÇ, ùëá ‚àà ‚Ñí(ùëâ), and det ùëâ ‚â† 0, then ùëâ has a square root (see 8.41). 368 Chapter 9 Multilinear Algebra and Determinants 12 Suppose ùëÜ, ùëá ‚àà ‚Ñí(ùëâ) and ùëÜ is invertible. Defineùëù‚à∂ ùêÖ ‚Üí ùêÖ by ùëù(ùëß) = det(ùëßùëÜ ‚àí ùëá). Prove that ùëù is a polynomial of degree dim ùëâ and that the coefficient of ùëßdim ùëâ in this polynomial is det ùëÜ. 13 Suppose ùêÖ = ùêÇ, ùëá ‚àà ‚Ñí(ùëâ), and ùëõ = dim ùëâ > 2. Let ùúÜ1, ‚Ä¶, ùúÜùëõ denote the eigenvalues of ùëá, with each eigenvalue included as many times as its multiplicity. (a) Find a formula for the coefficient of ùëß ùëõ ‚àí 2 in the characteristic polynomial of ùëá in terms of ùúÜ1, ‚Ä¶, ùúÜùëõ. (b) Find a formula for the coefficient of ùëß in the characteristic polynomial of ùëá in terms of ùúÜ1, ‚Ä¶, ùúÜùëõ. 14 Suppose ùëâ is an inner product space and ùëá is a positive operator on ùëâ. Prove that det ‚àöùëá = ‚àödet ùëá. 15 Suppose ùëâ is an inner product space and ùëá ‚àà ‚Ñí(ùëâ). Use the polar decom- position to give a proof that |det ùëá| = ‚àödet(ùëá‚àóùëá) that is different from the proof given earlier (see 9.60). 16 Suppose ùëá ‚àà ‚Ñí(ùëâ). Defineùëî‚à∂ ùêÖ ‚Üí ùêÖ by ùëî(ùë•) = det(ùêº + ùë•ùëá). Show that ùëî‚Äô(0) =tr ùëá. Look for a clean solution to this exercise, without using the explicit but complicated formula for the determinant of a matrix. 17 Suppose ùëé, ùëè, ùëê are positive numbers. Find the volume of the ellipsoid {(ùë•, ùë¶, ùëß) ‚àà ùêë3 ‚à∂ ùë•2 ùëé2 + ùë¶2 ùëè2 + ùëß 2 ùëê2 < 1} by finding a setŒ© ‚äÜ ùêë 3 whose volume you know and an operator ùëá on ùêë3 such that ùëá(Œ©) equals the ellipsoid above. 18 Suppose that ùê¥ is an invertible square matrix. Prove that Hadamard‚Äôs inequality (9.66) is an equality if and only if each column of ùê¥ is orthogonal to the other columns. 19 Suppose ùëâ is an inner product space, ùëí1, ‚Ä¶, ùëíùëõ is an orthonormal basis of ùëâ, and ùëá ‚àà ‚Ñí(ùëâ) is a positive operator. (a) Prove that det ùëá ‚â§‚àèùëõ ùëò = 1‚ü®ùëáùëíùëò, ùëíùëò‚ü©. (b) Prove that if ùëá is invertible, then the inequality in (a) is an equality if and only if ùëíùëò is an eigenvector of ùëá for each ùëò = 1, ‚Ä¶, ùëõ. Section 9C Determinants 369 20 Suppose ùê¥ is an ùëõ-by-ùëõ matrix, and suppose ùëê is such that |ùê¥ùëó, ùëò| ‚â§ ùëêfor all ùëó, ùëò ‚àà {1, ‚Ä¶, ùëõ}. Prove that |det ùê¥| ‚â§ ùëê ùëõùëõ ùëõ/2. The formula for the determinant of a matrix (9.46) shows that |det ùê¥| ‚â§ ùëê ùëõùëõ!. However, the estimate given by this exercise is much better. For example, if ùëê = 1and ùëõ = 100, then ùëêùëõùëõ! ‚âà 10 158, but the estimate given by this exercise is the much smaller number 10 100. If ùëõ is an integer power of 2, then the inequality above is sharp and cannot be improved. 21 Suppose ùëõ is a positive integer and ùõø‚à∂ ùêÇ ùëõ, ùëõ ‚Üí ùêÇ is a function such that ùõø(ùê¥ùêµ) = ùõø(ùê¥) ‚ãÖ ùõø(ùêµ) for all ùê¥, ùêµ ‚àà ùêÇùëõ, ùëõ and ùõø(ùê¥) equals the product of the diagonal entries of ùê¥ for each diagonal matrix ùê¥ ‚àà ùêÇùëõ, ùëõ. Prove that ùõø(ùê¥) = det ùê¥ for all ùê¥ ‚àà ùêÇùëõ, ùëõ. Recall that ùêÇ ùëõ, ùëõ denotes set of ùëõ-by-ùëõ matrices with entries in ùêÇ. This exercise shows that the determinant is the unique function defined on square matrices that is multiplicative and has the desired behavior on diagonal matrices. This result is analogous to Exercise 10 in Section 8D, which shows that the trace is uniquely determined by its algebraic properties. I find that in my own elementary lectures, I have, for pedagogical reasons, pushed determinants more and more into the background. Too often I have had the expe- rience that, while the students acquired facility with the formulas, which are so useful in abbreviating long expressions, they often failed to gain familiarity with their meaning, and skill in manipulation prevented the student from going into all the details of the subject and so gaining a mastery. ‚ÄîElementary Mathematics from an Advanced Standpoint: Geometry, Felix Klein 370 Chapter 9 Multilinear Algebra and Determinants 9D Tensor Products Tensor Product of Two Vector Spaces The motivation for our next topic comes from wanting to form the product of a vector ùë£ ‚àà ùëâ and a vector ùë§ ‚àà ùëä. This product will be denoted by ùë£ ‚äó ùë§, pronounced ‚Äúùë£ tensor ùë§‚Äù, and will be an element of some new vector space called ùëâ ‚äó ùëä (also pronounced ‚Äúùëâ tensor ùëä ‚Äù). We already have a vector space ùëâ √ó ùëä (see Section 3E), called the product of ùëâ and ùëä. However, ùëâ √ó ùëä will not serve our purposes here because it does not provide a natural way to multiply an element of ùëâ by an element of ùëä. We would like our tensor product to satisfy some of the usual properties of multiplication. For example, we would like the distributive property to be satisfied, meaning that if ùë£1, ùë£2, ùë£ ‚àà ùëâ and ùë§1, ùë§2, ùë§ ‚àà ùëä, then (ùë£1 + ùë£2) ‚äó ùë§ = ùë£1 ‚äó ùë§ + ùë£2 ‚äó ùë§ and ùë£ ‚äó (ùë§1 + ùë§2) = ùë£ ‚äó ùë§1 + ùë£ ‚äó ùë§2. To produce ‚äó in TEX, type \\otimes.We would also like scalar multiplica- tion to interact well with this new multi- plication, meaning that ùúÜ(ùë£ ‚äó ùë§) = (ùúÜùë£) ‚äó ùë§ = ùë£ ‚äó (ùúÜùë§) for all ùúÜ ‚àà ùêÖ, ùë£ ‚àà ùëâ, and ùë§ ‚àà ùëä. Furthermore, it would be nice if each basis of ùëâ when combined with each basis of ùëä produced a basis of ùëâ ‚äó ùëä. Specifically, ifùëí1, ‚Ä¶, ùëíùëö is a basis of ùëâ and ùëì1, ‚Ä¶, ùëìùëõ is a basis of ùëä, then we would like a list (in any order) consisting of ùëíùëó ‚äó ùëìùëò, as ùëó ranges from 1to ùëö and ùëò ranges from 1to ùëõ, to be a basis of ùëâ‚äó ùëä. This implies that dim(ùëâ‚äó ùëä) should equal (dim ùëâ)(dim ùëä). Recall that dim(ùëâ √ó ùëä) = dim ùëâ + dim ùëä (see 3.92), which shows that the product ùëâ √ó ùëä will not serve our purposes here. To produce a vector space whose dimension is (dim ùëâ)(dim ùëä) in a natural fashion from ùëâ and ùëä, we look at the vector space of bilinear functionals, as defined below. 9.68 definition:bilinear functional on ùëâ √ó ùëä, the vector space ‚Ñ¨(ùëâ, ùëä) ‚Ä¢ A bilinear functional on ùëâ √ó ùëä is a function ùõΩ‚à∂ ùëâ √ó ùëä ‚Üí ùêÖ such that ùë£ ‚Ü¶ ùõΩ(ùë£, ùë§) is a linear functional on ùëâ for each ùë§ ‚àà ùëä and ùë§ ‚Ü¶ ùõΩ(ùë£, ùë§) is a linear functional on ùëä for each ùë£ ‚àà ùëâ. ‚Ä¢ The vector space of bilinear functionals on ùëâ √ó ùëä is denoted by ‚Ñ¨(ùëâ, ùëä). If ùëä = ùëâ, then a bilinear functional on ùëâ √ó ùëä is a bilinear form; see 9.1. The operations of addition and scalar multiplication on ‚Ñ¨(ùëâ, ùëä) are defined to be the usual operations of addition and scalar multiplication of functions. As you can verify, these operations make ‚Ñ¨(ùëâ, ùëä) into a vector space whose additive identity is the zero function from ùëâ √ó ùëä to ùêÖ. Section 9D Tensor Products 371 9.69 example:bilinear functionals ‚Ä¢ Suppose ùúë ‚àà ùëâ‚Ä≤ and ùúè ‚àà ùëä‚Ä≤. DefineùõΩ‚à∂ ùëâ √ó ùëä ‚Üí ùêÖ by ùõΩ(ùë£, ùë§) = ùúë(ùë£)ùúè(ùë§). Then ùõΩ is a bilinear functional on ùëâ √ó ùëä. ‚Ä¢ Suppose ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä. DefineùõΩ‚à∂ ùëâ‚Ä≤ √ó ùëä‚Ä≤ ‚Üí ùêÖ by ùõΩ(ùúë, ùúè) = ùúë(ùë£)ùúè(ùë§). Then ùõΩ is a bilinear functional on ùëâ‚Ä≤ √ó ùëä‚Ä≤. ‚Ä¢ DefineùõΩ‚à∂ ùëâ √ó ùëâ‚Ä≤ ‚Üí ùêÖ by ùõΩ(ùë£, ùúë) = ùúë(ùë£). Then ùõΩ is a bilinear functional on ùëâ √ó ùëâ‚Ä≤. ‚Ä¢ Suppose ùúë ‚àà ùëâ‚Ä≤. DefineùõΩ‚à∂ ùëâ √ó ‚Ñí(ùëâ) ‚Üí ùêÖ by ùõΩ(ùë£, ùëá) = ùúë(ùëáùë£). Then ùõΩ is a bilinear functional on ùëâ √ó ‚Ñí(ùëâ). ‚Ä¢ Suppose ùëö and ùëõ are positive integers. DefineùõΩ‚à∂ ùêÖùëö, ùëõ√óùêÖùëõ, ùëö ‚Üí ùêÖ by ùõΩ(ùê¥, ùêµ) = tr(ùê¥ùêµ). Then ùõΩ is a bilinear functional on ùêÖùëö, ùëõ √ó ùêÖùëõ, ùëö. 9.70 dimension of the vector space of bilinear functionals dim ‚Ñ¨(ùëâ, ùëä) = (dim ùëâ)(dim ùëä). Proof Let ùëí1, ‚Ä¶, ùëíùëö be a basis of ùëâ and ùëì1, ‚Ä¶, ùëìùëõ be a basis of ùëä. For a bilinear functional ùõΩ ‚àà ‚Ñ¨(ùëâ, ùëä), let ‚Ñ≥(ùõΩ) be the ùëö-by-ùëõ matrix whose entry in row ùëó, column ùëò is ùõΩ(ùëíùëó, ùëìùëò). The map ùõΩ ‚Ü¶ ‚Ñ≥(ùõΩ) is a linear map of ‚Ñ¨(ùëâ, ùëä) into ùêÖùëö, ùëõ. For a matrix ùê∂ ‚àà ùêÖùëö, ùëõ, define a bilinear functionalùõΩùê∂ on ùëâ √ó ùëä by ùõΩùê∂(ùëé1ùëí1 + ‚ãØ + ùëéùëöùëíùëö, ùëè1 ùëì1 + ‚ãØ + ùëèùëõ ùëìùëõ) = ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1 ùê∂ùëó, ùëòùëéùëóùëèùëò for ùëé1, ‚Ä¶, ùëéùëö, ùëè1, ‚Ä¶, ùëèùëõ ‚àà ùêÖ. The linear map ùõΩ ‚Ü¶ ‚Ñ≥(ùõΩ) from ‚Ñ¨(ùëâ, ùëä) to ùêÖùëö, ùëõ and the linear map ùê∂ ‚Ü¶ ùõΩùê∂ from ùêÖùëö, ùëõ to ‚Ñ¨(ùëâ, ùëä) are inverses of each other because ùõΩ‚Ñ≥(ùõΩ)= ùõΩ for all ùõΩ ‚àà ‚Ñ¨(ùëâ, ùëä) and ‚Ñ≥(ùõΩùê∂) = ùê∂ for all ùê∂ ‚àà ùêÖùëö, ùëõ, as you should verify. Thus both maps are isomorphisms and the two spaces that they connect have the same dimension. Hence dim ‚Ñ¨(ùëâ, ùëä) = dim ùêÖùëö, ùëõ = ùëöùëõ = (dim ùëâ)(dim ùëä). Several different definitions ofùëâ ‚äó ùëä appear in the mathematical literature. These definitions are equivalent to each other, at least in the finite-dimensional context, because any two vector spaces of the same dimension are isomorphic. The result above states that ‚Ñ¨(ùëâ, ùëä) has the dimension that we seek, as do ‚Ñí(ùëâ, ùëä) and ùêÖdim ùëâ,dim ùëä. Thus it may be tempting to defineùëâ‚äó ùëä to be ‚Ñ¨(ùëâ, ùëä) or ‚Ñí(ùëâ, ùëä) or ùêÖdim ùëâ,dim ùëä. However, none of those definitions would lead to a basis-free definition ofùë£ ‚äó ùë§ for ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä. The following definition, while it may seem a bit strange and abstract at first, has the huge advantage that it definesùë£ ‚äó ùë§ in a basis-free fashion. We define ùëâ ‚äó ùëä to be the vector space of bilinear functionals on ùëâ‚Ä≤ √ó ùëä‚Ä≤ instead of the more tempting choice of the vector space of bilinear functionals on ùëâ √ó ùëä. 372 Chapter 9 Multilinear Algebra and Determinants 9.71 definition:tensor product, ùëâ ‚äó ùëä, ùë£ ‚äó ùë§ ‚Ä¢ The tensor product ùëâ ‚äó ùëä is defined to be‚Ñ¨(ùëâ‚Ä≤, ùëä‚Ä≤). ‚Ä¢ For ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä, the tensor product ùë£ ‚äó ùë§ is the element of ùëâ ‚äó ùëä defined by (ùë£ ‚äó ùë§)(ùúë, ùúè) = ùúë(ùë£)ùúè(ùë§) for all (ùúë, ùúè) ‚àà ùëâ‚Ä≤ √ó ùëä‚Ä≤. We can quickly prove that the definition ofùëâ‚äóùëä gives it the desired dimension. 9.72 dimension of the tensor product of two vector spaces dim(ùëâ ‚äó ùëä) = (dim ùëâ)(dim ùëä). Proof Because a vector space and its dual have the same dimension (by 3.111), we have dim ùëâ‚Ä≤ = dim ùëâ and dim ùëä‚Ä≤ = dim ùëä. Thus 9.70 tells us that the dimension of ‚Ñ¨(ùëâ‚Ä≤, ùëä‚Ä≤)equals (dim ùëâ)(dim ùëä). To understand the definition of the tensor productùë£ ‚äó ùë§ of two vectors ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä, focus on the kind of object it is. An element of ùëâ ‚äó ùëä is a bilinear functional on ùëâ‚Ä≤√ó ùëä‚Ä≤, and in particular it is a function from ùëâ‚Ä≤√ó ùëä‚Ä≤ to ùêÖ. Thus for each element of ùëâ‚Ä≤ √ó ùëä‚Ä≤, it should produce an element of ùêÖ. The definition above has this behavior, because ùë£ ‚äó ùë§ applied to a typical element (ùúë, ùúè) of ùëâ‚Ä≤ √ó ùëä‚Ä≤ produces the number ùúë(ùë£)ùúè(ùë§). The somewhat abstract nature of ùë£ ‚äó ùë§ should not matter. The important point is the behavior of these objects. The next result shows that tensor products of vectors have the desired bilinearity properties. 9.73 bilinearity of tensor product Suppose ùë£, ùë£1, ùë£2 ‚àà ùëâ and ùë§, ùë§1, ùë§2 ‚àà ùëä and ùúÜ ‚àà ùêÖ. Then (ùë£1 + ùë£2) ‚äó ùë§ = ùë£1 ‚äó ùë§ + ùë£2 ‚äó ùë§ and ùë£ ‚äó (ùë§1 + ùë§2) = ùë£ ‚äó ùë§1 + ùë£ ‚äó ùë§2 and ùúÜ(ùë£ ‚äó ùë§) = (ùúÜùë£) ‚äó ùë§ = ùë£ ‚äó (ùúÜùë§). Proof Suppose (ùúë, ùúè) ‚àà ùëâ‚Ä≤ √ó ùëä‚Ä≤. Then ((ùë£1 + ùë£2) ‚äó ùë§)(ùúë, ùúè) = ùúë(ùë£1 + ùë£2)ùúè(ùë§) = ùúë(ùë£1)ùúè(ùë§) + ùúë(ùë£2)ùúè(ùë§) = (ùë£1 ‚äó ùë§)(ùúë, ùúè) + (ùë£2 ‚äó ùë§)(ùúë, ùúè) = (ùë£1 ‚äó ùë§ + ùë£2 ‚äó ùë§)(ùúë, ùúè). Thus (ùë£1 + ùë£2) ‚äó ùë§ = ùë£1 ‚äó ùë§ + ùë£2 ‚äó ùë§. The other two equalities are proved similarly. Section 9D Tensor Products 373 Lists are, by definition, ordered. The order matters when, for example, we form the matrix of an operator with respect to a basis. For lists in this section with two indices, such as {ùëíùëó ‚äó ùëìùëò}ùëó = 1, ‚Ä¶, ùëö; ùëò = 1, ‚Ä¶, ùëõ in the next result, the ordering does not matter and we do not specify it‚Äîjust choose any convenient ordering. The linear independence of elements of ùëâ ‚äó ùëä in (a) of the result below captures the idea that there are no relationships among vectors in ùëâ ‚äó ùëä other than the relationships that come from bilinearity of the tensor product (see 9.73) and the relationships that may be present due to linear dependence of a list of vectors in ùëâ or a list of vectors in ùëä. 9.74 basis of ùëâ ‚äó ùëä Suppose ùëí1, ‚Ä¶, ùëíùëö is a list of vectors in ùëâ and ùëì1, ‚Ä¶, ùëìùëõ is a list of vectors in ùëä. (a) If ùëí1, ‚Ä¶, ùëíùëö and ùëì1, ‚Ä¶, ùëìùëõ are both linearly independent lists, then {ùëíùëó ‚äó ùëìùëò}ùëó = 1, ‚Ä¶, ùëö; ùëò = 1, ‚Ä¶, ùëõ is a linearly independent list in ùëâ ‚äó ùëä. (b) If ùëí1, ‚Ä¶, ùëíùëö is a basis of ùëâ and ùëì1, ‚Ä¶, ùëìùëõ is a basis of ùëä, then the list {ùëíùëó ‚äó ùëìùëò}ùëó = 1, ‚Ä¶, ùëö; ùëò = 1, ‚Ä¶, ùëõ is a basis of ùëâ ‚äó ùëä. Proof To prove (a), suppose ùëí1, ‚Ä¶, ùëíùëö and ùëì1, ‚Ä¶, ùëìùëõ are both linearly independent lists. This linear independence and the linear map lemma (3.4) imply that there exist ùúë1, ‚Ä¶, ùúëùëö ‚àà ùëâ‚Ä≤ and ùúè1, ‚Ä¶, ùúèùëõ ‚àà ùëä‚Ä≤ such that ùúëùëó(ùëíùëò) = ‚éß{ ‚é®{‚é© 1 if ùëó = ùëò, 0 if ùëó ‚â† ùëò and ùúèùëó( ùëìùëò) = ‚éß{ ‚é®{‚é© 1 if ùëó = ùëò, 0 if ùëó ‚â† ùëò, where ùëó, ùëò ‚àà {1, ‚Ä¶, ùëö} in the first equation andùëó, ùëò ‚àà {1, ‚Ä¶, ùëõ} in the second equation. Suppose {ùëéùëó, ùëò}ùëó = 1, ‚Ä¶, ùëö; ùëò = 1, ‚Ä¶, ùëõ is a list of scalars such that 9.75 ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1 ùëéùëó, ùëò(ùëíùëó ‚äó ùëìùëò) = 0. Note that (ùëíùëó ‚äó ùëìùëò)(ùúëùëÄ, ùúèùëÅ) equals 1if ùëó = ùëÄ and ùëò = ùëÅ, and equals 0otherwise. Thus applying both sides of 9.75 to (ùúëùëÄ, ùúèùëÅ) shows that ùëéùëÄ, ùëÅ = 0, proving that {ùëíùëó ‚äó ùëìùëò}ùëó = 1, ‚Ä¶, ùëö; ùëò = 1, ‚Ä¶, ùëõ is linearly independent. Now (b) follows from (a), the equation dim ùëâ ‚äó ùëä = (dim ùëâ)(dim ùëä) [see 9.72], and the result that a linearly independent list of the right length is a basis (see 2.38). Every element of ùëâ √ó ùëä is a finite sum of elements of the formùë£ ‚äó ùë§, where ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä, as implied by (b) in the result above. However, if dim ùëâ > 1 and dim ùëä > 1, then Exercise 4 shows that {ùë£ ‚äó ùë§ ‚à∂ (ùë£, ùë§) ‚àà ùëâ √ó ùëä}‚â† ùëâ ‚äó ùëä. 374 Chapter 9 Multilinear Algebra and Determinants 9.76 example:tensor product of element of ùêÖùëö with element of ùêÖùëõ Suppose ùëö and ùëõ are positive integers. Let ùëí1, ‚Ä¶, ùëíùëö denote the standard basis of ùêÖùëö and let ùëì1, ‚Ä¶, ùëìùëõ denote the standard basis of ùêÖùëõ. Suppose ùë£ = (ùë£1, ‚Ä¶, ùë£ùëö) ‚àà ùêÖùëö and ùë§ = (ùë§1, ‚Ä¶, ùë§ùëõ) ‚àà ùêÖùëõ. Then ùë£ ‚äó ùë§ = (ùëö ‚àë ùëó = 1 ùë£ùëóùëíùëó)‚äó ( ùëõ ‚àë ùëò = 1 ùë§ùëò ùëìùëò) = ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1(ùë£ùëóùë§ùëò)(ùëíùëó ‚äó ùëìùëò). Thus with respect to the basis {ùëíùëó ‚äó ùëìùëò}ùëó = 1, ‚Ä¶, ùëö; ùëò = 1, ‚Ä¶, ùëõ of ùêÖùëö ‚äó ùêÖùëõ provided by 9.74(b), the coefficients of ùë£ ‚äó ùë§ are the numbers {ùë£ùëóùë§ùëò}ùëó = 1, ‚Ä¶, ùëö; ùëò = 1, ‚Ä¶, ùëõ. If instead of writing these numbers in a list, we write them in an ùëö-by-ùëõ matrix with ùë£ùëóùë§ùëò in row ùëó, column ùëò, then we can identify ùë£ ‚äó ùë§ with the ùëö-by-ùëõ matrix ‚éõ‚éú‚éú‚éú‚éú‚éú‚éú ‚éù ùë£1ùë§1 ‚ãØ ùë£1ùë§ùëõ ‚ã± ùë£ùëöùë§1 ‚ãØ ùë£ùëöùë§ùëõ ‚éû‚éü‚éü‚éü‚éü‚éü‚éü ‚é† . See Exercises 5 and 6 for practice in using the identification from the example above. We now define bilinear maps, which differ from bilinear functionals in that the target space can be an arbitrary vector space rather than just the scalar field. 9.77 definition:bilinear map A bilinear map from ùëâ √ó ùëä to a vector space ùëà is a function Œì‚à∂ ùëâ √ó ùëä ‚Üí ùëà such that ùë£ ‚Ü¶ Œì(ùë£, ùë§) is a linear map from ùëâ to ùëà for each ùë§ ‚àà ùëä and ùë§ ‚Ü¶ Œì(ùë£, ùë§) is a linear map from ùëä to ùëà for each ùë£ ‚àà ùëâ. 9.78 example:bilinear maps ‚Ä¢ Every bilinear functional on ùëâ √ó ùëä is a bilinear map from ùëâ √ó ùëä to ùêÖ. ‚Ä¢ The function Œì‚à∂ ùëâ√ó ùëä ‚Üí ùëâ‚äó ùëä defined byŒì(ùë£, ùë§) = ùë£ ‚äó ùë§ is a bilinear map from ùëâ √ó ùëä to ùëâ ‚äó ùëä (by 9.73). ‚Ä¢ The function Œì‚à∂ ‚Ñí(ùëâ) √ó ‚Ñí(ùëâ) ‚Üí ‚Ñí(ùëâ) defined byŒì(ùëÜ, ùëá) = ùëÜùëá is a bilinear map from ‚Ñí(ùëâ) √ó ‚Ñí(ùëâ) to ‚Ñí(ùëâ). ‚Ä¢ The function Œì‚à∂ ùëâ √ó ‚Ñí(ùëâ, ùëä) ‚Üí ùëä defined byŒì(ùë£, ùëá) = ùëáùë£ is a bilinear map from ùëâ √ó ‚Ñí(ùëâ, ùëä) to ùëä. Section 9D Tensor Products 375 Tensor products allow us to convert bilinear maps on ùëâ√ó ùëä into linear maps on ùëâ‚äó ùëä (and vice versa), as shown by the next result. In the mathematical literature, (a) of the result below is called the ‚Äúuniversal property‚Äù of tensor products. 9.79 converting bilinear maps to linear maps Suppose ùëà is a vector space. (a) Suppose Œì‚à∂ ùëâ √ó ùëä ‚Üí ùëà is a bilinear map. Then there exists a unique linear map ÃÇŒì‚à∂ ùëâ ‚äó ùëä ‚Üí ùëà such that ÃÇŒì(ùë£ ‚äó ùë§) = Œì(ùë£, ùë§) for all (ùë£, ùë§) ‚àà ùëâ √ó ùëä. (b) Conversely, suppose ùëá‚à∂ ùëâ ‚äó ùëä ‚Üí ùëà is a linear map. There there exists a unique bilinear map ùëá# ‚à∂ ùëâ √ó ùëä ‚Üí ùëà such that ùëá#(ùë£, ùë§) = ùëá(ùë£ ‚äó ùë§) for all (ùë£, ùë§) ‚àà ùëâ √ó ùëä. Proof Let ùëí1, ‚Ä¶, ùëíùëö be a basis of ùëâ and let ùëì1, ‚Ä¶, ùëìùëõ be a basis of ùëä. By the linear map lemma (3.4) and 9.74(b), there exists a unique linear map ÃÇŒì‚à∂ ùëâ ‚äó ùëä ‚Üí ùëà such that ÃÇŒì(ùëíùëó ‚äó ùëìùëò) = Œì(ùëíùëó, ùëìùëò) for all ùëó ‚àà {1, ‚Ä¶, ùëö} and ùëò ‚àà {1, ‚Ä¶, ùëõ}. Now suppose (ùë£, ùë§) ‚àà ùëâ √ó ùëä. There exist ùëé1, ‚Ä¶, ùëéùëö, ùëè1, ‚Ä¶, ùëèùëõ ‚àà ùêÖ such that ùë£ = ùëé1ùëí1 + ‚ãØ + ùëéùëöùëíùëö and ùë§ = ùëè1 ùëì1 + ‚ãØ + ùëèùëõ ùëìùëõ. Thus ÃÇŒì(ùë£ ‚äó ùë§) = ÃÇŒì( ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1(ùëéùëóùëèùëò)(ùëíùëó ‚äó ùëìùëò)) = ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1 ùëéùëóùëèùëò ÃÇŒì(ùëíùëó ‚äó ùëìùëò) = ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1 ùëéùëóùëèùëòŒì(ùëíùëó, ùëìùëò) = Œì(ùë£, ùë§), as desired, where the second line holds because ÃÇŒì is linear, the third line holds by the definition of ÃÇŒì, and the fourth line holds because Œì is bilinear. The uniqueness of the linear map ÃÇŒì satisfying ÃÇŒì(ùë£ ‚äó ùë§) = Œì(ùë£, ùë§) follows from 9.74(b), completing the proof of (a). To prove (b), define a functionùëá# ‚à∂ ùëâ√ó ùëä ‚Üí ùëà by ùëá#(ùë£, ùë§) = ùëá(ùë£ ‚äó ùë§) for all (ùë£, ùë§) ‚àà ùëâ √ó ùëä. The bilinearity of the tensor product (see 9.73) and the linearity of ùëá imply that ùëá# is bilinear. Clearly the choice of ùëá# that satisfies the conditions is unique. 376 Chapter 9 Multilinear Algebra and Determinants To prove 9.79(a), we could not just define ÃÇŒì(ùë£ ‚äó ùë§) = Œì(ùë£, ùë§) for all ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä (and then extend ÃÇŒì linearly to all of ùëâ ‚äó ùëä)because elements of ùëâ ‚äó ùëä do not have unique representations as finite sums of elements of the form ùë£ ‚äó ùë§. Our proof used a basis of ùëâ and a basis of ùëä to get around this problem. Although our construction of ÃÇŒì in the proof of 9.79(a) depended on a basis of ùëâ and a basis of ùëä, the equation ÃÇŒì(ùë£ ‚äó ùë§) = Œì(ùë£, ùë§) that holds for all ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä shows that ÃÇŒì does not depend on the choice of bases for ùëâ and ùëä. Tensor Product of Inner Product Spaces The result below features three inner products‚Äîone on ùëâ‚äó ùëä, one on ùëâ, and one on ùëä, although we use the same symbol ‚ü®‚ãÖ, ‚ãÖ‚ü©for all three inner products. 9.80 inner product on tensor product of two inner product spaces Suppose ùëâ and ùëä are inner product spaces. Then there is a unique inner product on ùëâ ‚äó ùëä such that ‚ü®ùë£ ‚äó ùë§, ùë¢ ‚äó ùë•‚ü© = ‚ü®ùë£, ùë¢‚ü©‚ü®ùë§, ùë•‚ü© for all ùë£, ùë¢ ‚àà ùëâ and ùë§, ùë• ‚àà ùëä. Proof Suppose ùëí1, ‚Ä¶, ùëíùëö is an orthonormal basis of ùëâ and ùëì1, ‚Ä¶, ùëìùëõ is an ortho- normal basis of ùëä. Define an inner product onùëâ ‚äó ùëä by 9.81 ‚ü® ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1 ùëèùëó, ùëò ùëíùëó ‚äó ùëìùëò, ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1 ùëêùëó, ùëò ùëíùëó ‚äó ùëìùëò‚ü©= ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1 ùëèùëó, ùëòùëêùëó, ùëò. The straightforward verification that9.81 defines an inner product onùëâ √ó ùëä is left to the reader [use 9.74(b)]. Suppose that ùë£, ùë¢ ‚àà ùëâ and ùë§, ùë• ‚àà ùëä. Let ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùêÖ be such that ùë£ = ùë£1ùëí1 + ‚ãØ + ùë£ùëöùëíùëö, with similar expressions for ùë¢, ùë§, and ùë•. Then ‚ü®ùë£ ‚äó ùë§, ùë¢ ‚äó ùë•‚ü© =‚ü® ùëö ‚àë ùëó = 1 ùë£ùëóùëíùëó ‚äó ùëõ ‚àë ùëò = 1 ùë§ùëò ùëìùëò, ùëö ‚àë ùëó = 1 ùë¢ùëóùëíùëó ‚äó ùëõ ‚àë ùëò = 1 ùë•ùëò ùëìùëò‚ü© = ‚ü® ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1 ùë£ùëóùë§ùëò ùëíùëó ‚äó ùëìùëò, ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1 ùë¢ùëóùë•ùëò ùëíùëó ‚äó ùëìùëò‚ü© = ùëõ ‚àë ùëò = 1 ùëö ‚àë ùëó = 1 ùë£ùëóùë¢ùëóùë§ùëòùë•ùëò = ( ùëö ‚àë ùëó = 1 ùë£ùëóùë¢ùëó)( ùëõ ‚àë ùëò = 1 ùë§ùëòùë•ùëò) = ‚ü®ùë£, ùë¢‚ü©‚ü®ùë§, ùë•‚ü©. There is only one inner product on ùëâ‚äóùëä such that ‚ü®ùë£‚äóùë§, ùë¢‚äóùë•‚ü© = ‚ü®ùë£, ùë¢‚ü©‚ü®ùë§, ùë•‚ü© for all ùë£, ùë¢ ‚àà ùëâ and ùë§, ùë• ‚àà ùëä because every element of ùëâ ‚äó ùëä can be written as a linear combination of elements of the form ùë£ ‚äó ùë§ [by 9.74(b)]. Section 9D Tensor Products 377 The definition below of a natural inner product onùëâ ‚äó ùëä is now justified by 9.80. We could not have simply defined‚ü®ùë£ ‚äó ùë§, ùë¢ ‚äó ùë•‚ü©to be ‚ü®ùë£, ùë¢‚ü©‚ü®ùë§, ùë•‚ü©(and then used additivity in each slot separately to extend the definition toùëâ ‚äó ùëä) without some proof because elements of ùëâ ‚äó ùëä do not have unique representations as finite sums of elements of the formùë£ ‚äó ùë§. 9.82 definition: inner product on tensor product of two inner product spaces Suppose ùëâ and ùëä are inner product spaces. The inner product on ùëâ ‚äó ùëä is the unique function ‚ü®‚ãÖ, ‚ãÖ‚ü©from (ùëâ ‚äó ùëä) √ó (ùëâ ‚äó ùëä) to ùêÖ such that ‚ü®ùë£ ‚äó ùë§, ùë¢ ‚äó ùë•‚ü© = ‚ü®ùë£, ùë¢‚ü©‚ü®ùë§, ùë•‚ü© for all ùë£, ùë¢ ‚àà ùëâ and ùë§, ùë• ‚àà ùëä. Take ùë¢ = ùë£ and ùë• = ùë§ in the equation above and then take square roots to show that ‚Äñùë£ ‚äó ùë§‚Äñ = ‚Äñùë£‚Äñ ‚Äñùë§‚Äñ for all ùë£ ‚àà ùëâ and all ùë§ ‚àà ùëä. The construction of the inner product in the proof of 9.80 depended on an orthonormal basis ùëí1, ‚Ä¶, ùëíùëö of ùëâ and an orthonormal basis ùëì1, ‚Ä¶, ùëìùëõ of ùëä. Formula 9.81 implies that {ùëíùëó ‚äó ùëìùëò}ùëó = 1, ‚Ä¶, ùëö; ùëò = 1, ‚Ä¶, ùëõ is a doubly indexed orthonormal list in ùëâ‚äó ùëä and hence is an orthonormal basis of ùëâ‚äó ùëä [by 9.74(b)]. The importance of the next result arises because the orthonormal bases used there can be different from the orthonormal bases used to define the inner product in9.80. Although the notation for the bases is the same in the proof of 9.80 and in the result below, think of them as two different sets of orthonormal bases. 9.83 orthonormal basis of ùëâ ‚äó ùëä Suppose ùëâ and ùëä are inner product spaces, and ùëí1, ‚Ä¶, ùëíùëö is an orthonormal basis of ùëâ and ùëì1, ‚Ä¶, ùëìùëõ is an orthonormal basis of ùëä. Then {ùëíùëó ‚äó ùëìùëò}ùëó = 1, ‚Ä¶, ùëö; ùëò = 1, ‚Ä¶, ùëõ is an orthonormal basis of ùëâ ‚äó ùëä. Proof We know that {ùëíùëó ‚äó ùëìùëò}ùëó = 1, ‚Ä¶, ùëö; ùëò = 1, ‚Ä¶, ùëõ is a basis of ùëâ ‚äó ùëä [by 9.74(b)]. Thus we only need to verify orthonormality. To do this, suppose ùëó, ùëÄ ‚àà {1, ‚Ä¶, ùëö} and ùëò, ùëÅ ‚àà {1, ‚Ä¶, ùëõ}. Then ‚ü®ùëíùëó ‚äó ùëìùëò, ùëíùëÅ ‚äó ùëìùëÄ‚ü© = ‚ü®ùëíùëó, ùëíùëÅ‚ü©‚ü® ùëìùëò, ùëìùëÄ‚ü© = ‚éß{ ‚é®{‚é© 1 if ùëó = ùëÅ and ùëò = ùëÄ, 0 otherwise. Hence the doubly indexed list {ùëíùëó ‚äó ùëìùëò}ùëó = 1, ‚Ä¶, ùëö; ùëò = 1, ‚Ä¶, ùëõ is indeed an orthonormal basis of ùëâ ‚äó ùëä. See Exercise 11 for an example of how the inner product structure on ùëâ ‚äó ùëä interacts with operators on ùëâ and ùëä. 378 Chapter 9 Multilinear Algebra and Determinants Tensor Product of Multiple Vector Spaces We have been discussing properties of the tensor product of two finite-dimensional vector spaces. Now we turn our attention to the tensor product of multiple finite- dimensional vector spaces. This generalization requires no new ideas, only some slightly more complicated notation. Readers with a good understanding of the tensor product of two vector spaces should be able to make the extension to the tensor product of more than two vector spaces. Thus in this subsection, no proofs will be provided. The definitions and the statements of results that will be provided should be enough information to enable readers to fill in the details, using what has already been learned about the tensor product of two vector spaces. We begin with the following notational assumption. 9.84 notation: ùëâ1, ‚Ä¶, ùëâùëö For the rest of this subsection, ùëö denotes an integer greater than 1and ùëâ1, ‚Ä¶, ùëâùëö denote finite-dimensional vector spaces. The notion of an ùëö-linear functional, which we are about to define, generalizes the notion of a bilinear functional (see 9.68). Recall that the use of the word ‚Äúfunctional‚Äù indicates that we are mapping into the scalar fieldùêÖ. Recall also that the terminology ‚Äúùëö-linear form‚Äù is used in the special caseùëâ1 = ‚ãØ = ùëâùëö (see 9.25). The notation ‚Ñ¨(ùëâ1, ‚Ä¶, ùëâùëö) generalizes our previous notation ‚Ñ¨(ùëâ, ùëä). 9.85 definition: ùëö-linear functional, the vector space ‚Ñ¨(ùëâ1, ‚Ä¶, ùëâùëö) ‚Ä¢ An ùëö-linear functional on ùëâ1 √ó ‚ãØ √ó ùëâùëö is a function ùõΩ‚à∂ ùëâ1 √ó ‚ãØ √ó ùëâùëö ‚Üí ùêÖ that is a linear functional in each slot when the other slots are held fixed. ‚Ä¢ The vector space of ùëö-linear functionals on ùëâ1 √ó ‚ãØ √ó ùëâùëö is denoted by ‚Ñ¨(ùëâ1, ‚Ä¶, ùëâùëö). 9.86 example:ùëö-linear functional Suppose ùúëùëò ‚àà (ùëâùëò)‚Ä≤ for each ùëò ‚àà {1, ‚Ä¶, ùëö}. DefineùõΩ‚à∂ ùëâ1 √ó ‚ãØ √ó ùëâùëö ‚Üí ùêÖ by ùõΩ(ùë£1, ‚Ä¶, ùë£ùëö) = ùúë1(ùë£1) √ó ‚ãØ √ó ùúëùëö(ùë£ùëö). Then ùõΩ is an ùëö-linear functional on ùëâ1 √ó ‚ãØ √ó ùëâùëö. The next result can be proved by imitating the proof of 9.70. 9.87 dimension of the vector space of ùëö-linear functionals dim ‚Ñ¨(ùëâ1, ‚Ä¶, ùëâùëö) = (dim ùëâ1) √ó ‚ãØ √ó (dim ùëâùëö). Section 9D Tensor Products 379 Now we can define the tensor product of multiple vector spaces and the tensor product of elements of those vector spaces. The following definition is completely analogous to our previous definition (9.71) in the case ùëö = 2. 9.88 definition: tensor product, ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö, ùë£1 ‚äó ‚ãØ ‚äó ùë£ùëö ‚Ä¢ The tensor product ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö is defined to be‚Ñ¨(ùëâ1 ‚Ä≤, ‚Ä¶, ùëâùëö ‚Ä≤). ‚Ä¢ For ùë£1 ‚àà ùëâ1, ‚Ä¶, ùë£ùëö ‚àà ùëâùëö, the tensor product ùë£1 ‚äó ‚ãØ ‚äó ùë£ùëö is the element of ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö defined by (ùë£1 ‚äó ‚ãØ ‚äó ùë£ùëö)(ùúë1, ‚Ä¶, ùúëùëö) = ùúë1(ùë£1)‚ãØùúëùëö(ùë£ùëö) for all (ùúë1 ‚Ä¶, ùúëùëö) ‚àà ùëâ1 ‚Ä≤ √ó ‚ãØ √ó ùëâùëö ‚Ä≤. The next result can be proved by following the pattern of the proof of the analogous result when ùëö = 2(see 9.72). 9.89 dimension of the tensor product dim(ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö) = (dim ùëâ1)‚ãØ(dim ùëâùëö). Our next result generalizes 9.74. 9.90 basis of ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö Suppose dim ùëâùëò = ùëõùëò and ùëí ùëò 1 , ‚Ä¶, ùëí ùëò ùëõùëò is a basis of ùëâùëò for ùëò = 1, ‚Ä¶, ùëö. Then {ùëí1 ùëó1 ‚äó ‚ãØ ‚äó ùëíùëö ùëóùëö}ùëó1 = 1, ‚Ä¶, ùëõ1; ‚ãØ; ùëóùëö = 1, ‚Ä¶, ùëõùëö is a basis of ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö. Suppose ùëö = 2and ùëí1 1, ‚Ä¶, ùëí1 ùëõ1 is a basis of ùëâ1 and ùëí2 1, ‚Ä¶, ùëí2 ùëõ2 is a basis of ùëâ2. Then with respect to the basis {ùëí1 ùëó1 ‚äó ùëí2 ùëó2}ùëó1 = 1, ‚Ä¶, ùëõ1; ùëó2 = 1, ‚Ä¶, ùëõ2 in the result above, the coefficients of an element of ùëâ1 ‚äóùëâ2 can be represented by an ùëõ1-by-ùëõ2 matrix that contains the coefficient of ùëí1 ùëó1 ‚äó ùëí2 ùëó2 in row ùëó1, column ùëó2. Thus we need a matrix, which is an array specified by two indices, to represent an element ofùëâ1 ‚äó ùëâ2. If ùëö > 2, then the result above shows that we need an array specified byùëö indices to represent an arbitrary element of ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö. Thus tensor products may appear when we deal with objects specified by arrays with multiple indices. The next definition generalizes the notion of a bilinear map (see9.77). As with bilinear maps, the target space can be an arbitrary vector space. 9.91 definition: ùëö-linear map An ùëö-linear map from ùëâ1 √ó ‚ãØ √ó ùëâùëö to a vector space ùëà is a function Œì‚à∂ ùëâ1 √ó ‚ãØ √ó ùëâùëö ‚Üí ùëà that is a linear map in each slot when the other slots are held fixed. 380 Chapter 9 Multilinear Algebra and Determinants The next result can be proved by following the pattern of the proof of 9.79. 9.92 converting ùëö-linear maps to linear maps Suppose ùëà is a vector space. (a) Suppose that Œì‚à∂ ùëâ1 √ó ‚ãØ √ó ùëâùëö ‚Üí ùëà is an ùëö-linear map. Then there exists a unique linear map ÃÇŒì‚à∂ ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö ‚Üí ùëà such that ÃÇŒì(ùë£1 ‚äó ‚ãØ ‚äó ùë£ùëö) = Œì(ùë£1, ‚Ä¶, ùë£ùëö) for all (ùë£1, ‚Ä¶, ùë£ùëö) ‚àà ùëâ1 √ó ‚ãØ √ó ùëâùëö. (b) Conversely, suppose ùëá‚à∂ ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö ‚Üí ùëà is a linear map. There there exists a unique ùëö-linear map ùëá# ‚à∂ ùëâ1 √ó ‚ãØ √ó ùëâùëö ‚Üí ùëà such that ùëá#(ùë£1, ‚Ä¶, ùë£ùëö) = ùëá(ùë£1 ‚äó ‚ãØ ‚äó ùë£ùëö) for all (ùë£1, ‚Ä¶, ùë£ùëö) ‚àà ùëâ1 √ó ‚ãØ √ó ùëâùëö. See Exercises 12 and 13 for tensor products of multiple inner product spaces. Exercises 9D 1 Suppose ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä. Prove that ùë£ ‚äó ùë§ = 0if and only if ùë£ = 0or ùë§ = 0. 2 Give an example of six distinct vectors ùë£1, ùë£2, ùë£3, ùë§1, ùë§2, ùë§3 in ùêë3 such that ùë£1 ‚äó ùë§1 + ùë£2 ‚äó ùë§2 + ùë£3 ‚äó ùë§3 = 0 but none of ùë£1 ‚äó ùë§1, ùë£2 ‚äó ùë§2, ùë£3 ‚äó ùë§3 is a scalar multiple of another element of this list. 3 Suppose that ùë£1, ‚Ä¶, ùë£ùëö is a linearly independent list in ùëâ. Suppose also that ùë§1, ‚Ä¶, ùë§ùëö is a list in ùëä such that ùë£1 ‚äó ùë§1 + ‚ãØ + ùë£ùëö ‚äó ùë§ùëö = 0. Prove that ùë§1 = ‚ãØ = ùë§ùëö = 0. 4 Suppose dim ùëâ > 1and dim ùëä > 1. Prove that {ùë£ ‚äó ùë§ ‚à∂ (ùë£, ùë§) ‚àà ùëâ √ó ùëä} is not a subspace of ùëâ ‚äó ùëä. This exercise implies that if dim ùëâ > 1and dim ùëä > 1, then {ùë£ ‚äó ùë§ ‚à∂ (ùë£, ùë§) ‚àà ùëâ √ó ùëä}‚â† ùëâ ‚äó ùëä. Section 9D Tensor Products 381 5 Suppose ùëö and ùëõ are positive integers. For ùë£ ‚àà ùêÖùëö and ùë§ ‚àà ùêÖùëõ, identify ùë£ ‚äó ùë§ with an ùëö-by-ùëõ matrix as in Example 9.76. With that identification, show that the set {ùë£ ‚äó ùë§ ‚à∂ ùë£ ‚àà ùêÖùëö and ùë§ ‚àà ùêÖùëõ} is the set of ùëö-by-ùëõ matrices (with entries in ùêÖ) that have rank at most one. 6 Suppose ùëö and ùëõ are positive integers. Give a description, analogous to Exercise 5, of the set of ùëö-by-ùëõ matrices (with entries in ùêÖ) that have rank at most two. 7 Suppose dim ùëâ > 2and dim ùëä > 2. Prove that {ùë£1 ‚äó ùë§1 + ùë£2 ‚äó ùë§2 ‚à∂ ùë£1, ùë£2 ‚àà ùëâ and ùë§1, ùë§2 ‚àà ùëä} ‚â† ùëâ ‚äó ùëä. 8 Suppose ùë£1, ‚Ä¶, ùë£ùëö ‚àà ùëâ and ùë§1, ‚Ä¶, ùë§ùëö ‚àà ùëä are such that ùë£1 ‚äó ùë§1 + ‚ãØ + ùë£ùëö ‚äó ùë§ùëö = 0. Suppose that ùëà is a vector space and Œì‚à∂ ùëâ√ó ùëä ‚Üí ùëà is a bilinear map. Show that Œì(ùë£1, ùë§1) + ‚ãØ + Œì(ùë£ùëö, ùë§ùëö) = 0. 9 Suppose ùëÜ ‚àà ‚Ñí(ùëâ) and ùëá ‚àà ‚Ñí(ùëä). Prove that there exists a unique operator on ùëâ ‚äó ùëä that takes ùë£ ‚äó ùë§ to ùëÜùë£ ‚äó ùëáùë§ for all ùë£ ‚àà ùëâ and ùë§ ‚àà ùëä. In an abuse of notation, the operator on ùëâ ‚äó ùëä given by this exercise is often called ùëÜ ‚äó ùëá. 10 Suppose ùëÜ ‚àà ‚Ñí(ùëâ) and ùëá ‚àà ‚Ñí(ùëä). Prove that ùëÜ‚äóùëá is an invertible operator on ùëâ ‚äó ùëä if and only if both ùëÜ and ùëá are invertible operators. Also, prove that if both ùëÜ and ùëá are invertible operators, then (ùëÜ ‚äó ùëá)‚àí1 = ùëÜ‚àí1 ‚äó ùëá‚àí1, where we are using the notation from the comment after Exercise 9. 11 Suppose ùëâ and ùëä are inner product spaces. Prove that if ùëÜ ‚àà ‚Ñí(ùëâ) and ùëá ‚àà ‚Ñí(ùëä), then (ùëÜ ‚äó ùëá)‚àó = ùëÜ‚àó ‚äó ùëá‚àó, where we are using the notation from the comment after Exercise 9. 12 Suppose that ùëâ1, ‚Ä¶, ùëâùëö are finite-dimensional inner product spaces. Prove that there is a unique inner product on ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö such that ‚ü®ùë£1 ‚äó ‚ãØ ‚äó ùë£ùëö, ùë¢1 ‚äó ‚ãØ ‚äó ùë¢ùëö‚ü© = ‚ü®ùë£1, ùë¢1‚ü©‚ãØ‚ü®ùë£ùëö, ùë¢ùëö‚ü© for all (ùë£1, ‚Ä¶, ùë£ùëö) and (ùë¢1, ‚Ä¶, ùë¢ùëö) in ùëâ1 √ó ‚ãØ √ó ùëâùëö. Note that the equation above implies that ‚Äñùë£1 ‚äó ‚ãØ ‚äó ùë£ùëö‚Äñ = ‚Äñùë£1‚Äñ √ó ‚ãØ √ó ‚Äñùë£ùëö‚Äñ for all (ùë£1, ‚Ä¶, ùë£ùëö) ‚àà ùëâ1 √ó ‚ãØ √ó ùëâùëö. 382 Chapter 9 Multilinear Algebra and Determinants 13 Suppose that ùëâ1, ‚Ä¶, ùëâùëö are finite-dimensional inner product spaces and ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö is made into an inner product space using the inner product from Exercise 12. Suppose ùëí ùëò 1 , ‚Ä¶, ùëí ùëò ùëõùëò is an orthonormal basis of ùëâùëò for each ùëò = 1, ‚Ä¶, ùëö. Show that the list {ùëí1 ùëó1 ‚äó ‚ãØ ‚äó ùëíùëö ùëóùëö}ùëó1 = 1, ‚Ä¶, ùëõ1; ‚ãØ; ùëóùëö = 1, ‚Ä¶, ùëõùëö is an orthonormal basis of ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö. Photo Credits ‚Ä¢ page v: Photos by Carrie Heeter and Bishnu Sarangi. Public domain image. ‚Ä¢ page 1: Original painting by Pierre Louis Dumesnil; 1884 copy by Nils Forsberg. Public domain image downloaded on 29 March 2022 from https://commons.wikimedia.org/wiki/File:Ren√©_Descartes_i_samtal_med_Sveriges_drottning,_Kristina.jpg. ‚Ä¢ page 27: Public domain image downloaded on 4 February 2022 from https://commons.wikimedia.org/wiki/File:IAS_Princeton.jpg. ‚Ä¢ page 51: Photo by Stefan Sch√§fer; Creative Commons Attribution Share Alike license. Downloaded on 28 March 2022 from https://commons.wikimedia.org/wiki/File:BurgDankwarderode2016.jpg. ‚Ä¢ page 119: Photo by Alireza Javaheri. Creative Commons Attribution license. Downloaded on 12 March 2023 from https://commons.wikimedia.org/wiki/File:Hakim_Omar_Khayam_-_panoramio.jpg. ‚Ä¢ page 132: Statue completed by Giovanni Paganucci in 1863. Photo by Hans-Peter Postel; Creative Commons Attribution license. Downloaded on 14 March 2022 from https://commons.wikimedia.org/wiki/File:Leonardo_da_Pisa.jpg. ‚Ä¢ page 181: Photo by Matthew Petroff; Creative Commons Attribution Share Alike license. Downloaded on 31 March 2022 from https://commons.wikimedia.org/wiki/File:George-peabody-library.jpg. ‚Ä¢ page 227: Photo by Petar Milo≈°eviƒá; Creative Commons Attribution Share Alike license. Downloaded on 30 March 2022 from https://en.wikipedia.org/wiki/Lviv. ‚Ä¢ page 297: Photo by David Iliff; Creative Commons Attribution Share Alike license. Downloaded on 30 March 2022 from https://en.wikipedia.org/wiki/File:Long_Room_Interior,_Trinity_College_Dublin,_Ireland_-_Diliff.jpg. ‚Ä¢ page 332: Photo by Daniel Schwen; Creative Commons Attribution Share Alike license. Downloaded on 9 July 2019 from https://commons.wikimedia.org/wiki/File:Mathematik_G√∂ttingen.jpg. 383 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0 ¬© Sheldon Axler 2024 Symbol Index ùê¥ ‚àí1, 91 ùê¥ùëó, ‚ãÖ , 74 ùê¥ùëó, ùëò, 69 ùê¥‚ãÖ, ùëò, 74 ùõºùëá, 354 ùê¥‚àó, 231 ùê¥ t, 77 ÃÇŒì, 375, 380 ùêµ, 287 ‚Ñ¨(ùëâ1, ‚Ä¶, ùëâùëö), 378 ‚Ñ¨(ùëâ, ùëä), 370 ùêÇ, 2 ‚àò, 55 deg, 31 Œî, 196 det ùê¥, 355 det ùëá, 354 dim, 44 ‚äï, 21 ùê∏(ùë†1 ùëì1, ‚Ä¶, ùë†ùëõ ùëìùëõ), 287 ùê∏(ùúÜ, ùëá), 164 ùêÖ, 4 ùêÖ‚àû, 13 ùêÖùëö, ùëõ, 72 ùêÖùëõ, 6 ùêÖùëÜ, 13 ùê∫(ùúÜ, ùëá), 308 ùêº, 52, 90 ‚ü∫ , 23 Im, 120 ‚àí‚àû, 31 ‚Ñí(ùëâ), 52 ‚Ñí(ùëâ, ùëä), 52 ‚Ñ≥(ùõΩ), 334 ‚Ñ≥(ùëá), 69, 154 ‚Ñ≥(ùë£), 88 perm, 348 ùí´(ùêÖ), 30 ùúã, 101 ùí´ùëö(ùêÖ), 31 ùëù(ùëá), 137 ùëÉùëà, 214 ùëûùõΩ, 341 , 7 ùêë, 2 Re, 120 ùëÜ ‚äó ùëá, 381 ‚ää, 299 ‚àöùëá, 253 ÃÉùëá, 102 ùëá‚Ä≤, 107 ùëá‚àó, 228 ùëá‚àí1, 82 ùëá(Œ©), 288 ùëá‚Ä†, 221 ùëáùëö, 137 ‚Äñùëá‚Äñ, 280 ùëá#, 375, 380 tr ùê¥, 326 tr ùëá, 327 ùëá|ùëà, 133 ùëá/ùëà, 142 ùëà‚üÇ, 211 ùëà0, 109 ‚ü®ùë¢, ùë£‚ü©, 184 ùëâ, 15 ùëâ‚Ä≤, 105, 204 ùëâ/ùëà, 99 ‚àíùë£, 15 ùëâ1 ‚äó ‚ãØ ‚äó ùëâùëö, 379 ùë£1 ‚äó ‚ãØ ‚äó ùë£ùëö, 379 ùëâ(2), 334 ùëâ(2) alt , 339 ùëâ(2) sym, 337 ùëâùêÇ, 17 ùëâùëö, 103, 346 ùëâ(ùëö), 346 ùëâ(ùëö) alt , 347 ùëâ ‚äó ùëä, 372 ùë£ ‚äó ùë§, 372 ùë£ + ùëà, 98 ||ùë£||, 186 ùëß, 120 |ùëß|, 120 384 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0 ¬© Sheldon Axler 2024 Index Abbott, Edwin A., 6 absolute value, 120 addition in quotient space, 100 of complex numbers, 2 of functions, 13 of linear maps, 55 of matrices, 71 of subspaces, 19 of vectors, 12 of vectors in ùêÖùëõ, 6 additive inverse in ùêÇ, 3, 4 in ùêÖùëõ, 9 in vector space, 12, 15 additivity, 52 adjoint of a linear map, 228 algebraic multiplicity, 311 alternating bilinear form, 339 alternating ùëö-linear form, 347 annihilator, 109 Apollonius‚Äôs identity, 195 Artin, Emil, 80 associativity, 3, 12, 56 backward shift, 53, 59, 84, 140 ball, 287 Banach, Stefan, 227 basis, 39 of eigenvectors, 165, 245, 246, 250 of generalized eigenvectors, 301 Bernstein polynomials, 49 Bessel‚Äôs inequality, 198 bilinear form, 333 bilinear functional, 370 bilinear map, 374 block diagonal matrix, 314 Bunyakovsky, Viktor, 189 ùê∂‚àó-algebras, 295 Carroll, Lewis, 11 Cauchy, Augustin-Louis, 189 Cauchy‚ÄìSchwarz inequality, 189 Cayley, Arthur, 312 Cayley‚ÄìHamilton theorem, 364 on complex vector space, 312 change-of-basis formula for bilinear forms, 336 for operators, 93 characteristic polynomial, 363 on complex vector space, 311 ChatGPT, 196, 279 Cholesky factorization, 267 Cholesky, Andr√©-Louis, 267 Christina, Queen of Sweden, 1 closed under addition, 18 closed under scalar multiplication, 18 column rank of a matrix, 77, 114, 239 column‚Äìrow factorization, 78 commutativity, 3, 7, 12, 25, 56, 73, 80 commuting operators, 138, 175‚Äì180, 209, 235, 248‚Äì249, 256 companion matrix, 152 complex conjugate, 120 complex number, 2 complex spectral theorem, 246 complex vector space, 13 385 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0 ¬© Sheldon Axler 2024 386 Index complexification eigenvalues of, 140 generalized eigenvectors of, 318 minimal polynomial of, 153 multiplicity of eigenvalues, 318 of a linear map, 68 of a vector space, 17, 43 of an inner product space, 194 conjugate symmetry, 183 conjugate transpose of a matrix, 231 coordinate, 6 cube root of an operator, 248 De Moivre‚Äôs theorem, 125 degree of a polynomial, 31 Descartes, Ren√©, 1 determinant of matrix, 355 of operator, 354 of positive operator, 362 of unitary operator, 362 diagonal matrix, 163, 274 diagonal of a square matrix, 155 diagonalizable, 163, 172, 176, 245, 246, 294, 307, 316 differentiation linear map, 53, 56, 59, 61, 62, 67, 70, 79, 138, 208, 304 dimension, 44 of a sum of subspaces, 47 direct sum, 21, 42, 98 of a subspace and its orthogonal complement, 212 of null ùëádim ùëâ and range ùëádim ùëâ, 299 discrete Fourier transform, 269 distributive property, 3, 12, 15, 56, 80 division algorithm for polynomials, 124 division of complex numbers, 4 dot product, 182 double dual space, 118 dual of a basis, 106 of a linear map, 107, 153, 162, 174 of a linear operator, 140 of a vector space, 105, 204 eigenspace, 164 eigenvalue of adjoint, 239 of dual of linear operator, 140 of operator, 134 of positive operator, 252 of self-adjoint operator, 233 of unitary operator, 262 on odd-dimensional space, 150, 318, 367 eigenvector, 135 ellipsoid, 287 Euclidean inner product, 184 Fibonacci, 132 Fibonacci sequence, 174 field,10 finite-dimensional vector space,30 Flatland, 6 forward shift, 140 Frankenstein, 50 Frobenius norm, 331 Fuglede‚Äôs theorem, 248 fundamental theorem of algebra, 125 fundamental theorem of linear maps, 62 Gauss, Carl Friedrich, 51 Gaussian elimination, 51, 65, 361 generalized eigenspace, 308 generalized eigenvector, 300 geometric multiplicity, 311 Gershgorin disk, 170 Index 387 Gershgorin disk theorem, 171 Gershgorin, Semyon Aronovich, 171 Gram, J√∏rgen, 200 Gram‚ÄìSchmidt procedure, 200 graph of a linear map, 103 Hadamard‚Äôs inequality, 365 Halmos, Paul, 27 Hamilton, William, 297 harmonic function, 196 Hilbert matrix, 256 Hilbert‚ÄìSchmidt norm, 331 homogeneity, 52 homogeneous system of linear equations, 65, 95 hyponormal operator, 241 identity matrix, 90 identity operator, 52, 56 imaginary part, 120 infinite-dimensional vector space,31 inhomogeneous system of linear equations, 65, 95 injective, 60 inner product, 183 inner product space, 184 Institute for Advanced Study, 27 invariant subspace, 133 inverse of a linear map, 82 of a matrix, 91 invertible linear map, 82 invertible matrix, 91 isometry, 258 isomorphic vector spaces, 86 isomorphism, 86 Jordan basis, 322 Jordan form, 324 Jordan, Camille, 324 kernel, 59 Khayyam, Omar, 119 Laplacian, 196 length of list, 5 Leonardo of Pisa, 132 linear combination, 28 linear dependence lemma, 33 linear equations, 64‚Äì65, 95 linear functional, 105, 204 linear map, 52 linear map lemma, 54 linear span, 29 linear subspace, 18 linear transformation, 52 linearly dependent, 33 linearly independent, 32 list, 5 of vectors, 28 lower-triangular matrix, 162, 267 Lviv, 227 Lw√≥w, 227 matrix, 69 multiplication, 73 of bilinear form, 334 of linear map, 69 of nilpotent operator, 305 of operator, 154 of product of linear maps, 74, 91 of ùëá‚Ä≤, 113 of ùëá‚àó, 232 of vector, 88 minimal polynomial and basis of generalized eigenvectors, 306 and characteristic polynomial, 312 and diagonalizability, 169 and generalized eigenspace decomposition, 316 and generalized eigenspaces, 317 and invertibility, 149 388 Index and upper-triangular matrices, 159, 203 computing, 145 definition of,145 gcd with its derivative, 173 no direct sum decomposition, 325 of adjoint, 241 of companion matrix, 152 of complexification,153 of dual map, 153 of nilpotent operator, 305, 324 of normal operator, 241 of quotient operator, 153 of restriction operator, 148 of self-adjoint operator, 244 polynomial multiple of, 148 zeros of, 146 minimizing distance, 217 ùëö-linear form, 346 ùëö-linear functional, 378 ùëö-linear map, 379 monic polynomial, 144 Moon, v, xvii Moore‚ÄìPenrose inverse, 221 multilinear form, 346 multiplication, see product multiplicity of an eigenvalue, 310 nilpotent operator, 303, 322 Noether, Emmy, 332 nonsingular matrix, 91 norm, 182, 186 normal operator, 235 null space, 59 of powers of an operator, 298 of ùëá‚Ä≤, 111 of ùëá‚àó, 231 one-to-one, 60 onto, 62 operator, 133 orthogonal complement, 211 projection, 214 vectors, 187 orthonormal basis, 199 list, 197 parallelogram equality, 191 Parseval‚Äôs identity, 200 partial differentiation operator, 175 Peabody Library, 181 permutation, 348 photo credits, 383 point, 12 polar decomposition, 286 polynomial, 30 positive definite,266 positive operator, 251 positive semidefinite operator,251 principal axes, 287 product of complex numbers, 2 of linear maps, 55 of matrices, 73 of polynomials, 138 of scalar and linear map, 55 of scalar and vector, 12 of scalar and vector in ùêÖùëõ, 9 of vector spaces, 96 pseudoinverse, 221, 250, 255, 275, 279 Pythagorean theorem, 187 QR factorization, 264, 365 quadratic form, 341 quotient map, 101 operator, 142, 153, 162, 173 space, 99 range, 61 Index 389 of powers of an operator, 306 of ùëá‚Ä≤, 112 of ùëá‚àó, 231 rank of a matrix, 79, 114, 239 real part, 120 real spectral theorem, 245 real vector space, 13 reverse triangle inequality, 129, 193, 294 Riesz representation theorem, 205, 210, 216, 224, 225 Riesz, Frigyes, 205 row rank of a matrix, 77, 114, 239 scalar, 4 scalar multiplication, 9, 12 in quotient space, 100 of linear maps, 55 of matrices, 71 Schmidt pair, 278 Schmidt, Erhard, 200, 278 Schur‚Äôs theorem, 204 Schur, Issai, 204 Schwarz, Hermann, 189 self-adjoint operator, 233 Shelley, Mary Wollstonecraft, 50 sign of a permutation, 349 simultaneous diagonalization, 176 simultaneously upper triangularizable, 178 singular matrix, 91 singular value decomposition of adjoint, 275 of linear map, 273 of pseudoinverse, 275 singular values, 271, 362 skew operator, 240, 247, 269 span, 29 spans, 29 spectral theorem, 245, 246 square root of an operator, 248, 251, 253, 320 standard basis of ùêÖùëõ, 39 of ùí´ùëö(ùêÖ), 39 subspace, 18 subtraction of complex numbers, 4 sum, see addition sum of subspaces, 19 Supreme Court, 210 surjective, 62 SVD, see singular value decomposition Sylvester, James, 181 symmetric bilinear form, 337 symmetric matrix, 269, 337 tensor product, 372, 379 Through the Looking Glass, 11 trace of a matrix, 326 of an operator, 327 translate, 99 transpose of a matrix, 77, 231 triangle inequality, 121, 190, 281 tuple, 5 two-sided ideal, 58 unit circle in ùêÇ, 262, 269 unitary matrix, 263 unitary operator, 260 University of Dublin, 297 University of G√∂ttingen, 332 upper-triangular matrix, 155‚Äì160, 264, 267, 314 Vandermonde matrix, 366 vector, 8, 12 vector space, 12 volume, 292, 363 of a box, 291 zero of a polynomial, 122 Colophon: Notes on Typesetting ‚Ä¢ This book was typeset in LuaLATEX by the author, who wrote the LATEX code to implement the book‚Äôs design. ‚Ä¢ The LATEX software used for this book was written by Leslie Lamport. The TEX software, which forms the base for LATEX, was written by Donald Knuth. ‚Ä¢ The main text font in this book is the Open Type Format version of TEX Gyre Termes, a font based on Times, which was designed by Stanley Morison and Victor Lardent for the British newspaper The Times in 1931. ‚Ä¢ The main math font in this book is the Open Type Format version of TEX Gyre Pagella Math, a font based on Palatino, which was designed by Hermann Zapf. ‚Ä¢ The sans serif font used for page headings and some other design elements is the Open Type Format version of TEX Gyre Heros, a font based on Helvetica, which was designed by Max Miedinger and Eduard Hoffmann. ‚Ä¢ The LuaLATEX packages fontspec and unicode-math, both written by Will Robertson, were used to manage fonts. ‚Ä¢ The LATEX package fontsize, written by Ivan Valbusa, was used to gracefully change the main fonts to 10.5 point size. ‚Ä¢ The figures in the book were produced byMathematica, using Mathematica code written by the author. Mathematica was created by Stephen Wolfram. The Mathematica package MaTeX, written by Szabolcs Horv√°t, was used to place LATEX-generated labels in the Mathematica figures. ‚Ä¢ The LATEX package graphicx, written by David Carlisle and Sebastian Rahtz, was used to include photos and figures. ‚Ä¢ The LATEX package multicol, written by Frank Mittelbach, was used to get around LATEX‚Äôs limitation that two-column format must start on a new page (needed for the Symbol Index and the Index). ‚Ä¢ The LATEX packages TikZ, written by Till Tantau, and tcolorbox, written by Thomas Sturm, were used to produce the definition boxes and result boxes. ‚Ä¢ The LATEX package color, written by David Carlisle, was used to add appropriate color to various design elements. ‚Ä¢ The LATEX package wrapfig, written by Donald Arseneau, was used to wrap text around the comment boxes. ‚Ä¢ The LATEX package microtype, written by Robert Schlicht, was used to reduce hyphenation and produce more pleasing right justification. 390 S. Axler, Linear Algebra Done Right, Undergraduate Texts in Mathematics, https://doi.org/10.1007/978-3-031-41026-0 ¬© Sheldon Axler 2024","libVersion":"0.3.2","langs":""}